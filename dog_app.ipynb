{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for a Dog Identification App \n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'(IMPLEMENTATION)'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section, and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully! \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut.  Markdown cells can be edited by double-clicking the cell to enter edit mode.\n",
    "\n",
    "The rubric contains _optional_ \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. If you decide to pursue the \"Stand Out Suggestions\", you should include the code in this IPython notebook.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### Why We're Here \n",
    "\n",
    "In this notebook, you will make the first steps towards developing an algorithm that could be used as part of a mobile or web app.  At the end of this project, your code will accept any user-supplied image as input.  If a dog is detected in the image, it will provide an estimate of the dog's breed.  If a human is detected, it will provide an estimate of the dog breed that is most resembling.  The image below displays potential sample output of your finished project (... but we expect that each student's algorithm will behave differently!). \n",
    "\n",
    "![Sample Dog Output](images/sample_dog_output.png)\n",
    "\n",
    "In this real-world setting, you will need to piece together a series of models to perform different tasks; for instance, the algorithm that detects humans in an image will be different from the CNN that infers dog breed.  There are many points of possible failure, and no perfect algorithm exists.  Your imperfect solution will nonetheless create a fun user experience!\n",
    "\n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Import Datasets\n",
    "* [Step 1](#step1): Detect Humans\n",
    "* [Step 2](#step2): Detect Dogs\n",
    "* [Step 3](#step3): Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "* [Step 4](#step4): Use a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 5](#step5): Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 6](#step6): Write your Algorithm\n",
    "* [Step 7](#step7): Test Your Algorithm\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Import Datasets\n",
    "\n",
    "### Import Dog Dataset\n",
    "\n",
    "In the code cell below, we import a dataset of dog images.  We populate a few variables through the use of the `load_files` function from the scikit-learn library:\n",
    "- `train_files`, `valid_files`, `test_files` - numpy arrays containing file paths to images\n",
    "- `train_targets`, `valid_targets`, `test_targets` - numpy arrays containing onehot-encoded classification labels \n",
    "- `dog_names` - list of string-valued dog breed names for translating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']))#, 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "# the [20:-1] portion simply removes the filepath and folder number\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6680,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Human Dataset\n",
    "\n",
    "In the code cell below, we import a dataset of human images, where the file paths are stored in the numpy array `human_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13233 total human images.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(8675309)\n",
    "\n",
    "# load filenames in shuffled human dataset\n",
    "human_files = np.array(glob(\"lfw/*/*\"))\n",
    "random.shuffle(human_files)\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total human images.' % len(human_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step1'></a>\n",
    "## Step 1: Detect Humans\n",
    "\n",
    "We use OpenCV's implementation of [Haar feature-based cascade classifiers](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html) to detect human faces in images.  OpenCV provides many pre-trained face detectors, stored as XML files on [github](https://github.com/opencv/opencv/tree/master/data/haarcascades).  We have downloaded one of these detectors and stored it in the `haarcascades` directory.\n",
    "\n",
    "In the next code cell, we demonstrate how to use this detector to find human faces in a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "# extract pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# load color (BGR) image\n",
    "img = cv2.imread(human_files[5])\n",
    "# convert BGR image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find faces in image\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "# print number of faces detected in the image\n",
    "print('Number of faces detected:', len(faces))\n",
    "\n",
    "# get bounding box for each detected face\n",
    "for (x,y,w,h) in faces:\n",
    "    # add bounding box to color image\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "# convert BGR image to RGB for plotting\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display the image, along with bounding box\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using any of the face detectors, it is standard procedure to convert the images to grayscale.  The `detectMultiScale` function executes the classifier stored in `face_cascade` and takes the grayscale image as a parameter.  \n",
    "\n",
    "In the above code, `faces` is a numpy array of detected faces, where each row corresponds to a detected face.  Each detected face is a 1D array with four entries that specifies the bounding box of the detected face.  The first two entries in the array (extracted in the above code as `x` and `y`) specify the horizontal and vertical positions of the top left corner of the bounding box.  The last two entries in the array (extracted here as `w` and `h`) specify the width and height of the box.\n",
    "\n",
    "### Write a Human Face Detector\n",
    "\n",
    "We can use this procedure to write a function that returns `True` if a human face is detected in an image and `False` otherwise.  This function, aptly named `face_detector`, takes a string-valued file path to an image as input and appears in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns \"True\" if face is detected in image stored at img_path\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Human Face Detector\n",
    "\n",
    "__Question 1:__ Use the code cell below to test the performance of the `face_detector` function.  \n",
    "- What percentage of the first 100 images in `human_files` have a detected human face?  \n",
    "- What percentage of the first 100 images in `dog_files` have a detected human face? \n",
    "\n",
    "Ideally, we would like 100% of human images with a detected face and 0% of dog images with a detected face.  You will see that our algorithm falls short of this goal, but still gives acceptable performance.  We extract the file paths for the first 100 images from each of the datasets and store them in the numpy arrays `human_files_short` and `dog_files_short`.\n",
    "\n",
    "__Answer:__ \n",
    "\n",
    "The algorithm finds human faces in 99% of the human subset and 12% of the dog subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 99 faces in the human dataset\n",
      "Found 12 faces in the dog dataset\n"
     ]
    }
   ],
   "source": [
    "human_files_short = human_files[:100]\n",
    "dog_files_short = train_files[:100]\n",
    "# Do NOT modify the code above this line.\n",
    "\n",
    "## TODO: Test the performance of the face_detector algorithm \n",
    "## on the images in human_files_short and dog_files_short.\n",
    "human_found = 0\n",
    "dogman_found = 0\n",
    "for img_path in human_files_short:\n",
    "    if face_detector(img_path):\n",
    "        human_found += 1\n",
    "\n",
    "for img_path in dog_files_short:\n",
    "    if face_detector(img_path):\n",
    "        dogman_found += 1\n",
    "        \n",
    "print(f'Found {human_found} faces in the human dataset')\n",
    "print(f'Found {dogman_found} faces in the dog dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2:__ This algorithmic choice necessitates that we communicate to the user that we accept human images only when they provide a clear view of a face (otherwise, we risk having unneccessarily frustrated users!). In your opinion, is this a reasonable expectation to pose on the user? If not, can you think of a way to detect humans in images that does not necessitate an image with a clearly presented face?\n",
    "\n",
    "__Answer:__\n",
    "\n",
    "We suggest the face detector from OpenCV as a potential way to detect human images in your algorithm, but you are free to explore other approaches, especially approaches that make use of deep learning :).  Please use the code cell below to design and test your own face detection algorithm.  If you decide to pursue this _optional_ task, report performance on each of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (Optional) TODO: Report the performance of another  \n",
    "## face detection algorithm on the LFW dataset\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Detect Dogs\n",
    "\n",
    "In this section, we use a pre-trained [ResNet-50](http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006) model to detect dogs in images.  Our first line of code downloads the ResNet-50 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).  Given an image, this pre-trained ResNet-50 model returns a prediction (derived from the available categories in ImageNet) for the object that is contained in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# define ResNet50 model\n",
    "ResNet50_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data\n",
    "\n",
    "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, \\text{rows}, \\text{columns}, \\text{channels}),\n",
    "$$\n",
    "\n",
    "where `nb_samples` corresponds to the total number of images (or samples), and `rows`, `columns`, and `channels` correspond to the number of rows, columns, and channels for each image, respectively.  \n",
    "\n",
    "The `path_to_tensor` function below takes a string-valued file path to a color image as input and returns a 4D tensor suitable for supplying to a Keras CNN.  The function first loads the image and resizes it to a square image that is $224 \\times 224$ pixels.  Next, the image is converted to an array, which is then resized to a 4D tensor.  In this case, since we are working with color images, each image has three channels.  Likewise, since we are processing a single image (or sample), the returned tensor will always have shape\n",
    "\n",
    "$$\n",
    "(1, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "The `paths_to_tensor` function takes a numpy array of string-valued image paths as input and returns a 4D tensor with shape \n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "Here, `nb_samples` is the number of samples, or number of images, in the supplied array of image paths.  It is best to think of `nb_samples` as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with ResNet-50\n",
    "\n",
    "Getting the 4D tensor ready for ResNet-50, and for any other pre-trained model in Keras, requires some additional processing.  First, the RGB image is converted to BGR by reordering the channels.  All pre-trained models have the additional normalization step that the mean pixel (expressed in RGB as $[103.939, 116.779, 123.68]$ and calculated from all pixels in all images in ImageNet) must be subtracted from every pixel in each image.  This is implemented in the imported function `preprocess_input`.  If you're curious, you can check the code for `preprocess_input` [here](https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py).\n",
    "\n",
    "Now that we have a way to format our image for supplying to ResNet-50, we are now ready to use the model to extract the predictions.  This is accomplished with the `predict` method, which returns an array whose $i$-th entry is the model's predicted probability that the image belongs to the $i$-th ImageNet category.  This is implemented in the `ResNet50_predict_labels` function below.\n",
    "\n",
    "By taking the argmax of the predicted probability vector, we obtain an integer corresponding to the model's predicted object class, which we can identify with an object category through the use of this [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    # returns prediction vector for image located at img_path\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Dog Detector\n",
    "\n",
    "While looking at the [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a), you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, to include all categories from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained ResNet-50 model, we need only check if the `ResNet50_predict_labels` function above returns a value between 151 and 268 (inclusive).\n",
    "\n",
    "We use these ideas to complete the `dog_detector` function below, which returns `True` if a dog is detected in an image (and `False` if not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Dog Detector\n",
    "\n",
    "__Question 3:__ Use the code cell below to test the performance of your `dog_detector` function.  \n",
    "- What percentage of the images in `human_files_short` have a detected dog?  \n",
    "- What percentage of the images in `dog_files_short` have a detected dog?\n",
    "\n",
    "__Answer:__ \n",
    "\n",
    "1% of the photos in the human dataset have a detected dog; 100% of the photos in the dog dataset have a detected dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 dogs in the human dataset\n",
      "Found 100 dogs in the dog dataset\n"
     ]
    }
   ],
   "source": [
    "# Following block is neccessary to utilize GPU\n",
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "### TODO: Test the performance of the dog_detector function\n",
    "### on the images in human_files_short and dog_files_short.\n",
    "dog_detected_dog_short = 0\n",
    "dog_detected_human_short = 0\n",
    "\n",
    "for img_path in human_files_short:\n",
    "    if dog_detector(img_path):\n",
    "        dog_detected_human_short += 1\n",
    "\n",
    "for img_path in dog_files_short:\n",
    "    if dog_detector(img_path):\n",
    "        dog_detected_dog_short += 1\n",
    "        \n",
    "print(f'Found {dog_detected_human_short} dogs in the human dataset')\n",
    "print(f'Found {dog_detected_dog_short} dogs in the dog dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "Now that we have functions for detecting humans and dogs in images, we need a way to predict breed from images.  In this step, you will create a CNN that classifies dog breeds.  You must create your CNN _from scratch_ (so, you can't use transfer learning _yet_ !), and you must attain a test accuracy of at least 1%.  In Step 5 of this notebook, you will have the opportunity to use transfer learning to create a CNN that attains greatly improved accuracy.\n",
    "\n",
    "Be careful with adding too many trainable layers!  More parameters means longer training, which means you are more likely to need a GPU to accelerate the training process.  Thankfully, Keras provides a handy estimate of the time that each epoch is likely to take; you can extrapolate this estimate to figure out how long it will take for your algorithm to train. \n",
    "\n",
    "We mention that the task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have great difficulty in distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n",
    "Brittany | Welsh Springer Spaniel\n",
    "- | - \n",
    "<img src=\"images/Brittany_02625.jpg\" width=\"100\"> | <img src=\"images/Welsh_springer_spaniel_08203.jpg\" width=\"200\">\n",
    "\n",
    "It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).  \n",
    "\n",
    "Curly-Coated Retriever | American Water Spaniel\n",
    "- | -\n",
    "<img src=\"images/Curly-coated_retriever_03896.jpg\" width=\"200\"> | <img src=\"images/American_water_spaniel_00648.jpg\" width=\"200\">\n",
    "\n",
    "\n",
    "Likewise, recall that labradors come in yellow, chocolate, and black.  Your vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.  \n",
    "\n",
    "Yellow Labrador | Chocolate Labrador | Black Labrador\n",
    "- | -\n",
    "<img src=\"images/Labrador_retriever_06457.jpg\" width=\"150\"> | <img src=\"images/Labrador_retriever_06455.jpg\" width=\"240\"> | <img src=\"images/Labrador_retriever_06449.jpg\" width=\"220\">\n",
    "\n",
    "We also mention that random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%.  \n",
    "\n",
    "Remember that the practice is far ahead of the theory in deep learning.  Experiment with many different architectures, and trust your intuition.  And, of course, have fun! \n",
    "\n",
    "### Pre-process the Data\n",
    "\n",
    "We rescale the images by dividing every pixel in every image by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6680/6680 [00:39<00:00, 170.99it/s]\n",
      "100%|| 835/835 [00:05<00:00, 140.88it/s]\n",
      "100%|| 836/836 [00:05<00:00, 141.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:\n",
    "    \n",
    "        model.summary()\n",
    "\n",
    "We have imported some Python modules to get you started, but feel free to import as many modules as you need.  If you end up getting stuck, here's a hint that specifies a model that trains relatively fast on CPU and attains >1% test accuracy in 5 epochs:\n",
    "\n",
    "![Sample CNN](images/sample_cnn.png)\n",
    "           \n",
    "__Question 4:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  If you chose to use the hinted architecture above, describe why you think that CNN architecture should work well for the image classification task.\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 223, 223, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 110, 110, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 54, 54, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               8645      \n",
      "=================================================================\n",
      "Total params: 19,189\n",
      "Trainable params: 19,189\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Define your architecture.\n",
    "model.add(Conv2D(16, kernel_size=2, activation='relu', input_shape=(224,224,3))) # activation nonlinearity typically performed before pooling\n",
    "model.add(MaxPooling2D()) # defaults to pool_size = (2,2), stride = None = pool_size\n",
    "model.add(Conv2D(32, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train the Model\n",
    "\n",
    "Train your model in the code cell below.  Use model checkpointing to save the model that attains the best validation loss.\n",
    "\n",
    "You are welcome to [augment the training data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), but this is not a requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10370004969066181242\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 6700198133\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2080443140667105873\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\testenv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/3\n",
      " - 8s - loss: 4.8854 - acc: 0.0081 - val_loss: 4.8697 - val_acc: 0.0108\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.86967, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/3\n",
      " - 8s - loss: 4.8573 - acc: 0.0141 - val_loss: 4.8377 - val_acc: 0.0156\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.86967 to 4.83769, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 3/3\n",
      " - 8s - loss: 4.8092 - acc: 0.0177 - val_loss: 4.8074 - val_acc: 0.0168\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.83769 to 4.80737, saving model to saved_models/weights.best.from_scratch.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2deb30c60f0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "# specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images.  Ensure that your test accuracy is greater than 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.6746%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Use a CNN to Classify Dog Breeds\n",
    "\n",
    "To reduce training time without sacrificing accuracy, we show you how to train a CNN using transfer learning.  In the following step, you will get a chance to use transfer learning to train your own CNN.\n",
    "\n",
    "### Obtain Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')\n",
    "train_VGG16 = bottleneck_features['train']\n",
    "valid_VGG16 = bottleneck_features['valid']\n",
    "test_VGG16 = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6680, 7, 7, 512)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_VGG16.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "The model uses the the pre-trained VGG-16 model as a fixed feature extractor, where the last convolutional output of VGG-16 is fed as input to our model.  We only add a global average pooling layer and a fully connected layer, where the latter contains one node for each dog category and is equipped with a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG16_model = Sequential()\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))\n",
    "VGG16_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      "6680/6680 [==============================] - ETA: 2:47 - loss: 15.3356 - acc: 0.05 - ETA: 11s - loss: 14.4584 - acc: 0.0200 - ETA: 5s - loss: 14.1699 - acc: 0.030 - ETA: 3s - loss: 13.9988 - acc: 0.03 - ETA: 2s - loss: 13.8500 - acc: 0.03 - ETA: 2s - loss: 13.6995 - acc: 0.04 - ETA: 1s - loss: 13.5964 - acc: 0.04 - ETA: 1s - loss: 13.4494 - acc: 0.05 - ETA: 1s - loss: 13.2402 - acc: 0.06 - ETA: 1s - loss: 13.0985 - acc: 0.07 - ETA: 0s - loss: 13.0102 - acc: 0.07 - ETA: 0s - loss: 12.9271 - acc: 0.08 - ETA: 0s - loss: 12.8374 - acc: 0.09 - ETA: 0s - loss: 12.7149 - acc: 0.10 - ETA: 0s - loss: 12.6553 - acc: 0.10 - ETA: 0s - loss: 12.5585 - acc: 0.10 - ETA: 0s - loss: 12.4965 - acc: 0.11 - ETA: 0s - loss: 12.4430 - acc: 0.11 - ETA: 0s - loss: 12.3927 - acc: 0.11 - 2s 243us/step - loss: 12.3550 - acc: 0.1189 - val_loss: 10.8724 - val_acc: 0.2168\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 10.87242, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 2/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 10.1963 - acc: 0.20 - ETA: 1s - loss: 11.1114 - acc: 0.20 - ETA: 0s - loss: 10.6060 - acc: 0.23 - ETA: 0s - loss: 10.4319 - acc: 0.24 - ETA: 0s - loss: 10.4082 - acc: 0.25 - ETA: 0s - loss: 10.3692 - acc: 0.26 - ETA: 0s - loss: 10.4376 - acc: 0.25 - ETA: 0s - loss: 10.4248 - acc: 0.25 - ETA: 0s - loss: 10.3669 - acc: 0.26 - ETA: 0s - loss: 10.3489 - acc: 0.26 - ETA: 0s - loss: 10.3208 - acc: 0.26 - ETA: 0s - loss: 10.3294 - acc: 0.26 - ETA: 0s - loss: 10.3084 - acc: 0.26 - ETA: 0s - loss: 10.3220 - acc: 0.26 - ETA: 0s - loss: 10.3262 - acc: 0.26 - ETA: 0s - loss: 10.2900 - acc: 0.26 - ETA: 0s - loss: 10.2589 - acc: 0.26 - ETA: 0s - loss: 10.2201 - acc: 0.27 - ETA: 0s - loss: 10.2377 - acc: 0.27 - 1s 156us/step - loss: 10.2307 - acc: 0.2725 - val_loss: 10.0891 - val_acc: 0.2611\n",
      "\n",
      "Epoch 00002: val_loss improved from 10.87242 to 10.08907, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 3/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 9.4001 - acc: 0.250 - ETA: 0s - loss: 9.6065 - acc: 0.330 - ETA: 0s - loss: 9.8751 - acc: 0.320 - ETA: 0s - loss: 9.7243 - acc: 0.321 - ETA: 0s - loss: 9.7037 - acc: 0.322 - ETA: 0s - loss: 9.6131 - acc: 0.326 - ETA: 0s - loss: 9.5671 - acc: 0.331 - ETA: 0s - loss: 9.5103 - acc: 0.336 - ETA: 0s - loss: 9.4922 - acc: 0.337 - ETA: 0s - loss: 9.4506 - acc: 0.342 - ETA: 0s - loss: 9.4615 - acc: 0.344 - ETA: 0s - loss: 9.5379 - acc: 0.340 - ETA: 0s - loss: 9.5176 - acc: 0.343 - ETA: 0s - loss: 9.5166 - acc: 0.344 - ETA: 0s - loss: 9.5220 - acc: 0.343 - ETA: 0s - loss: 9.5615 - acc: 0.341 - ETA: 0s - loss: 9.5506 - acc: 0.341 - ETA: 0s - loss: 9.5030 - acc: 0.344 - ETA: 0s - loss: 9.5025 - acc: 0.343 - 1s 156us/step - loss: 9.5306 - acc: 0.3421 - val_loss: 9.6697 - val_acc: 0.2886\n",
      "\n",
      "Epoch 00003: val_loss improved from 10.08907 to 9.66972, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 4/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 10.0616 - acc: 0.30 - ETA: 0s - loss: 9.8414 - acc: 0.3333 - ETA: 0s - loss: 9.3721 - acc: 0.366 - ETA: 0s - loss: 9.2294 - acc: 0.371 - ETA: 0s - loss: 9.0854 - acc: 0.381 - ETA: 0s - loss: 8.9751 - acc: 0.390 - ETA: 0s - loss: 8.9394 - acc: 0.394 - ETA: 0s - loss: 9.0253 - acc: 0.392 - ETA: 0s - loss: 9.1062 - acc: 0.386 - ETA: 0s - loss: 9.0549 - acc: 0.388 - ETA: 0s - loss: 9.0869 - acc: 0.386 - ETA: 0s - loss: 9.1413 - acc: 0.381 - ETA: 0s - loss: 9.1195 - acc: 0.384 - ETA: 0s - loss: 9.0997 - acc: 0.386 - ETA: 0s - loss: 9.0787 - acc: 0.387 - ETA: 0s - loss: 9.0717 - acc: 0.387 - ETA: 0s - loss: 9.0732 - acc: 0.387 - ETA: 0s - loss: 9.0533 - acc: 0.389 - ETA: 0s - loss: 9.0934 - acc: 0.386 - 1s 155us/step - loss: 9.1230 - acc: 0.3847 - val_loss: 9.4520 - val_acc: 0.3305\n",
      "\n",
      "Epoch 00004: val_loss improved from 9.66972 to 9.45199, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 5/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 9.4405 - acc: 0.400 - ETA: 1s - loss: 8.6179 - acc: 0.429 - ETA: 0s - loss: 8.7334 - acc: 0.419 - ETA: 0s - loss: 8.8230 - acc: 0.415 - ETA: 0s - loss: 8.8775 - acc: 0.411 - ETA: 0s - loss: 8.8748 - acc: 0.415 - ETA: 0s - loss: 8.8779 - acc: 0.416 - ETA: 0s - loss: 8.9215 - acc: 0.415 - ETA: 0s - loss: 8.9485 - acc: 0.409 - ETA: 0s - loss: 8.9511 - acc: 0.407 - ETA: 0s - loss: 8.9210 - acc: 0.407 - ETA: 0s - loss: 9.0333 - acc: 0.402 - ETA: 0s - loss: 9.0290 - acc: 0.402 - ETA: 0s - loss: 9.0997 - acc: 0.397 - ETA: 0s - loss: 9.0338 - acc: 0.401 - ETA: 0s - loss: 8.9708 - acc: 0.404 - ETA: 0s - loss: 8.9585 - acc: 0.404 - ETA: 0s - loss: 8.9731 - acc: 0.403 - ETA: 0s - loss: 8.9539 - acc: 0.405 - 1s 155us/step - loss: 8.9570 - acc: 0.4058 - val_loss: 9.2860 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00005: val_loss improved from 9.45199 to 9.28597, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 6/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 10.1862 - acc: 0.30 - ETA: 1s - loss: 9.2686 - acc: 0.4059 - ETA: 0s - loss: 9.1437 - acc: 0.404 - ETA: 0s - loss: 8.9789 - acc: 0.408 - ETA: 0s - loss: 8.9304 - acc: 0.414 - ETA: 0s - loss: 8.9405 - acc: 0.414 - ETA: 0s - loss: 8.9667 - acc: 0.411 - ETA: 0s - loss: 8.9587 - acc: 0.411 - ETA: 0s - loss: 8.8577 - acc: 0.418 - ETA: 0s - loss: 8.8235 - acc: 0.419 - ETA: 0s - loss: 8.8324 - acc: 0.420 - ETA: 0s - loss: 8.8065 - acc: 0.421 - ETA: 0s - loss: 8.7381 - acc: 0.426 - ETA: 0s - loss: 8.6822 - acc: 0.429 - ETA: 0s - loss: 8.7164 - acc: 0.426 - ETA: 0s - loss: 8.7089 - acc: 0.426 - ETA: 0s - loss: 8.7225 - acc: 0.423 - ETA: 0s - loss: 8.7076 - acc: 0.424 - ETA: 0s - loss: 8.7037 - acc: 0.425 - 1s 157us/step - loss: 8.6704 - acc: 0.4269 - val_loss: 9.0507 - val_acc: 0.3605\n",
      "\n",
      "Epoch 00006: val_loss improved from 9.28597 to 9.05072, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 7/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 12.9158 - acc: 0.20 - ETA: 0s - loss: 8.8243 - acc: 0.4389 - ETA: 0s - loss: 8.9975 - acc: 0.422 - ETA: 0s - loss: 8.8456 - acc: 0.433 - ETA: 0s - loss: 9.0435 - acc: 0.417 - ETA: 0s - loss: 8.9837 - acc: 0.421 - ETA: 0s - loss: 8.8833 - acc: 0.426 - ETA: 0s - loss: 8.8949 - acc: 0.425 - ETA: 0s - loss: 8.8007 - acc: 0.431 - ETA: 0s - loss: 8.6819 - acc: 0.437 - ETA: 0s - loss: 8.6161 - acc: 0.441 - ETA: 0s - loss: 8.5834 - acc: 0.443 - ETA: 0s - loss: 8.5974 - acc: 0.442 - ETA: 0s - loss: 8.5897 - acc: 0.442 - ETA: 0s - loss: 8.5817 - acc: 0.442 - ETA: 0s - loss: 8.5590 - acc: 0.443 - ETA: 0s - loss: 8.5693 - acc: 0.442 - ETA: 0s - loss: 8.5048 - acc: 0.446 - ETA: 0s - loss: 8.4757 - acc: 0.447 - ETA: 0s - loss: 8.4764 - acc: 0.446 - 1s 160us/step - loss: 8.4752 - acc: 0.4466 - val_loss: 8.8178 - val_acc: 0.3665\n",
      "\n",
      "Epoch 00007: val_loss improved from 9.05072 to 8.81775, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 8/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 8.1944 - acc: 0.450 - ETA: 1s - loss: 7.4346 - acc: 0.509 - ETA: 0s - loss: 7.9867 - acc: 0.475 - ETA: 0s - loss: 8.0895 - acc: 0.472 - ETA: 0s - loss: 8.3740 - acc: 0.455 - ETA: 0s - loss: 8.2548 - acc: 0.461 - ETA: 0s - loss: 8.3223 - acc: 0.453 - ETA: 0s - loss: 8.3038 - acc: 0.454 - ETA: 0s - loss: 8.2280 - acc: 0.460 - ETA: 0s - loss: 8.2456 - acc: 0.459 - ETA: 0s - loss: 8.2567 - acc: 0.459 - ETA: 0s - loss: 8.2810 - acc: 0.457 - ETA: 0s - loss: 8.2556 - acc: 0.459 - ETA: 0s - loss: 8.2570 - acc: 0.460 - ETA: 0s - loss: 8.2484 - acc: 0.461 - ETA: 0s - loss: 8.2670 - acc: 0.459 - ETA: 0s - loss: 8.2310 - acc: 0.460 - ETA: 0s - loss: 8.2295 - acc: 0.460 - ETA: 0s - loss: 8.2143 - acc: 0.461 - 1s 156us/step - loss: 8.1744 - acc: 0.4636 - val_loss: 8.6249 - val_acc: 0.3808\n",
      "\n",
      "Epoch 00008: val_loss improved from 8.81775 to 8.62487, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 1s - loss: 5.6513 - acc: 0.650 - ETA: 0s - loss: 7.9709 - acc: 0.491 - ETA: 0s - loss: 8.0477 - acc: 0.482 - ETA: 0s - loss: 8.1245 - acc: 0.476 - ETA: 0s - loss: 7.9843 - acc: 0.483 - ETA: 0s - loss: 7.9446 - acc: 0.486 - ETA: 0s - loss: 7.8347 - acc: 0.492 - ETA: 0s - loss: 7.9440 - acc: 0.483 - ETA: 0s - loss: 7.9887 - acc: 0.478 - ETA: 0s - loss: 7.9098 - acc: 0.482 - ETA: 0s - loss: 7.9793 - acc: 0.477 - ETA: 0s - loss: 7.8937 - acc: 0.483 - ETA: 0s - loss: 7.9101 - acc: 0.481 - ETA: 0s - loss: 7.9120 - acc: 0.481 - ETA: 0s - loss: 7.8565 - acc: 0.484 - ETA: 0s - loss: 7.8075 - acc: 0.487 - ETA: 0s - loss: 7.8503 - acc: 0.484 - ETA: 0s - loss: 7.8589 - acc: 0.484 - ETA: 0s - loss: 7.8597 - acc: 0.484 - 1s 157us/step - loss: 7.8664 - acc: 0.4837 - val_loss: 8.4136 - val_acc: 0.3856\n",
      "\n",
      "Epoch 00009: val_loss improved from 8.62487 to 8.41359, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 10/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 9.6723 - acc: 0.400 - ETA: 0s - loss: 7.3018 - acc: 0.523 - ETA: 0s - loss: 7.4812 - acc: 0.517 - ETA: 0s - loss: 7.5228 - acc: 0.519 - ETA: 0s - loss: 7.6088 - acc: 0.513 - ETA: 0s - loss: 7.6471 - acc: 0.511 - ETA: 0s - loss: 7.6368 - acc: 0.511 - ETA: 0s - loss: 7.6521 - acc: 0.509 - ETA: 0s - loss: 7.6525 - acc: 0.507 - ETA: 0s - loss: 7.6317 - acc: 0.507 - ETA: 0s - loss: 7.5710 - acc: 0.509 - ETA: 0s - loss: 7.5888 - acc: 0.508 - ETA: 0s - loss: 7.5995 - acc: 0.508 - ETA: 0s - loss: 7.6210 - acc: 0.506 - ETA: 0s - loss: 7.6370 - acc: 0.505 - ETA: 0s - loss: 7.6019 - acc: 0.507 - ETA: 0s - loss: 7.6061 - acc: 0.506 - ETA: 0s - loss: 7.5907 - acc: 0.507 - ETA: 0s - loss: 7.6000 - acc: 0.506 - ETA: 0s - loss: 7.6120 - acc: 0.505 - 1s 160us/step - loss: 7.6097 - acc: 0.5051 - val_loss: 8.2885 - val_acc: 0.3916\n",
      "\n",
      "Epoch 00010: val_loss improved from 8.41359 to 8.28853, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 11/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 6.4497 - acc: 0.600 - ETA: 0s - loss: 8.0289 - acc: 0.491 - ETA: 0s - loss: 7.7152 - acc: 0.508 - ETA: 0s - loss: 7.6544 - acc: 0.510 - ETA: 0s - loss: 7.4928 - acc: 0.515 - ETA: 0s - loss: 7.4532 - acc: 0.516 - ETA: 0s - loss: 7.4882 - acc: 0.512 - ETA: 0s - loss: 7.4729 - acc: 0.513 - ETA: 0s - loss: 7.3996 - acc: 0.518 - ETA: 0s - loss: 7.2663 - acc: 0.525 - ETA: 0s - loss: 7.3215 - acc: 0.522 - ETA: 0s - loss: 7.3784 - acc: 0.517 - ETA: 0s - loss: 7.3832 - acc: 0.518 - ETA: 0s - loss: 7.3939 - acc: 0.517 - ETA: 0s - loss: 7.4312 - acc: 0.514 - ETA: 0s - loss: 7.4336 - acc: 0.515 - ETA: 0s - loss: 7.4073 - acc: 0.516 - ETA: 0s - loss: 7.3834 - acc: 0.518 - ETA: 0s - loss: 7.3691 - acc: 0.519 - 1s 157us/step - loss: 7.4013 - acc: 0.5165 - val_loss: 8.0804 - val_acc: 0.3988\n",
      "\n",
      "Epoch 00011: val_loss improved from 8.28853 to 8.08044, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 12/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 7.2560 - acc: 0.550 - ETA: 0s - loss: 7.1290 - acc: 0.544 - ETA: 0s - loss: 7.4265 - acc: 0.518 - ETA: 0s - loss: 7.1781 - acc: 0.533 - ETA: 0s - loss: 7.3040 - acc: 0.525 - ETA: 0s - loss: 7.3570 - acc: 0.522 - ETA: 0s - loss: 7.2772 - acc: 0.526 - ETA: 0s - loss: 7.2196 - acc: 0.530 - ETA: 0s - loss: 7.2321 - acc: 0.528 - ETA: 0s - loss: 7.1983 - acc: 0.529 - ETA: 0s - loss: 7.0983 - acc: 0.536 - ETA: 0s - loss: 7.1305 - acc: 0.533 - ETA: 0s - loss: 7.1694 - acc: 0.529 - ETA: 0s - loss: 7.1726 - acc: 0.529 - ETA: 0s - loss: 7.1615 - acc: 0.529 - ETA: 0s - loss: 7.1675 - acc: 0.529 - ETA: 0s - loss: 7.1733 - acc: 0.529 - ETA: 0s - loss: 7.1729 - acc: 0.529 - ETA: 0s - loss: 7.1818 - acc: 0.528 - 1s 157us/step - loss: 7.1905 - acc: 0.5281 - val_loss: 7.9119 - val_acc: 0.4120\n",
      "\n",
      "Epoch 00012: val_loss improved from 8.08044 to 7.91187, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 13/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 7.2532 - acc: 0.550 - ETA: 1s - loss: 6.9271 - acc: 0.550 - ETA: 0s - loss: 7.5839 - acc: 0.509 - ETA: 0s - loss: 7.1957 - acc: 0.537 - ETA: 0s - loss: 7.1993 - acc: 0.539 - ETA: 0s - loss: 7.2638 - acc: 0.534 - ETA: 0s - loss: 7.0798 - acc: 0.542 - ETA: 0s - loss: 7.1577 - acc: 0.539 - ETA: 0s - loss: 7.0946 - acc: 0.544 - ETA: 0s - loss: 7.1047 - acc: 0.544 - ETA: 0s - loss: 7.0783 - acc: 0.546 - ETA: 0s - loss: 7.0513 - acc: 0.548 - ETA: 0s - loss: 7.0591 - acc: 0.546 - ETA: 0s - loss: 7.0554 - acc: 0.546 - ETA: 0s - loss: 7.0576 - acc: 0.544 - ETA: 0s - loss: 7.0337 - acc: 0.546 - ETA: 0s - loss: 7.0415 - acc: 0.545 - ETA: 0s - loss: 7.0521 - acc: 0.544 - ETA: 0s - loss: 7.0588 - acc: 0.544 - 1s 156us/step - loss: 7.0662 - acc: 0.5437 - val_loss: 7.7729 - val_acc: 0.4311\n",
      "\n",
      "Epoch 00013: val_loss improved from 7.91187 to 7.77294, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 14/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 5.0506 - acc: 0.650 - ETA: 1s - loss: 6.6223 - acc: 0.563 - ETA: 1s - loss: 6.6199 - acc: 0.572 - ETA: 0s - loss: 6.9585 - acc: 0.551 - ETA: 0s - loss: 6.8044 - acc: 0.560 - ETA: 0s - loss: 6.9619 - acc: 0.549 - ETA: 0s - loss: 6.9159 - acc: 0.548 - ETA: 0s - loss: 6.8976 - acc: 0.549 - ETA: 0s - loss: 6.9085 - acc: 0.547 - ETA: 0s - loss: 6.9380 - acc: 0.546 - ETA: 0s - loss: 6.9183 - acc: 0.547 - ETA: 0s - loss: 6.8760 - acc: 0.550 - ETA: 0s - loss: 6.9112 - acc: 0.548 - ETA: 0s - loss: 6.8866 - acc: 0.549 - ETA: 0s - loss: 6.8911 - acc: 0.549 - ETA: 0s - loss: 6.8514 - acc: 0.553 - ETA: 0s - loss: 6.8528 - acc: 0.553 - ETA: 0s - loss: 6.8851 - acc: 0.551 - ETA: 0s - loss: 6.8953 - acc: 0.550 - 1s 158us/step - loss: 6.8995 - acc: 0.5497 - val_loss: 7.4960 - val_acc: 0.4479\n",
      "\n",
      "Epoch 00014: val_loss improved from 7.77294 to 7.49600, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 15/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 8.4712 - acc: 0.350 - ETA: 1s - loss: 6.1404 - acc: 0.591 - ETA: 0s - loss: 6.1178 - acc: 0.597 - ETA: 0s - loss: 6.4861 - acc: 0.575 - ETA: 0s - loss: 6.5376 - acc: 0.570 - ETA: 0s - loss: 6.6710 - acc: 0.563 - ETA: 0s - loss: 6.6321 - acc: 0.565 - ETA: 0s - loss: 6.7580 - acc: 0.558 - ETA: 0s - loss: 6.6766 - acc: 0.563 - ETA: 0s - loss: 6.7281 - acc: 0.561 - ETA: 0s - loss: 6.6971 - acc: 0.563 - ETA: 0s - loss: 6.6887 - acc: 0.563 - ETA: 0s - loss: 6.6519 - acc: 0.566 - ETA: 0s - loss: 6.5964 - acc: 0.568 - ETA: 0s - loss: 6.6052 - acc: 0.566 - ETA: 0s - loss: 6.6494 - acc: 0.564 - ETA: 0s - loss: 6.6119 - acc: 0.566 - ETA: 0s - loss: 6.6370 - acc: 0.564 - ETA: 0s - loss: 6.6448 - acc: 0.565 - 1s 156us/step - loss: 6.6489 - acc: 0.5648 - val_loss: 7.3729 - val_acc: 0.4503\n",
      "\n",
      "Epoch 00015: val_loss improved from 7.49600 to 7.37286, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 16/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 6.4480 - acc: 0.600 - ETA: 1s - loss: 6.0934 - acc: 0.617 - ETA: 0s - loss: 6.0336 - acc: 0.614 - ETA: 0s - loss: 6.0572 - acc: 0.615 - ETA: 0s - loss: 6.4524 - acc: 0.589 - ETA: 0s - loss: 6.5020 - acc: 0.585 - ETA: 0s - loss: 6.5593 - acc: 0.580 - ETA: 0s - loss: 6.6100 - acc: 0.577 - ETA: 0s - loss: 6.5300 - acc: 0.583 - ETA: 0s - loss: 6.6329 - acc: 0.576 - ETA: 0s - loss: 6.5959 - acc: 0.577 - ETA: 0s - loss: 6.5709 - acc: 0.579 - ETA: 0s - loss: 6.5768 - acc: 0.578 - ETA: 0s - loss: 6.5759 - acc: 0.577 - ETA: 0s - loss: 6.5198 - acc: 0.581 - ETA: 0s - loss: 6.5302 - acc: 0.580 - ETA: 0s - loss: 6.4958 - acc: 0.581 - ETA: 0s - loss: 6.4910 - acc: 0.581 - ETA: 0s - loss: 6.4703 - acc: 0.582 - 1s 158us/step - loss: 6.4717 - acc: 0.5819 - val_loss: 7.2344 - val_acc: 0.4719\n",
      "\n",
      "Epoch 00016: val_loss improved from 7.37286 to 7.23436, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - ETA: 0s - loss: 5.6466 - acc: 0.650 - ETA: 1s - loss: 7.1217 - acc: 0.552 - ETA: 0s - loss: 6.7761 - acc: 0.567 - ETA: 0s - loss: 6.7224 - acc: 0.570 - ETA: 0s - loss: 6.7990 - acc: 0.565 - ETA: 0s - loss: 6.5863 - acc: 0.576 - ETA: 0s - loss: 6.5318 - acc: 0.580 - ETA: 0s - loss: 6.4623 - acc: 0.585 - ETA: 0s - loss: 6.4768 - acc: 0.584 - ETA: 0s - loss: 6.4489 - acc: 0.586 - ETA: 0s - loss: 6.3794 - acc: 0.589 - ETA: 0s - loss: 6.3990 - acc: 0.589 - ETA: 0s - loss: 6.3739 - acc: 0.591 - ETA: 0s - loss: 6.3169 - acc: 0.594 - ETA: 0s - loss: 6.3454 - acc: 0.592 - ETA: 0s - loss: 6.2860 - acc: 0.595 - ETA: 0s - loss: 6.2932 - acc: 0.595 - ETA: 0s - loss: 6.3056 - acc: 0.595 - ETA: 0s - loss: 6.3482 - acc: 0.592 - 1s 155us/step - loss: 6.3780 - acc: 0.5915 - val_loss: 7.2336 - val_acc: 0.4635\n",
      "\n",
      "Epoch 00017: val_loss improved from 7.23436 to 7.23359, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 18/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 4.8493 - acc: 0.700 - ETA: 0s - loss: 6.5382 - acc: 0.578 - ETA: 0s - loss: 6.2985 - acc: 0.595 - ETA: 0s - loss: 6.4208 - acc: 0.589 - ETA: 0s - loss: 6.4311 - acc: 0.590 - ETA: 0s - loss: 6.2490 - acc: 0.601 - ETA: 0s - loss: 6.4214 - acc: 0.589 - ETA: 0s - loss: 6.4351 - acc: 0.588 - ETA: 0s - loss: 6.4140 - acc: 0.589 - ETA: 0s - loss: 6.3130 - acc: 0.594 - ETA: 0s - loss: 6.3054 - acc: 0.594 - ETA: 0s - loss: 6.2922 - acc: 0.595 - ETA: 0s - loss: 6.2937 - acc: 0.595 - ETA: 0s - loss: 6.3020 - acc: 0.595 - ETA: 0s - loss: 6.3391 - acc: 0.592 - ETA: 0s - loss: 6.3392 - acc: 0.592 - ETA: 0s - loss: 6.3804 - acc: 0.589 - ETA: 0s - loss: 6.3625 - acc: 0.590 - ETA: 0s - loss: 6.3497 - acc: 0.591 - ETA: 0s - loss: 6.3207 - acc: 0.593 - ETA: 0s - loss: 6.2836 - acc: 0.596 - 1s 168us/step - loss: 6.2768 - acc: 0.5967 - val_loss: 7.1646 - val_acc: 0.4599\n",
      "\n",
      "Epoch 00018: val_loss improved from 7.23359 to 7.16463, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 19/20\n",
      "6680/6680 [==============================] - ETA: 0s - loss: 5.6443 - acc: 0.650 - ETA: 1s - loss: 5.7150 - acc: 0.635 - ETA: 0s - loss: 6.3412 - acc: 0.591 - ETA: 0s - loss: 6.3023 - acc: 0.593 - ETA: 0s - loss: 6.4629 - acc: 0.583 - ETA: 0s - loss: 6.3754 - acc: 0.590 - ETA: 0s - loss: 6.3505 - acc: 0.592 - ETA: 0s - loss: 6.2711 - acc: 0.597 - ETA: 0s - loss: 6.2554 - acc: 0.597 - ETA: 0s - loss: 6.2401 - acc: 0.596 - ETA: 0s - loss: 6.2635 - acc: 0.595 - ETA: 0s - loss: 6.2448 - acc: 0.596 - ETA: 0s - loss: 6.2753 - acc: 0.594 - ETA: 0s - loss: 6.2039 - acc: 0.598 - ETA: 0s - loss: 6.1929 - acc: 0.598 - ETA: 0s - loss: 6.1425 - acc: 0.602 - ETA: 0s - loss: 6.1307 - acc: 0.601 - ETA: 0s - loss: 6.1610 - acc: 0.600 - ETA: 0s - loss: 6.1446 - acc: 0.601 - 1s 154us/step - loss: 6.1178 - acc: 0.6030 - val_loss: 6.8840 - val_acc: 0.4874\n",
      "\n",
      "Epoch 00019: val_loss improved from 7.16463 to 6.88404, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "Epoch 20/20\n",
      "6680/6680 [==============================] - ETA: 1s - loss: 8.0749 - acc: 0.500 - ETA: 1s - loss: 5.9281 - acc: 0.608 - ETA: 0s - loss: 6.3101 - acc: 0.584 - ETA: 0s - loss: 6.1705 - acc: 0.596 - ETA: 0s - loss: 6.1568 - acc: 0.599 - ETA: 0s - loss: 6.0260 - acc: 0.606 - ETA: 0s - loss: 5.9641 - acc: 0.612 - ETA: 0s - loss: 5.9577 - acc: 0.612 - ETA: 0s - loss: 5.9898 - acc: 0.610 - ETA: 0s - loss: 5.9993 - acc: 0.609 - ETA: 0s - loss: 5.9510 - acc: 0.612 - ETA: 0s - loss: 5.9477 - acc: 0.612 - ETA: 0s - loss: 5.9440 - acc: 0.612 - ETA: 0s - loss: 5.9183 - acc: 0.614 - ETA: 0s - loss: 5.9276 - acc: 0.615 - ETA: 0s - loss: 5.9584 - acc: 0.612 - ETA: 0s - loss: 5.9691 - acc: 0.611 - ETA: 0s - loss: 5.9595 - acc: 0.612 - ETA: 0s - loss: 5.9698 - acc: 0.612 - 1s 157us/step - loss: 5.9767 - acc: 0.6123 - val_loss: 6.9569 - val_acc: 0.4587\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 6.88404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2dedcf93278>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG16.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(train_VGG16, train_targets, \n",
    "          validation_data=(valid_VGG16, valid_targets),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16_model.load_weights('saved_models/weights.best.VGG16.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "Now, we can use the CNN to test how well it identifies breed within our test dataset of dog images.  We print the test accuracy below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 48.4450%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Dog Breed with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_bottleneck_features import *\n",
    "\n",
    "def VGG16_predict_breed(img_path):\n",
    "    # extract bottleneck features\n",
    "    bottleneck_feature = extract_VGG16(path_to_tensor(img_path))\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = VGG16_model.predict(bottleneck_feature)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.\n",
    "\n",
    "In Step 4, we used transfer learning to create a CNN using VGG-16 bottleneck features.  In this section, you must use the bottleneck features from a different pre-trained model.  To make things easier for you, we have pre-computed the features for all of the networks that are currently available in Keras:\n",
    "- [VGG-19](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogVGG19Data.npz) bottleneck features\n",
    "- [ResNet-50](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz) bottleneck features\n",
    "- [Inception](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogInceptionV3Data.npz) bottleneck features\n",
    "- [Xception](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogXceptionData.npz) bottleneck features\n",
    "\n",
    "The files are encoded as such:\n",
    "\n",
    "    Dog{network}Data.npz\n",
    "    \n",
    "where `{network}`, in the above filename, can be one of `VGG19`, `Resnet50`, `InceptionV3`, or `Xception`.  Pick one of the above architectures, download the corresponding bottleneck features, and store the downloaded file in the `bottleneck_features/` folder in the repository.\n",
    "\n",
    "### (IMPLEMENTATION) Obtain Bottleneck Features\n",
    "\n",
    "In the code block below, extract the bottleneck features corresponding to the train, test, and validation sets by running the following:\n",
    "\n",
    "    bottleneck_features = np.load('bottleneck_features/Dog{network}Data.npz')\n",
    "    train_{network} = bottleneck_features['train']\n",
    "    valid_{network} = bottleneck_features['valid']\n",
    "    test_{network} = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing network: VGG19\n",
      "\tgetting bottleneck features...\n",
      "\tcompiling custom output nodes...\n",
      "\ttraining model...\n",
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 11.5839 - acc: 0.1473 - val_loss: 9.8418 - val_acc: 0.2515\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 9.84184, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 2/20\n",
      " - 1s - loss: 8.8813 - acc: 0.3310 - val_loss: 8.8034 - val_acc: 0.3341\n",
      "\n",
      "Epoch 00002: val_loss improved from 9.84184 to 8.80335, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 3/20\n",
      " - 1s - loss: 8.1341 - acc: 0.4133 - val_loss: 8.4515 - val_acc: 0.3868\n",
      "\n",
      "Epoch 00003: val_loss improved from 8.80335 to 8.45153, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 4/20\n",
      " - 1s - loss: 7.8852 - acc: 0.4545 - val_loss: 8.2301 - val_acc: 0.4060\n",
      "\n",
      "Epoch 00004: val_loss improved from 8.45153 to 8.23007, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 5/20\n",
      " - 1s - loss: 7.4923 - acc: 0.4820 - val_loss: 7.7915 - val_acc: 0.4192\n",
      "\n",
      "Epoch 00005: val_loss improved from 8.23007 to 7.79150, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 6/20\n",
      " - 1s - loss: 7.0635 - acc: 0.5142 - val_loss: 7.5412 - val_acc: 0.4455\n",
      "\n",
      "Epoch 00006: val_loss improved from 7.79150 to 7.54124, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 7/20\n",
      " - 1s - loss: 6.8431 - acc: 0.5410 - val_loss: 7.4953 - val_acc: 0.4503\n",
      "\n",
      "Epoch 00007: val_loss improved from 7.54124 to 7.49529, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 8/20\n",
      " - 1s - loss: 6.6417 - acc: 0.5581 - val_loss: 7.3462 - val_acc: 0.4647\n",
      "\n",
      "Epoch 00008: val_loss improved from 7.49529 to 7.34620, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 9/20\n",
      " - 1s - loss: 6.5801 - acc: 0.5731 - val_loss: 7.3342 - val_acc: 0.4731\n",
      "\n",
      "Epoch 00009: val_loss improved from 7.34620 to 7.33423, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 10/20\n",
      " - 1s - loss: 6.5593 - acc: 0.5762 - val_loss: 7.3509 - val_acc: 0.4647\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 7.33423\n",
      "Epoch 11/20\n",
      " - 1s - loss: 6.5364 - acc: 0.5841 - val_loss: 7.3994 - val_acc: 0.4731\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 7.33423\n",
      "Epoch 12/20\n",
      " - 1s - loss: 6.4840 - acc: 0.5843 - val_loss: 7.3040 - val_acc: 0.4731\n",
      "\n",
      "Epoch 00012: val_loss improved from 7.33423 to 7.30396, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 13/20\n",
      " - 1s - loss: 6.4126 - acc: 0.5930 - val_loss: 7.2123 - val_acc: 0.4838\n",
      "\n",
      "Epoch 00013: val_loss improved from 7.30396 to 7.21234, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 14/20\n",
      " - 1s - loss: 6.3671 - acc: 0.5951 - val_loss: 7.2335 - val_acc: 0.4671\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 7.21234\n",
      "Epoch 15/20\n",
      " - 1s - loss: 6.1630 - acc: 0.5978 - val_loss: 7.0376 - val_acc: 0.4826\n",
      "\n",
      "Epoch 00015: val_loss improved from 7.21234 to 7.03765, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 16/20\n",
      " - 1s - loss: 6.0448 - acc: 0.6111 - val_loss: 7.0377 - val_acc: 0.4934\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 7.03765\n",
      "Epoch 17/20\n",
      " - 1s - loss: 5.9515 - acc: 0.6138 - val_loss: 6.8426 - val_acc: 0.4934\n",
      "\n",
      "Epoch 00017: val_loss improved from 7.03765 to 6.84261, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 18/20\n",
      " - 1s - loss: 5.6993 - acc: 0.6254 - val_loss: 6.5812 - val_acc: 0.5222\n",
      "\n",
      "Epoch 00018: val_loss improved from 6.84261 to 6.58118, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 19/20\n",
      " - 1s - loss: 5.4674 - acc: 0.6422 - val_loss: 6.4593 - val_acc: 0.5126\n",
      "\n",
      "Epoch 00019: val_loss improved from 6.58118 to 6.45931, saving model to saved_models/weights.best.VGG19.hdf5\n",
      "Epoch 20/20\n",
      " - 1s - loss: 5.3652 - acc: 0.6533 - val_loss: 6.4645 - val_acc: 0.5234\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 6.45931\n",
      "\tloading best model...\n",
      "\ttesting model...\n",
      "VGG19 Test accuracy: 52.5120\n",
      "testing network: ResNet50\n",
      "\tgetting bottleneck features...\n",
      "\tcompiling custom output nodes...\n",
      "\ttraining model...\n",
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      " - 2s - loss: 1.6313 - acc: 0.6016 - val_loss: 0.8638 - val_acc: 0.7377\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.86384, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 2/20\n",
      " - 1s - loss: 0.4452 - acc: 0.8638 - val_loss: 0.6999 - val_acc: 0.7964\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.86384 to 0.69986, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 3/20\n",
      " - 1s - loss: 0.2629 - acc: 0.9201 - val_loss: 0.7041 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.69986\n",
      "Epoch 4/20\n",
      " - 1s - loss: 0.1758 - acc: 0.9433 - val_loss: 0.6817 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69986 to 0.68175, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 5/20\n",
      " - 1s - loss: 0.1210 - acc: 0.9615 - val_loss: 0.6697 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.68175 to 0.66969, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 6/20\n",
      " - 1s - loss: 0.0839 - acc: 0.9747 - val_loss: 0.7349 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.66969\n",
      "Epoch 7/20\n",
      " - 1s - loss: 0.0628 - acc: 0.9808 - val_loss: 0.6931 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.66969\n",
      "Epoch 8/20\n",
      " - 1s - loss: 0.0471 - acc: 0.9858 - val_loss: 0.7258 - val_acc: 0.8096\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.66969\n",
      "Epoch 9/20\n",
      " - 1s - loss: 0.0360 - acc: 0.9906 - val_loss: 0.7248 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.66969\n",
      "Epoch 10/20\n",
      " - 1s - loss: 0.0250 - acc: 0.9930 - val_loss: 0.7319 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.66969\n",
      "Epoch 11/20\n",
      " - 1s - loss: 0.0229 - acc: 0.9930 - val_loss: 0.8004 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.66969\n",
      "Epoch 12/20\n",
      " - 1s - loss: 0.0171 - acc: 0.9948 - val_loss: 0.7220 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.66969\n",
      "Epoch 13/20\n",
      " - 1s - loss: 0.0131 - acc: 0.9964 - val_loss: 0.8319 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.66969\n",
      "Epoch 14/20\n",
      " - 1s - loss: 0.0116 - acc: 0.9970 - val_loss: 0.8489 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.66969\n",
      "Epoch 15/20\n",
      " - 1s - loss: 0.0092 - acc: 0.9978 - val_loss: 0.8485 - val_acc: 0.8251\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.66969\n",
      "Epoch 16/20\n",
      " - 1s - loss: 0.0081 - acc: 0.9978 - val_loss: 0.8449 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.66969\n",
      "Epoch 17/20\n",
      " - 1s - loss: 0.0076 - acc: 0.9982 - val_loss: 0.8852 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.66969\n",
      "Epoch 18/20\n",
      " - 1s - loss: 0.0070 - acc: 0.9981 - val_loss: 0.8624 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.66969\n",
      "Epoch 19/20\n",
      " - 1s - loss: 0.0073 - acc: 0.9981 - val_loss: 0.8768 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.66969\n",
      "Epoch 20/20\n",
      " - 1s - loss: 0.0057 - acc: 0.9987 - val_loss: 0.8941 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.66969\n",
      "\tloading best model...\n",
      "\ttesting model...\n",
      "ResNet50 Test accuracy: 80.9809\n",
      "testing network: InceptionV3\n",
      "\tgetting bottleneck features...\n",
      "\tcompiling custom output nodes...\n",
      "\ttraining model...\n",
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      " - 3s - loss: 1.1641 - acc: 0.7033 - val_loss: 0.6539 - val_acc: 0.8132\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65390, saving model to saved_models/weights.best.InceptionV3.hdf5\n",
      "Epoch 2/20\n",
      " - 2s - loss: 0.4695 - acc: 0.8543 - val_loss: 0.6188 - val_acc: 0.8251\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65390 to 0.61877, saving model to saved_models/weights.best.InceptionV3.hdf5\n",
      "Epoch 3/20\n",
      " - 2s - loss: 0.3683 - acc: 0.8904 - val_loss: 0.6694 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.61877\n",
      "Epoch 4/20\n",
      " - 2s - loss: 0.2943 - acc: 0.9099 - val_loss: 0.6772 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.61877\n",
      "Epoch 5/20\n",
      " - 2s - loss: 0.2350 - acc: 0.9249 - val_loss: 0.7683 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.61877\n",
      "Epoch 6/20\n",
      " - 2s - loss: 0.2048 - acc: 0.9377 - val_loss: 0.7597 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.61877\n",
      "Epoch 7/20\n",
      " - 2s - loss: 0.1763 - acc: 0.9458 - val_loss: 0.7367 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.61877\n",
      "Epoch 8/20\n",
      " - 2s - loss: 0.1472 - acc: 0.9554 - val_loss: 0.7432 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.61877\n",
      "Epoch 9/20\n",
      " - 2s - loss: 0.1284 - acc: 0.9600 - val_loss: 0.7791 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.61877\n",
      "Epoch 10/20\n",
      " - 2s - loss: 0.1069 - acc: 0.9660 - val_loss: 0.8079 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.61877\n",
      "Epoch 11/20\n",
      " - 2s - loss: 0.0923 - acc: 0.9719 - val_loss: 0.8435 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.61877\n",
      "Epoch 12/20\n",
      " - 2s - loss: 0.0782 - acc: 0.9741 - val_loss: 0.8167 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.61877\n",
      "Epoch 13/20\n",
      " - 2s - loss: 0.0727 - acc: 0.9772 - val_loss: 0.8832 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.61877\n",
      "Epoch 14/20\n",
      " - 2s - loss: 0.0607 - acc: 0.9799 - val_loss: 0.8298 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.61877\n",
      "Epoch 15/20\n",
      " - 2s - loss: 0.0540 - acc: 0.9828 - val_loss: 0.8734 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.61877\n",
      "Epoch 16/20\n",
      " - 2s - loss: 0.0447 - acc: 0.9870 - val_loss: 0.8585 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.61877\n",
      "Epoch 17/20\n",
      " - 2s - loss: 0.0415 - acc: 0.9880 - val_loss: 0.8783 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.61877\n",
      "Epoch 18/20\n",
      " - 2s - loss: 0.0390 - acc: 0.9885 - val_loss: 0.9566 - val_acc: 0.8467\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.61877\n",
      "Epoch 19/20\n",
      " - 2s - loss: 0.0341 - acc: 0.9885 - val_loss: 0.9176 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.61877\n",
      "Epoch 20/20\n",
      " - 2s - loss: 0.0320 - acc: 0.9904 - val_loss: 0.9540 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.61877\n",
      "\tloading best model...\n",
      "\ttesting model...\n",
      "InceptionV3 Test accuracy: 78.4689\n",
      "testing network: Xception\n",
      "\tgetting bottleneck features...\n",
      "\tcompiling custom output nodes...\n",
      "\ttraining model...\n",
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      " - 4s - loss: 1.0547 - acc: 0.7401 - val_loss: 0.5272 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.52718, saving model to saved_models/weights.best.Xception.hdf5\n",
      "Epoch 2/20\n",
      " - 3s - loss: 0.3967 - acc: 0.8740 - val_loss: 0.5053 - val_acc: 0.8479\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.52718 to 0.50529, saving model to saved_models/weights.best.Xception.hdf5\n",
      "Epoch 3/20\n",
      " - 3s - loss: 0.3213 - acc: 0.8990 - val_loss: 0.4843 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.50529 to 0.48428, saving model to saved_models/weights.best.Xception.hdf5\n",
      "Epoch 4/20\n",
      " - 3s - loss: 0.2763 - acc: 0.9151 - val_loss: 0.5278 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.48428\n",
      "Epoch 5/20\n",
      " - 3s - loss: 0.2437 - acc: 0.9238 - val_loss: 0.5381 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.48428\n",
      "Epoch 6/20\n",
      " - 3s - loss: 0.2164 - acc: 0.9313 - val_loss: 0.5322 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.48428\n",
      "Epoch 7/20\n",
      " - 3s - loss: 0.1966 - acc: 0.9406 - val_loss: 0.5466 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.48428\n",
      "Epoch 8/20\n",
      " - 3s - loss: 0.1784 - acc: 0.9446 - val_loss: 0.5430 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.48428\n",
      "Epoch 9/20\n",
      " - 3s - loss: 0.1592 - acc: 0.9509 - val_loss: 0.5631 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.48428\n",
      "Epoch 10/20\n",
      " - 3s - loss: 0.1435 - acc: 0.9546 - val_loss: 0.5691 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.48428\n",
      "Epoch 11/20\n",
      " - 3s - loss: 0.1314 - acc: 0.9581 - val_loss: 0.6004 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.48428\n",
      "Epoch 12/20\n",
      " - 3s - loss: 0.1245 - acc: 0.9608 - val_loss: 0.5857 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.48428\n",
      "Epoch 13/20\n",
      " - 3s - loss: 0.1132 - acc: 0.9654 - val_loss: 0.6167 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.48428\n",
      "Epoch 14/20\n",
      " - 3s - loss: 0.1049 - acc: 0.9684 - val_loss: 0.6156 - val_acc: 0.8599\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.48428\n",
      "Epoch 15/20\n",
      " - 3s - loss: 0.0998 - acc: 0.9702 - val_loss: 0.6248 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.48428\n",
      "Epoch 16/20\n",
      " - 3s - loss: 0.0917 - acc: 0.9719 - val_loss: 0.6193 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.48428\n",
      "Epoch 17/20\n",
      " - 3s - loss: 0.0849 - acc: 0.9735 - val_loss: 0.6661 - val_acc: 0.8563\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.48428\n",
      "Epoch 18/20\n",
      " - 3s - loss: 0.0800 - acc: 0.9757 - val_loss: 0.6455 - val_acc: 0.8587\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.48428\n",
      "Epoch 19/20\n",
      " - 3s - loss: 0.0768 - acc: 0.9760 - val_loss: 0.6718 - val_acc: 0.8635\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.48428\n",
      "Epoch 20/20\n",
      " - 3s - loss: 0.0700 - acc: 0.9787 - val_loss: 0.6972 - val_acc: 0.8539\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.48428\n",
      "\tloading best model...\n",
      "\ttesting model...\n",
      "Xception Test accuracy: 84.3301\n",
      "[('VGG19', 52.51196172248804), ('ResNet50', 80.98086124401914), ('InceptionV3', 78.4688995215311), ('Xception', 84.33014354066985)]\n"
     ]
    }
   ],
   "source": [
    "# Obtain bottleneck features from another pre-trained CNN.\n",
    "\n",
    "# function to test a network\n",
    "networks = ['VGG19', 'ResNet50', 'InceptionV3', 'Xception']\n",
    "\n",
    "def xfer_net_tester(network_name):\n",
    "    print(f'testing network: {network}')\n",
    "    \n",
    "    # get bottleneck features\n",
    "    print('\\tgetting bottleneck features...')\n",
    "    bottleneck_features = np.load(f'bottleneck_features/Dog{network}Data.npz')\n",
    "    \n",
    "    # translate read-in features into test-train-validate\n",
    "    train_bottle = bottleneck_features['train']\n",
    "    valid_bottle = bottleneck_features['valid']\n",
    "    test_bottle = bottleneck_features['test']\n",
    "    \n",
    "    # compile our own output sigmoids\n",
    "    print('\\tcompiling custom output nodes...')\n",
    "    xfer_model = Sequential()\n",
    "    xfer_model.add(GlobalAveragePooling2D(input_shape=train_bottle.shape[1:]))\n",
    "    xfer_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "    #xfer_model.summary()\n",
    "    xfer_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "    print('\\ttraining model...')\n",
    "    checkpointer = ModelCheckpoint(filepath=f'saved_models/weights.best.{network}.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "    xfer_model.fit(train_bottle, train_targets, \n",
    "          validation_data=(valid_bottle, valid_targets),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=2)\n",
    "    \n",
    "    # load best model\n",
    "    print('\\tloading best model...')\n",
    "    xfer_model.load_weights(f'saved_models/weights.best.{network}.hdf5')\n",
    "    \n",
    "    # get index of predicted dog breed for each image in test set\n",
    "    print('\\ttesting model...')\n",
    "    xfer_predictions = [np.argmax(xfer_model.predict(np.expand_dims(feature, axis=0))) for feature in test_bottle]\n",
    "\n",
    "    # report test accuracy\n",
    "    test_accuracy = 100*np.sum(np.array(xfer_predictions)==np.argmax(test_targets, axis=1))/len(xfer_predictions)\n",
    "    \n",
    "    print('{} Test accuracy: {:.4f}'.format(network, test_accuracy))\n",
    "    return test_accuracy\n",
    "    \n",
    "n_accs = []\n",
    "for network in networks:\n",
    "    n_acc = xfer_net_tester(network)\n",
    "    n_accs.append((network, n_acc))\n",
    "\n",
    "print(n_accs)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:\n",
    "    \n",
    "        <your model's name>.summary()\n",
    "   \n",
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem.\n",
    "\n",
    "__Answer:__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your architecture.\n",
    "# it appears that the Xception model performs the best\n",
    "\n",
    "from keras.callbacks import History \n",
    "history = History()\n",
    "\n",
    "#net = 'Xception' # too much entropic capacity - memorized models with its parameters\n",
    "net = 'ResNet50'\n",
    "#net = 'VGG19'\n",
    "#net = 'InceptionV3'\n",
    "\n",
    "# get bottleneck features\n",
    "bottleneck_features = np.load(f'bottleneck_features/Dog{net}Data.npz')\n",
    "\n",
    "# translate read-in features into test-train-validate\n",
    "train_bottle = bottleneck_features['train']\n",
    "valid_bottle = bottleneck_features['valid']\n",
    "test_bottle = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_4 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define custom model architecture 1\n",
    "custom_model = Sequential()\n",
    "custom_model.add(GlobalAveragePooling2D(input_shape=train_bottle.shape[1:]))\n",
    "custom_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_6 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 133)               34181     \n",
      "=================================================================\n",
      "Total params: 1,214,597\n",
      "Trainable params: 1,214,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define custom model architecture 2\n",
    "from keras import regularizers\n",
    "\n",
    "custom_model = Sequential()\n",
    "#custom_model.add(Flatten(input_shape=train_bottle.shape[1:]))\n",
    "custom_model.add(GlobalAveragePooling2D(input_shape = train_bottle.shape[1:]))\n",
    "custom_model.add(Dense(512,\n",
    "                       activation = 'relu',\n",
    "                       kernel_regularizer = regularizers.l2(0.02)))\n",
    "custom_model.add(Dropout(0.5))\n",
    "custom_model.add(Dense(256,\n",
    "                       activation = 'relu',\n",
    "                       kernel_regularizer = regularizers.l2(0.02)))\n",
    "custom_model.add(Dropout(0.5))\n",
    "custom_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "from keras import optimizers\n",
    "\n",
    "#custom_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "custom_model.compile(loss='categorical_crossentropy',\n",
    "                     optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train the Model\n",
    "\n",
    "Train your model in the code cell below.  Use model checkpointing to save the model that attains the best validation loss.  \n",
    "\n",
    "You are welcome to [augment the training data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), but this is not a requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n",
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/500\n",
      " - 3s - loss: 28.1927 - acc: 0.0120 - val_loss: 27.4013 - val_acc: 0.0383\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 27.40131, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 2/500\n",
      " - 1s - loss: 27.2520 - acc: 0.0166 - val_loss: 26.7155 - val_acc: 0.0731\n",
      "\n",
      "Epoch 00002: val_loss improved from 27.40131 to 26.71553, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 3/500\n",
      " - 1s - loss: 26.5381 - acc: 0.0228 - val_loss: 26.0695 - val_acc: 0.1234\n",
      "\n",
      "Epoch 00003: val_loss improved from 26.71553 to 26.06951, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 4/500\n",
      " - 1s - loss: 25.8718 - acc: 0.0326 - val_loss: 25.4333 - val_acc: 0.1509\n",
      "\n",
      "Epoch 00004: val_loss improved from 26.06951 to 25.43335, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 5/500\n",
      " - 1s - loss: 25.2584 - acc: 0.0443 - val_loss: 24.8067 - val_acc: 0.1952\n",
      "\n",
      "Epoch 00005: val_loss improved from 25.43335 to 24.80670, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 6/500\n",
      " - 1s - loss: 24.6334 - acc: 0.0648 - val_loss: 24.1863 - val_acc: 0.2311\n",
      "\n",
      "Epoch 00006: val_loss improved from 24.80670 to 24.18628, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 7/500\n",
      " - 1s - loss: 24.0328 - acc: 0.0738 - val_loss: 23.5685 - val_acc: 0.2563\n",
      "\n",
      "Epoch 00007: val_loss improved from 24.18628 to 23.56850, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 8/500\n",
      " - 1s - loss: 23.4243 - acc: 0.0928 - val_loss: 22.9456 - val_acc: 0.2874\n",
      "\n",
      "Epoch 00008: val_loss improved from 23.56850 to 22.94565, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 9/500\n",
      " - 1s - loss: 22.8427 - acc: 0.1042 - val_loss: 22.3342 - val_acc: 0.3090\n",
      "\n",
      "Epoch 00009: val_loss improved from 22.94565 to 22.33419, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 10/500\n",
      " - 1s - loss: 22.2698 - acc: 0.1228 - val_loss: 21.7322 - val_acc: 0.3281\n",
      "\n",
      "Epoch 00010: val_loss improved from 22.33419 to 21.73219, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 11/500\n",
      " - 1s - loss: 21.6903 - acc: 0.1433 - val_loss: 21.1269 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00011: val_loss improved from 21.73219 to 21.12693, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 12/500\n",
      " - 1s - loss: 21.0991 - acc: 0.1611 - val_loss: 20.5269 - val_acc: 0.3749\n",
      "\n",
      "Epoch 00012: val_loss improved from 21.12693 to 20.52688, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 13/500\n",
      " - 1s - loss: 20.5579 - acc: 0.1744 - val_loss: 19.9424 - val_acc: 0.3904\n",
      "\n",
      "Epoch 00013: val_loss improved from 20.52688 to 19.94236, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 14/500\n",
      " - 1s - loss: 20.0450 - acc: 0.1814 - val_loss: 19.3746 - val_acc: 0.4168\n",
      "\n",
      "Epoch 00014: val_loss improved from 19.94236 to 19.37464, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 15/500\n",
      " - 1s - loss: 19.5170 - acc: 0.2070 - val_loss: 18.8201 - val_acc: 0.4479\n",
      "\n",
      "Epoch 00015: val_loss improved from 19.37464 to 18.82007, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 16/500\n",
      " - 1s - loss: 18.9990 - acc: 0.2211 - val_loss: 18.2758 - val_acc: 0.4754\n",
      "\n",
      "Epoch 00016: val_loss improved from 18.82007 to 18.27582, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 17/500\n",
      " - 1s - loss: 18.4816 - acc: 0.2398 - val_loss: 17.7437 - val_acc: 0.4910\n",
      "\n",
      "Epoch 00017: val_loss improved from 18.27582 to 17.74371, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 18/500\n",
      " - 1s - loss: 18.0037 - acc: 0.2549 - val_loss: 17.2308 - val_acc: 0.5150\n",
      "\n",
      "Epoch 00018: val_loss improved from 17.74371 to 17.23076, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 19/500\n",
      " - 1s - loss: 17.5224 - acc: 0.2783 - val_loss: 16.7387 - val_acc: 0.5317\n",
      "\n",
      "Epoch 00019: val_loss improved from 17.23076 to 16.73869, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 20/500\n",
      " - 1s - loss: 17.0670 - acc: 0.2855 - val_loss: 16.2701 - val_acc: 0.5557\n",
      "\n",
      "Epoch 00020: val_loss improved from 16.73869 to 16.27015, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 21/500\n",
      " - 1s - loss: 16.6054 - acc: 0.3112 - val_loss: 15.8002 - val_acc: 0.5737\n",
      "\n",
      "Epoch 00021: val_loss improved from 16.27015 to 15.80024, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 22/500\n",
      " - 1s - loss: 16.1800 - acc: 0.3171 - val_loss: 15.3683 - val_acc: 0.5904\n",
      "\n",
      "Epoch 00022: val_loss improved from 15.80024 to 15.36826, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 23/500\n",
      " - 1s - loss: 15.7382 - acc: 0.3379 - val_loss: 14.9390 - val_acc: 0.6024\n",
      "\n",
      "Epoch 00023: val_loss improved from 15.36826 to 14.93900, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 24/500\n",
      " - 1s - loss: 15.3523 - acc: 0.3510 - val_loss: 14.5326 - val_acc: 0.6144\n",
      "\n",
      "Epoch 00024: val_loss improved from 14.93900 to 14.53264, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 25/500\n",
      " - 1s - loss: 14.9588 - acc: 0.3683 - val_loss: 14.1359 - val_acc: 0.6299\n",
      "\n",
      "Epoch 00025: val_loss improved from 14.53264 to 14.13593, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 26/500\n",
      " - 1s - loss: 14.5787 - acc: 0.3769 - val_loss: 13.7630 - val_acc: 0.6443\n",
      "\n",
      "Epoch 00026: val_loss improved from 14.13593 to 13.76305, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 27/500\n",
      " - 1s - loss: 14.2165 - acc: 0.3811 - val_loss: 13.3976 - val_acc: 0.6599\n",
      "\n",
      "Epoch 00027: val_loss improved from 13.76305 to 13.39755, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 28/500\n",
      " - 1s - loss: 13.8564 - acc: 0.3943 - val_loss: 13.0502 - val_acc: 0.6707\n",
      "\n",
      "Epoch 00028: val_loss improved from 13.39755 to 13.05023, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 29/500\n",
      " - 1s - loss: 13.4982 - acc: 0.4165 - val_loss: 12.7059 - val_acc: 0.6850\n",
      "\n",
      "Epoch 00029: val_loss improved from 13.05023 to 12.70590, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 30/500\n",
      " - 1s - loss: 13.1927 - acc: 0.4112 - val_loss: 12.3856 - val_acc: 0.6910\n",
      "\n",
      "Epoch 00030: val_loss improved from 12.70590 to 12.38556, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 31/500\n",
      " - 1s - loss: 12.8625 - acc: 0.4244 - val_loss: 12.0752 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00031: val_loss improved from 12.38556 to 12.07516, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 32/500\n",
      " - 1s - loss: 12.5627 - acc: 0.4412 - val_loss: 11.7754 - val_acc: 0.7066\n",
      "\n",
      "Epoch 00032: val_loss improved from 12.07516 to 11.77542, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 33/500\n",
      " - 1s - loss: 12.2564 - acc: 0.4481 - val_loss: 11.4765 - val_acc: 0.7078\n",
      "\n",
      "Epoch 00033: val_loss improved from 11.77542 to 11.47649, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 34/500\n",
      " - 1s - loss: 11.9632 - acc: 0.4563 - val_loss: 11.2018 - val_acc: 0.7162\n",
      "\n",
      "Epoch 00034: val_loss improved from 11.47649 to 11.20177, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 35/500\n",
      " - 1s - loss: 11.6956 - acc: 0.4632 - val_loss: 10.9310 - val_acc: 0.7210\n",
      "\n",
      "Epoch 00035: val_loss improved from 11.20177 to 10.93096, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 36/500\n",
      " - 1s - loss: 11.4098 - acc: 0.4668 - val_loss: 10.6601 - val_acc: 0.7246\n",
      "\n",
      "Epoch 00036: val_loss improved from 10.93096 to 10.66012, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 37/500\n",
      " - 1s - loss: 11.1442 - acc: 0.4756 - val_loss: 10.4061 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00037: val_loss improved from 10.66012 to 10.40612, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 38/500\n",
      " - 1s - loss: 10.8946 - acc: 0.4817 - val_loss: 10.1578 - val_acc: 0.7353\n",
      "\n",
      "Epoch 00038: val_loss improved from 10.40612 to 10.15779, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 39/500\n",
      " - 1s - loss: 10.6325 - acc: 0.5012 - val_loss: 9.9206 - val_acc: 0.7341\n",
      "\n",
      "Epoch 00039: val_loss improved from 10.15779 to 9.92062, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 40/500\n",
      " - 1s - loss: 10.3936 - acc: 0.5040 - val_loss: 9.6870 - val_acc: 0.7377\n",
      "\n",
      "Epoch 00040: val_loss improved from 9.92062 to 9.68696, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 41/500\n",
      " - 1s - loss: 10.1755 - acc: 0.5096 - val_loss: 9.4662 - val_acc: 0.7461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: val_loss improved from 9.68696 to 9.46622, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 42/500\n",
      " - 1s - loss: 9.9287 - acc: 0.5254 - val_loss: 9.2449 - val_acc: 0.7497\n",
      "\n",
      "Epoch 00042: val_loss improved from 9.46622 to 9.24489, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 43/500\n",
      " - 1s - loss: 9.7195 - acc: 0.5172 - val_loss: 9.0373 - val_acc: 0.7509\n",
      "\n",
      "Epoch 00043: val_loss improved from 9.24489 to 9.03729, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 44/500\n",
      " - 1s - loss: 9.5079 - acc: 0.5249 - val_loss: 8.8336 - val_acc: 0.7509\n",
      "\n",
      "Epoch 00044: val_loss improved from 9.03729 to 8.83355, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 45/500\n",
      " - 1s - loss: 9.2931 - acc: 0.5350 - val_loss: 8.6323 - val_acc: 0.7545\n",
      "\n",
      "Epoch 00045: val_loss improved from 8.83355 to 8.63231, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 46/500\n",
      " - 1s - loss: 9.0748 - acc: 0.5335 - val_loss: 8.4383 - val_acc: 0.7533\n",
      "\n",
      "Epoch 00046: val_loss improved from 8.63231 to 8.43826, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 47/500\n",
      " - 1s - loss: 8.8794 - acc: 0.5439 - val_loss: 8.2525 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00047: val_loss improved from 8.43826 to 8.25246, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 48/500\n",
      " - 1s - loss: 8.6911 - acc: 0.5448 - val_loss: 8.0661 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00048: val_loss improved from 8.25246 to 8.06611, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 49/500\n",
      " - 1s - loss: 8.5137 - acc: 0.5485 - val_loss: 7.8942 - val_acc: 0.7629\n",
      "\n",
      "Epoch 00049: val_loss improved from 8.06611 to 7.89416, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 50/500\n",
      " - 1s - loss: 8.3551 - acc: 0.5506 - val_loss: 7.7226 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00050: val_loss improved from 7.89416 to 7.72258, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 51/500\n",
      " - 1s - loss: 8.1468 - acc: 0.5615 - val_loss: 7.5530 - val_acc: 0.7665\n",
      "\n",
      "Epoch 00051: val_loss improved from 7.72258 to 7.55302, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 52/500\n",
      " - 1s - loss: 7.9710 - acc: 0.5684 - val_loss: 7.3851 - val_acc: 0.7653\n",
      "\n",
      "Epoch 00052: val_loss improved from 7.55302 to 7.38511, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 53/500\n",
      " - 1s - loss: 7.8291 - acc: 0.5606 - val_loss: 7.2329 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00053: val_loss improved from 7.38511 to 7.23289, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 54/500\n",
      " - 1s - loss: 7.6603 - acc: 0.5687 - val_loss: 7.0788 - val_acc: 0.7713\n",
      "\n",
      "Epoch 00054: val_loss improved from 7.23289 to 7.07883, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 55/500\n",
      " - 1s - loss: 7.4942 - acc: 0.5811 - val_loss: 6.9280 - val_acc: 0.7749\n",
      "\n",
      "Epoch 00055: val_loss improved from 7.07883 to 6.92799, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 56/500\n",
      " - 1s - loss: 7.3561 - acc: 0.5787 - val_loss: 6.7860 - val_acc: 0.7749\n",
      "\n",
      "Epoch 00056: val_loss improved from 6.92799 to 6.78598, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 57/500\n",
      " - 1s - loss: 7.2131 - acc: 0.5734 - val_loss: 6.6462 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00057: val_loss improved from 6.78598 to 6.64622, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 58/500\n",
      " - 1s - loss: 7.0556 - acc: 0.6010 - val_loss: 6.5045 - val_acc: 0.7892\n",
      "\n",
      "Epoch 00058: val_loss improved from 6.64622 to 6.50448, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 59/500\n",
      " - 1s - loss: 6.9263 - acc: 0.5856 - val_loss: 6.3745 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00059: val_loss improved from 6.50448 to 6.37452, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 60/500\n",
      " - 1s - loss: 6.7678 - acc: 0.6001 - val_loss: 6.2448 - val_acc: 0.7868\n",
      "\n",
      "Epoch 00060: val_loss improved from 6.37452 to 6.24482, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 61/500\n",
      " - 1s - loss: 6.6550 - acc: 0.5972 - val_loss: 6.1209 - val_acc: 0.7832\n",
      "\n",
      "Epoch 00061: val_loss improved from 6.24482 to 6.12092, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 62/500\n",
      " - 1s - loss: 6.5114 - acc: 0.6033 - val_loss: 5.9982 - val_acc: 0.7892\n",
      "\n",
      "Epoch 00062: val_loss improved from 6.12092 to 5.99818, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 63/500\n",
      " - 1s - loss: 6.3959 - acc: 0.5997 - val_loss: 5.8784 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00063: val_loss improved from 5.99818 to 5.87842, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 64/500\n",
      " - 1s - loss: 6.2896 - acc: 0.6046 - val_loss: 5.7638 - val_acc: 0.7916\n",
      "\n",
      "Epoch 00064: val_loss improved from 5.87842 to 5.76378, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 65/500\n",
      " - 1s - loss: 6.1602 - acc: 0.6117 - val_loss: 5.6514 - val_acc: 0.7952\n",
      "\n",
      "Epoch 00065: val_loss improved from 5.76378 to 5.65140, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 66/500\n",
      " - 1s - loss: 6.0307 - acc: 0.6133 - val_loss: 5.5405 - val_acc: 0.7952\n",
      "\n",
      "Epoch 00066: val_loss improved from 5.65140 to 5.54047, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 67/500\n",
      " - 1s - loss: 5.9203 - acc: 0.6160 - val_loss: 5.4346 - val_acc: 0.7988\n",
      "\n",
      "Epoch 00067: val_loss improved from 5.54047 to 5.43464, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 68/500\n",
      " - 1s - loss: 5.8285 - acc: 0.6166 - val_loss: 5.3344 - val_acc: 0.8036\n",
      "\n",
      "Epoch 00068: val_loss improved from 5.43464 to 5.33438, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 69/500\n",
      " - 1s - loss: 5.7069 - acc: 0.6256 - val_loss: 5.2312 - val_acc: 0.7976\n",
      "\n",
      "Epoch 00069: val_loss improved from 5.33438 to 5.23123, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 70/500\n",
      " - 1s - loss: 5.6336 - acc: 0.6127 - val_loss: 5.1403 - val_acc: 0.8036\n",
      "\n",
      "Epoch 00070: val_loss improved from 5.23123 to 5.14028, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 71/500\n",
      " - 1s - loss: 5.5035 - acc: 0.6259 - val_loss: 5.0399 - val_acc: 0.8024\n",
      "\n",
      "Epoch 00071: val_loss improved from 5.14028 to 5.03987, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 72/500\n",
      " - 1s - loss: 5.4266 - acc: 0.6295 - val_loss: 4.9472 - val_acc: 0.8072\n",
      "\n",
      "Epoch 00072: val_loss improved from 5.03987 to 4.94720, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 73/500\n",
      " - 1s - loss: 5.3303 - acc: 0.6187 - val_loss: 4.8552 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00073: val_loss improved from 4.94720 to 4.85521, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 74/500\n",
      " - 1s - loss: 5.2121 - acc: 0.6362 - val_loss: 4.7683 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00074: val_loss improved from 4.85521 to 4.76832, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 75/500\n",
      " - 1s - loss: 5.1547 - acc: 0.6225 - val_loss: 4.6864 - val_acc: 0.8108\n",
      "\n",
      "Epoch 00075: val_loss improved from 4.76832 to 4.68637, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 76/500\n",
      " - 1s - loss: 5.0641 - acc: 0.6322 - val_loss: 4.6019 - val_acc: 0.8048\n",
      "\n",
      "Epoch 00076: val_loss improved from 4.68637 to 4.60191, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 77/500\n",
      " - 1s - loss: 4.9555 - acc: 0.6418 - val_loss: 4.5178 - val_acc: 0.8108\n",
      "\n",
      "Epoch 00077: val_loss improved from 4.60191 to 4.51778, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 78/500\n",
      " - 1s - loss: 4.8715 - acc: 0.6412 - val_loss: 4.4405 - val_acc: 0.8108\n",
      "\n",
      "Epoch 00078: val_loss improved from 4.51778 to 4.44053, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 79/500\n",
      " - 1s - loss: 4.7965 - acc: 0.6446 - val_loss: 4.3603 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00079: val_loss improved from 4.44053 to 4.36032, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 80/500\n",
      " - 1s - loss: 4.7232 - acc: 0.6404 - val_loss: 4.2904 - val_acc: 0.8036\n",
      "\n",
      "Epoch 00080: val_loss improved from 4.36032 to 4.29038, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 81/500\n",
      " - 1s - loss: 4.6376 - acc: 0.6458 - val_loss: 4.2151 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00081: val_loss improved from 4.29038 to 4.21506, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 82/500\n",
      " - 1s - loss: 4.5658 - acc: 0.6428 - val_loss: 4.1461 - val_acc: 0.8072\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00082: val_loss improved from 4.21506 to 4.14611, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 83/500\n",
      " - 1s - loss: 4.4932 - acc: 0.6455 - val_loss: 4.0768 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00083: val_loss improved from 4.14611 to 4.07683, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 84/500\n",
      " - 1s - loss: 4.4009 - acc: 0.6573 - val_loss: 4.0088 - val_acc: 0.8084\n",
      "\n",
      "Epoch 00084: val_loss improved from 4.07683 to 4.00885, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 85/500\n",
      " - 1s - loss: 4.3592 - acc: 0.6552 - val_loss: 3.9458 - val_acc: 0.8096\n",
      "\n",
      "Epoch 00085: val_loss improved from 4.00885 to 3.94581, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 86/500\n",
      " - 1s - loss: 4.2761 - acc: 0.6656 - val_loss: 3.8823 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00086: val_loss improved from 3.94581 to 3.88228, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 87/500\n",
      " - 1s - loss: 4.2359 - acc: 0.6476 - val_loss: 3.8231 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00087: val_loss improved from 3.88228 to 3.82310, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 88/500\n",
      " - 1s - loss: 4.1698 - acc: 0.6591 - val_loss: 3.7620 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00088: val_loss improved from 3.82310 to 3.76200, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 89/500\n",
      " - 1s - loss: 4.0963 - acc: 0.6575 - val_loss: 3.7025 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00089: val_loss improved from 3.76200 to 3.70251, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 90/500\n",
      " - 1s - loss: 4.0173 - acc: 0.6684 - val_loss: 3.6403 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00090: val_loss improved from 3.70251 to 3.64030, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 91/500\n",
      " - 1s - loss: 3.9818 - acc: 0.6575 - val_loss: 3.5898 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00091: val_loss improved from 3.64030 to 3.58979, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 92/500\n",
      " - 1s - loss: 3.9140 - acc: 0.6603 - val_loss: 3.5359 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00092: val_loss improved from 3.58979 to 3.53595, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 93/500\n",
      " - 1s - loss: 3.8571 - acc: 0.6638 - val_loss: 3.4797 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00093: val_loss improved from 3.53595 to 3.47972, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 94/500\n",
      " - 1s - loss: 3.7955 - acc: 0.6749 - val_loss: 3.4280 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00094: val_loss improved from 3.47972 to 3.42798, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 95/500\n",
      " - 1s - loss: 3.7545 - acc: 0.6609 - val_loss: 3.3782 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00095: val_loss improved from 3.42798 to 3.37815, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 96/500\n",
      " - 1s - loss: 3.6880 - acc: 0.6702 - val_loss: 3.3291 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00096: val_loss improved from 3.37815 to 3.32915, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 97/500\n",
      " - 1s - loss: 3.6599 - acc: 0.6630 - val_loss: 3.2846 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00097: val_loss improved from 3.32915 to 3.28463, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 98/500\n",
      " - 1s - loss: 3.6020 - acc: 0.6744 - val_loss: 3.2369 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00098: val_loss improved from 3.28463 to 3.23691, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 99/500\n",
      " - 1s - loss: 3.5608 - acc: 0.6740 - val_loss: 3.1901 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00099: val_loss improved from 3.23691 to 3.19012, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 100/500\n",
      " - 1s - loss: 3.5045 - acc: 0.6723 - val_loss: 3.1476 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00100: val_loss improved from 3.19012 to 3.14758, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 101/500\n",
      " - 1s - loss: 3.4584 - acc: 0.6777 - val_loss: 3.1011 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00101: val_loss improved from 3.14758 to 3.10113, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 102/500\n",
      " - 1s - loss: 3.4142 - acc: 0.6786 - val_loss: 3.0616 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00102: val_loss improved from 3.10113 to 3.06164, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 103/500\n",
      " - 1s - loss: 3.3773 - acc: 0.6751 - val_loss: 3.0228 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00103: val_loss improved from 3.06164 to 3.02284, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 104/500\n",
      " - 1s - loss: 3.3319 - acc: 0.6768 - val_loss: 2.9839 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00104: val_loss improved from 3.02284 to 2.98394, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 105/500\n",
      " - 1s - loss: 3.2912 - acc: 0.6786 - val_loss: 2.9455 - val_acc: 0.8144\n",
      "\n",
      "Epoch 00105: val_loss improved from 2.98394 to 2.94549, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 106/500\n",
      " - 1s - loss: 3.2495 - acc: 0.6810 - val_loss: 2.9060 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00106: val_loss improved from 2.94549 to 2.90602, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 107/500\n",
      " - 1s - loss: 3.2189 - acc: 0.6786 - val_loss: 2.8696 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00107: val_loss improved from 2.90602 to 2.86961, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 108/500\n",
      " - 1s - loss: 3.1789 - acc: 0.6771 - val_loss: 2.8354 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00108: val_loss improved from 2.86961 to 2.83543, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 109/500\n",
      " - 1s - loss: 3.1347 - acc: 0.6792 - val_loss: 2.7980 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00109: val_loss improved from 2.83543 to 2.79797, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 110/500\n",
      " - 1s - loss: 3.1048 - acc: 0.6820 - val_loss: 2.7668 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00110: val_loss improved from 2.79797 to 2.76676, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 111/500\n",
      " - 1s - loss: 3.0494 - acc: 0.6865 - val_loss: 2.7304 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00111: val_loss improved from 2.76676 to 2.73043, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 112/500\n",
      " - 1s - loss: 3.0286 - acc: 0.6886 - val_loss: 2.6983 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00112: val_loss improved from 2.73043 to 2.69828, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 113/500\n",
      " - 1s - loss: 2.9913 - acc: 0.6876 - val_loss: 2.6689 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00113: val_loss improved from 2.69828 to 2.66892, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 114/500\n",
      " - 1s - loss: 2.9575 - acc: 0.6865 - val_loss: 2.6416 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00114: val_loss improved from 2.66892 to 2.64157, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 115/500\n",
      " - 1s - loss: 2.9433 - acc: 0.6781 - val_loss: 2.6106 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00115: val_loss improved from 2.64157 to 2.61057, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 116/500\n",
      " - 1s - loss: 2.9030 - acc: 0.6954 - val_loss: 2.5838 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00116: val_loss improved from 2.61057 to 2.58379, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 117/500\n",
      " - 1s - loss: 2.8624 - acc: 0.6954 - val_loss: 2.5532 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00117: val_loss improved from 2.58379 to 2.55317, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 118/500\n",
      " - 1s - loss: 2.8403 - acc: 0.6898 - val_loss: 2.5244 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00118: val_loss improved from 2.55317 to 2.52440, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 119/500\n",
      " - 1s - loss: 2.8030 - acc: 0.6939 - val_loss: 2.4953 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00119: val_loss improved from 2.52440 to 2.49535, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 120/500\n",
      " - 1s - loss: 2.7841 - acc: 0.6963 - val_loss: 2.4693 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00120: val_loss improved from 2.49535 to 2.46925, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 121/500\n",
      " - 1s - loss: 2.7556 - acc: 0.6927 - val_loss: 2.4461 - val_acc: 0.8168\n",
      "\n",
      "Epoch 00121: val_loss improved from 2.46925 to 2.44608, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 122/500\n",
      " - 1s - loss: 2.7258 - acc: 0.6970 - val_loss: 2.4212 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00122: val_loss improved from 2.44608 to 2.42125, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 123/500\n",
      " - 1s - loss: 2.6882 - acc: 0.6969 - val_loss: 2.3934 - val_acc: 0.8228\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00123: val_loss improved from 2.42125 to 2.39336, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 124/500\n",
      " - 1s - loss: 2.6893 - acc: 0.6913 - val_loss: 2.3717 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00124: val_loss improved from 2.39336 to 2.37170, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 125/500\n",
      " - 1s - loss: 2.6479 - acc: 0.6973 - val_loss: 2.3485 - val_acc: 0.8251\n",
      "\n",
      "Epoch 00125: val_loss improved from 2.37170 to 2.34851, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 126/500\n",
      " - 1s - loss: 2.6335 - acc: 0.6990 - val_loss: 2.3266 - val_acc: 0.8204\n",
      "\n",
      "Epoch 00126: val_loss improved from 2.34851 to 2.32656, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 127/500\n",
      " - 1s - loss: 2.5982 - acc: 0.7006 - val_loss: 2.3050 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00127: val_loss improved from 2.32656 to 2.30499, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 128/500\n",
      " - 1s - loss: 2.5861 - acc: 0.7012 - val_loss: 2.2843 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00128: val_loss improved from 2.30499 to 2.28434, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 129/500\n",
      " - 1s - loss: 2.5527 - acc: 0.6997 - val_loss: 2.2642 - val_acc: 0.8192\n",
      "\n",
      "Epoch 00129: val_loss improved from 2.28434 to 2.26420, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 130/500\n",
      " - 1s - loss: 2.5260 - acc: 0.7090 - val_loss: 2.2412 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00130: val_loss improved from 2.26420 to 2.24123, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 131/500\n",
      " - 1s - loss: 2.5056 - acc: 0.7043 - val_loss: 2.2198 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00131: val_loss improved from 2.24123 to 2.21978, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 132/500\n",
      " - 1s - loss: 2.5014 - acc: 0.6988 - val_loss: 2.2022 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00132: val_loss improved from 2.21978 to 2.20225, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 133/500\n",
      " - 1s - loss: 2.4687 - acc: 0.7066 - val_loss: 2.1810 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00133: val_loss improved from 2.20225 to 2.18103, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 134/500\n",
      " - 1s - loss: 2.4531 - acc: 0.7019 - val_loss: 2.1642 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00134: val_loss improved from 2.18103 to 2.16416, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 135/500\n",
      " - 1s - loss: 2.4229 - acc: 0.7151 - val_loss: 2.1439 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00135: val_loss improved from 2.16416 to 2.14390, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 136/500\n",
      " - 1s - loss: 2.4080 - acc: 0.7010 - val_loss: 2.1277 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00136: val_loss improved from 2.14390 to 2.12772, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 137/500\n",
      " - 1s - loss: 2.3910 - acc: 0.7052 - val_loss: 2.1090 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00137: val_loss improved from 2.12772 to 2.10903, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 138/500\n",
      " - 1s - loss: 2.3844 - acc: 0.7015 - val_loss: 2.0944 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00138: val_loss improved from 2.10903 to 2.09436, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 139/500\n",
      " - 1s - loss: 2.3678 - acc: 0.6987 - val_loss: 2.0781 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00139: val_loss improved from 2.09436 to 2.07807, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 140/500\n",
      " - 1s - loss: 2.3461 - acc: 0.7124 - val_loss: 2.0615 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00140: val_loss improved from 2.07807 to 2.06150, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 141/500\n",
      " - 1s - loss: 2.3329 - acc: 0.7096 - val_loss: 2.0465 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00141: val_loss improved from 2.06150 to 2.04646, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 142/500\n",
      " - 1s - loss: 2.3093 - acc: 0.7154 - val_loss: 2.0319 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00142: val_loss improved from 2.04646 to 2.03186, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 143/500\n",
      " - 2s - loss: 2.2823 - acc: 0.7096 - val_loss: 2.0147 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00143: val_loss improved from 2.03186 to 2.01470, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 144/500\n",
      " - 1s - loss: 2.2629 - acc: 0.7171 - val_loss: 1.9989 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00144: val_loss improved from 2.01470 to 1.99888, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 145/500\n",
      " - 1s - loss: 2.2458 - acc: 0.7177 - val_loss: 1.9845 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00145: val_loss improved from 1.99888 to 1.98452, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 146/500\n",
      " - 1s - loss: 2.2328 - acc: 0.7199 - val_loss: 1.9725 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00146: val_loss improved from 1.98452 to 1.97248, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 147/500\n",
      " - 1s - loss: 2.2444 - acc: 0.7087 - val_loss: 1.9618 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00147: val_loss improved from 1.97248 to 1.96176, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 148/500\n",
      " - 1s - loss: 2.2134 - acc: 0.7141 - val_loss: 1.9480 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00148: val_loss improved from 1.96176 to 1.94799, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 149/500\n",
      " - 2s - loss: 2.2068 - acc: 0.7120 - val_loss: 1.9340 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00149: val_loss improved from 1.94799 to 1.93401, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 150/500\n",
      " - 1s - loss: 2.1815 - acc: 0.7124 - val_loss: 1.9164 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00150: val_loss improved from 1.93401 to 1.91638, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 151/500\n",
      " - 1s - loss: 2.1662 - acc: 0.7091 - val_loss: 1.9062 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00151: val_loss improved from 1.91638 to 1.90622, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 152/500\n",
      " - 1s - loss: 2.1673 - acc: 0.7102 - val_loss: 1.8966 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00152: val_loss improved from 1.90622 to 1.89658, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 153/500\n",
      " - 2s - loss: 2.1363 - acc: 0.7238 - val_loss: 1.8845 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00153: val_loss improved from 1.89658 to 1.88450, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 154/500\n",
      " - 1s - loss: 2.1339 - acc: 0.7201 - val_loss: 1.8747 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00154: val_loss improved from 1.88450 to 1.87466, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 155/500\n",
      " - 1s - loss: 2.1158 - acc: 0.7190 - val_loss: 1.8614 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00155: val_loss improved from 1.87466 to 1.86135, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 156/500\n",
      " - 1s - loss: 2.0841 - acc: 0.7244 - val_loss: 1.8484 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00156: val_loss improved from 1.86135 to 1.84837, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 157/500\n",
      " - 1s - loss: 2.0973 - acc: 0.7201 - val_loss: 1.8407 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00157: val_loss improved from 1.84837 to 1.84069, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 158/500\n",
      " - 1s - loss: 2.0726 - acc: 0.7231 - val_loss: 1.8287 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00158: val_loss improved from 1.84069 to 1.82873, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 159/500\n",
      " - 1s - loss: 2.0657 - acc: 0.7223 - val_loss: 1.8178 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00159: val_loss improved from 1.82873 to 1.81779, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 160/500\n",
      " - 1s - loss: 2.0531 - acc: 0.7271 - val_loss: 1.8092 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00160: val_loss improved from 1.81779 to 1.80922, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 161/500\n",
      " - 1s - loss: 2.0380 - acc: 0.7316 - val_loss: 1.7976 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00161: val_loss improved from 1.80922 to 1.79759, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 162/500\n",
      " - 2s - loss: 2.0299 - acc: 0.7225 - val_loss: 1.7902 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00162: val_loss improved from 1.79759 to 1.79017, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 163/500\n",
      " - 1s - loss: 2.0276 - acc: 0.7235 - val_loss: 1.7817 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00163: val_loss improved from 1.79017 to 1.78165, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 164/500\n",
      " - 1s - loss: 2.0169 - acc: 0.7249 - val_loss: 1.7701 - val_acc: 0.8323\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00164: val_loss improved from 1.78165 to 1.77006, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 165/500\n",
      " - 1s - loss: 1.9940 - acc: 0.7301 - val_loss: 1.7608 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00165: val_loss improved from 1.77006 to 1.76084, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 166/500\n",
      " - 1s - loss: 1.9844 - acc: 0.7251 - val_loss: 1.7528 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00166: val_loss improved from 1.76084 to 1.75277, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 167/500\n",
      " - 1s - loss: 1.9872 - acc: 0.7240 - val_loss: 1.7465 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00167: val_loss improved from 1.75277 to 1.74646, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 168/500\n",
      " - 1s - loss: 1.9772 - acc: 0.7256 - val_loss: 1.7372 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00168: val_loss improved from 1.74646 to 1.73723, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 169/500\n",
      " - 1s - loss: 1.9688 - acc: 0.7226 - val_loss: 1.7293 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00169: val_loss improved from 1.73723 to 1.72932, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 170/500\n",
      " - 1s - loss: 1.9661 - acc: 0.7308 - val_loss: 1.7226 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00170: val_loss improved from 1.72932 to 1.72258, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 171/500\n",
      " - 1s - loss: 1.9578 - acc: 0.7235 - val_loss: 1.7137 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00171: val_loss improved from 1.72258 to 1.71373, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 172/500\n",
      " - 1s - loss: 1.9426 - acc: 0.7260 - val_loss: 1.7058 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00172: val_loss improved from 1.71373 to 1.70575, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 173/500\n",
      " - 1s - loss: 1.9316 - acc: 0.7249 - val_loss: 1.7003 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00173: val_loss improved from 1.70575 to 1.70026, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 174/500\n",
      " - 1s - loss: 1.9247 - acc: 0.7316 - val_loss: 1.6926 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00174: val_loss improved from 1.70026 to 1.69259, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 175/500\n",
      " - 2s - loss: 1.9082 - acc: 0.7386 - val_loss: 1.6818 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00175: val_loss improved from 1.69259 to 1.68182, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 176/500\n",
      " - 1s - loss: 1.9105 - acc: 0.7305 - val_loss: 1.6757 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00176: val_loss improved from 1.68182 to 1.67567, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 177/500\n",
      " - 1s - loss: 1.9006 - acc: 0.7353 - val_loss: 1.6680 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00177: val_loss improved from 1.67567 to 1.66795, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 178/500\n",
      " - 1s - loss: 1.8826 - acc: 0.7302 - val_loss: 1.6623 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00178: val_loss improved from 1.66795 to 1.66231, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 179/500\n",
      " - 1s - loss: 1.8982 - acc: 0.7250 - val_loss: 1.6552 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00179: val_loss improved from 1.66231 to 1.65519, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 180/500\n",
      " - 1s - loss: 1.8899 - acc: 0.7241 - val_loss: 1.6500 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00180: val_loss improved from 1.65519 to 1.64996, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 181/500\n",
      " - 1s - loss: 1.8671 - acc: 0.7350 - val_loss: 1.6399 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00181: val_loss improved from 1.64996 to 1.63986, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 182/500\n",
      " - 1s - loss: 1.8611 - acc: 0.7343 - val_loss: 1.6354 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00182: val_loss improved from 1.63986 to 1.63541, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 183/500\n",
      " - 1s - loss: 1.8646 - acc: 0.7308 - val_loss: 1.6312 - val_acc: 0.8275\n",
      "\n",
      "Epoch 00183: val_loss improved from 1.63541 to 1.63120, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 184/500\n",
      " - 1s - loss: 1.8391 - acc: 0.7340 - val_loss: 1.6255 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00184: val_loss improved from 1.63120 to 1.62548, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 185/500\n",
      " - 1s - loss: 1.8330 - acc: 0.7373 - val_loss: 1.6178 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00185: val_loss improved from 1.62548 to 1.61781, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 186/500\n",
      " - 1s - loss: 1.8322 - acc: 0.7356 - val_loss: 1.6108 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00186: val_loss improved from 1.61781 to 1.61081, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 187/500\n",
      " - 1s - loss: 1.8272 - acc: 0.7331 - val_loss: 1.6049 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00187: val_loss improved from 1.61081 to 1.60486, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 188/500\n",
      " - 1s - loss: 1.8325 - acc: 0.7374 - val_loss: 1.6009 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00188: val_loss improved from 1.60486 to 1.60091, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 189/500\n",
      " - 1s - loss: 1.8092 - acc: 0.7398 - val_loss: 1.5935 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00189: val_loss improved from 1.60091 to 1.59354, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 190/500\n",
      " - 1s - loss: 1.8119 - acc: 0.7364 - val_loss: 1.5908 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00190: val_loss improved from 1.59354 to 1.59083, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 191/500\n",
      " - 1s - loss: 1.7966 - acc: 0.7316 - val_loss: 1.5848 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00191: val_loss improved from 1.59083 to 1.58480, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 192/500\n",
      " - 1s - loss: 1.8079 - acc: 0.7358 - val_loss: 1.5796 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00192: val_loss improved from 1.58480 to 1.57961, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 193/500\n",
      " - 1s - loss: 1.7914 - acc: 0.7328 - val_loss: 1.5748 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00193: val_loss improved from 1.57961 to 1.57483, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 194/500\n",
      " - 1s - loss: 1.7817 - acc: 0.7394 - val_loss: 1.5696 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00194: val_loss improved from 1.57483 to 1.56962, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 195/500\n",
      " - 1s - loss: 1.7817 - acc: 0.7425 - val_loss: 1.5691 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00195: val_loss improved from 1.56962 to 1.56909, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 196/500\n",
      " - 1s - loss: 1.7813 - acc: 0.7320 - val_loss: 1.5625 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00196: val_loss improved from 1.56909 to 1.56252, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 197/500\n",
      " - 1s - loss: 1.7708 - acc: 0.7403 - val_loss: 1.5599 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00197: val_loss improved from 1.56252 to 1.55993, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 198/500\n",
      " - 1s - loss: 1.7642 - acc: 0.7397 - val_loss: 1.5537 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00198: val_loss improved from 1.55993 to 1.55373, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 199/500\n",
      " - 1s - loss: 1.7505 - acc: 0.7446 - val_loss: 1.5470 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00199: val_loss improved from 1.55373 to 1.54703, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 200/500\n",
      " - 1s - loss: 1.7613 - acc: 0.7371 - val_loss: 1.5467 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00200: val_loss improved from 1.54703 to 1.54671, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 201/500\n",
      " - 1s - loss: 1.7608 - acc: 0.7358 - val_loss: 1.5416 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00201: val_loss improved from 1.54671 to 1.54163, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 202/500\n",
      " - 1s - loss: 1.7414 - acc: 0.7452 - val_loss: 1.5363 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00202: val_loss improved from 1.54163 to 1.53628, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 203/500\n",
      " - 1s - loss: 1.7246 - acc: 0.7473 - val_loss: 1.5310 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00203: val_loss improved from 1.53628 to 1.53096, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 204/500\n",
      " - 1s - loss: 1.7393 - acc: 0.7349 - val_loss: 1.5286 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00204: val_loss improved from 1.53096 to 1.52856, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 205/500\n",
      " - 1s - loss: 1.7377 - acc: 0.7436 - val_loss: 1.5246 - val_acc: 0.8335\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00205: val_loss improved from 1.52856 to 1.52458, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 206/500\n",
      " - 1s - loss: 1.7191 - acc: 0.7458 - val_loss: 1.5177 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00206: val_loss improved from 1.52458 to 1.51774, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 207/500\n",
      " - 1s - loss: 1.7258 - acc: 0.7440 - val_loss: 1.5170 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00207: val_loss improved from 1.51774 to 1.51701, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 208/500\n",
      " - 1s - loss: 1.7108 - acc: 0.7458 - val_loss: 1.5139 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00208: val_loss improved from 1.51701 to 1.51394, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 209/500\n",
      " - 1s - loss: 1.7115 - acc: 0.7400 - val_loss: 1.5099 - val_acc: 0.8287\n",
      "\n",
      "Epoch 00209: val_loss improved from 1.51394 to 1.50987, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 210/500\n",
      " - 1s - loss: 1.7101 - acc: 0.7449 - val_loss: 1.5077 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00210: val_loss improved from 1.50987 to 1.50770, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 211/500\n",
      " - 1s - loss: 1.6978 - acc: 0.7463 - val_loss: 1.5002 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00211: val_loss improved from 1.50770 to 1.50022, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 212/500\n",
      " - 1s - loss: 1.7101 - acc: 0.7413 - val_loss: 1.5002 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00212: val_loss improved from 1.50022 to 1.50020, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 213/500\n",
      " - 1s - loss: 1.6990 - acc: 0.7472 - val_loss: 1.4969 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00213: val_loss improved from 1.50020 to 1.49686, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 214/500\n",
      " - 1s - loss: 1.6934 - acc: 0.7430 - val_loss: 1.4938 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00214: val_loss improved from 1.49686 to 1.49381, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 215/500\n",
      " - 1s - loss: 1.6932 - acc: 0.7439 - val_loss: 1.4920 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00215: val_loss improved from 1.49381 to 1.49199, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 216/500\n",
      " - 1s - loss: 1.6765 - acc: 0.7552 - val_loss: 1.4867 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00216: val_loss improved from 1.49199 to 1.48672, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 217/500\n",
      " - 1s - loss: 1.6891 - acc: 0.7428 - val_loss: 1.4838 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00217: val_loss improved from 1.48672 to 1.48383, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 218/500\n",
      " - 1s - loss: 1.6822 - acc: 0.7373 - val_loss: 1.4805 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00218: val_loss improved from 1.48383 to 1.48046, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 219/500\n",
      " - 1s - loss: 1.6892 - acc: 0.7415 - val_loss: 1.4779 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00219: val_loss improved from 1.48046 to 1.47789, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 220/500\n",
      " - 1s - loss: 1.6701 - acc: 0.7503 - val_loss: 1.4760 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00220: val_loss improved from 1.47789 to 1.47599, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 221/500\n",
      " - 1s - loss: 1.6550 - acc: 0.7570 - val_loss: 1.4703 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00221: val_loss improved from 1.47599 to 1.47026, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 222/500\n",
      " - 1s - loss: 1.6657 - acc: 0.7496 - val_loss: 1.4700 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00222: val_loss improved from 1.47026 to 1.47001, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 223/500\n",
      " - 1s - loss: 1.6673 - acc: 0.7440 - val_loss: 1.4667 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00223: val_loss improved from 1.47001 to 1.46666, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 224/500\n",
      " - 1s - loss: 1.6543 - acc: 0.7518 - val_loss: 1.4623 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00224: val_loss improved from 1.46666 to 1.46230, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 225/500\n",
      " - 1s - loss: 1.6602 - acc: 0.7445 - val_loss: 1.4614 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00225: val_loss improved from 1.46230 to 1.46138, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 226/500\n",
      " - 1s - loss: 1.6437 - acc: 0.7515 - val_loss: 1.4557 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00226: val_loss improved from 1.46138 to 1.45568, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 227/500\n",
      " - 1s - loss: 1.6446 - acc: 0.7499 - val_loss: 1.4557 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00227: val_loss improved from 1.45568 to 1.45566, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 228/500\n",
      " - 1s - loss: 1.6352 - acc: 0.7496 - val_loss: 1.4516 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00228: val_loss improved from 1.45566 to 1.45163, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 229/500\n",
      " - 1s - loss: 1.6443 - acc: 0.7469 - val_loss: 1.4514 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00229: val_loss improved from 1.45163 to 1.45144, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 230/500\n",
      " - 1s - loss: 1.6273 - acc: 0.7531 - val_loss: 1.4464 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00230: val_loss improved from 1.45144 to 1.44641, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 231/500\n",
      " - 1s - loss: 1.6412 - acc: 0.7487 - val_loss: 1.4433 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00231: val_loss improved from 1.44641 to 1.44330, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 232/500\n",
      " - 1s - loss: 1.6359 - acc: 0.7522 - val_loss: 1.4423 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00232: val_loss improved from 1.44330 to 1.44233, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 233/500\n",
      " - 1s - loss: 1.6305 - acc: 0.7470 - val_loss: 1.4398 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00233: val_loss improved from 1.44233 to 1.43982, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 234/500\n",
      " - 1s - loss: 1.6191 - acc: 0.7567 - val_loss: 1.4371 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00234: val_loss improved from 1.43982 to 1.43709, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 235/500\n",
      " - 1s - loss: 1.6241 - acc: 0.7522 - val_loss: 1.4367 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00235: val_loss improved from 1.43709 to 1.43673, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 236/500\n",
      " - 1s - loss: 1.6082 - acc: 0.7582 - val_loss: 1.4311 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00236: val_loss improved from 1.43673 to 1.43111, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 237/500\n",
      " - 1s - loss: 1.6083 - acc: 0.7549 - val_loss: 1.4277 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00237: val_loss improved from 1.43111 to 1.42770, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 238/500\n",
      " - 1s - loss: 1.6135 - acc: 0.7551 - val_loss: 1.4273 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00238: val_loss improved from 1.42770 to 1.42729, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 239/500\n",
      " - 1s - loss: 1.6140 - acc: 0.7506 - val_loss: 1.4265 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00239: val_loss improved from 1.42729 to 1.42650, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 240/500\n",
      " - 1s - loss: 1.5938 - acc: 0.7585 - val_loss: 1.4240 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00240: val_loss improved from 1.42650 to 1.42403, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 241/500\n",
      " - 1s - loss: 1.5975 - acc: 0.7542 - val_loss: 1.4207 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00241: val_loss improved from 1.42403 to 1.42066, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 242/500\n",
      " - 1s - loss: 1.5982 - acc: 0.7539 - val_loss: 1.4182 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00242: val_loss improved from 1.42066 to 1.41820, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 243/500\n",
      " - 1s - loss: 1.6020 - acc: 0.7537 - val_loss: 1.4168 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00243: val_loss improved from 1.41820 to 1.41683, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 244/500\n",
      " - 1s - loss: 1.6036 - acc: 0.7527 - val_loss: 1.4149 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00244: val_loss improved from 1.41683 to 1.41494, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 245/500\n",
      " - 1s - loss: 1.5901 - acc: 0.7524 - val_loss: 1.4116 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00245: val_loss improved from 1.41494 to 1.41157, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 246/500\n",
      " - 1s - loss: 1.5816 - acc: 0.7564 - val_loss: 1.4097 - val_acc: 0.8335\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00246: val_loss improved from 1.41157 to 1.40974, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 247/500\n",
      " - 1s - loss: 1.5881 - acc: 0.7569 - val_loss: 1.4070 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00247: val_loss improved from 1.40974 to 1.40701, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 248/500\n",
      " - 1s - loss: 1.5816 - acc: 0.7597 - val_loss: 1.4059 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00248: val_loss improved from 1.40701 to 1.40592, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 249/500\n",
      " - 1s - loss: 1.5777 - acc: 0.7579 - val_loss: 1.4030 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00249: val_loss improved from 1.40592 to 1.40298, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 250/500\n",
      " - 1s - loss: 1.5756 - acc: 0.7606 - val_loss: 1.4016 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00250: val_loss improved from 1.40298 to 1.40159, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 251/500\n",
      " - 1s - loss: 1.5698 - acc: 0.7645 - val_loss: 1.4017 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 1.40159\n",
      "Epoch 252/500\n",
      " - 1s - loss: 1.5785 - acc: 0.7579 - val_loss: 1.3991 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00252: val_loss improved from 1.40159 to 1.39905, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 253/500\n",
      " - 1s - loss: 1.5805 - acc: 0.7549 - val_loss: 1.3990 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00253: val_loss improved from 1.39905 to 1.39897, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 254/500\n",
      " - 1s - loss: 1.5731 - acc: 0.7546 - val_loss: 1.3973 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00254: val_loss improved from 1.39897 to 1.39735, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 255/500\n",
      " - 1s - loss: 1.5498 - acc: 0.7645 - val_loss: 1.3914 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00255: val_loss improved from 1.39735 to 1.39141, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 256/500\n",
      " - 1s - loss: 1.5580 - acc: 0.7629 - val_loss: 1.3906 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00256: val_loss improved from 1.39141 to 1.39062, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 257/500\n",
      " - 1s - loss: 1.5711 - acc: 0.7606 - val_loss: 1.3908 - val_acc: 0.8299\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 1.39062\n",
      "Epoch 258/500\n",
      " - 1s - loss: 1.5636 - acc: 0.7614 - val_loss: 1.3885 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00258: val_loss improved from 1.39062 to 1.38848, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 259/500\n",
      " - 1s - loss: 1.5592 - acc: 0.7569 - val_loss: 1.3857 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00259: val_loss improved from 1.38848 to 1.38567, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 260/500\n",
      " - 1s - loss: 1.5524 - acc: 0.7576 - val_loss: 1.3853 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00260: val_loss improved from 1.38567 to 1.38529, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 261/500\n",
      " - 1s - loss: 1.5479 - acc: 0.7590 - val_loss: 1.3813 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00261: val_loss improved from 1.38529 to 1.38128, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 262/500\n",
      " - 1s - loss: 1.5563 - acc: 0.7549 - val_loss: 1.3820 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 1.38128\n",
      "Epoch 263/500\n",
      " - 1s - loss: 1.5484 - acc: 0.7605 - val_loss: 1.3806 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00263: val_loss improved from 1.38128 to 1.38061, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 264/500\n",
      " - 1s - loss: 1.5618 - acc: 0.7552 - val_loss: 1.3806 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00264: val_loss improved from 1.38061 to 1.38055, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 265/500\n",
      " - 1s - loss: 1.5438 - acc: 0.7597 - val_loss: 1.3780 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00265: val_loss improved from 1.38055 to 1.37796, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 266/500\n",
      " - 1s - loss: 1.5471 - acc: 0.7624 - val_loss: 1.3764 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00266: val_loss improved from 1.37796 to 1.37644, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 267/500\n",
      " - 1s - loss: 1.5314 - acc: 0.7675 - val_loss: 1.3722 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00267: val_loss improved from 1.37644 to 1.37216, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 268/500\n",
      " - 1s - loss: 1.5341 - acc: 0.7618 - val_loss: 1.3708 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00268: val_loss improved from 1.37216 to 1.37079, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 269/500\n",
      " - 1s - loss: 1.5392 - acc: 0.7569 - val_loss: 1.3702 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00269: val_loss improved from 1.37079 to 1.37023, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 270/500\n",
      " - 1s - loss: 1.5237 - acc: 0.7672 - val_loss: 1.3678 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00270: val_loss improved from 1.37023 to 1.36778, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 271/500\n",
      " - 1s - loss: 1.5235 - acc: 0.7605 - val_loss: 1.3679 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 1.36778\n",
      "Epoch 272/500\n",
      " - 1s - loss: 1.5274 - acc: 0.7660 - val_loss: 1.3674 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00272: val_loss improved from 1.36778 to 1.36738, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 273/500\n",
      " - 1s - loss: 1.5254 - acc: 0.7623 - val_loss: 1.3658 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00273: val_loss improved from 1.36738 to 1.36577, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 274/500\n",
      " - 1s - loss: 1.5336 - acc: 0.7639 - val_loss: 1.3675 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 1.36577\n",
      "Epoch 275/500\n",
      " - 1s - loss: 1.5250 - acc: 0.7596 - val_loss: 1.3639 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00275: val_loss improved from 1.36577 to 1.36395, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 276/500\n",
      " - 1s - loss: 1.5218 - acc: 0.7639 - val_loss: 1.3609 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00276: val_loss improved from 1.36395 to 1.36093, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 277/500\n",
      " - 1s - loss: 1.5228 - acc: 0.7615 - val_loss: 1.3609 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00277: val_loss improved from 1.36093 to 1.36092, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 278/500\n",
      " - 1s - loss: 1.5177 - acc: 0.7686 - val_loss: 1.3588 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00278: val_loss improved from 1.36092 to 1.35877, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 279/500\n",
      " - 1s - loss: 1.5055 - acc: 0.7662 - val_loss: 1.3535 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00279: val_loss improved from 1.35877 to 1.35352, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 280/500\n",
      " - 1s - loss: 1.5197 - acc: 0.7609 - val_loss: 1.3527 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00280: val_loss improved from 1.35352 to 1.35266, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 281/500\n",
      " - 1s - loss: 1.4990 - acc: 0.7690 - val_loss: 1.3532 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 1.35266\n",
      "Epoch 282/500\n",
      " - 1s - loss: 1.5042 - acc: 0.7686 - val_loss: 1.3534 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 1.35266\n",
      "Epoch 283/500\n",
      " - 1s - loss: 1.5160 - acc: 0.7570 - val_loss: 1.3528 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 1.35266\n",
      "Epoch 284/500\n",
      " - 1s - loss: 1.5093 - acc: 0.7626 - val_loss: 1.3493 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00284: val_loss improved from 1.35266 to 1.34925, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 285/500\n",
      " - 1s - loss: 1.5138 - acc: 0.7665 - val_loss: 1.3502 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 1.34925\n",
      "Epoch 286/500\n",
      " - 1s - loss: 1.5121 - acc: 0.7644 - val_loss: 1.3496 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 1.34925\n",
      "Epoch 287/500\n",
      " - 1s - loss: 1.5094 - acc: 0.7659 - val_loss: 1.3469 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00287: val_loss improved from 1.34925 to 1.34686, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 288/500\n",
      " - 1s - loss: 1.5020 - acc: 0.7648 - val_loss: 1.3476 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 1.34686\n",
      "Epoch 289/500\n",
      " - 1s - loss: 1.4941 - acc: 0.7693 - val_loss: 1.3425 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00289: val_loss improved from 1.34686 to 1.34254, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 290/500\n",
      " - 1s - loss: 1.5024 - acc: 0.7650 - val_loss: 1.3432 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 1.34254\n",
      "Epoch 291/500\n",
      " - 1s - loss: 1.4957 - acc: 0.7642 - val_loss: 1.3438 - val_acc: 0.8335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00291: val_loss did not improve from 1.34254\n",
      "Epoch 292/500\n",
      " - 1s - loss: 1.5104 - acc: 0.7605 - val_loss: 1.3425 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00292: val_loss improved from 1.34254 to 1.34245, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 293/500\n",
      " - 1s - loss: 1.4969 - acc: 0.7711 - val_loss: 1.3408 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00293: val_loss improved from 1.34245 to 1.34083, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 294/500\n",
      " - 1s - loss: 1.4791 - acc: 0.7751 - val_loss: 1.3393 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00294: val_loss improved from 1.34083 to 1.33931, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 295/500\n",
      " - 1s - loss: 1.4891 - acc: 0.7641 - val_loss: 1.3388 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00295: val_loss improved from 1.33931 to 1.33880, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 296/500\n",
      " - 1s - loss: 1.4800 - acc: 0.7734 - val_loss: 1.3372 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00296: val_loss improved from 1.33880 to 1.33718, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 297/500\n",
      " - 1s - loss: 1.4765 - acc: 0.7705 - val_loss: 1.3348 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00297: val_loss improved from 1.33718 to 1.33483, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 298/500\n",
      " - 1s - loss: 1.4852 - acc: 0.7648 - val_loss: 1.3379 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 1.33483\n",
      "Epoch 299/500\n",
      " - 1s - loss: 1.4800 - acc: 0.7719 - val_loss: 1.3341 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00299: val_loss improved from 1.33483 to 1.33405, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 300/500\n",
      " - 1s - loss: 1.4803 - acc: 0.7636 - val_loss: 1.3314 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00300: val_loss improved from 1.33405 to 1.33141, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 301/500\n",
      " - 1s - loss: 1.4712 - acc: 0.7740 - val_loss: 1.3293 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00301: val_loss improved from 1.33141 to 1.32933, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 302/500\n",
      " - 1s - loss: 1.4884 - acc: 0.7677 - val_loss: 1.3324 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 1.32933\n",
      "Epoch 303/500\n",
      " - 1s - loss: 1.4806 - acc: 0.7687 - val_loss: 1.3297 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 1.32933\n",
      "Epoch 304/500\n",
      " - 1s - loss: 1.4821 - acc: 0.7704 - val_loss: 1.3280 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00304: val_loss improved from 1.32933 to 1.32799, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 305/500\n",
      " - 1s - loss: 1.4686 - acc: 0.7692 - val_loss: 1.3264 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00305: val_loss improved from 1.32799 to 1.32639, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 306/500\n",
      " - 1s - loss: 1.4605 - acc: 0.7734 - val_loss: 1.3257 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00306: val_loss improved from 1.32639 to 1.32568, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 307/500\n",
      " - 1s - loss: 1.4659 - acc: 0.7722 - val_loss: 1.3235 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00307: val_loss improved from 1.32568 to 1.32348, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 308/500\n",
      " - 1s - loss: 1.4674 - acc: 0.7716 - val_loss: 1.3233 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00308: val_loss improved from 1.32348 to 1.32330, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 309/500\n",
      " - 1s - loss: 1.4684 - acc: 0.7768 - val_loss: 1.3231 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00309: val_loss improved from 1.32330 to 1.32314, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 310/500\n",
      " - 1s - loss: 1.4660 - acc: 0.7704 - val_loss: 1.3204 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00310: val_loss improved from 1.32314 to 1.32036, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 311/500\n",
      " - 1s - loss: 1.4689 - acc: 0.7702 - val_loss: 1.3196 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00311: val_loss improved from 1.32036 to 1.31962, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 312/500\n",
      " - 1s - loss: 1.4655 - acc: 0.7726 - val_loss: 1.3221 - val_acc: 0.8311\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 1.31962\n",
      "Epoch 313/500\n",
      " - 1s - loss: 1.4707 - acc: 0.7642 - val_loss: 1.3207 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 1.31962\n",
      "Epoch 314/500\n",
      " - 1s - loss: 1.4513 - acc: 0.7747 - val_loss: 1.3185 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00314: val_loss improved from 1.31962 to 1.31847, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 315/500\n",
      " - 1s - loss: 1.4573 - acc: 0.7720 - val_loss: 1.3165 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00315: val_loss improved from 1.31847 to 1.31651, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 316/500\n",
      " - 1s - loss: 1.4422 - acc: 0.7798 - val_loss: 1.3151 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00316: val_loss improved from 1.31651 to 1.31505, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 317/500\n",
      " - 1s - loss: 1.4571 - acc: 0.7683 - val_loss: 1.3176 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 1.31505\n",
      "Epoch 318/500\n",
      " - 1s - loss: 1.4590 - acc: 0.7768 - val_loss: 1.3167 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 1.31505\n",
      "Epoch 319/500\n",
      " - 1s - loss: 1.4577 - acc: 0.7747 - val_loss: 1.3148 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00319: val_loss improved from 1.31505 to 1.31478, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 320/500\n",
      " - 1s - loss: 1.4487 - acc: 0.7780 - val_loss: 1.3116 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00320: val_loss improved from 1.31478 to 1.31160, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 321/500\n",
      " - 1s - loss: 1.4576 - acc: 0.7743 - val_loss: 1.3128 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 1.31160\n",
      "Epoch 322/500\n",
      " - 1s - loss: 1.4562 - acc: 0.7799 - val_loss: 1.3106 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00322: val_loss improved from 1.31160 to 1.31057, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 323/500\n",
      " - 1s - loss: 1.4554 - acc: 0.7750 - val_loss: 1.3110 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 1.31057\n",
      "Epoch 324/500\n",
      " - 1s - loss: 1.4482 - acc: 0.7711 - val_loss: 1.3102 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00324: val_loss improved from 1.31057 to 1.31015, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 325/500\n",
      " - 1s - loss: 1.4444 - acc: 0.7802 - val_loss: 1.3075 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00325: val_loss improved from 1.31015 to 1.30752, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 326/500\n",
      " - 1s - loss: 1.4601 - acc: 0.7737 - val_loss: 1.3090 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 1.30752\n",
      "Epoch 327/500\n",
      " - 1s - loss: 1.4425 - acc: 0.7766 - val_loss: 1.3064 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00327: val_loss improved from 1.30752 to 1.30636, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 328/500\n",
      " - 1s - loss: 1.4298 - acc: 0.7780 - val_loss: 1.3067 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 1.30636\n",
      "Epoch 329/500\n",
      " - 1s - loss: 1.4343 - acc: 0.7771 - val_loss: 1.3057 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00329: val_loss improved from 1.30636 to 1.30569, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 330/500\n",
      " - 1s - loss: 1.4393 - acc: 0.7756 - val_loss: 1.3067 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 1.30569\n",
      "Epoch 331/500\n",
      " - 1s - loss: 1.4384 - acc: 0.7753 - val_loss: 1.3043 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00331: val_loss improved from 1.30569 to 1.30429, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 332/500\n",
      " - 1s - loss: 1.4361 - acc: 0.7729 - val_loss: 1.3019 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00332: val_loss improved from 1.30429 to 1.30185, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 333/500\n",
      " - 1s - loss: 1.4232 - acc: 0.7801 - val_loss: 1.3009 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00333: val_loss improved from 1.30185 to 1.30087, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 334/500\n",
      " - 1s - loss: 1.4436 - acc: 0.7713 - val_loss: 1.3022 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 1.30087\n",
      "Epoch 335/500\n",
      " - 1s - loss: 1.4357 - acc: 0.7796 - val_loss: 1.3001 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00335: val_loss improved from 1.30087 to 1.30011, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 336/500\n",
      " - 1s - loss: 1.4384 - acc: 0.7746 - val_loss: 1.3010 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 1.30011\n",
      "Epoch 337/500\n",
      " - 1s - loss: 1.4358 - acc: 0.7749 - val_loss: 1.3001 - val_acc: 0.8335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00337: val_loss improved from 1.30011 to 1.30005, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 338/500\n",
      " - 1s - loss: 1.4289 - acc: 0.7823 - val_loss: 1.2965 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00338: val_loss improved from 1.30005 to 1.29650, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 339/500\n",
      " - 1s - loss: 1.4274 - acc: 0.7799 - val_loss: 1.2966 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 1.29650\n",
      "Epoch 340/500\n",
      " - 1s - loss: 1.4235 - acc: 0.7799 - val_loss: 1.2968 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 1.29650\n",
      "Epoch 341/500\n",
      " - 1s - loss: 1.4208 - acc: 0.7832 - val_loss: 1.2948 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00341: val_loss improved from 1.29650 to 1.29479, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 342/500\n",
      " - 1s - loss: 1.4391 - acc: 0.7732 - val_loss: 1.2959 - val_acc: 0.8443\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 1.29479\n",
      "Epoch 343/500\n",
      " - 1s - loss: 1.4302 - acc: 0.7754 - val_loss: 1.2955 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 1.29479\n",
      "Epoch 344/500\n",
      " - 1s - loss: 1.4244 - acc: 0.7762 - val_loss: 1.2936 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00344: val_loss improved from 1.29479 to 1.29365, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 345/500\n",
      " - 1s - loss: 1.4291 - acc: 0.7790 - val_loss: 1.2928 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00345: val_loss improved from 1.29365 to 1.29281, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 346/500\n",
      " - 1s - loss: 1.4224 - acc: 0.7807 - val_loss: 1.2911 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00346: val_loss improved from 1.29281 to 1.29107, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 347/500\n",
      " - 1s - loss: 1.4133 - acc: 0.7814 - val_loss: 1.2905 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00347: val_loss improved from 1.29107 to 1.29054, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 348/500\n",
      " - 1s - loss: 1.4037 - acc: 0.7840 - val_loss: 1.2880 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00348: val_loss improved from 1.29054 to 1.28801, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 349/500\n",
      " - 1s - loss: 1.3995 - acc: 0.7886 - val_loss: 1.2874 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00349: val_loss improved from 1.28801 to 1.28741, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 350/500\n",
      " - 1s - loss: 1.4280 - acc: 0.7765 - val_loss: 1.2891 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 1.28741\n",
      "Epoch 351/500\n",
      " - 1s - loss: 1.4155 - acc: 0.7832 - val_loss: 1.2875 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 1.28741\n",
      "Epoch 352/500\n",
      " - 1s - loss: 1.4131 - acc: 0.7790 - val_loss: 1.2857 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00352: val_loss improved from 1.28741 to 1.28575, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 353/500\n",
      " - 1s - loss: 1.4077 - acc: 0.7826 - val_loss: 1.2868 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 1.28575\n",
      "Epoch 354/500\n",
      " - 1s - loss: 1.4081 - acc: 0.7871 - val_loss: 1.2856 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00354: val_loss improved from 1.28575 to 1.28561, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 355/500\n",
      " - 1s - loss: 1.4224 - acc: 0.7796 - val_loss: 1.2860 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 1.28561\n",
      "Epoch 356/500\n",
      " - 1s - loss: 1.4106 - acc: 0.7813 - val_loss: 1.2854 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00356: val_loss improved from 1.28561 to 1.28540, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 357/500\n",
      " - 1s - loss: 1.4014 - acc: 0.7844 - val_loss: 1.2831 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00357: val_loss improved from 1.28540 to 1.28312, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 358/500\n",
      " - 1s - loss: 1.4065 - acc: 0.7868 - val_loss: 1.2849 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 1.28312\n",
      "Epoch 359/500\n",
      " - 1s - loss: 1.4059 - acc: 0.7805 - val_loss: 1.2820 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00359: val_loss improved from 1.28312 to 1.28200, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 360/500\n",
      " - 1s - loss: 1.4089 - acc: 0.7801 - val_loss: 1.2800 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00360: val_loss improved from 1.28200 to 1.28003, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 361/500\n",
      " - 1s - loss: 1.3935 - acc: 0.7840 - val_loss: 1.2791 - val_acc: 0.8443\n",
      "\n",
      "Epoch 00361: val_loss improved from 1.28003 to 1.27911, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 362/500\n",
      " - 1s - loss: 1.4034 - acc: 0.7793 - val_loss: 1.2798 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 1.27911\n",
      "Epoch 363/500\n",
      " - 1s - loss: 1.4015 - acc: 0.7840 - val_loss: 1.2806 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 1.27911\n",
      "Epoch 364/500\n",
      " - 1s - loss: 1.4007 - acc: 0.7802 - val_loss: 1.2780 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00364: val_loss improved from 1.27911 to 1.27798, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 365/500\n",
      " - 1s - loss: 1.3981 - acc: 0.7883 - val_loss: 1.2763 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00365: val_loss improved from 1.27798 to 1.27630, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 366/500\n",
      " - 1s - loss: 1.4049 - acc: 0.7777 - val_loss: 1.2771 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 1.27630\n",
      "Epoch 367/500\n",
      " - 1s - loss: 1.3917 - acc: 0.7799 - val_loss: 1.2725 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00367: val_loss improved from 1.27630 to 1.27248, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 368/500\n",
      " - 1s - loss: 1.3920 - acc: 0.7874 - val_loss: 1.2760 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 1.27248\n",
      "Epoch 369/500\n",
      " - 1s - loss: 1.3970 - acc: 0.7847 - val_loss: 1.2741 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 1.27248\n",
      "Epoch 370/500\n",
      " - 1s - loss: 1.3952 - acc: 0.7804 - val_loss: 1.2746 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 1.27248\n",
      "Epoch 371/500\n",
      " - 1s - loss: 1.4037 - acc: 0.7795 - val_loss: 1.2737 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 1.27248\n",
      "Epoch 372/500\n",
      " - 1s - loss: 1.3975 - acc: 0.7808 - val_loss: 1.2729 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 1.27248\n",
      "Epoch 373/500\n",
      " - 1s - loss: 1.3851 - acc: 0.7883 - val_loss: 1.2714 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00373: val_loss improved from 1.27248 to 1.27141, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 374/500\n",
      " - 1s - loss: 1.3910 - acc: 0.7898 - val_loss: 1.2707 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00374: val_loss improved from 1.27141 to 1.27070, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 375/500\n",
      " - 1s - loss: 1.3897 - acc: 0.7892 - val_loss: 1.2691 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00375: val_loss improved from 1.27070 to 1.26911, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 376/500\n",
      " - 1s - loss: 1.3929 - acc: 0.7832 - val_loss: 1.2718 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 1.26911\n",
      "Epoch 377/500\n",
      " - 1s - loss: 1.3715 - acc: 0.7922 - val_loss: 1.2694 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 1.26911\n",
      "Epoch 378/500\n",
      " - 1s - loss: 1.3935 - acc: 0.7810 - val_loss: 1.2676 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00378: val_loss improved from 1.26911 to 1.26758, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 379/500\n",
      " - 1s - loss: 1.3778 - acc: 0.7874 - val_loss: 1.2672 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00379: val_loss improved from 1.26758 to 1.26720, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 380/500\n",
      " - 1s - loss: 1.3747 - acc: 0.7909 - val_loss: 1.2659 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00380: val_loss improved from 1.26720 to 1.26592, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 381/500\n",
      " - 1s - loss: 1.3913 - acc: 0.7837 - val_loss: 1.2691 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 1.26592\n",
      "Epoch 382/500\n",
      " - 1s - loss: 1.3780 - acc: 0.7907 - val_loss: 1.2673 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 1.26592\n",
      "Epoch 383/500\n",
      " - 1s - loss: 1.3755 - acc: 0.7928 - val_loss: 1.2678 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 1.26592\n",
      "Epoch 384/500\n",
      " - 1s - loss: 1.3680 - acc: 0.7943 - val_loss: 1.2646 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00384: val_loss improved from 1.26592 to 1.26461, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 385/500\n",
      " - 1s - loss: 1.3844 - acc: 0.7847 - val_loss: 1.2619 - val_acc: 0.8407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00385: val_loss improved from 1.26461 to 1.26192, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 386/500\n",
      " - 1s - loss: 1.3819 - acc: 0.7849 - val_loss: 1.2646 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 1.26192\n",
      "Epoch 387/500\n",
      " - 1s - loss: 1.3808 - acc: 0.7882 - val_loss: 1.2623 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 1.26192\n",
      "Epoch 388/500\n",
      " - 1s - loss: 1.3778 - acc: 0.7826 - val_loss: 1.2647 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 1.26192\n",
      "Epoch 389/500\n",
      " - 1s - loss: 1.3683 - acc: 0.7915 - val_loss: 1.2615 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00389: val_loss improved from 1.26192 to 1.26152, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 390/500\n",
      " - 1s - loss: 1.3755 - acc: 0.7883 - val_loss: 1.2627 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 1.26152\n",
      "Epoch 391/500\n",
      " - 1s - loss: 1.3586 - acc: 0.7948 - val_loss: 1.2621 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 1.26152\n",
      "Epoch 392/500\n",
      " - 1s - loss: 1.3735 - acc: 0.7892 - val_loss: 1.2627 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 1.26152\n",
      "Epoch 393/500\n",
      " - 1s - loss: 1.3664 - acc: 0.7922 - val_loss: 1.2617 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 1.26152\n",
      "Epoch 394/500\n",
      " - 1s - loss: 1.3659 - acc: 0.7904 - val_loss: 1.2592 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00394: val_loss improved from 1.26152 to 1.25918, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 395/500\n",
      " - 1s - loss: 1.3603 - acc: 0.7885 - val_loss: 1.2590 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00395: val_loss improved from 1.25918 to 1.25902, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 396/500\n",
      " - 1s - loss: 1.3749 - acc: 0.7855 - val_loss: 1.2599 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 1.25902\n",
      "Epoch 397/500\n",
      " - 1s - loss: 1.3791 - acc: 0.7865 - val_loss: 1.2600 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 1.25902\n",
      "Epoch 398/500\n",
      " - 1s - loss: 1.3689 - acc: 0.7868 - val_loss: 1.2576 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00398: val_loss improved from 1.25902 to 1.25755, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 399/500\n",
      " - 1s - loss: 1.3482 - acc: 0.7975 - val_loss: 1.2577 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 1.25755\n",
      "Epoch 400/500\n",
      " - 1s - loss: 1.3615 - acc: 0.7931 - val_loss: 1.2560 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00400: val_loss improved from 1.25755 to 1.25600, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 401/500\n",
      " - 1s - loss: 1.3681 - acc: 0.7907 - val_loss: 1.2552 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00401: val_loss improved from 1.25600 to 1.25518, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 402/500\n",
      " - 1s - loss: 1.3673 - acc: 0.7903 - val_loss: 1.2580 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 1.25518\n",
      "Epoch 403/500\n",
      " - 1s - loss: 1.3663 - acc: 0.7895 - val_loss: 1.2544 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00403: val_loss improved from 1.25518 to 1.25440, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 404/500\n",
      " - 1s - loss: 1.3527 - acc: 0.7964 - val_loss: 1.2536 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00404: val_loss improved from 1.25440 to 1.25357, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 405/500\n",
      " - 1s - loss: 1.3546 - acc: 0.7877 - val_loss: 1.2538 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 1.25357\n",
      "Epoch 406/500\n",
      " - 1s - loss: 1.3494 - acc: 0.7885 - val_loss: 1.2514 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00406: val_loss improved from 1.25357 to 1.25137, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 407/500\n",
      " - 1s - loss: 1.3630 - acc: 0.7904 - val_loss: 1.2526 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 1.25137\n",
      "Epoch 408/500\n",
      " - 1s - loss: 1.3506 - acc: 0.7918 - val_loss: 1.2488 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00408: val_loss improved from 1.25137 to 1.24883, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 409/500\n",
      " - 1s - loss: 1.3661 - acc: 0.7802 - val_loss: 1.2508 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 1.24883\n",
      "Epoch 410/500\n",
      " - 1s - loss: 1.3592 - acc: 0.7891 - val_loss: 1.2503 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 1.24883\n",
      "Epoch 411/500\n",
      " - 1s - loss: 1.3440 - acc: 0.7903 - val_loss: 1.2473 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00411: val_loss improved from 1.24883 to 1.24731, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 412/500\n",
      " - 1s - loss: 1.3532 - acc: 0.7876 - val_loss: 1.2500 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 1.24731\n",
      "Epoch 413/500\n",
      " - 1s - loss: 1.3496 - acc: 0.7918 - val_loss: 1.2490 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 1.24731\n",
      "Epoch 414/500\n",
      " - 1s - loss: 1.3524 - acc: 0.7949 - val_loss: 1.2471 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00414: val_loss improved from 1.24731 to 1.24712, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 415/500\n",
      " - 1s - loss: 1.3483 - acc: 0.7951 - val_loss: 1.2460 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00415: val_loss improved from 1.24712 to 1.24598, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 416/500\n",
      " - 1s - loss: 1.3480 - acc: 0.7906 - val_loss: 1.2464 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 1.24598\n",
      "Epoch 417/500\n",
      " - 1s - loss: 1.3519 - acc: 0.7913 - val_loss: 1.2463 - val_acc: 0.8419\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 1.24598\n",
      "Epoch 418/500\n",
      " - 1s - loss: 1.3450 - acc: 0.7931 - val_loss: 1.2470 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 1.24598\n",
      "Epoch 419/500\n",
      " - 1s - loss: 1.3323 - acc: 0.7981 - val_loss: 1.2446 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00419: val_loss improved from 1.24598 to 1.24455, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 420/500\n",
      " - 1s - loss: 1.3500 - acc: 0.7963 - val_loss: 1.2439 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00420: val_loss improved from 1.24455 to 1.24388, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 421/500\n",
      " - 1s - loss: 1.3415 - acc: 0.7912 - val_loss: 1.2446 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 1.24388\n",
      "Epoch 422/500\n",
      " - 1s - loss: 1.3438 - acc: 0.7913 - val_loss: 1.2436 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00422: val_loss improved from 1.24388 to 1.24363, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 423/500\n",
      " - 1s - loss: 1.3555 - acc: 0.7879 - val_loss: 1.2453 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 1.24363\n",
      "Epoch 424/500\n",
      " - 1s - loss: 1.3337 - acc: 0.7888 - val_loss: 1.2421 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00424: val_loss improved from 1.24363 to 1.24207, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 425/500\n",
      " - 1s - loss: 1.3527 - acc: 0.7888 - val_loss: 1.2403 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00425: val_loss improved from 1.24207 to 1.24026, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 426/500\n",
      " - 1s - loss: 1.3399 - acc: 0.7897 - val_loss: 1.2412 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 1.24026\n",
      "Epoch 427/500\n",
      " - 1s - loss: 1.3507 - acc: 0.7910 - val_loss: 1.2410 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 1.24026\n",
      "Epoch 428/500\n",
      " - 1s - loss: 1.3375 - acc: 0.7945 - val_loss: 1.2413 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 1.24026\n",
      "Epoch 429/500\n",
      " - 1s - loss: 1.3279 - acc: 0.8027 - val_loss: 1.2394 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00429: val_loss improved from 1.24026 to 1.23939, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 430/500\n",
      " - 1s - loss: 1.3302 - acc: 0.7895 - val_loss: 1.2392 - val_acc: 0.8443\n",
      "\n",
      "Epoch 00430: val_loss improved from 1.23939 to 1.23918, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 431/500\n",
      " - 1s - loss: 1.3423 - acc: 0.7927 - val_loss: 1.2389 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00431: val_loss improved from 1.23918 to 1.23887, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 432/500\n",
      " - 1s - loss: 1.3468 - acc: 0.7945 - val_loss: 1.2376 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00432: val_loss improved from 1.23887 to 1.23760, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 433/500\n",
      " - 1s - loss: 1.3398 - acc: 0.7910 - val_loss: 1.2384 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 1.23760\n",
      "Epoch 434/500\n",
      " - 1s - loss: 1.3404 - acc: 0.7967 - val_loss: 1.2373 - val_acc: 0.8395\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00434: val_loss improved from 1.23760 to 1.23730, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 435/500\n",
      " - 1s - loss: 1.3380 - acc: 0.7915 - val_loss: 1.2362 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00435: val_loss improved from 1.23730 to 1.23617, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 436/500\n",
      " - 1s - loss: 1.3421 - acc: 0.7897 - val_loss: 1.2358 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00436: val_loss improved from 1.23617 to 1.23585, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 437/500\n",
      " - 1s - loss: 1.3375 - acc: 0.7946 - val_loss: 1.2361 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 1.23585\n",
      "Epoch 438/500\n",
      " - 1s - loss: 1.3450 - acc: 0.7928 - val_loss: 1.2366 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 1.23585\n",
      "Epoch 439/500\n",
      " - 1s - loss: 1.3354 - acc: 0.7907 - val_loss: 1.2358 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00439: val_loss improved from 1.23585 to 1.23577, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 440/500\n",
      " - 1s - loss: 1.3357 - acc: 0.7930 - val_loss: 1.2349 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00440: val_loss improved from 1.23577 to 1.23489, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 441/500\n",
      " - 1s - loss: 1.3373 - acc: 0.7922 - val_loss: 1.2351 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 1.23489\n",
      "Epoch 442/500\n",
      " - 1s - loss: 1.3136 - acc: 0.7966 - val_loss: 1.2347 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00442: val_loss improved from 1.23489 to 1.23472, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 443/500\n",
      " - 1s - loss: 1.3419 - acc: 0.7895 - val_loss: 1.2338 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00443: val_loss improved from 1.23472 to 1.23376, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 444/500\n",
      " - 1s - loss: 1.3093 - acc: 0.8004 - val_loss: 1.2308 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00444: val_loss improved from 1.23376 to 1.23077, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 445/500\n",
      " - 1s - loss: 1.3298 - acc: 0.8007 - val_loss: 1.2317 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 1.23077\n",
      "Epoch 446/500\n",
      " - 1s - loss: 1.3236 - acc: 0.7997 - val_loss: 1.2336 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 1.23077\n",
      "Epoch 447/500\n",
      " - 1s - loss: 1.3145 - acc: 0.8000 - val_loss: 1.2292 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00447: val_loss improved from 1.23077 to 1.22921, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 448/500\n",
      " - 1s - loss: 1.3252 - acc: 0.8003 - val_loss: 1.2312 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 1.22921\n",
      "Epoch 449/500\n",
      " - 1s - loss: 1.3095 - acc: 0.8063 - val_loss: 1.2312 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 1.22921\n",
      "Epoch 450/500\n",
      " - 1s - loss: 1.3176 - acc: 0.7969 - val_loss: 1.2287 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00450: val_loss improved from 1.22921 to 1.22866, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 451/500\n",
      " - 1s - loss: 1.3246 - acc: 0.7927 - val_loss: 1.2265 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00451: val_loss improved from 1.22866 to 1.22646, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 452/500\n",
      " - 1s - loss: 1.3300 - acc: 0.7919 - val_loss: 1.2280 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 1.22646\n",
      "Epoch 453/500\n",
      " - 1s - loss: 1.3074 - acc: 0.8073 - val_loss: 1.2290 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 1.22646\n",
      "Epoch 454/500\n",
      " - 1s - loss: 1.3235 - acc: 0.7978 - val_loss: 1.2256 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00454: val_loss improved from 1.22646 to 1.22564, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 455/500\n",
      " - 1s - loss: 1.3166 - acc: 0.8039 - val_loss: 1.2292 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 1.22564\n",
      "Epoch 456/500\n",
      " - 1s - loss: 1.3241 - acc: 0.7940 - val_loss: 1.2288 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 1.22564\n",
      "Epoch 457/500\n",
      " - 1s - loss: 1.3135 - acc: 0.7970 - val_loss: 1.2242 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00457: val_loss improved from 1.22564 to 1.22423, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 458/500\n",
      " - 1s - loss: 1.3082 - acc: 0.7996 - val_loss: 1.2240 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00458: val_loss improved from 1.22423 to 1.22396, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 459/500\n",
      " - 1s - loss: 1.3203 - acc: 0.7967 - val_loss: 1.2249 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 1.22396\n",
      "Epoch 460/500\n",
      " - 1s - loss: 1.3137 - acc: 0.7988 - val_loss: 1.2259 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 1.22396\n",
      "Epoch 461/500\n",
      " - 1s - loss: 1.3192 - acc: 0.7927 - val_loss: 1.2265 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 1.22396\n",
      "Epoch 462/500\n",
      " - 1s - loss: 1.3221 - acc: 0.7979 - val_loss: 1.2252 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 1.22396\n",
      "Epoch 463/500\n",
      " - 1s - loss: 1.3201 - acc: 0.7952 - val_loss: 1.2238 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00463: val_loss improved from 1.22396 to 1.22380, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 464/500\n",
      " - 1s - loss: 1.3141 - acc: 0.7985 - val_loss: 1.2241 - val_acc: 0.8431\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 1.22380\n",
      "Epoch 465/500\n",
      " - 1s - loss: 1.3051 - acc: 0.8040 - val_loss: 1.2222 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00465: val_loss improved from 1.22380 to 1.22216, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 466/500\n",
      " - 1s - loss: 1.3201 - acc: 0.7927 - val_loss: 1.2222 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 1.22216\n",
      "Epoch 467/500\n",
      " - 1s - loss: 1.3100 - acc: 0.7942 - val_loss: 1.2221 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00467: val_loss improved from 1.22216 to 1.22212, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 468/500\n",
      " - 1s - loss: 1.3002 - acc: 0.7991 - val_loss: 1.2205 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00468: val_loss improved from 1.22212 to 1.22053, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 469/500\n",
      " - 1s - loss: 1.3107 - acc: 0.7972 - val_loss: 1.2237 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 1.22053\n",
      "Epoch 470/500\n",
      " - 1s - loss: 1.3098 - acc: 0.8022 - val_loss: 1.2205 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 1.22053\n",
      "Epoch 471/500\n",
      " - 1s - loss: 1.3134 - acc: 0.7981 - val_loss: 1.2198 - val_acc: 0.8323\n",
      "\n",
      "Epoch 00471: val_loss improved from 1.22053 to 1.21984, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 472/500\n",
      " - 1s - loss: 1.3033 - acc: 0.8018 - val_loss: 1.2199 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 1.21984\n",
      "Epoch 473/500\n",
      " - 1s - loss: 1.3076 - acc: 0.8003 - val_loss: 1.2184 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00473: val_loss improved from 1.21984 to 1.21840, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 474/500\n",
      " - 1s - loss: 1.3001 - acc: 0.8018 - val_loss: 1.2172 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00474: val_loss improved from 1.21840 to 1.21718, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 475/500\n",
      " - 1s - loss: 1.3108 - acc: 0.7930 - val_loss: 1.2197 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 1.21718\n",
      "Epoch 476/500\n",
      " - 1s - loss: 1.3034 - acc: 0.8045 - val_loss: 1.2193 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 1.21718\n",
      "Epoch 477/500\n",
      " - 1s - loss: 1.2983 - acc: 0.8007 - val_loss: 1.2154 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00477: val_loss improved from 1.21718 to 1.21541, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 478/500\n",
      " - 1s - loss: 1.3114 - acc: 0.7964 - val_loss: 1.2184 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 1.21541\n",
      "Epoch 479/500\n",
      " - 1s - loss: 1.3027 - acc: 0.7946 - val_loss: 1.2167 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 1.21541\n",
      "Epoch 480/500\n",
      " - 1s - loss: 1.3126 - acc: 0.7912 - val_loss: 1.2175 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 1.21541\n",
      "Epoch 481/500\n",
      " - 1s - loss: 1.2932 - acc: 0.8028 - val_loss: 1.2152 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00481: val_loss improved from 1.21541 to 1.21518, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 482/500\n",
      " - 1s - loss: 1.2957 - acc: 0.8015 - val_loss: 1.2155 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 1.21518\n",
      "Epoch 483/500\n",
      " - 1s - loss: 1.2923 - acc: 0.8075 - val_loss: 1.2152 - val_acc: 0.8371\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00483: val_loss did not improve from 1.21518\n",
      "Epoch 484/500\n",
      " - 1s - loss: 1.3021 - acc: 0.7994 - val_loss: 1.2168 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 1.21518\n",
      "Epoch 485/500\n",
      " - 1s - loss: 1.3013 - acc: 0.7964 - val_loss: 1.2165 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 1.21518\n",
      "Epoch 486/500\n",
      " - 1s - loss: 1.2966 - acc: 0.7964 - val_loss: 1.2152 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 1.21518\n",
      "Epoch 487/500\n",
      " - 1s - loss: 1.2984 - acc: 0.8015 - val_loss: 1.2152 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 1.21518\n",
      "Epoch 488/500\n",
      " - 1s - loss: 1.2927 - acc: 0.8078 - val_loss: 1.2121 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00488: val_loss improved from 1.21518 to 1.21210, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 489/500\n",
      " - 1s - loss: 1.2898 - acc: 0.7999 - val_loss: 1.2127 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 1.21210\n",
      "Epoch 490/500\n",
      " - 1s - loss: 1.3013 - acc: 0.8010 - val_loss: 1.2132 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 1.21210\n",
      "Epoch 491/500\n",
      " - 1s - loss: 1.2879 - acc: 0.8013 - val_loss: 1.2123 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 1.21210\n",
      "Epoch 492/500\n",
      " - 1s - loss: 1.2798 - acc: 0.8058 - val_loss: 1.2100 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00492: val_loss improved from 1.21210 to 1.21002, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 493/500\n",
      " - 1s - loss: 1.2821 - acc: 0.8039 - val_loss: 1.2090 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00493: val_loss improved from 1.21002 to 1.20895, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 494/500\n",
      " - 1s - loss: 1.2945 - acc: 0.7972 - val_loss: 1.2111 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 1.20895\n",
      "Epoch 495/500\n",
      " - 1s - loss: 1.2970 - acc: 0.7987 - val_loss: 1.2093 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 1.20895\n",
      "Epoch 496/500\n",
      " - 1s - loss: 1.2967 - acc: 0.8016 - val_loss: 1.2120 - val_acc: 0.8383\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 1.20895\n",
      "Epoch 497/500\n",
      " - 1s - loss: 1.2931 - acc: 0.8016 - val_loss: 1.2118 - val_acc: 0.8395\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 1.20895\n",
      "Epoch 498/500\n",
      " - 1s - loss: 1.2957 - acc: 0.7999 - val_loss: 1.2115 - val_acc: 0.8371\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 1.20895\n",
      "Epoch 499/500\n",
      " - 1s - loss: 1.2903 - acc: 0.8042 - val_loss: 1.2089 - val_acc: 0.8407\n",
      "\n",
      "Epoch 00499: val_loss improved from 1.20895 to 1.20888, saving model to saved_models/weights.best.ResNet50.hdf5\n",
      "Epoch 500/500\n",
      " - 1s - loss: 1.2773 - acc: 0.8010 - val_loss: 1.2097 - val_acc: 0.8359\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 1.20888\n",
      "Wall time: 10min 17s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e324229f60>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model.\n",
    "\n",
    "print('training model...')\n",
    "checkpointer = ModelCheckpoint(filepath=f'saved_models/weights.best.{net}.hdf5', \n",
    "                           verbose=1, save_best_only=True)\n",
    "\n",
    "custom_model.fit(train_bottle, train_targets, \n",
    "      validation_data=(valid_bottle, valid_targets),\n",
    "      epochs=500, batch_size=20, callbacks=[checkpointer, history], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model achieved a max validation accuracy of 0.8455089798230611\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "epochs = range(len(history.history['acc']))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2)\n",
    "\n",
    "sns.lineplot(x = epochs, y=history.history['acc'], ax=ax1, label = 'acc')\n",
    "sns.lineplot(x = epochs, y=history.history['val_acc'], ax=ax1, label = 'val_acc')\n",
    "ax1.set_ylim(0, 1.05);\n",
    "ax1.set_title('Rolling accuracy');\n",
    "\n",
    "sns.lineplot(x = epochs, y=history.history['loss'], ax=ax2, label = 'loss')\n",
    "sns.lineplot(x = epochs, y=history.history['val_loss'], ax=ax2, label = 'val_loss')\n",
    "#ax[1].set_ylim(.5, 1.05);\n",
    "ax2.set_title('Rolling loss');\n",
    "\n",
    "fig.suptitle(f'{net} training metrics', fontsize = 16);\n",
    "max_val_acc = max(history.history['val_acc'])\n",
    "print(f'This model achieved a max validation accuracy of {max_val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 81.8182%\n"
     ]
    }
   ],
   "source": [
    "final_model = Sequential()\n",
    "\n",
    "# ResNet50_cnn_model = ResNet50(weights='imagenet', include_top=False)\n",
    "custom_model.load_weights(f'saved_models/weights.best.{net}.hdf5')\n",
    "\n",
    "# final_model.add(ResNet50_cnn_model)\n",
    "# final_model.add(custom_model)\n",
    "\n",
    "# get index of predicted dog breed for each image in test set\n",
    "final_predictions = [np.argmax(custom_model.predict(np.expand_dims(feature, axis=0))) for feature in test_bottle]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(final_predictions)==np.argmax(test_targets, axis=1))/len(final_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)\n",
    "print('saving...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom model layer 1: global average pooling, dense_1; RMSProp optim\n",
    "### Xception\n",
    "accuracy and loss was static for both validation and training\n",
    "\n",
    "### ResNet50\n",
    "accuracy quickly jumped to near 100 while validation accuracy rose very slightly between .79-.81. Train loss went quickly to 0 while validation loss rose slowly to .8\n",
    "\n",
    "### VGG19\n",
    "Over 50 epochs, accuracy climbed from .7 - .8, val acc climbed for the first 30 epochs slightly but stagnated. Loss and val loss both dropped steadily to 3.5 and 5 respectively.\n",
    "\n",
    "## Custom model layer 2: Flatten, dense_1, dropout, dense_2; SGD optim\n",
    "### ResNet50\n",
    "Over 250 epochs, val accuracy and accuracy met at .8 around 90 epochs, then accuracy continued to grow while val accuracy stagnated. Loss steadily dropped...\n",
    "\n",
    "Trying increasing dropout... same results, except accuracy took a full 250 epochs to hit .8\n",
    "\n",
    "Trying l2 regularization... same results more or less\n",
    "\n",
    "Trying l1 regularization... failed to learn\n",
    "\n",
    "### VGG19\n",
    "Over 250 epochs, accuracy slowly rose to about .7, val accuracy stagnated at about .5. Loss steadily dropped, val loss dropped with diminishing returns\n",
    "\n",
    "### Xception\n",
    "25 million parameters training, with full dropout and l2 .01\n",
    "\n",
    "Over 250 epochs, accuracy continued to rise while validationa accuracy capped at about 85% after just 30 or so epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the ground-up bottlenecking and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6680 images belonging to 133 classes.\n",
      "Found 835 images belonging to 133 classes.\n"
     ]
    }
   ],
   "source": [
    "# training image augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras import optimizers\n",
    "from keras.callbacks import History \n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# this is the augmentation configuration I will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest')\n",
    "\n",
    "# This is the augmentation configuration I will use for testing/validation... just a rescale\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# This is the generator which will read pictures found in my training subset\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dogImages/train',\n",
    "    target_size = (150, 150),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "# This is the generator for calidation data\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    'dogImages/valid',\n",
    "    target_size = (150, 150),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 150, 150, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 64)                1183808   \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 133)               8645      \n",
      "=================================================================\n",
      "Total params: 1,221,093\n",
      "Trainable params: 1,221,093\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/417 [==============>...............] - ETA: 1:33 - loss: 4.8673 - acc: 0.0000e+0 - ETA: 1:23 - loss: 4.8726 - acc: 0.0000e+0 - ETA: 1:13 - loss: 4.8772 - acc: 0.0000e+0 - ETA: 1:15 - loss: 4.8779 - acc: 0.0000e+0 - ETA: 1:11 - loss: 4.8802 - acc: 0.0000e+0 - ETA: 1:08 - loss: 4.8786 - acc: 0.0000e+0 - ETA: 1:07 - loss: 4.8814 - acc: 0.0000e+0 - ETA: 1:08 - loss: 4.8823 - acc: 0.0000e+0 - ETA: 1:06 - loss: 4.8828 - acc: 0.0000e+0 - ETA: 1:08 - loss: 4.8856 - acc: 0.0063    - ETA: 1:08 - loss: 4.8856 - acc: 0.005 - ETA: 1:06 - loss: 4.8858 - acc: 0.010 - ETA: 1:05 - loss: 4.8839 - acc: 0.009 - ETA: 1:04 - loss: 4.8833 - acc: 0.008 - ETA: 1:03 - loss: 4.8838 - acc: 0.012 - ETA: 1:02 - loss: 4.8848 - acc: 0.011 - ETA: 1:01 - loss: 4.8854 - acc: 0.011 - ETA: 1:01 - loss: 4.8859 - acc: 0.010 - ETA: 1:00 - loss: 4.8863 - acc: 0.009 - ETA: 59s - loss: 4.8857 - acc: 0.009 - ETA: 1:00 - loss: 4.8841 - acc: 0.011 - ETA: 1:01 - loss: 4.8841 - acc: 0.011 - ETA: 1:00 - loss: 4.8835 - acc: 0.010 - ETA: 1:00 - loss: 4.8847 - acc: 0.010 - ETA: 1:00 - loss: 4.8853 - acc: 0.010 - ETA: 1:00 - loss: 4.8851 - acc: 0.009 - ETA: 1:00 - loss: 4.8849 - acc: 0.009 - ETA: 1:00 - loss: 4.8848 - acc: 0.008 - ETA: 1:00 - loss: 4.8857 - acc: 0.008 - ETA: 1:00 - loss: 4.8857 - acc: 0.008 - ETA: 59s - loss: 4.8857 - acc: 0.008 - ETA: 1:01 - loss: 4.8860 - acc: 0.007 - ETA: 1:00 - loss: 4.8865 - acc: 0.007 - ETA: 1:00 - loss: 4.8870 - acc: 0.007 - ETA: 1:00 - loss: 4.8871 - acc: 0.007 - ETA: 1:00 - loss: 4.8867 - acc: 0.006 - ETA: 1:00 - loss: 4.8861 - acc: 0.006 - ETA: 1:01 - loss: 4.8861 - acc: 0.006 - ETA: 1:00 - loss: 4.8870 - acc: 0.006 - ETA: 1:00 - loss: 4.8866 - acc: 0.006 - ETA: 1:00 - loss: 4.8866 - acc: 0.006 - ETA: 59s - loss: 4.8862 - acc: 0.006 - ETA: 59s - loss: 4.8864 - acc: 0.00 - ETA: 59s - loss: 4.8861 - acc: 0.00 - ETA: 58s - loss: 4.8862 - acc: 0.00 - ETA: 58s - loss: 4.8861 - acc: 0.00 - ETA: 59s - loss: 4.8862 - acc: 0.00 - ETA: 59s - loss: 4.8863 - acc: 0.00 - ETA: 58s - loss: 4.8862 - acc: 0.00 - ETA: 58s - loss: 4.8861 - acc: 0.00 - ETA: 58s - loss: 4.8864 - acc: 0.00 - ETA: 58s - loss: 4.8871 - acc: 0.00 - ETA: 58s - loss: 4.8870 - acc: 0.00 - ETA: 58s - loss: 4.8869 - acc: 0.00 - ETA: 58s - loss: 4.8867 - acc: 0.00 - ETA: 57s - loss: 4.8862 - acc: 0.00 - ETA: 57s - loss: 4.8862 - acc: 0.00 - ETA: 57s - loss: 4.8861 - acc: 0.00 - ETA: 57s - loss: 4.8860 - acc: 0.00 - ETA: 56s - loss: 4.8862 - acc: 0.00 - ETA: 56s - loss: 4.8865 - acc: 0.00 - ETA: 56s - loss: 4.8868 - acc: 0.00 - ETA: 56s - loss: 4.8868 - acc: 0.00 - ETA: 57s - loss: 4.8869 - acc: 0.00 - ETA: 55s - loss: 4.8871 - acc: 0.00 - ETA: 56s - loss: 4.8873 - acc: 0.00 - ETA: 56s - loss: 4.8874 - acc: 0.00 - ETA: 57s - loss: 4.8870 - acc: 0.00 - ETA: 56s - loss: 4.8869 - acc: 0.00 - ETA: 56s - loss: 4.8866 - acc: 0.00 - ETA: 56s - loss: 4.8868 - acc: 0.00 - ETA: 56s - loss: 4.8867 - acc: 0.00 - ETA: 55s - loss: 4.8869 - acc: 0.00 - ETA: 55s - loss: 4.8869 - acc: 0.00 - ETA: 55s - loss: 4.8869 - acc: 0.00 - ETA: 55s - loss: 4.8865 - acc: 0.00 - ETA: 54s - loss: 4.8865 - acc: 0.00 - ETA: 54s - loss: 4.8871 - acc: 0.00 - ETA: 54s - loss: 4.8872 - acc: 0.00 - ETA: 54s - loss: 4.8873 - acc: 0.00 - ETA: 54s - loss: 4.8872 - acc: 0.00 - ETA: 53s - loss: 4.8874 - acc: 0.00 - ETA: 53s - loss: 4.8873 - acc: 0.00 - ETA: 53s - loss: 4.8870 - acc: 0.00 - ETA: 52s - loss: 4.8872 - acc: 0.00 - ETA: 52s - loss: 4.8874 - acc: 0.00 - ETA: 52s - loss: 4.8875 - acc: 0.00 - ETA: 52s - loss: 4.8873 - acc: 0.00 - ETA: 52s - loss: 4.8873 - acc: 0.00 - ETA: 52s - loss: 4.8875 - acc: 0.00 - ETA: 52s - loss: 4.8874 - acc: 0.00 - ETA: 52s - loss: 4.8874 - acc: 0.00 - ETA: 51s - loss: 4.8874 - acc: 0.00 - ETA: 51s - loss: 4.8876 - acc: 0.00 - ETA: 51s - loss: 4.8878 - acc: 0.00 - ETA: 51s - loss: 4.8877 - acc: 0.00 - ETA: 50s - loss: 4.8879 - acc: 0.00 - ETA: 50s - loss: 4.8879 - acc: 0.00 - ETA: 50s - loss: 4.8877 - acc: 0.00 - ETA: 50s - loss: 4.8878 - acc: 0.00 - ETA: 49s - loss: 4.8879 - acc: 0.00 - ETA: 49s - loss: 4.8877 - acc: 0.00 - ETA: 49s - loss: 4.8877 - acc: 0.00 - ETA: 49s - loss: 4.8877 - acc: 0.00 - ETA: 49s - loss: 4.8878 - acc: 0.00 - ETA: 48s - loss: 4.8880 - acc: 0.00 - ETA: 48s - loss: 4.8877 - acc: 0.00 - ETA: 48s - loss: 4.8878 - acc: 0.00 - ETA: 48s - loss: 4.8877 - acc: 0.00 - ETA: 48s - loss: 4.8876 - acc: 0.00 - ETA: 47s - loss: 4.8875 - acc: 0.00 - ETA: 47s - loss: 4.8874 - acc: 0.00 - ETA: 47s - loss: 4.8874 - acc: 0.00 - ETA: 47s - loss: 4.8875 - acc: 0.00 - ETA: 47s - loss: 4.8877 - acc: 0.00 - ETA: 47s - loss: 4.8878 - acc: 0.00 - ETA: 46s - loss: 4.8877 - acc: 0.00 - ETA: 46s - loss: 4.8879 - acc: 0.00 - ETA: 46s - loss: 4.8878 - acc: 0.00 - ETA: 46s - loss: 4.8879 - acc: 0.00 - ETA: 46s - loss: 4.8879 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 45s - loss: 4.8879 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 45s - loss: 4.8879 - acc: 0.00 - ETA: 45s - loss: 4.8878 - acc: 0.00 - ETA: 44s - loss: 4.8878 - acc: 0.00 - ETA: 44s - loss: 4.8876 - acc: 0.00 - ETA: 44s - loss: 4.8877 - acc: 0.00 - ETA: 44s - loss: 4.8878 - acc: 0.00 - ETA: 44s - loss: 4.8876 - acc: 0.00 - ETA: 44s - loss: 4.8877 - acc: 0.00 - ETA: 44s - loss: 4.8879 - acc: 0.00 - ETA: 44s - loss: 4.8879 - acc: 0.00 - ETA: 43s - loss: 4.8879 - acc: 0.00 - ETA: 43s - loss: 4.8879 - acc: 0.00 - ETA: 43s - loss: 4.8880 - acc: 0.00 - ETA: 43s - loss: 4.8881 - acc: 0.00 - ETA: 43s - loss: 4.8881 - acc: 0.00 - ETA: 42s - loss: 4.8881 - acc: 0.00 - ETA: 42s - loss: 4.8880 - acc: 0.00 - ETA: 42s - loss: 4.8879 - acc: 0.00 - ETA: 42s - loss: 4.8877 - acc: 0.00 - ETA: 42s - loss: 4.8876 - acc: 0.00 - ETA: 42s - loss: 4.8877 - acc: 0.00 - ETA: 42s - loss: 4.8877 - acc: 0.00 - ETA: 41s - loss: 4.8878 - acc: 0.00 - ETA: 41s - loss: 4.8878 - acc: 0.00 - ETA: 41s - loss: 4.8877 - acc: 0.00 - ETA: 41s - loss: 4.8876 - acc: 0.00 - ETA: 41s - loss: 4.8874 - acc: 0.00 - ETA: 41s - loss: 4.8875 - acc: 0.00 - ETA: 41s - loss: 4.8874 - acc: 0.00 - ETA: 41s - loss: 4.8873 - acc: 0.00 - ETA: 40s - loss: 4.8874 - acc: 0.00 - ETA: 40s - loss: 4.8875 - acc: 0.00 - ETA: 40s - loss: 4.8875 - acc: 0.00 - ETA: 40s - loss: 4.8874 - acc: 0.00 - ETA: 40s - loss: 4.8875 - acc: 0.00 - ETA: 39s - loss: 4.8875 - acc: 0.00 - ETA: 39s - loss: 4.8874 - acc: 0.00 - ETA: 39s - loss: 4.8874 - acc: 0.00 - ETA: 39s - loss: 4.8876 - acc: 0.00 - ETA: 39s - loss: 4.8877 - acc: 0.00 - ETA: 38s - loss: 4.8877 - acc: 0.00 - ETA: 38s - loss: 4.8877 - acc: 0.00 - ETA: 38s - loss: 4.8877 - acc: 0.00 - ETA: 38s - loss: 4.8877 - acc: 0.00 - ETA: 38s - loss: 4.8877 - acc: 0.00 - ETA: 38s - loss: 4.8876 - acc: 0.00 - ETA: 37s - loss: 4.8875 - acc: 0.00 - ETA: 37s - loss: 4.8875 - acc: 0.00 - ETA: 37s - loss: 4.8874 - acc: 0.00 - ETA: 37s - loss: 4.8872 - acc: 0.00 - ETA: 37s - loss: 4.8872 - acc: 0.00 - ETA: 37s - loss: 4.8872 - acc: 0.00 - ETA: 36s - loss: 4.8872 - acc: 0.00 - ETA: 36s - loss: 4.8872 - acc: 0.00 - ETA: 36s - loss: 4.8873 - acc: 0.00 - ETA: 36s - loss: 4.8872 - acc: 0.00 - ETA: 36s - loss: 4.8873 - acc: 0.00 - ETA: 36s - loss: 4.8873 - acc: 0.00 - ETA: 36s - loss: 4.8874 - acc: 0.00 - ETA: 35s - loss: 4.8874 - acc: 0.00 - ETA: 35s - loss: 4.8876 - acc: 0.00 - ETA: 35s - loss: 4.8875 - acc: 0.00 - ETA: 35s - loss: 4.8877 - acc: 0.00 - ETA: 35s - loss: 4.8877 - acc: 0.00 - ETA: 35s - loss: 4.8877 - acc: 0.00 - ETA: 34s - loss: 4.8878 - acc: 0.00 - ETA: 34s - loss: 4.8878 - acc: 0.00 - ETA: 34s - loss: 4.8878 - acc: 0.00 - ETA: 34s - loss: 4.8879 - acc: 0.00 - ETA: 34s - loss: 4.8878 - acc: 0.00 - ETA: 34s - loss: 4.8877 - acc: 0.00 - ETA: 33s - loss: 4.8877 - acc: 0.00 - ETA: 33s - loss: 4.8876 - acc: 0.00 - ETA: 33s - loss: 4.8877 - acc: 0.00 - ETA: 33s - loss: 4.8877 - acc: 0.00 - ETA: 33s - loss: 4.8877 - acc: 0.00 - ETA: 33s - loss: 4.8876 - acc: 0.00 - ETA: 33s - loss: 4.8877 - acc: 0.00 - ETA: 32s - loss: 4.8878 - acc: 0.00 - ETA: 32s - loss: 4.8879 - acc: 0.00 - ETA: 32s - loss: 4.8881 - acc: 0.00 - ETA: 32s - loss: 4.8882 - acc: 0.00 - ETA: 32s - loss: 4.8883 - acc: 0.00 - ETA: 32s - loss: 4.8883 - acc: 0.00 - ETA: 31s - loss: 4.8883 - acc: 0.0091\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 31s - loss: 4.8884 - acc: 0.00 - ETA: 31s - loss: 4.8883 - acc: 0.00 - ETA: 31s - loss: 4.8882 - acc: 0.00 - ETA: 31s - loss: 4.8882 - acc: 0.00 - ETA: 31s - loss: 4.8882 - acc: 0.00 - ETA: 31s - loss: 4.8883 - acc: 0.00 - ETA: 30s - loss: 4.8883 - acc: 0.00 - ETA: 30s - loss: 4.8883 - acc: 0.00 - ETA: 30s - loss: 4.8883 - acc: 0.00 - ETA: 30s - loss: 4.8883 - acc: 0.00 - ETA: 30s - loss: 4.8882 - acc: 0.00 - ETA: 29s - loss: 4.8882 - acc: 0.00 - ETA: 29s - loss: 4.8883 - acc: 0.00 - ETA: 29s - loss: 4.8883 - acc: 0.00 - ETA: 29s - loss: 4.8882 - acc: 0.00 - ETA: 29s - loss: 4.8881 - acc: 0.00 - ETA: 29s - loss: 4.8880 - acc: 0.00 - ETA: 28s - loss: 4.8881 - acc: 0.00 - ETA: 28s - loss: 4.8881 - acc: 0.00 - ETA: 28s - loss: 4.8882 - acc: 0.00 - ETA: 28s - loss: 4.8882 - acc: 0.00 - ETA: 28s - loss: 4.8881 - acc: 0.00 - ETA: 28s - loss: 4.8882 - acc: 0.00 - ETA: 28s - loss: 4.8882 - acc: 0.00 - ETA: 27s - loss: 4.8881 - acc: 0.00 - ETA: 27s - loss: 4.8882 - acc: 0.00 - ETA: 27s - loss: 4.8882 - acc: 0.00 - ETA: 27s - loss: 4.8882 - acc: 0.00 - ETA: 27s - loss: 4.8883 - acc: 0.00 - ETA: 27s - loss: 4.8884 - acc: 0.00 - ETA: 26s - loss: 4.8885 - acc: 0.00 - ETA: 26s - loss: 4.8887 - acc: 0.00 - ETA: 26s - loss: 4.8887 - acc: 0.00 - ETA: 26s - loss: 4.8887 - acc: 0.00 - ETA: 26s - loss: 4.8887 - acc: 0.00 - ETA: 26s - loss: 4.8887 - acc: 0.00 - ETA: 26s - loss: 4.8887 - acc: 0.00 - ETA: 25s - loss: 4.8886 - acc: 0.00 - ETA: 25s - loss: 4.8887 - acc: 0.00 - ETA: 25s - loss: 4.8886 - acc: 0.00 - ETA: 25s - loss: 4.8887 - acc: 0.00 - ETA: 25s - loss: 4.8887 - acc: 0.00 - ETA: 25s - loss: 4.8886 - acc: 0.00 - ETA: 24s - loss: 4.8887 - acc: 0.00 - ETA: 24s - loss: 4.8888 - acc: 0.00 - ETA: 24s - loss: 4.8889 - acc: 0.00 - ETA: 24s - loss: 4.8888 - acc: 0.00 - ETA: 24s - loss: 4.8887 - acc: 0.00 - ETA: 24s - loss: 4.8887 - acc: 0.00 - ETA: 23s - loss: 4.8887 - acc: 0.00 - ETA: 23s - loss: 4.8887 - acc: 0.00 - ETA: 23s - loss: 4.8887 - acc: 0.00 - ETA: 23s - loss: 4.8886 - acc: 0.00 - ETA: 23s - loss: 4.8887 - acc: 0.00 - ETA: 23s - loss: 4.8887 - acc: 0.00 - ETA: 22s - loss: 4.8887 - acc: 0.00 - ETA: 22s - loss: 4.8887 - acc: 0.00 - ETA: 22s - loss: 4.8887 - acc: 0.00 - ETA: 22s - loss: 4.8888 - acc: 0.00 - ETA: 22s - loss: 4.8888 - acc: 0.00 - ETA: 22s - loss: 4.8887 - acc: 0.00 - ETA: 21s - loss: 4.8888 - acc: 0.00 - ETA: 21s - loss: 4.8889 - acc: 0.00 - ETA: 21s - loss: 4.8888 - acc: 0.00 - ETA: 21s - loss: 4.8888 - acc: 0.00 - ETA: 21s - loss: 4.8888 - acc: 0.00 - ETA: 21s - loss: 4.8888 - acc: 0.00 - ETA: 20s - loss: 4.8889 - acc: 0.00 - ETA: 20s - loss: 4.8889 - acc: 0.00 - ETA: 20s - loss: 4.8889 - acc: 0.00 - ETA: 20s - loss: 4.8889 - acc: 0.00 - ETA: 20s - loss: 4.8889 - acc: 0.00 - ETA: 20s - loss: 4.8889 - acc: 0.00 - ETA: 19s - loss: 4.8889 - acc: 0.00 - ETA: 19s - loss: 4.8887 - acc: 0.00 - ETA: 19s - loss: 4.8888 - acc: 0.00 - ETA: 19s - loss: 4.8888 - acc: 0.00 - ETA: 19s - loss: 4.8887 - acc: 0.00 - ETA: 19s - loss: 4.8887 - acc: 0.00 - ETA: 18s - loss: 4.8886 - acc: 0.00 - ETA: 18s - loss: 4.8886 - acc: 0.00 - ETA: 18s - loss: 4.8886 - acc: 0.00 - ETA: 18s - loss: 4.8886 - acc: 0.00 - ETA: 18s - loss: 4.8886 - acc: 0.00 - ETA: 18s - loss: 4.8886 - acc: 0.00 - ETA: 18s - loss: 4.8887 - acc: 0.00 - ETA: 17s - loss: 4.8888 - acc: 0.00 - ETA: 17s - loss: 4.8888 - acc: 0.00 - ETA: 17s - loss: 4.8888 - acc: 0.00 - ETA: 17s - loss: 4.8889 - acc: 0.00 - ETA: 17s - loss: 4.8889 - acc: 0.00 - ETA: 17s - loss: 4.8889 - acc: 0.00 - ETA: 16s - loss: 4.8890 - acc: 0.00 - ETA: 16s - loss: 4.8891 - acc: 0.00 - ETA: 16s - loss: 4.8889 - acc: 0.00 - ETA: 16s - loss: 4.8889 - acc: 0.00 - ETA: 16s - loss: 4.8889 - acc: 0.00 - ETA: 16s - loss: 4.8888 - acc: 0.00 - ETA: 16s - loss: 4.8887 - acc: 0.00 - ETA: 15s - loss: 4.8888 - acc: 0.00 - ETA: 15s - loss: 4.8887 - acc: 0.00 - ETA: 15s - loss: 4.8887 - acc: 0.00 - ETA: 15s - loss: 4.8886 - acc: 0.00 - ETA: 15s - loss: 4.8886 - acc: 0.00 - ETA: 15s - loss: 4.8887 - acc: 0.00 - ETA: 14s - loss: 4.8887 - acc: 0.00 - ETA: 14s - loss: 4.8887 - acc: 0.00 - ETA: 14s - loss: 4.8887 - acc: 0.00 - ETA: 14s - loss: 4.8886 - acc: 0.00 - ETA: 14s - loss: 4.8887 - acc: 0.00 - ETA: 14s - loss: 4.8886 - acc: 0.00 - ETA: 14s - loss: 4.8886 - acc: 0.00 - ETA: 13s - loss: 4.8885 - acc: 0.00 - ETA: 13s - loss: 4.8885 - acc: 0.00 - ETA: 13s - loss: 4.8885 - acc: 0.00 - ETA: 13s - loss: 4.8885 - acc: 0.00 - ETA: 13s - loss: 4.8885 - acc: 0.00 - ETA: 13s - loss: 4.8885 - acc: 0.00 - ETA: 12s - loss: 4.8885 - acc: 0.00 - ETA: 12s - loss: 4.8885 - acc: 0.00 - ETA: 12s - loss: 4.8886 - acc: 0.00 - ETA: 12s - loss: 4.8886 - acc: 0.00 - ETA: 12s - loss: 4.8886 - acc: 0.00 - ETA: 12s - loss: 4.8886 - acc: 0.00 - ETA: 11s - loss: 4.8887 - acc: 0.00 - ETA: 11s - loss: 4.8888 - acc: 0.00 - ETA: 11s - loss: 4.8888 - acc: 0.00 - ETA: 11s - loss: 4.8888 - acc: 0.00 - ETA: 11s - loss: 4.8888 - acc: 0.00 - ETA: 11s - loss: 4.8887 - acc: 0.00 - ETA: 11s - loss: 4.8888 - acc: 0.00 - ETA: 10s - loss: 4.8888 - acc: 0.00 - ETA: 10s - loss: 4.8888 - acc: 0.00 - ETA: 10s - loss: 4.8888 - acc: 0.00 - ETA: 10s - loss: 4.8888 - acc: 0.00 - ETA: 10s - loss: 4.8888 - acc: 0.00 - ETA: 10s - loss: 4.8887 - acc: 0.00 - ETA: 9s - loss: 4.8887 - acc: 0.0087 - ETA: 9s - loss: 4.8888 - acc: 0.008 - ETA: 9s - loss: 4.8888 - acc: 0.008 - ETA: 9s - loss: 4.8888 - acc: 0.008 - ETA: 9s - loss: 4.8887 - acc: 0.008 - ETA: 9s - loss: 4.8886 - acc: 0.008 - ETA: 9s - loss: 4.8887 - acc: 0.008 - ETA: 8s - loss: 4.8886 - acc: 0.008 - ETA: 8s - loss: 4.8886 - acc: 0.008 - ETA: 8s - loss: 4.8887 - acc: 0.008 - ETA: 8s - loss: 4.8887 - acc: 0.008 - ETA: 8s - loss: 4.8887 - acc: 0.008 - ETA: 8s - loss: 4.8887 - acc: 0.008 - ETA: 8s - loss: 4.8886 - acc: 0.008 - ETA: 7s - loss: 4.8886 - acc: 0.008 - ETA: 7s - loss: 4.8886 - acc: 0.008 - ETA: 7s - loss: 4.8886 - acc: 0.008 - ETA: 7s - loss: 4.8887 - acc: 0.008 - ETA: 7s - loss: 4.8888 - acc: 0.008 - ETA: 6s - loss: 4.8888 - acc: 0.008 - ETA: 6s - loss: 4.8888 - acc: 0.008 - ETA: 6s - loss: 4.8888 - acc: 0.008 - ETA: 6s - loss: 4.8889 - acc: 0.008 - ETA: 6s - loss: 4.8890 - acc: 0.008 - ETA: 6s - loss: 4.8889 - acc: 0.008 - ETA: 5s - loss: 4.8890 - acc: 0.008 - ETA: 5s - loss: 4.8889 - acc: 0.008 - ETA: 5s - loss: 4.8890 - acc: 0.008 - ETA: 5s - loss: 4.8890 - acc: 0.008 - ETA: 5s - loss: 4.8890 - acc: 0.008 - ETA: 5s - loss: 4.8890 - acc: 0.008 - ETA: 5s - loss: 4.8890 - acc: 0.008 - ETA: 4s - loss: 4.8890 - acc: 0.008 - ETA: 4s - loss: 4.8890 - acc: 0.008 - ETA: 4s - loss: 4.8890 - acc: 0.008 - ETA: 4s - loss: 4.8890 - acc: 0.008 - ETA: 4s - loss: 4.8889 - acc: 0.008 - ETA: 4s - loss: 4.8889 - acc: 0.008 - ETA: 3s - loss: 4.8889 - acc: 0.008 - ETA: 3s - loss: 4.8888 - acc: 0.008 - ETA: 3s - loss: 4.8888 - acc: 0.008 - ETA: 3s - loss: 4.8888 - acc: 0.008 - ETA: 3s - loss: 4.8888 - acc: 0.008 - ETA: 3s - loss: 4.8888 - acc: 0.008 - ETA: 3s - loss: 4.8888 - acc: 0.008 - ETA: 2s - loss: 4.8889 - acc: 0.008 - ETA: 2s - loss: 4.8890 - acc: 0.008 - ETA: 2s - loss: 4.8890 - acc: 0.008 - ETA: 2s - loss: 4.8890 - acc: 0.008 - ETA: 2s - loss: 4.8889 - acc: 0.008 - ETA: 2s - loss: 4.8889 - acc: 0.008 - ETA: 1s - loss: 4.8889 - acc: 0.008 - ETA: 1s - loss: 4.8890 - acc: 0.008 - ETA: 1s - loss: 4.8890 - acc: 0.008 - ETA: 1s - loss: 4.8890 - acc: 0.008 - ETA: 1s - loss: 4.8890 - acc: 0.008 - ETA: 1s - loss: 4.8889 - acc: 0.008 - ETA: 0s - loss: 4.8889 - acc: 0.008 - ETA: 0s - loss: 4.8889 - acc: 0.008 - ETA: 0s - loss: 4.8890 - acc: 0.008 - ETA: 0s - loss: 4.8889 - acc: 0.008 - ETA: 0s - loss: 4.8890 - acc: 0.008 - ETA: 0s - loss: 4.8890 - acc: 0.008 - 70s 168ms/step - loss: 4.8890 - acc: 0.0085 - val_loss: 4.8862 - val_acc: 0.0073\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.88618, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 6s - loss: 4.8723 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8761 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8865 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8842 - acc: 0.0052    - ETA: 11s - loss: 4.8818 - acc: 0.00 - ETA: 13s - loss: 4.8831 - acc: 0.00 - ETA: 16s - loss: 4.8818 - acc: 0.01 - ETA: 18s - loss: 4.8828 - acc: 0.01 - ETA: 21s - loss: 4.8829 - acc: 0.01 - ETA: 29s - loss: 4.8834 - acc: 0.01 - ETA: 29s - loss: 4.8837 - acc: 0.00 - ETA: 30s - loss: 4.8849 - acc: 0.00 - ETA: 30s - loss: 4.8849 - acc: 0.00 - ETA: 33s - loss: 4.8855 - acc: 0.00 - ETA: 33s - loss: 4.8858 - acc: 0.00 - ETA: 34s - loss: 4.8859 - acc: 0.00 - ETA: 35s - loss: 4.8871 - acc: 0.00 - ETA: 35s - loss: 4.8859 - acc: 0.00 - ETA: 36s - loss: 4.8862 - acc: 0.01 - ETA: 38s - loss: 4.8864 - acc: 0.01 - ETA: 39s - loss: 4.8860 - acc: 0.01 - ETA: 39s - loss: 4.8865 - acc: 0.01 - ETA: 39s - loss: 4.8867 - acc: 0.01 - ETA: 39s - loss: 4.8874 - acc: 0.00 - ETA: 40s - loss: 4.8883 - acc: 0.00 - ETA: 42s - loss: 4.8877 - acc: 0.00 - ETA: 42s - loss: 4.8874 - acc: 0.01 - ETA: 43s - loss: 4.8869 - acc: 0.01 - ETA: 43s - loss: 4.8870 - acc: 0.01 - ETA: 43s - loss: 4.8877 - acc: 0.00 - ETA: 43s - loss: 4.8883 - acc: 0.00 - ETA: 43s - loss: 4.8883 - acc: 0.01 - ETA: 43s - loss: 4.8882 - acc: 0.01 - ETA: 44s - loss: 4.8879 - acc: 0.01 - ETA: 45s - loss: 4.8878 - acc: 0.01 - ETA: 45s - loss: 4.8874 - acc: 0.01 - ETA: 45s - loss: 4.8873 - acc: 0.01 - ETA: 45s - loss: 4.8877 - acc: 0.01 - ETA: 45s - loss: 4.8878 - acc: 0.01 - ETA: 45s - loss: 4.8877 - acc: 0.01 - ETA: 45s - loss: 4.8878 - acc: 0.01 - ETA: 45s - loss: 4.8877 - acc: 0.01 - ETA: 45s - loss: 4.8877 - acc: 0.00 - ETA: 45s - loss: 4.8874 - acc: 0.00 - ETA: 45s - loss: 4.8877 - acc: 0.00 - ETA: 45s - loss: 4.8878 - acc: 0.00 - ETA: 45s - loss: 4.8876 - acc: 0.00 - ETA: 45s - loss: 4.8878 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 45s - loss: 4.8882 - acc: 0.00 - ETA: 45s - loss: 4.8877 - acc: 0.00 - ETA: 45s - loss: 4.8877 - acc: 0.00 - ETA: 45s - loss: 4.8877 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 45s - loss: 4.8879 - acc: 0.00 - ETA: 46s - loss: 4.8881 - acc: 0.00 - ETA: 45s - loss: 4.8884 - acc: 0.00 - ETA: 45s - loss: 4.8887 - acc: 0.00 - ETA: 45s - loss: 4.8893 - acc: 0.00 - ETA: 45s - loss: 4.8897 - acc: 0.00 - ETA: 46s - loss: 4.8894 - acc: 0.00 - ETA: 45s - loss: 4.8893 - acc: 0.00 - ETA: 45s - loss: 4.8895 - acc: 0.00 - ETA: 45s - loss: 4.8894 - acc: 0.00 - ETA: 45s - loss: 4.8894 - acc: 0.00 - ETA: 45s - loss: 4.8895 - acc: 0.00 - ETA: 45s - loss: 4.8894 - acc: 0.00 - ETA: 45s - loss: 4.8894 - acc: 0.00 - ETA: 45s - loss: 4.8893 - acc: 0.00 - ETA: 45s - loss: 4.8892 - acc: 0.00 - ETA: 45s - loss: 4.8894 - acc: 0.00 - ETA: 45s - loss: 4.8890 - acc: 0.00 - ETA: 45s - loss: 4.8889 - acc: 0.00 - ETA: 45s - loss: 4.8887 - acc: 0.00 - ETA: 45s - loss: 4.8888 - acc: 0.00 - ETA: 45s - loss: 4.8889 - acc: 0.00 - ETA: 45s - loss: 4.8887 - acc: 0.00 - ETA: 45s - loss: 4.8885 - acc: 0.00 - ETA: 45s - loss: 4.8882 - acc: 0.00 - ETA: 45s - loss: 4.8882 - acc: 0.00 - ETA: 45s - loss: 4.8881 - acc: 0.00 - ETA: 46s - loss: 4.8879 - acc: 0.00 - ETA: 46s - loss: 4.8879 - acc: 0.00 - ETA: 46s - loss: 4.8880 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 46s - loss: 4.8879 - acc: 0.00 - ETA: 45s - loss: 4.8879 - acc: 0.00 - ETA: 45s - loss: 4.8880 - acc: 0.00 - ETA: 46s - loss: 4.8879 - acc: 0.00 - ETA: 46s - loss: 4.8878 - acc: 0.00 - ETA: 46s - loss: 4.8877 - acc: 0.00 - ETA: 46s - loss: 4.8877 - acc: 0.00 - ETA: 46s - loss: 4.8877 - acc: 0.00 - ETA: 46s - loss: 4.8875 - acc: 0.00 - ETA: 46s - loss: 4.8875 - acc: 0.00 - ETA: 45s - loss: 4.8877 - acc: 0.00 - ETA: 45s - loss: 4.8876 - acc: 0.00 - ETA: 45s - loss: 4.8876 - acc: 0.00 - ETA: 45s - loss: 4.8876 - acc: 0.00 - ETA: 45s - loss: 4.8875 - acc: 0.00 - ETA: 44s - loss: 4.8873 - acc: 0.00 - ETA: 44s - loss: 4.8872 - acc: 0.00 - ETA: 44s - loss: 4.8875 - acc: 0.00 - ETA: 44s - loss: 4.8876 - acc: 0.00 - ETA: 44s - loss: 4.8876 - acc: 0.00 - ETA: 44s - loss: 4.8877 - acc: 0.00 - ETA: 44s - loss: 4.8873 - acc: 0.00 - ETA: 44s - loss: 4.8873 - acc: 0.00 - ETA: 44s - loss: 4.8873 - acc: 0.00 - ETA: 44s - loss: 4.8876 - acc: 0.00 - ETA: 43s - loss: 4.8876 - acc: 0.00 - ETA: 43s - loss: 4.8877 - acc: 0.00 - ETA: 43s - loss: 4.8879 - acc: 0.00 - ETA: 43s - loss: 4.8879 - acc: 0.00 - ETA: 43s - loss: 4.8879 - acc: 0.00 - ETA: 43s - loss: 4.8882 - acc: 0.00 - ETA: 43s - loss: 4.8882 - acc: 0.00 - ETA: 43s - loss: 4.8882 - acc: 0.00 - ETA: 43s - loss: 4.8880 - acc: 0.00 - ETA: 43s - loss: 4.8880 - acc: 0.00 - ETA: 42s - loss: 4.8882 - acc: 0.00 - ETA: 42s - loss: 4.8882 - acc: 0.00 - ETA: 42s - loss: 4.8883 - acc: 0.00 - ETA: 42s - loss: 4.8884 - acc: 0.00 - ETA: 42s - loss: 4.8882 - acc: 0.00 - ETA: 42s - loss: 4.8883 - acc: 0.00 - ETA: 42s - loss: 4.8883 - acc: 0.00 - ETA: 42s - loss: 4.8884 - acc: 0.00 - ETA: 42s - loss: 4.8883 - acc: 0.00 - ETA: 41s - loss: 4.8884 - acc: 0.00 - ETA: 41s - loss: 4.8884 - acc: 0.00 - ETA: 41s - loss: 4.8884 - acc: 0.00 - ETA: 41s - loss: 4.8884 - acc: 0.00 - ETA: 41s - loss: 4.8884 - acc: 0.00 - ETA: 41s - loss: 4.8885 - acc: 0.00 - ETA: 41s - loss: 4.8887 - acc: 0.00 - ETA: 41s - loss: 4.8888 - acc: 0.00 - ETA: 40s - loss: 4.8887 - acc: 0.00 - ETA: 40s - loss: 4.8887 - acc: 0.00 - ETA: 40s - loss: 4.8889 - acc: 0.00 - ETA: 40s - loss: 4.8888 - acc: 0.00 - ETA: 40s - loss: 4.8889 - acc: 0.00 - ETA: 40s - loss: 4.8891 - acc: 0.00 - ETA: 40s - loss: 4.8890 - acc: 0.00 - ETA: 39s - loss: 4.8890 - acc: 0.00 - ETA: 39s - loss: 4.8888 - acc: 0.00 - ETA: 39s - loss: 4.8888 - acc: 0.00 - ETA: 39s - loss: 4.8889 - acc: 0.00 - ETA: 39s - loss: 4.8887 - acc: 0.00 - ETA: 39s - loss: 4.8887 - acc: 0.00 - ETA: 39s - loss: 4.8887 - acc: 0.00 - ETA: 39s - loss: 4.8887 - acc: 0.00 - ETA: 39s - loss: 4.8888 - acc: 0.00 - ETA: 39s - loss: 4.8888 - acc: 0.00 - ETA: 38s - loss: 4.8889 - acc: 0.00 - ETA: 38s - loss: 4.8890 - acc: 0.00 - ETA: 38s - loss: 4.8891 - acc: 0.00 - ETA: 38s - loss: 4.8890 - acc: 0.00 - ETA: 38s - loss: 4.8890 - acc: 0.00 - ETA: 37s - loss: 4.8891 - acc: 0.00 - ETA: 37s - loss: 4.8891 - acc: 0.00 - ETA: 37s - loss: 4.8891 - acc: 0.00 - ETA: 37s - loss: 4.8891 - acc: 0.00 - ETA: 37s - loss: 4.8891 - acc: 0.00 - ETA: 37s - loss: 4.8892 - acc: 0.00 - ETA: 36s - loss: 4.8892 - acc: 0.00 - ETA: 36s - loss: 4.8892 - acc: 0.00 - ETA: 36s - loss: 4.8892 - acc: 0.00 - ETA: 36s - loss: 4.8891 - acc: 0.00 - ETA: 36s - loss: 4.8891 - acc: 0.00 - ETA: 36s - loss: 4.8891 - acc: 0.00 - ETA: 36s - loss: 4.8890 - acc: 0.00 - ETA: 36s - loss: 4.8891 - acc: 0.00 - ETA: 35s - loss: 4.8892 - acc: 0.00 - ETA: 35s - loss: 4.8891 - acc: 0.00 - ETA: 35s - loss: 4.8891 - acc: 0.00 - ETA: 35s - loss: 4.8891 - acc: 0.00 - ETA: 35s - loss: 4.8890 - acc: 0.01 - ETA: 35s - loss: 4.8890 - acc: 0.01 - ETA: 34s - loss: 4.8887 - acc: 0.01 - ETA: 34s - loss: 4.8886 - acc: 0.01 - ETA: 34s - loss: 4.8887 - acc: 0.01 - ETA: 34s - loss: 4.8887 - acc: 0.01 - ETA: 34s - loss: 4.8886 - acc: 0.01 - ETA: 34s - loss: 4.8885 - acc: 0.01 - ETA: 34s - loss: 4.8886 - acc: 0.01 - ETA: 34s - loss: 4.8885 - acc: 0.01 - ETA: 33s - loss: 4.8886 - acc: 0.01 - ETA: 33s - loss: 4.8885 - acc: 0.01 - ETA: 33s - loss: 4.8885 - acc: 0.01 - ETA: 33s - loss: 4.8887 - acc: 0.01 - ETA: 33s - loss: 4.8886 - acc: 0.01 - ETA: 33s - loss: 4.8886 - acc: 0.01 - ETA: 33s - loss: 4.8885 - acc: 0.01 - ETA: 32s - loss: 4.8885 - acc: 0.01 - ETA: 32s - loss: 4.8886 - acc: 0.01 - ETA: 32s - loss: 4.8886 - acc: 0.01 - ETA: 32s - loss: 4.8884 - acc: 0.01 - ETA: 32s - loss: 4.8883 - acc: 0.01 - ETA: 32s - loss: 4.8884 - acc: 0.01 - ETA: 32s - loss: 4.8883 - acc: 0.01 - ETA: 31s - loss: 4.8882 - acc: 0.01 - ETA: 31s - loss: 4.8881 - acc: 0.01 - ETA: 31s - loss: 4.8880 - acc: 0.01 - ETA: 31s - loss: 4.8879 - acc: 0.01 - ETA: 31s - loss: 4.8878 - acc: 0.01 - ETA: 31s - loss: 4.8879 - acc: 0.01 - ETA: 30s - loss: 4.8880 - acc: 0.01 - ETA: 30s - loss: 4.8881 - acc: 0.01 - ETA: 30s - loss: 4.8882 - acc: 0.01 - ETA: 30s - loss: 4.8880 - acc: 0.01 - ETA: 30s - loss: 4.8880 - acc: 0.01 - ETA: 30s - loss: 4.8881 - acc: 0.01 - ETA: 29s - loss: 4.8880 - acc: 0.0118"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 29s - loss: 4.8881 - acc: 0.01 - ETA: 29s - loss: 4.8882 - acc: 0.01 - ETA: 29s - loss: 4.8882 - acc: 0.01 - ETA: 29s - loss: 4.8881 - acc: 0.01 - ETA: 29s - loss: 4.8880 - acc: 0.01 - ETA: 28s - loss: 4.8880 - acc: 0.01 - ETA: 28s - loss: 4.8880 - acc: 0.01 - ETA: 28s - loss: 4.8881 - acc: 0.01 - ETA: 28s - loss: 4.8880 - acc: 0.01 - ETA: 28s - loss: 4.8880 - acc: 0.01 - ETA: 27s - loss: 4.8880 - acc: 0.01 - ETA: 27s - loss: 4.8880 - acc: 0.01 - ETA: 27s - loss: 4.8879 - acc: 0.01 - ETA: 27s - loss: 4.8880 - acc: 0.01 - ETA: 27s - loss: 4.8878 - acc: 0.01 - ETA: 27s - loss: 4.8879 - acc: 0.01 - ETA: 27s - loss: 4.8879 - acc: 0.01 - ETA: 27s - loss: 4.8879 - acc: 0.01 - ETA: 26s - loss: 4.8878 - acc: 0.01 - ETA: 26s - loss: 4.8878 - acc: 0.01 - ETA: 26s - loss: 4.8877 - acc: 0.01 - ETA: 26s - loss: 4.8876 - acc: 0.01 - ETA: 26s - loss: 4.8876 - acc: 0.01 - ETA: 26s - loss: 4.8877 - acc: 0.01 - ETA: 25s - loss: 4.8876 - acc: 0.01 - ETA: 25s - loss: 4.8876 - acc: 0.01 - ETA: 25s - loss: 4.8875 - acc: 0.01 - ETA: 25s - loss: 4.8875 - acc: 0.01 - ETA: 25s - loss: 4.8875 - acc: 0.01 - ETA: 25s - loss: 4.8875 - acc: 0.01 - ETA: 24s - loss: 4.8876 - acc: 0.01 - ETA: 24s - loss: 4.8875 - acc: 0.01 - ETA: 24s - loss: 4.8876 - acc: 0.01 - ETA: 24s - loss: 4.8876 - acc: 0.01 - ETA: 24s - loss: 4.8876 - acc: 0.01 - ETA: 24s - loss: 4.8876 - acc: 0.01 - ETA: 23s - loss: 4.8876 - acc: 0.01 - ETA: 23s - loss: 4.8876 - acc: 0.01 - ETA: 23s - loss: 4.8877 - acc: 0.01 - ETA: 23s - loss: 4.8877 - acc: 0.01 - ETA: 23s - loss: 4.8876 - acc: 0.01 - ETA: 23s - loss: 4.8875 - acc: 0.01 - ETA: 23s - loss: 4.8875 - acc: 0.01 - ETA: 22s - loss: 4.8874 - acc: 0.01 - ETA: 22s - loss: 4.8873 - acc: 0.01 - ETA: 22s - loss: 4.8873 - acc: 0.01 - ETA: 22s - loss: 4.8874 - acc: 0.01 - ETA: 22s - loss: 4.8875 - acc: 0.01 - ETA: 22s - loss: 4.8874 - acc: 0.01 - ETA: 22s - loss: 4.8874 - acc: 0.01 - ETA: 21s - loss: 4.8875 - acc: 0.01 - ETA: 21s - loss: 4.8874 - acc: 0.01 - ETA: 21s - loss: 4.8873 - acc: 0.01 - ETA: 21s - loss: 4.8873 - acc: 0.01 - ETA: 21s - loss: 4.8873 - acc: 0.01 - ETA: 21s - loss: 4.8873 - acc: 0.01 - ETA: 21s - loss: 4.8871 - acc: 0.01 - ETA: 20s - loss: 4.8871 - acc: 0.01 - ETA: 20s - loss: 4.8871 - acc: 0.01 - ETA: 20s - loss: 4.8871 - acc: 0.01 - ETA: 20s - loss: 4.8872 - acc: 0.01 - ETA: 20s - loss: 4.8872 - acc: 0.01 - ETA: 20s - loss: 4.8873 - acc: 0.01 - ETA: 20s - loss: 4.8874 - acc: 0.01 - ETA: 19s - loss: 4.8874 - acc: 0.01 - ETA: 19s - loss: 4.8873 - acc: 0.01 - ETA: 19s - loss: 4.8873 - acc: 0.01 - ETA: 19s - loss: 4.8873 - acc: 0.01 - ETA: 19s - loss: 4.8873 - acc: 0.01 - ETA: 19s - loss: 4.8873 - acc: 0.01 - ETA: 18s - loss: 4.8873 - acc: 0.01 - ETA: 18s - loss: 4.8872 - acc: 0.01 - ETA: 18s - loss: 4.8872 - acc: 0.01 - ETA: 18s - loss: 4.8872 - acc: 0.01 - ETA: 18s - loss: 4.8873 - acc: 0.01 - ETA: 18s - loss: 4.8874 - acc: 0.01 - ETA: 18s - loss: 4.8874 - acc: 0.01 - ETA: 17s - loss: 4.8874 - acc: 0.01 - ETA: 17s - loss: 4.8874 - acc: 0.01 - ETA: 17s - loss: 4.8874 - acc: 0.01 - ETA: 17s - loss: 4.8874 - acc: 0.01 - ETA: 17s - loss: 4.8874 - acc: 0.01 - ETA: 17s - loss: 4.8874 - acc: 0.01 - ETA: 16s - loss: 4.8875 - acc: 0.01 - ETA: 16s - loss: 4.8875 - acc: 0.01 - ETA: 16s - loss: 4.8874 - acc: 0.01 - ETA: 16s - loss: 4.8875 - acc: 0.01 - ETA: 16s - loss: 4.8875 - acc: 0.01 - ETA: 16s - loss: 4.8874 - acc: 0.01 - ETA: 15s - loss: 4.8874 - acc: 0.01 - ETA: 15s - loss: 4.8873 - acc: 0.01 - ETA: 15s - loss: 4.8873 - acc: 0.01 - ETA: 15s - loss: 4.8873 - acc: 0.01 - ETA: 15s - loss: 4.8873 - acc: 0.01 - ETA: 15s - loss: 4.8872 - acc: 0.01 - ETA: 15s - loss: 4.8871 - acc: 0.01 - ETA: 14s - loss: 4.8870 - acc: 0.01 - ETA: 14s - loss: 4.8870 - acc: 0.01 - ETA: 14s - loss: 4.8870 - acc: 0.01 - ETA: 14s - loss: 4.8870 - acc: 0.01 - ETA: 14s - loss: 4.8870 - acc: 0.01 - ETA: 14s - loss: 4.8869 - acc: 0.01 - ETA: 13s - loss: 4.8869 - acc: 0.01 - ETA: 13s - loss: 4.8868 - acc: 0.01 - ETA: 13s - loss: 4.8868 - acc: 0.01 - ETA: 13s - loss: 4.8868 - acc: 0.01 - ETA: 13s - loss: 4.8868 - acc: 0.01 - ETA: 13s - loss: 4.8870 - acc: 0.01 - ETA: 13s - loss: 4.8869 - acc: 0.01 - ETA: 12s - loss: 4.8869 - acc: 0.01 - ETA: 12s - loss: 4.8869 - acc: 0.01 - ETA: 12s - loss: 4.8869 - acc: 0.01 - ETA: 12s - loss: 4.8869 - acc: 0.01 - ETA: 12s - loss: 4.8868 - acc: 0.01 - ETA: 12s - loss: 4.8868 - acc: 0.01 - ETA: 11s - loss: 4.8869 - acc: 0.01 - ETA: 11s - loss: 4.8868 - acc: 0.01 - ETA: 11s - loss: 4.8868 - acc: 0.01 - ETA: 11s - loss: 4.8868 - acc: 0.01 - ETA: 11s - loss: 4.8867 - acc: 0.01 - ETA: 11s - loss: 4.8868 - acc: 0.01 - ETA: 10s - loss: 4.8868 - acc: 0.01 - ETA: 10s - loss: 4.8867 - acc: 0.01 - ETA: 10s - loss: 4.8868 - acc: 0.01 - ETA: 10s - loss: 4.8869 - acc: 0.01 - ETA: 10s - loss: 4.8868 - acc: 0.01 - ETA: 10s - loss: 4.8868 - acc: 0.01 - ETA: 10s - loss: 4.8868 - acc: 0.01 - ETA: 9s - loss: 4.8868 - acc: 0.0113 - ETA: 9s - loss: 4.8868 - acc: 0.011 - ETA: 9s - loss: 4.8867 - acc: 0.011 - ETA: 9s - loss: 4.8867 - acc: 0.011 - ETA: 9s - loss: 4.8867 - acc: 0.011 - ETA: 9s - loss: 4.8867 - acc: 0.011 - ETA: 8s - loss: 4.8867 - acc: 0.011 - ETA: 8s - loss: 4.8867 - acc: 0.011 - ETA: 8s - loss: 4.8867 - acc: 0.011 - ETA: 8s - loss: 4.8868 - acc: 0.011 - ETA: 8s - loss: 4.8868 - acc: 0.011 - ETA: 8s - loss: 4.8869 - acc: 0.011 - ETA: 8s - loss: 4.8869 - acc: 0.011 - ETA: 7s - loss: 4.8869 - acc: 0.011 - ETA: 7s - loss: 4.8869 - acc: 0.011 - ETA: 7s - loss: 4.8870 - acc: 0.011 - ETA: 7s - loss: 4.8870 - acc: 0.011 - ETA: 7s - loss: 4.8871 - acc: 0.011 - ETA: 7s - loss: 4.8870 - acc: 0.011 - ETA: 6s - loss: 4.8870 - acc: 0.011 - ETA: 6s - loss: 4.8870 - acc: 0.011 - ETA: 6s - loss: 4.8870 - acc: 0.011 - ETA: 6s - loss: 4.8871 - acc: 0.011 - ETA: 6s - loss: 4.8871 - acc: 0.011 - ETA: 6s - loss: 4.8871 - acc: 0.011 - ETA: 6s - loss: 4.8871 - acc: 0.011 - ETA: 5s - loss: 4.8871 - acc: 0.011 - ETA: 5s - loss: 4.8870 - acc: 0.011 - ETA: 5s - loss: 4.8869 - acc: 0.011 - ETA: 5s - loss: 4.8869 - acc: 0.011 - ETA: 5s - loss: 4.8870 - acc: 0.011 - ETA: 5s - loss: 4.8870 - acc: 0.011 - ETA: 5s - loss: 4.8870 - acc: 0.011 - ETA: 4s - loss: 4.8869 - acc: 0.011 - ETA: 4s - loss: 4.8868 - acc: 0.011 - ETA: 4s - loss: 4.8868 - acc: 0.011 - ETA: 4s - loss: 4.8867 - acc: 0.012 - ETA: 4s - loss: 4.8867 - acc: 0.012 - ETA: 4s - loss: 4.8867 - acc: 0.012 - ETA: 3s - loss: 4.8866 - acc: 0.012 - ETA: 3s - loss: 4.8867 - acc: 0.011 - ETA: 3s - loss: 4.8867 - acc: 0.011 - ETA: 3s - loss: 4.8868 - acc: 0.011 - ETA: 3s - loss: 4.8867 - acc: 0.011 - ETA: 3s - loss: 4.8867 - acc: 0.012 - ETA: 2s - loss: 4.8866 - acc: 0.011 - ETA: 2s - loss: 4.8866 - acc: 0.011 - ETA: 2s - loss: 4.8866 - acc: 0.011 - ETA: 2s - loss: 4.8866 - acc: 0.012 - ETA: 2s - loss: 4.8866 - acc: 0.012 - ETA: 2s - loss: 4.8866 - acc: 0.011 - ETA: 2s - loss: 4.8867 - acc: 0.011 - ETA: 1s - loss: 4.8867 - acc: 0.011 - ETA: 1s - loss: 4.8867 - acc: 0.011 - ETA: 1s - loss: 4.8868 - acc: 0.011 - ETA: 1s - loss: 4.8867 - acc: 0.011 - ETA: 1s - loss: 4.8867 - acc: 0.011 - ETA: 1s - loss: 4.8868 - acc: 0.011 - ETA: 0s - loss: 4.8868 - acc: 0.012 - ETA: 0s - loss: 4.8867 - acc: 0.012 - ETA: 0s - loss: 4.8868 - acc: 0.012 - ETA: 0s - loss: 4.8868 - acc: 0.012 - ETA: 0s - loss: 4.8868 - acc: 0.012 - ETA: 0s - loss: 4.8869 - acc: 0.012 - 69s 166ms/step - loss: 4.8869 - acc: 0.0120 - val_loss: 4.8865 - val_acc: 0.0061\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.88618\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 4s - loss: 4.8859 - acc: 0.0000e+0 - ETA: 5s - loss: 4.8674 - acc: 0.0000e+0 - ETA: 5s - loss: 4.8743 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8795 - acc: 0.0052    - ETA: 12s - loss: 4.8814 - acc: 0.00 - ETA: 14s - loss: 4.8817 - acc: 0.00 - ETA: 17s - loss: 4.8851 - acc: 0.00 - ETA: 20s - loss: 4.8856 - acc: 0.00 - ETA: 25s - loss: 4.8839 - acc: 0.00 - ETA: 27s - loss: 4.8838 - acc: 0.00 - ETA: 33s - loss: 4.8853 - acc: 0.00 - ETA: 36s - loss: 4.8857 - acc: 0.00 - ETA: 36s - loss: 4.8848 - acc: 0.00 - ETA: 39s - loss: 4.8850 - acc: 0.00 - ETA: 40s - loss: 4.8847 - acc: 0.00 - ETA: 40s - loss: 4.8851 - acc: 0.00 - ETA: 40s - loss: 4.8860 - acc: 0.00 - ETA: 40s - loss: 4.8857 - acc: 0.00 - ETA: 41s - loss: 4.8845 - acc: 0.00 - ETA: 42s - loss: 4.8861 - acc: 0.00 - ETA: 42s - loss: 4.8857 - acc: 0.00 - ETA: 43s - loss: 4.8853 - acc: 0.00 - ETA: 46s - loss: 4.8844 - acc: 0.00 - ETA: 47s - loss: 4.8842 - acc: 0.00 - ETA: 49s - loss: 4.8847 - acc: 0.00 - ETA: 50s - loss: 4.8841 - acc: 0.00 - ETA: 50s - loss: 4.8835 - acc: 0.00 - ETA: 49s - loss: 4.8843 - acc: 0.00 - ETA: 50s - loss: 4.8844 - acc: 0.00 - ETA: 50s - loss: 4.8844 - acc: 0.00 - ETA: 51s - loss: 4.8849 - acc: 0.00 - ETA: 50s - loss: 4.8854 - acc: 0.00 - ETA: 50s - loss: 4.8856 - acc: 0.00 - ETA: 51s - loss: 4.8859 - acc: 0.00 - ETA: 51s - loss: 4.8857 - acc: 0.00 - ETA: 52s - loss: 4.8861 - acc: 0.00 - ETA: 51s - loss: 4.8856 - acc: 0.00 - ETA: 53s - loss: 4.8859 - acc: 0.00 - ETA: 52s - loss: 4.8861 - acc: 0.00 - ETA: 53s - loss: 4.8858 - acc: 0.00 - ETA: 52s - loss: 4.8868 - acc: 0.00 - ETA: 52s - loss: 4.8873 - acc: 0.00 - ETA: 52s - loss: 4.8875 - acc: 0.00 - ETA: 52s - loss: 4.8869 - acc: 0.00 - ETA: 52s - loss: 4.8875 - acc: 0.00 - ETA: 51s - loss: 4.8874 - acc: 0.00 - ETA: 51s - loss: 4.8872 - acc: 0.00 - ETA: 51s - loss: 4.8870 - acc: 0.00 - ETA: 51s - loss: 4.8872 - acc: 0.00 - ETA: 50s - loss: 4.8865 - acc: 0.00 - ETA: 50s - loss: 4.8868 - acc: 0.00 - ETA: 50s - loss: 4.8869 - acc: 0.00 - ETA: 50s - loss: 4.8866 - acc: 0.00 - ETA: 50s - loss: 4.8866 - acc: 0.00 - ETA: 49s - loss: 4.8864 - acc: 0.00 - ETA: 49s - loss: 4.8863 - acc: 0.00 - ETA: 49s - loss: 4.8862 - acc: 0.00 - ETA: 49s - loss: 4.8865 - acc: 0.00 - ETA: 49s - loss: 4.8863 - acc: 0.00 - ETA: 49s - loss: 4.8866 - acc: 0.00 - ETA: 49s - loss: 4.8866 - acc: 0.00 - ETA: 49s - loss: 4.8865 - acc: 0.00 - ETA: 49s - loss: 4.8862 - acc: 0.00 - ETA: 49s - loss: 4.8858 - acc: 0.00 - ETA: 49s - loss: 4.8855 - acc: 0.00 - ETA: 49s - loss: 4.8851 - acc: 0.00 - ETA: 49s - loss: 4.8853 - acc: 0.00 - ETA: 49s - loss: 4.8854 - acc: 0.00 - ETA: 49s - loss: 4.8849 - acc: 0.00 - ETA: 49s - loss: 4.8847 - acc: 0.00 - ETA: 49s - loss: 4.8850 - acc: 0.00 - ETA: 49s - loss: 4.8849 - acc: 0.00 - ETA: 49s - loss: 4.8847 - acc: 0.00 - ETA: 48s - loss: 4.8849 - acc: 0.00 - ETA: 48s - loss: 4.8848 - acc: 0.00 - ETA: 48s - loss: 4.8848 - acc: 0.00 - ETA: 48s - loss: 4.8844 - acc: 0.00 - ETA: 48s - loss: 4.8843 - acc: 0.00 - ETA: 48s - loss: 4.8843 - acc: 0.00 - ETA: 47s - loss: 4.8844 - acc: 0.00 - ETA: 47s - loss: 4.8842 - acc: 0.00 - ETA: 47s - loss: 4.8840 - acc: 0.00 - ETA: 47s - loss: 4.8842 - acc: 0.00 - ETA: 47s - loss: 4.8843 - acc: 0.00 - ETA: 46s - loss: 4.8843 - acc: 0.00 - ETA: 46s - loss: 4.8848 - acc: 0.00 - ETA: 46s - loss: 4.8852 - acc: 0.00 - ETA: 46s - loss: 4.8855 - acc: 0.00 - ETA: 46s - loss: 4.8856 - acc: 0.00 - ETA: 46s - loss: 4.8858 - acc: 0.00 - ETA: 46s - loss: 4.8862 - acc: 0.00 - ETA: 46s - loss: 4.8865 - acc: 0.00 - ETA: 46s - loss: 4.8863 - acc: 0.00 - ETA: 46s - loss: 4.8864 - acc: 0.00 - ETA: 46s - loss: 4.8865 - acc: 0.00 - ETA: 46s - loss: 4.8866 - acc: 0.00 - ETA: 46s - loss: 4.8863 - acc: 0.00 - ETA: 46s - loss: 4.8859 - acc: 0.00 - ETA: 46s - loss: 4.8856 - acc: 0.00 - ETA: 46s - loss: 4.8856 - acc: 0.00 - ETA: 46s - loss: 4.8857 - acc: 0.00 - ETA: 46s - loss: 4.8858 - acc: 0.00 - ETA: 46s - loss: 4.8859 - acc: 0.00 - ETA: 45s - loss: 4.8860 - acc: 0.00 - ETA: 45s - loss: 4.8858 - acc: 0.00 - ETA: 45s - loss: 4.8858 - acc: 0.00 - ETA: 45s - loss: 4.8860 - acc: 0.00 - ETA: 45s - loss: 4.8860 - acc: 0.00 - ETA: 45s - loss: 4.8860 - acc: 0.00 - ETA: 45s - loss: 4.8862 - acc: 0.00 - ETA: 45s - loss: 4.8860 - acc: 0.00 - ETA: 45s - loss: 4.8859 - acc: 0.00 - ETA: 45s - loss: 4.8857 - acc: 0.00 - ETA: 44s - loss: 4.8858 - acc: 0.00 - ETA: 44s - loss: 4.8856 - acc: 0.00 - ETA: 44s - loss: 4.8855 - acc: 0.00 - ETA: 44s - loss: 4.8855 - acc: 0.00 - ETA: 44s - loss: 4.8856 - acc: 0.00 - ETA: 44s - loss: 4.8856 - acc: 0.00 - ETA: 44s - loss: 4.8859 - acc: 0.00 - ETA: 44s - loss: 4.8860 - acc: 0.00 - ETA: 43s - loss: 4.8860 - acc: 0.00 - ETA: 43s - loss: 4.8861 - acc: 0.00 - ETA: 43s - loss: 4.8860 - acc: 0.00 - ETA: 43s - loss: 4.8860 - acc: 0.00 - ETA: 43s - loss: 4.8858 - acc: 0.00 - ETA: 43s - loss: 4.8857 - acc: 0.00 - ETA: 43s - loss: 4.8856 - acc: 0.00 - ETA: 43s - loss: 4.8858 - acc: 0.00 - ETA: 43s - loss: 4.8857 - acc: 0.00 - ETA: 43s - loss: 4.8859 - acc: 0.00 - ETA: 43s - loss: 4.8859 - acc: 0.00 - ETA: 42s - loss: 4.8862 - acc: 0.00 - ETA: 42s - loss: 4.8861 - acc: 0.00 - ETA: 42s - loss: 4.8861 - acc: 0.00 - ETA: 42s - loss: 4.8861 - acc: 0.00 - ETA: 42s - loss: 4.8862 - acc: 0.00 - ETA: 42s - loss: 4.8863 - acc: 0.00 - ETA: 41s - loss: 4.8860 - acc: 0.00 - ETA: 41s - loss: 4.8863 - acc: 0.00 - ETA: 41s - loss: 4.8862 - acc: 0.00 - ETA: 41s - loss: 4.8860 - acc: 0.00 - ETA: 41s - loss: 4.8859 - acc: 0.00 - ETA: 41s - loss: 4.8858 - acc: 0.00 - ETA: 41s - loss: 4.8858 - acc: 0.00 - ETA: 41s - loss: 4.8858 - acc: 0.00 - ETA: 40s - loss: 4.8856 - acc: 0.00 - ETA: 40s - loss: 4.8854 - acc: 0.00 - ETA: 40s - loss: 4.8854 - acc: 0.00 - ETA: 40s - loss: 4.8856 - acc: 0.00 - ETA: 40s - loss: 4.8856 - acc: 0.00 - ETA: 40s - loss: 4.8855 - acc: 0.00 - ETA: 40s - loss: 4.8855 - acc: 0.00 - ETA: 39s - loss: 4.8856 - acc: 0.00 - ETA: 39s - loss: 4.8855 - acc: 0.00 - ETA: 39s - loss: 4.8855 - acc: 0.00 - ETA: 39s - loss: 4.8855 - acc: 0.00 - ETA: 39s - loss: 4.8853 - acc: 0.00 - ETA: 38s - loss: 4.8853 - acc: 0.00 - ETA: 38s - loss: 4.8851 - acc: 0.00 - ETA: 38s - loss: 4.8851 - acc: 0.00 - ETA: 38s - loss: 4.8850 - acc: 0.00 - ETA: 38s - loss: 4.8850 - acc: 0.00 - ETA: 37s - loss: 4.8851 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8854 - acc: 0.00 - ETA: 37s - loss: 4.8854 - acc: 0.00 - ETA: 37s - loss: 4.8854 - acc: 0.00 - ETA: 37s - loss: 4.8852 - acc: 0.00 - ETA: 37s - loss: 4.8852 - acc: 0.00 - ETA: 37s - loss: 4.8852 - acc: 0.00 - ETA: 36s - loss: 4.8853 - acc: 0.00 - ETA: 36s - loss: 4.8851 - acc: 0.00 - ETA: 36s - loss: 4.8852 - acc: 0.00 - ETA: 36s - loss: 4.8851 - acc: 0.00 - ETA: 36s - loss: 4.8852 - acc: 0.00 - ETA: 36s - loss: 4.8851 - acc: 0.00 - ETA: 36s - loss: 4.8852 - acc: 0.00 - ETA: 35s - loss: 4.8851 - acc: 0.00 - ETA: 35s - loss: 4.8850 - acc: 0.00 - ETA: 35s - loss: 4.8850 - acc: 0.00 - ETA: 35s - loss: 4.8849 - acc: 0.00 - ETA: 35s - loss: 4.8850 - acc: 0.00 - ETA: 35s - loss: 4.8850 - acc: 0.00 - ETA: 34s - loss: 4.8851 - acc: 0.00 - ETA: 34s - loss: 4.8849 - acc: 0.00 - ETA: 34s - loss: 4.8848 - acc: 0.00 - ETA: 34s - loss: 4.8848 - acc: 0.00 - ETA: 34s - loss: 4.8850 - acc: 0.00 - ETA: 34s - loss: 4.8851 - acc: 0.00 - ETA: 34s - loss: 4.8852 - acc: 0.00 - ETA: 33s - loss: 4.8854 - acc: 0.00 - ETA: 33s - loss: 4.8854 - acc: 0.00 - ETA: 33s - loss: 4.8855 - acc: 0.00 - ETA: 33s - loss: 4.8856 - acc: 0.00 - ETA: 33s - loss: 4.8855 - acc: 0.00 - ETA: 33s - loss: 4.8855 - acc: 0.00 - ETA: 33s - loss: 4.8854 - acc: 0.00 - ETA: 32s - loss: 4.8854 - acc: 0.00 - ETA: 32s - loss: 4.8854 - acc: 0.00 - ETA: 32s - loss: 4.8854 - acc: 0.00 - ETA: 32s - loss: 4.8855 - acc: 0.00 - ETA: 32s - loss: 4.8855 - acc: 0.00 - ETA: 32s - loss: 4.8854 - acc: 0.00 - ETA: 31s - loss: 4.8854 - acc: 0.00 - ETA: 31s - loss: 4.8854 - acc: 0.00 - ETA: 31s - loss: 4.8855 - acc: 0.00 - ETA: 31s - loss: 4.8856 - acc: 0.00 - ETA: 31s - loss: 4.8856 - acc: 0.00 - ETA: 31s - loss: 4.8855 - acc: 0.00 - ETA: 30s - loss: 4.8857 - acc: 0.00 - ETA: 30s - loss: 4.8857 - acc: 0.00 - ETA: 30s - loss: 4.8857 - acc: 0.00 - ETA: 30s - loss: 4.8857 - acc: 0.00 - ETA: 30s - loss: 4.8856 - acc: 0.0075"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8857 - acc: 0.00 - ETA: 30s - loss: 4.8856 - acc: 0.00 - ETA: 29s - loss: 4.8857 - acc: 0.00 - ETA: 29s - loss: 4.8859 - acc: 0.00 - ETA: 29s - loss: 4.8858 - acc: 0.00 - ETA: 29s - loss: 4.8859 - acc: 0.00 - ETA: 29s - loss: 4.8860 - acc: 0.00 - ETA: 29s - loss: 4.8860 - acc: 0.00 - ETA: 29s - loss: 4.8859 - acc: 0.00 - ETA: 28s - loss: 4.8861 - acc: 0.00 - ETA: 28s - loss: 4.8860 - acc: 0.00 - ETA: 28s - loss: 4.8860 - acc: 0.00 - ETA: 28s - loss: 4.8860 - acc: 0.00 - ETA: 28s - loss: 4.8861 - acc: 0.00 - ETA: 28s - loss: 4.8861 - acc: 0.00 - ETA: 27s - loss: 4.8862 - acc: 0.00 - ETA: 27s - loss: 4.8862 - acc: 0.00 - ETA: 27s - loss: 4.8863 - acc: 0.00 - ETA: 27s - loss: 4.8863 - acc: 0.00 - ETA: 27s - loss: 4.8861 - acc: 0.00 - ETA: 27s - loss: 4.8860 - acc: 0.00 - ETA: 26s - loss: 4.8861 - acc: 0.00 - ETA: 26s - loss: 4.8863 - acc: 0.00 - ETA: 26s - loss: 4.8864 - acc: 0.00 - ETA: 26s - loss: 4.8865 - acc: 0.00 - ETA: 26s - loss: 4.8863 - acc: 0.00 - ETA: 25s - loss: 4.8863 - acc: 0.00 - ETA: 25s - loss: 4.8862 - acc: 0.00 - ETA: 25s - loss: 4.8862 - acc: 0.00 - ETA: 25s - loss: 4.8861 - acc: 0.00 - ETA: 25s - loss: 4.8861 - acc: 0.00 - ETA: 25s - loss: 4.8861 - acc: 0.00 - ETA: 24s - loss: 4.8861 - acc: 0.00 - ETA: 24s - loss: 4.8861 - acc: 0.00 - ETA: 24s - loss: 4.8860 - acc: 0.00 - ETA: 24s - loss: 4.8861 - acc: 0.00 - ETA: 24s - loss: 4.8860 - acc: 0.00 - ETA: 24s - loss: 4.8860 - acc: 0.00 - ETA: 24s - loss: 4.8861 - acc: 0.00 - ETA: 23s - loss: 4.8861 - acc: 0.00 - ETA: 23s - loss: 4.8860 - acc: 0.00 - ETA: 23s - loss: 4.8860 - acc: 0.00 - ETA: 23s - loss: 4.8861 - acc: 0.00 - ETA: 23s - loss: 4.8862 - acc: 0.00 - ETA: 23s - loss: 4.8863 - acc: 0.00 - ETA: 23s - loss: 4.8862 - acc: 0.00 - ETA: 22s - loss: 4.8861 - acc: 0.00 - ETA: 22s - loss: 4.8860 - acc: 0.00 - ETA: 22s - loss: 4.8860 - acc: 0.00 - ETA: 22s - loss: 4.8860 - acc: 0.00 - ETA: 22s - loss: 4.8859 - acc: 0.00 - ETA: 22s - loss: 4.8858 - acc: 0.00 - ETA: 21s - loss: 4.8858 - acc: 0.00 - ETA: 21s - loss: 4.8858 - acc: 0.00 - ETA: 21s - loss: 4.8857 - acc: 0.00 - ETA: 21s - loss: 4.8856 - acc: 0.00 - ETA: 21s - loss: 4.8855 - acc: 0.00 - ETA: 21s - loss: 4.8856 - acc: 0.00 - ETA: 21s - loss: 4.8856 - acc: 0.00 - ETA: 20s - loss: 4.8854 - acc: 0.00 - ETA: 20s - loss: 4.8855 - acc: 0.00 - ETA: 20s - loss: 4.8855 - acc: 0.00 - ETA: 20s - loss: 4.8854 - acc: 0.00 - ETA: 20s - loss: 4.8854 - acc: 0.00 - ETA: 20s - loss: 4.8854 - acc: 0.00 - ETA: 19s - loss: 4.8853 - acc: 0.00 - ETA: 19s - loss: 4.8853 - acc: 0.00 - ETA: 19s - loss: 4.8854 - acc: 0.00 - ETA: 19s - loss: 4.8853 - acc: 0.00 - ETA: 19s - loss: 4.8853 - acc: 0.00 - ETA: 19s - loss: 4.8853 - acc: 0.00 - ETA: 19s - loss: 4.8853 - acc: 0.00 - ETA: 18s - loss: 4.8854 - acc: 0.00 - ETA: 18s - loss: 4.8854 - acc: 0.00 - ETA: 18s - loss: 4.8852 - acc: 0.00 - ETA: 18s - loss: 4.8853 - acc: 0.00 - ETA: 18s - loss: 4.8852 - acc: 0.00 - ETA: 18s - loss: 4.8852 - acc: 0.00 - ETA: 17s - loss: 4.8853 - acc: 0.00 - ETA: 17s - loss: 4.8852 - acc: 0.00 - ETA: 17s - loss: 4.8851 - acc: 0.00 - ETA: 17s - loss: 4.8851 - acc: 0.00 - ETA: 17s - loss: 4.8852 - acc: 0.00 - ETA: 17s - loss: 4.8853 - acc: 0.00 - ETA: 16s - loss: 4.8853 - acc: 0.00 - ETA: 16s - loss: 4.8853 - acc: 0.00 - ETA: 16s - loss: 4.8853 - acc: 0.00 - ETA: 16s - loss: 4.8853 - acc: 0.00 - ETA: 16s - loss: 4.8852 - acc: 0.00 - ETA: 16s - loss: 4.8853 - acc: 0.00 - ETA: 16s - loss: 4.8853 - acc: 0.00 - ETA: 15s - loss: 4.8854 - acc: 0.00 - ETA: 15s - loss: 4.8853 - acc: 0.00 - ETA: 15s - loss: 4.8854 - acc: 0.00 - ETA: 15s - loss: 4.8854 - acc: 0.00 - ETA: 15s - loss: 4.8854 - acc: 0.00 - ETA: 15s - loss: 4.8854 - acc: 0.00 - ETA: 14s - loss: 4.8853 - acc: 0.00 - ETA: 14s - loss: 4.8853 - acc: 0.00 - ETA: 14s - loss: 4.8853 - acc: 0.00 - ETA: 14s - loss: 4.8853 - acc: 0.00 - ETA: 14s - loss: 4.8852 - acc: 0.00 - ETA: 14s - loss: 4.8853 - acc: 0.00 - ETA: 14s - loss: 4.8853 - acc: 0.00 - ETA: 13s - loss: 4.8853 - acc: 0.00 - ETA: 13s - loss: 4.8853 - acc: 0.00 - ETA: 13s - loss: 4.8853 - acc: 0.00 - ETA: 13s - loss: 4.8854 - acc: 0.00 - ETA: 13s - loss: 4.8854 - acc: 0.00 - ETA: 13s - loss: 4.8852 - acc: 0.00 - ETA: 12s - loss: 4.8852 - acc: 0.00 - ETA: 12s - loss: 4.8853 - acc: 0.00 - ETA: 12s - loss: 4.8852 - acc: 0.00 - ETA: 12s - loss: 4.8852 - acc: 0.00 - ETA: 12s - loss: 4.8853 - acc: 0.00 - ETA: 12s - loss: 4.8854 - acc: 0.00 - ETA: 12s - loss: 4.8854 - acc: 0.00 - ETA: 11s - loss: 4.8853 - acc: 0.00 - ETA: 11s - loss: 4.8852 - acc: 0.00 - ETA: 11s - loss: 4.8851 - acc: 0.00 - ETA: 11s - loss: 4.8852 - acc: 0.00 - ETA: 11s - loss: 4.8854 - acc: 0.00 - ETA: 11s - loss: 4.8854 - acc: 0.00 - ETA: 10s - loss: 4.8853 - acc: 0.00 - ETA: 10s - loss: 4.8852 - acc: 0.00 - ETA: 10s - loss: 4.8852 - acc: 0.00 - ETA: 10s - loss: 4.8852 - acc: 0.00 - ETA: 10s - loss: 4.8852 - acc: 0.00 - ETA: 10s - loss: 4.8851 - acc: 0.00 - ETA: 9s - loss: 4.8851 - acc: 0.0081 - ETA: 9s - loss: 4.8850 - acc: 0.008 - ETA: 9s - loss: 4.8850 - acc: 0.008 - ETA: 9s - loss: 4.8851 - acc: 0.008 - ETA: 9s - loss: 4.8850 - acc: 0.008 - ETA: 9s - loss: 4.8850 - acc: 0.008 - ETA: 8s - loss: 4.8851 - acc: 0.008 - ETA: 8s - loss: 4.8851 - acc: 0.008 - ETA: 8s - loss: 4.8851 - acc: 0.008 - ETA: 8s - loss: 4.8850 - acc: 0.008 - ETA: 8s - loss: 4.8851 - acc: 0.008 - ETA: 8s - loss: 4.8851 - acc: 0.008 - ETA: 8s - loss: 4.8852 - acc: 0.008 - ETA: 7s - loss: 4.8853 - acc: 0.008 - ETA: 7s - loss: 4.8853 - acc: 0.008 - ETA: 7s - loss: 4.8852 - acc: 0.008 - ETA: 7s - loss: 4.8852 - acc: 0.008 - ETA: 7s - loss: 4.8852 - acc: 0.008 - ETA: 7s - loss: 4.8853 - acc: 0.008 - ETA: 6s - loss: 4.8851 - acc: 0.008 - ETA: 6s - loss: 4.8850 - acc: 0.008 - ETA: 6s - loss: 4.8850 - acc: 0.008 - ETA: 6s - loss: 4.8851 - acc: 0.008 - ETA: 6s - loss: 4.8851 - acc: 0.008 - ETA: 6s - loss: 4.8850 - acc: 0.008 - ETA: 5s - loss: 4.8851 - acc: 0.008 - ETA: 5s - loss: 4.8852 - acc: 0.008 - ETA: 5s - loss: 4.8853 - acc: 0.008 - ETA: 5s - loss: 4.8853 - acc: 0.008 - ETA: 5s - loss: 4.8853 - acc: 0.008 - ETA: 5s - loss: 4.8852 - acc: 0.008 - ETA: 5s - loss: 4.8853 - acc: 0.008 - ETA: 4s - loss: 4.8853 - acc: 0.008 - ETA: 4s - loss: 4.8853 - acc: 0.008 - ETA: 4s - loss: 4.8853 - acc: 0.008 - ETA: 4s - loss: 4.8853 - acc: 0.008 - ETA: 4s - loss: 4.8854 - acc: 0.008 - ETA: 4s - loss: 4.8856 - acc: 0.008 - ETA: 3s - loss: 4.8856 - acc: 0.008 - ETA: 3s - loss: 4.8856 - acc: 0.008 - ETA: 3s - loss: 4.8856 - acc: 0.008 - ETA: 3s - loss: 4.8856 - acc: 0.008 - ETA: 3s - loss: 4.8855 - acc: 0.008 - ETA: 2s - loss: 4.8855 - acc: 0.008 - ETA: 2s - loss: 4.8856 - acc: 0.008 - ETA: 2s - loss: 4.8856 - acc: 0.008 - ETA: 2s - loss: 4.8856 - acc: 0.008 - ETA: 2s - loss: 4.8856 - acc: 0.008 - ETA: 2s - loss: 4.8857 - acc: 0.008 - ETA: 2s - loss: 4.8857 - acc: 0.008 - ETA: 1s - loss: 4.8857 - acc: 0.008 - ETA: 1s - loss: 4.8856 - acc: 0.008 - ETA: 1s - loss: 4.8856 - acc: 0.008 - ETA: 1s - loss: 4.8856 - acc: 0.008 - ETA: 1s - loss: 4.8856 - acc: 0.008 - ETA: 0s - loss: 4.8855 - acc: 0.008 - ETA: 0s - loss: 4.8855 - acc: 0.008 - ETA: 0s - loss: 4.8855 - acc: 0.008 - ETA: 0s - loss: 4.8856 - acc: 0.008 - ETA: 0s - loss: 4.8856 - acc: 0.008 - ETA: 0s - loss: 4.8855 - acc: 0.008 - 69s 166ms/step - loss: 4.8854 - acc: 0.0079 - val_loss: 4.8838 - val_acc: 0.0110\n",
      "\n",
      "Epoch 00003: val_loss improved from 4.88618 to 4.88378, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 5s - loss: 4.8873 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8920 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8884 - acc: 0.0139    - ETA: 6s - loss: 4.8843 - acc: 0.010 - ETA: 11s - loss: 4.8857 - acc: 0.00 - ETA: 15s - loss: 4.8859 - acc: 0.00 - ETA: 21s - loss: 4.8887 - acc: 0.00 - ETA: 25s - loss: 4.8881 - acc: 0.00 - ETA: 27s - loss: 4.8885 - acc: 0.00 - ETA: 29s - loss: 4.8886 - acc: 0.00 - ETA: 30s - loss: 4.8901 - acc: 0.00 - ETA: 32s - loss: 4.8895 - acc: 0.00 - ETA: 34s - loss: 4.8907 - acc: 0.00 - ETA: 36s - loss: 4.8906 - acc: 0.00 - ETA: 37s - loss: 4.8910 - acc: 0.00 - ETA: 38s - loss: 4.8910 - acc: 0.00 - ETA: 39s - loss: 4.8912 - acc: 0.00 - ETA: 40s - loss: 4.8908 - acc: 0.00 - ETA: 40s - loss: 4.8901 - acc: 0.00 - ETA: 41s - loss: 4.8901 - acc: 0.00 - ETA: 42s - loss: 4.8894 - acc: 0.00 - ETA: 43s - loss: 4.8893 - acc: 0.00 - ETA: 43s - loss: 4.8883 - acc: 0.00 - ETA: 43s - loss: 4.8879 - acc: 0.00 - ETA: 43s - loss: 4.8874 - acc: 0.01 - ETA: 44s - loss: 4.8875 - acc: 0.01 - ETA: 45s - loss: 4.8880 - acc: 0.01 - ETA: 46s - loss: 4.8876 - acc: 0.01 - ETA: 46s - loss: 4.8880 - acc: 0.01 - ETA: 46s - loss: 4.8872 - acc: 0.01 - ETA: 46s - loss: 4.8877 - acc: 0.01 - ETA: 47s - loss: 4.8877 - acc: 0.01 - ETA: 47s - loss: 4.8872 - acc: 0.01 - ETA: 47s - loss: 4.8871 - acc: 0.01 - ETA: 47s - loss: 4.8865 - acc: 0.01 - ETA: 48s - loss: 4.8863 - acc: 0.00 - ETA: 48s - loss: 4.8863 - acc: 0.00 - ETA: 48s - loss: 4.8859 - acc: 0.00 - ETA: 48s - loss: 4.8862 - acc: 0.00 - ETA: 49s - loss: 4.8860 - acc: 0.00 - ETA: 49s - loss: 4.8858 - acc: 0.00 - ETA: 49s - loss: 4.8859 - acc: 0.00 - ETA: 49s - loss: 4.8865 - acc: 0.00 - ETA: 49s - loss: 4.8869 - acc: 0.00 - ETA: 49s - loss: 4.8873 - acc: 0.00 - ETA: 49s - loss: 4.8871 - acc: 0.00 - ETA: 49s - loss: 4.8871 - acc: 0.00 - ETA: 49s - loss: 4.8870 - acc: 0.00 - ETA: 50s - loss: 4.8869 - acc: 0.00 - ETA: 50s - loss: 4.8867 - acc: 0.00 - ETA: 50s - loss: 4.8868 - acc: 0.00 - ETA: 50s - loss: 4.8865 - acc: 0.00 - ETA: 51s - loss: 4.8865 - acc: 0.00 - ETA: 50s - loss: 4.8863 - acc: 0.00 - ETA: 50s - loss: 4.8867 - acc: 0.00 - ETA: 50s - loss: 4.8870 - acc: 0.00 - ETA: 50s - loss: 4.8873 - acc: 0.00 - ETA: 50s - loss: 4.8874 - acc: 0.00 - ETA: 51s - loss: 4.8879 - acc: 0.00 - ETA: 50s - loss: 4.8881 - acc: 0.00 - ETA: 50s - loss: 4.8881 - acc: 0.00 - ETA: 50s - loss: 4.8880 - acc: 0.00 - ETA: 51s - loss: 4.8875 - acc: 0.00 - ETA: 51s - loss: 4.8872 - acc: 0.00 - ETA: 51s - loss: 4.8875 - acc: 0.00 - ETA: 51s - loss: 4.8872 - acc: 0.00 - ETA: 50s - loss: 4.8870 - acc: 0.00 - ETA: 50s - loss: 4.8870 - acc: 0.00 - ETA: 50s - loss: 4.8873 - acc: 0.00 - ETA: 50s - loss: 4.8873 - acc: 0.00 - ETA: 50s - loss: 4.8876 - acc: 0.00 - ETA: 51s - loss: 4.8875 - acc: 0.00 - ETA: 50s - loss: 4.8870 - acc: 0.00 - ETA: 50s - loss: 4.8868 - acc: 0.00 - ETA: 50s - loss: 4.8869 - acc: 0.00 - ETA: 50s - loss: 4.8868 - acc: 0.00 - ETA: 49s - loss: 4.8865 - acc: 0.00 - ETA: 49s - loss: 4.8865 - acc: 0.00 - ETA: 49s - loss: 4.8865 - acc: 0.00 - ETA: 49s - loss: 4.8858 - acc: 0.00 - ETA: 49s - loss: 4.8860 - acc: 0.00 - ETA: 49s - loss: 4.8857 - acc: 0.00 - ETA: 49s - loss: 4.8861 - acc: 0.00 - ETA: 49s - loss: 4.8861 - acc: 0.00 - ETA: 49s - loss: 4.8859 - acc: 0.00 - ETA: 49s - loss: 4.8854 - acc: 0.00 - ETA: 50s - loss: 4.8852 - acc: 0.00 - ETA: 50s - loss: 4.8857 - acc: 0.00 - ETA: 50s - loss: 4.8861 - acc: 0.00 - ETA: 50s - loss: 4.8864 - acc: 0.00 - ETA: 49s - loss: 4.8867 - acc: 0.00 - ETA: 49s - loss: 4.8869 - acc: 0.00 - ETA: 49s - loss: 4.8868 - acc: 0.00 - ETA: 49s - loss: 4.8865 - acc: 0.00 - ETA: 49s - loss: 4.8865 - acc: 0.00 - ETA: 48s - loss: 4.8866 - acc: 0.00 - ETA: 48s - loss: 4.8865 - acc: 0.00 - ETA: 48s - loss: 4.8862 - acc: 0.00 - ETA: 48s - loss: 4.8861 - acc: 0.00 - ETA: 48s - loss: 4.8861 - acc: 0.00 - ETA: 47s - loss: 4.8856 - acc: 0.00 - ETA: 47s - loss: 4.8855 - acc: 0.00 - ETA: 47s - loss: 4.8857 - acc: 0.00 - ETA: 47s - loss: 4.8861 - acc: 0.00 - ETA: 47s - loss: 4.8860 - acc: 0.00 - ETA: 47s - loss: 4.8856 - acc: 0.00 - ETA: 46s - loss: 4.8855 - acc: 0.00 - ETA: 46s - loss: 4.8856 - acc: 0.00 - ETA: 46s - loss: 4.8858 - acc: 0.00 - ETA: 46s - loss: 4.8857 - acc: 0.00 - ETA: 46s - loss: 4.8857 - acc: 0.00 - ETA: 46s - loss: 4.8860 - acc: 0.00 - ETA: 46s - loss: 4.8858 - acc: 0.00 - ETA: 45s - loss: 4.8859 - acc: 0.00 - ETA: 45s - loss: 4.8861 - acc: 0.00 - ETA: 45s - loss: 4.8860 - acc: 0.00 - ETA: 45s - loss: 4.8859 - acc: 0.00 - ETA: 44s - loss: 4.8858 - acc: 0.00 - ETA: 44s - loss: 4.8859 - acc: 0.00 - ETA: 44s - loss: 4.8859 - acc: 0.00 - ETA: 44s - loss: 4.8858 - acc: 0.00 - ETA: 44s - loss: 4.8860 - acc: 0.00 - ETA: 43s - loss: 4.8859 - acc: 0.00 - ETA: 43s - loss: 4.8859 - acc: 0.00 - ETA: 43s - loss: 4.8858 - acc: 0.00 - ETA: 43s - loss: 4.8857 - acc: 0.00 - ETA: 43s - loss: 4.8856 - acc: 0.00 - ETA: 43s - loss: 4.8853 - acc: 0.00 - ETA: 43s - loss: 4.8853 - acc: 0.00 - ETA: 42s - loss: 4.8852 - acc: 0.00 - ETA: 42s - loss: 4.8856 - acc: 0.00 - ETA: 42s - loss: 4.8853 - acc: 0.00 - ETA: 42s - loss: 4.8852 - acc: 0.00 - ETA: 42s - loss: 4.8855 - acc: 0.00 - ETA: 42s - loss: 4.8854 - acc: 0.00 - ETA: 41s - loss: 4.8856 - acc: 0.00 - ETA: 41s - loss: 4.8854 - acc: 0.00 - ETA: 41s - loss: 4.8856 - acc: 0.00 - ETA: 41s - loss: 4.8859 - acc: 0.00 - ETA: 41s - loss: 4.8857 - acc: 0.00 - ETA: 41s - loss: 4.8859 - acc: 0.00 - ETA: 40s - loss: 4.8857 - acc: 0.00 - ETA: 40s - loss: 4.8858 - acc: 0.00 - ETA: 40s - loss: 4.8857 - acc: 0.00 - ETA: 40s - loss: 4.8856 - acc: 0.00 - ETA: 40s - loss: 4.8856 - acc: 0.00 - ETA: 40s - loss: 4.8857 - acc: 0.00 - ETA: 40s - loss: 4.8858 - acc: 0.00 - ETA: 40s - loss: 4.8860 - acc: 0.00 - ETA: 39s - loss: 4.8862 - acc: 0.00 - ETA: 39s - loss: 4.8861 - acc: 0.00 - ETA: 39s - loss: 4.8860 - acc: 0.00 - ETA: 39s - loss: 4.8860 - acc: 0.00 - ETA: 39s - loss: 4.8861 - acc: 0.00 - ETA: 39s - loss: 4.8860 - acc: 0.00 - ETA: 39s - loss: 4.8860 - acc: 0.00 - ETA: 38s - loss: 4.8858 - acc: 0.00 - ETA: 38s - loss: 4.8857 - acc: 0.00 - ETA: 38s - loss: 4.8855 - acc: 0.00 - ETA: 38s - loss: 4.8855 - acc: 0.00 - ETA: 38s - loss: 4.8854 - acc: 0.00 - ETA: 38s - loss: 4.8854 - acc: 0.00 - ETA: 38s - loss: 4.8855 - acc: 0.00 - ETA: 38s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8850 - acc: 0.00 - ETA: 37s - loss: 4.8850 - acc: 0.00 - ETA: 37s - loss: 4.8851 - acc: 0.00 - ETA: 37s - loss: 4.8854 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8854 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8855 - acc: 0.00 - ETA: 37s - loss: 4.8854 - acc: 0.00 - ETA: 36s - loss: 4.8854 - acc: 0.00 - ETA: 36s - loss: 4.8854 - acc: 0.00 - ETA: 36s - loss: 4.8856 - acc: 0.00 - ETA: 36s - loss: 4.8854 - acc: 0.00 - ETA: 36s - loss: 4.8854 - acc: 0.00 - ETA: 36s - loss: 4.8852 - acc: 0.00 - ETA: 35s - loss: 4.8852 - acc: 0.01 - ETA: 35s - loss: 4.8852 - acc: 0.01 - ETA: 35s - loss: 4.8850 - acc: 0.01 - ETA: 35s - loss: 4.8850 - acc: 0.01 - ETA: 35s - loss: 4.8848 - acc: 0.01 - ETA: 35s - loss: 4.8848 - acc: 0.01 - ETA: 34s - loss: 4.8847 - acc: 0.01 - ETA: 34s - loss: 4.8846 - acc: 0.01 - ETA: 34s - loss: 4.8847 - acc: 0.01 - ETA: 34s - loss: 4.8848 - acc: 0.01 - ETA: 34s - loss: 4.8849 - acc: 0.01 - ETA: 34s - loss: 4.8849 - acc: 0.01 - ETA: 33s - loss: 4.8848 - acc: 0.01 - ETA: 33s - loss: 4.8849 - acc: 0.01 - ETA: 33s - loss: 4.8851 - acc: 0.01 - ETA: 33s - loss: 4.8850 - acc: 0.01 - ETA: 33s - loss: 4.8847 - acc: 0.01 - ETA: 33s - loss: 4.8847 - acc: 0.01 - ETA: 32s - loss: 4.8848 - acc: 0.00 - ETA: 32s - loss: 4.8848 - acc: 0.00 - ETA: 32s - loss: 4.8847 - acc: 0.00 - ETA: 32s - loss: 4.8848 - acc: 0.00 - ETA: 32s - loss: 4.8848 - acc: 0.00 - ETA: 32s - loss: 4.8847 - acc: 0.00 - ETA: 32s - loss: 4.8848 - acc: 0.00 - ETA: 31s - loss: 4.8847 - acc: 0.01 - ETA: 31s - loss: 4.8849 - acc: 0.01 - ETA: 31s - loss: 4.8851 - acc: 0.01 - ETA: 31s - loss: 4.8849 - acc: 0.01 - ETA: 31s - loss: 4.8847 - acc: 0.01 - ETA: 31s - loss: 4.8849 - acc: 0.01 - ETA: 30s - loss: 4.8847 - acc: 0.01 - ETA: 30s - loss: 4.8846 - acc: 0.01 - ETA: 30s - loss: 4.8846 - acc: 0.0107"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8846 - acc: 0.01 - ETA: 30s - loss: 4.8846 - acc: 0.01 - ETA: 30s - loss: 4.8847 - acc: 0.01 - ETA: 30s - loss: 4.8848 - acc: 0.01 - ETA: 29s - loss: 4.8849 - acc: 0.01 - ETA: 29s - loss: 4.8851 - acc: 0.01 - ETA: 29s - loss: 4.8852 - acc: 0.01 - ETA: 29s - loss: 4.8853 - acc: 0.01 - ETA: 29s - loss: 4.8851 - acc: 0.01 - ETA: 28s - loss: 4.8853 - acc: 0.01 - ETA: 28s - loss: 4.8852 - acc: 0.01 - ETA: 28s - loss: 4.8853 - acc: 0.01 - ETA: 28s - loss: 4.8853 - acc: 0.01 - ETA: 28s - loss: 4.8852 - acc: 0.01 - ETA: 28s - loss: 4.8853 - acc: 0.01 - ETA: 28s - loss: 4.8853 - acc: 0.01 - ETA: 27s - loss: 4.8854 - acc: 0.01 - ETA: 27s - loss: 4.8854 - acc: 0.01 - ETA: 27s - loss: 4.8855 - acc: 0.01 - ETA: 27s - loss: 4.8855 - acc: 0.01 - ETA: 27s - loss: 4.8856 - acc: 0.01 - ETA: 27s - loss: 4.8855 - acc: 0.01 - ETA: 27s - loss: 4.8855 - acc: 0.01 - ETA: 26s - loss: 4.8855 - acc: 0.01 - ETA: 26s - loss: 4.8854 - acc: 0.01 - ETA: 26s - loss: 4.8854 - acc: 0.01 - ETA: 26s - loss: 4.8855 - acc: 0.01 - ETA: 26s - loss: 4.8855 - acc: 0.01 - ETA: 26s - loss: 4.8854 - acc: 0.01 - ETA: 26s - loss: 4.8854 - acc: 0.01 - ETA: 25s - loss: 4.8854 - acc: 0.01 - ETA: 25s - loss: 4.8854 - acc: 0.01 - ETA: 25s - loss: 4.8854 - acc: 0.01 - ETA: 25s - loss: 4.8853 - acc: 0.01 - ETA: 25s - loss: 4.8851 - acc: 0.01 - ETA: 25s - loss: 4.8852 - acc: 0.01 - ETA: 24s - loss: 4.8853 - acc: 0.01 - ETA: 24s - loss: 4.8851 - acc: 0.01 - ETA: 24s - loss: 4.8853 - acc: 0.01 - ETA: 24s - loss: 4.8853 - acc: 0.01 - ETA: 24s - loss: 4.8853 - acc: 0.01 - ETA: 24s - loss: 4.8851 - acc: 0.01 - ETA: 23s - loss: 4.8851 - acc: 0.01 - ETA: 23s - loss: 4.8851 - acc: 0.01 - ETA: 23s - loss: 4.8852 - acc: 0.01 - ETA: 23s - loss: 4.8851 - acc: 0.01 - ETA: 23s - loss: 4.8850 - acc: 0.01 - ETA: 23s - loss: 4.8850 - acc: 0.01 - ETA: 23s - loss: 4.8851 - acc: 0.01 - ETA: 22s - loss: 4.8851 - acc: 0.01 - ETA: 22s - loss: 4.8850 - acc: 0.01 - ETA: 22s - loss: 4.8850 - acc: 0.01 - ETA: 22s - loss: 4.8850 - acc: 0.01 - ETA: 22s - loss: 4.8851 - acc: 0.01 - ETA: 22s - loss: 4.8849 - acc: 0.01 - ETA: 21s - loss: 4.8850 - acc: 0.01 - ETA: 21s - loss: 4.8850 - acc: 0.01 - ETA: 21s - loss: 4.8850 - acc: 0.01 - ETA: 21s - loss: 4.8851 - acc: 0.01 - ETA: 21s - loss: 4.8851 - acc: 0.01 - ETA: 21s - loss: 4.8851 - acc: 0.01 - ETA: 20s - loss: 4.8850 - acc: 0.01 - ETA: 20s - loss: 4.8850 - acc: 0.01 - ETA: 20s - loss: 4.8850 - acc: 0.01 - ETA: 20s - loss: 4.8850 - acc: 0.01 - ETA: 20s - loss: 4.8849 - acc: 0.01 - ETA: 20s - loss: 4.8849 - acc: 0.01 - ETA: 20s - loss: 4.8848 - acc: 0.01 - ETA: 19s - loss: 4.8848 - acc: 0.01 - ETA: 19s - loss: 4.8848 - acc: 0.01 - ETA: 19s - loss: 4.8848 - acc: 0.01 - ETA: 19s - loss: 4.8849 - acc: 0.01 - ETA: 19s - loss: 4.8849 - acc: 0.01 - ETA: 19s - loss: 4.8850 - acc: 0.01 - ETA: 19s - loss: 4.8850 - acc: 0.01 - ETA: 18s - loss: 4.8850 - acc: 0.01 - ETA: 18s - loss: 4.8850 - acc: 0.01 - ETA: 18s - loss: 4.8851 - acc: 0.01 - ETA: 18s - loss: 4.8851 - acc: 0.01 - ETA: 18s - loss: 4.8852 - acc: 0.01 - ETA: 18s - loss: 4.8851 - acc: 0.01 - ETA: 17s - loss: 4.8851 - acc: 0.01 - ETA: 17s - loss: 4.8852 - acc: 0.01 - ETA: 17s - loss: 4.8852 - acc: 0.01 - ETA: 17s - loss: 4.8853 - acc: 0.01 - ETA: 17s - loss: 4.8852 - acc: 0.01 - ETA: 17s - loss: 4.8851 - acc: 0.01 - ETA: 16s - loss: 4.8850 - acc: 0.01 - ETA: 16s - loss: 4.8851 - acc: 0.01 - ETA: 16s - loss: 4.8852 - acc: 0.01 - ETA: 16s - loss: 4.8852 - acc: 0.01 - ETA: 16s - loss: 4.8852 - acc: 0.01 - ETA: 16s - loss: 4.8851 - acc: 0.01 - ETA: 15s - loss: 4.8851 - acc: 0.01 - ETA: 15s - loss: 4.8850 - acc: 0.01 - ETA: 15s - loss: 4.8850 - acc: 0.01 - ETA: 15s - loss: 4.8850 - acc: 0.01 - ETA: 15s - loss: 4.8850 - acc: 0.01 - ETA: 15s - loss: 4.8850 - acc: 0.01 - ETA: 14s - loss: 4.8850 - acc: 0.01 - ETA: 14s - loss: 4.8850 - acc: 0.01 - ETA: 14s - loss: 4.8850 - acc: 0.01 - ETA: 14s - loss: 4.8850 - acc: 0.01 - ETA: 14s - loss: 4.8851 - acc: 0.01 - ETA: 14s - loss: 4.8852 - acc: 0.01 - ETA: 13s - loss: 4.8852 - acc: 0.01 - ETA: 13s - loss: 4.8852 - acc: 0.01 - ETA: 13s - loss: 4.8851 - acc: 0.01 - ETA: 13s - loss: 4.8852 - acc: 0.01 - ETA: 13s - loss: 4.8852 - acc: 0.01 - ETA: 13s - loss: 4.8853 - acc: 0.01 - ETA: 13s - loss: 4.8852 - acc: 0.01 - ETA: 12s - loss: 4.8853 - acc: 0.01 - ETA: 12s - loss: 4.8853 - acc: 0.01 - ETA: 12s - loss: 4.8852 - acc: 0.01 - ETA: 12s - loss: 4.8852 - acc: 0.01 - ETA: 12s - loss: 4.8853 - acc: 0.01 - ETA: 12s - loss: 4.8852 - acc: 0.01 - ETA: 11s - loss: 4.8852 - acc: 0.01 - ETA: 11s - loss: 4.8852 - acc: 0.01 - ETA: 11s - loss: 4.8852 - acc: 0.01 - ETA: 11s - loss: 4.8852 - acc: 0.01 - ETA: 11s - loss: 4.8853 - acc: 0.01 - ETA: 11s - loss: 4.8852 - acc: 0.01 - ETA: 10s - loss: 4.8853 - acc: 0.01 - ETA: 10s - loss: 4.8853 - acc: 0.01 - ETA: 10s - loss: 4.8853 - acc: 0.01 - ETA: 10s - loss: 4.8852 - acc: 0.01 - ETA: 10s - loss: 4.8852 - acc: 0.01 - ETA: 10s - loss: 4.8853 - acc: 0.01 - ETA: 10s - loss: 4.8853 - acc: 0.01 - ETA: 9s - loss: 4.8853 - acc: 0.0113 - ETA: 9s - loss: 4.8853 - acc: 0.011 - ETA: 9s - loss: 4.8854 - acc: 0.011 - ETA: 9s - loss: 4.8854 - acc: 0.011 - ETA: 9s - loss: 4.8854 - acc: 0.011 - ETA: 9s - loss: 4.8854 - acc: 0.011 - ETA: 8s - loss: 4.8854 - acc: 0.011 - ETA: 8s - loss: 4.8854 - acc: 0.011 - ETA: 8s - loss: 4.8852 - acc: 0.011 - ETA: 8s - loss: 4.8853 - acc: 0.011 - ETA: 8s - loss: 4.8853 - acc: 0.011 - ETA: 8s - loss: 4.8853 - acc: 0.011 - ETA: 7s - loss: 4.8853 - acc: 0.011 - ETA: 7s - loss: 4.8854 - acc: 0.011 - ETA: 7s - loss: 4.8853 - acc: 0.011 - ETA: 7s - loss: 4.8854 - acc: 0.011 - ETA: 7s - loss: 4.8855 - acc: 0.011 - ETA: 7s - loss: 4.8856 - acc: 0.011 - ETA: 7s - loss: 4.8855 - acc: 0.011 - ETA: 6s - loss: 4.8854 - acc: 0.011 - ETA: 6s - loss: 4.8854 - acc: 0.011 - ETA: 6s - loss: 4.8855 - acc: 0.011 - ETA: 6s - loss: 4.8856 - acc: 0.010 - ETA: 6s - loss: 4.8855 - acc: 0.010 - ETA: 6s - loss: 4.8855 - acc: 0.010 - ETA: 5s - loss: 4.8855 - acc: 0.010 - ETA: 5s - loss: 4.8855 - acc: 0.011 - ETA: 5s - loss: 4.8855 - acc: 0.011 - ETA: 5s - loss: 4.8855 - acc: 0.010 - ETA: 5s - loss: 4.8856 - acc: 0.010 - ETA: 5s - loss: 4.8856 - acc: 0.010 - ETA: 4s - loss: 4.8856 - acc: 0.010 - ETA: 4s - loss: 4.8856 - acc: 0.010 - ETA: 4s - loss: 4.8857 - acc: 0.010 - ETA: 4s - loss: 4.8856 - acc: 0.010 - ETA: 4s - loss: 4.8856 - acc: 0.010 - ETA: 4s - loss: 4.8857 - acc: 0.010 - ETA: 3s - loss: 4.8857 - acc: 0.010 - ETA: 3s - loss: 4.8857 - acc: 0.010 - ETA: 3s - loss: 4.8857 - acc: 0.010 - ETA: 3s - loss: 4.8858 - acc: 0.010 - ETA: 3s - loss: 4.8859 - acc: 0.010 - ETA: 3s - loss: 4.8859 - acc: 0.010 - ETA: 3s - loss: 4.8858 - acc: 0.010 - ETA: 2s - loss: 4.8857 - acc: 0.010 - ETA: 2s - loss: 4.8857 - acc: 0.010 - ETA: 2s - loss: 4.8857 - acc: 0.010 - ETA: 2s - loss: 4.8857 - acc: 0.010 - ETA: 2s - loss: 4.8857 - acc: 0.010 - ETA: 2s - loss: 4.8856 - acc: 0.010 - ETA: 1s - loss: 4.8856 - acc: 0.010 - ETA: 1s - loss: 4.8856 - acc: 0.010 - ETA: 1s - loss: 4.8857 - acc: 0.010 - ETA: 1s - loss: 4.8857 - acc: 0.010 - ETA: 1s - loss: 4.8857 - acc: 0.010 - ETA: 1s - loss: 4.8857 - acc: 0.010 - ETA: 0s - loss: 4.8857 - acc: 0.010 - ETA: 0s - loss: 4.8857 - acc: 0.010 - ETA: 0s - loss: 4.8857 - acc: 0.010 - ETA: 0s - loss: 4.8857 - acc: 0.010 - ETA: 0s - loss: 4.8856 - acc: 0.010 - ETA: 0s - loss: 4.8856 - acc: 0.010 - 70s 168ms/step - loss: 4.8856 - acc: 0.0106 - val_loss: 4.8835 - val_acc: 0.0134\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.88378 to 4.88351, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 5s - loss: 4.8644 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8719 - acc: 0.0125    - ETA: 6s - loss: 4.8767 - acc: 0.020 - ETA: 8s - loss: 4.8803 - acc: 0.020 - ETA: 13s - loss: 4.8793 - acc: 0.02 - ETA: 17s - loss: 4.8798 - acc: 0.02 - ETA: 19s - loss: 4.8800 - acc: 0.02 - ETA: 21s - loss: 4.8815 - acc: 0.02 - ETA: 23s - loss: 4.8813 - acc: 0.02 - ETA: 26s - loss: 4.8830 - acc: 0.02 - ETA: 28s - loss: 4.8845 - acc: 0.01 - ETA: 33s - loss: 4.8812 - acc: 0.02 - ETA: 35s - loss: 4.8810 - acc: 0.02 - ETA: 36s - loss: 4.8814 - acc: 0.01 - ETA: 36s - loss: 4.8805 - acc: 0.01 - ETA: 37s - loss: 4.8800 - acc: 0.01 - ETA: 37s - loss: 4.8793 - acc: 0.01 - ETA: 38s - loss: 4.8795 - acc: 0.01 - ETA: 40s - loss: 4.8793 - acc: 0.01 - ETA: 40s - loss: 4.8788 - acc: 0.01 - ETA: 42s - loss: 4.8798 - acc: 0.01 - ETA: 42s - loss: 4.8792 - acc: 0.01 - ETA: 43s - loss: 4.8790 - acc: 0.01 - ETA: 43s - loss: 4.8798 - acc: 0.01 - ETA: 43s - loss: 4.8805 - acc: 0.01 - ETA: 43s - loss: 4.8807 - acc: 0.01 - ETA: 45s - loss: 4.8816 - acc: 0.01 - ETA: 45s - loss: 4.8823 - acc: 0.01 - ETA: 45s - loss: 4.8816 - acc: 0.01 - ETA: 45s - loss: 4.8817 - acc: 0.01 - ETA: 45s - loss: 4.8818 - acc: 0.01 - ETA: 46s - loss: 4.8825 - acc: 0.01 - ETA: 46s - loss: 4.8823 - acc: 0.01 - ETA: 46s - loss: 4.8827 - acc: 0.01 - ETA: 46s - loss: 4.8833 - acc: 0.01 - ETA: 46s - loss: 4.8831 - acc: 0.01 - ETA: 46s - loss: 4.8835 - acc: 0.01 - ETA: 47s - loss: 4.8836 - acc: 0.01 - ETA: 47s - loss: 4.8835 - acc: 0.01 - ETA: 48s - loss: 4.8837 - acc: 0.01 - ETA: 48s - loss: 4.8837 - acc: 0.01 - ETA: 48s - loss: 4.8831 - acc: 0.01 - ETA: 48s - loss: 4.8830 - acc: 0.01 - ETA: 48s - loss: 4.8833 - acc: 0.01 - ETA: 48s - loss: 4.8833 - acc: 0.01 - ETA: 48s - loss: 4.8835 - acc: 0.01 - ETA: 48s - loss: 4.8842 - acc: 0.01 - ETA: 48s - loss: 4.8851 - acc: 0.01 - ETA: 49s - loss: 4.8852 - acc: 0.01 - ETA: 49s - loss: 4.8860 - acc: 0.01 - ETA: 49s - loss: 4.8861 - acc: 0.01 - ETA: 49s - loss: 4.8861 - acc: 0.01 - ETA: 49s - loss: 4.8862 - acc: 0.01 - ETA: 49s - loss: 4.8858 - acc: 0.01 - ETA: 49s - loss: 4.8859 - acc: 0.01 - ETA: 49s - loss: 4.8857 - acc: 0.01 - ETA: 50s - loss: 4.8854 - acc: 0.01 - ETA: 50s - loss: 4.8856 - acc: 0.01 - ETA: 50s - loss: 4.8856 - acc: 0.01 - ETA: 50s - loss: 4.8854 - acc: 0.01 - ETA: 49s - loss: 4.8851 - acc: 0.01 - ETA: 49s - loss: 4.8847 - acc: 0.01 - ETA: 49s - loss: 4.8851 - acc: 0.01 - ETA: 49s - loss: 4.8849 - acc: 0.01 - ETA: 49s - loss: 4.8852 - acc: 0.01 - ETA: 49s - loss: 4.8851 - acc: 0.01 - ETA: 48s - loss: 4.8849 - acc: 0.01 - ETA: 48s - loss: 4.8852 - acc: 0.00 - ETA: 48s - loss: 4.8849 - acc: 0.01 - ETA: 48s - loss: 4.8850 - acc: 0.01 - ETA: 48s - loss: 4.8849 - acc: 0.01 - ETA: 48s - loss: 4.8849 - acc: 0.01 - ETA: 48s - loss: 4.8847 - acc: 0.01 - ETA: 48s - loss: 4.8845 - acc: 0.00 - ETA: 48s - loss: 4.8846 - acc: 0.00 - ETA: 48s - loss: 4.8848 - acc: 0.00 - ETA: 48s - loss: 4.8843 - acc: 0.01 - ETA: 48s - loss: 4.8841 - acc: 0.01 - ETA: 47s - loss: 4.8841 - acc: 0.01 - ETA: 48s - loss: 4.8842 - acc: 0.00 - ETA: 47s - loss: 4.8841 - acc: 0.00 - ETA: 47s - loss: 4.8840 - acc: 0.00 - ETA: 47s - loss: 4.8843 - acc: 0.00 - ETA: 47s - loss: 4.8842 - acc: 0.00 - ETA: 47s - loss: 4.8846 - acc: 0.00 - ETA: 46s - loss: 4.8847 - acc: 0.00 - ETA: 47s - loss: 4.8844 - acc: 0.00 - ETA: 47s - loss: 4.8843 - acc: 0.00 - ETA: 46s - loss: 4.8841 - acc: 0.00 - ETA: 46s - loss: 4.8841 - acc: 0.00 - ETA: 46s - loss: 4.8841 - acc: 0.00 - ETA: 46s - loss: 4.8847 - acc: 0.00 - ETA: 46s - loss: 4.8845 - acc: 0.00 - ETA: 46s - loss: 4.8845 - acc: 0.00 - ETA: 45s - loss: 4.8846 - acc: 0.00 - ETA: 45s - loss: 4.8849 - acc: 0.00 - ETA: 45s - loss: 4.8850 - acc: 0.00 - ETA: 45s - loss: 4.8850 - acc: 0.00 - ETA: 45s - loss: 4.8852 - acc: 0.00 - ETA: 45s - loss: 4.8855 - acc: 0.00 - ETA: 45s - loss: 4.8854 - acc: 0.00 - ETA: 44s - loss: 4.8853 - acc: 0.00 - ETA: 44s - loss: 4.8854 - acc: 0.00 - ETA: 44s - loss: 4.8855 - acc: 0.00 - ETA: 44s - loss: 4.8855 - acc: 0.00 - ETA: 44s - loss: 4.8856 - acc: 0.00 - ETA: 44s - loss: 4.8853 - acc: 0.00 - ETA: 44s - loss: 4.8854 - acc: 0.00 - ETA: 44s - loss: 4.8852 - acc: 0.00 - ETA: 44s - loss: 4.8852 - acc: 0.00 - ETA: 43s - loss: 4.8853 - acc: 0.00 - ETA: 44s - loss: 4.8854 - acc: 0.00 - ETA: 44s - loss: 4.8853 - acc: 0.00 - ETA: 43s - loss: 4.8854 - acc: 0.00 - ETA: 43s - loss: 4.8855 - acc: 0.00 - ETA: 43s - loss: 4.8854 - acc: 0.00 - ETA: 43s - loss: 4.8854 - acc: 0.00 - ETA: 43s - loss: 4.8853 - acc: 0.00 - ETA: 42s - loss: 4.8855 - acc: 0.00 - ETA: 42s - loss: 4.8854 - acc: 0.00 - ETA: 42s - loss: 4.8856 - acc: 0.00 - ETA: 42s - loss: 4.8859 - acc: 0.00 - ETA: 42s - loss: 4.8858 - acc: 0.00 - ETA: 41s - loss: 4.8857 - acc: 0.00 - ETA: 41s - loss: 4.8860 - acc: 0.00 - ETA: 41s - loss: 4.8860 - acc: 0.00 - ETA: 41s - loss: 4.8858 - acc: 0.00 - ETA: 41s - loss: 4.8858 - acc: 0.00 - ETA: 41s - loss: 4.8856 - acc: 0.00 - ETA: 41s - loss: 4.8858 - acc: 0.00 - ETA: 40s - loss: 4.8859 - acc: 0.00 - ETA: 40s - loss: 4.8860 - acc: 0.00 - ETA: 40s - loss: 4.8861 - acc: 0.00 - ETA: 40s - loss: 4.8861 - acc: 0.00 - ETA: 40s - loss: 4.8862 - acc: 0.00 - ETA: 40s - loss: 4.8860 - acc: 0.00 - ETA: 40s - loss: 4.8859 - acc: 0.00 - ETA: 40s - loss: 4.8858 - acc: 0.00 - ETA: 40s - loss: 4.8859 - acc: 0.00 - ETA: 39s - loss: 4.8857 - acc: 0.00 - ETA: 39s - loss: 4.8857 - acc: 0.00 - ETA: 39s - loss: 4.8856 - acc: 0.00 - ETA: 39s - loss: 4.8856 - acc: 0.00 - ETA: 39s - loss: 4.8855 - acc: 0.00 - ETA: 39s - loss: 4.8854 - acc: 0.00 - ETA: 38s - loss: 4.8853 - acc: 0.00 - ETA: 38s - loss: 4.8853 - acc: 0.00 - ETA: 38s - loss: 4.8852 - acc: 0.00 - ETA: 38s - loss: 4.8852 - acc: 0.00 - ETA: 38s - loss: 4.8850 - acc: 0.00 - ETA: 38s - loss: 4.8850 - acc: 0.00 - ETA: 38s - loss: 4.8852 - acc: 0.00 - ETA: 37s - loss: 4.8851 - acc: 0.00 - ETA: 37s - loss: 4.8849 - acc: 0.00 - ETA: 37s - loss: 4.8851 - acc: 0.00 - ETA: 37s - loss: 4.8851 - acc: 0.00 - ETA: 37s - loss: 4.8852 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 37s - loss: 4.8853 - acc: 0.00 - ETA: 36s - loss: 4.8854 - acc: 0.00 - ETA: 36s - loss: 4.8854 - acc: 0.00 - ETA: 36s - loss: 4.8854 - acc: 0.00 - ETA: 36s - loss: 4.8853 - acc: 0.00 - ETA: 36s - loss: 4.8851 - acc: 0.00 - ETA: 36s - loss: 4.8851 - acc: 0.00 - ETA: 36s - loss: 4.8851 - acc: 0.00 - ETA: 36s - loss: 4.8851 - acc: 0.00 - ETA: 36s - loss: 4.8852 - acc: 0.00 - ETA: 36s - loss: 4.8851 - acc: 0.00 - ETA: 35s - loss: 4.8852 - acc: 0.00 - ETA: 35s - loss: 4.8853 - acc: 0.00 - ETA: 35s - loss: 4.8854 - acc: 0.00 - ETA: 35s - loss: 4.8853 - acc: 0.00 - ETA: 35s - loss: 4.8854 - acc: 0.00 - ETA: 35s - loss: 4.8853 - acc: 0.00 - ETA: 34s - loss: 4.8855 - acc: 0.00 - ETA: 34s - loss: 4.8854 - acc: 0.00 - ETA: 34s - loss: 4.8855 - acc: 0.00 - ETA: 34s - loss: 4.8855 - acc: 0.00 - ETA: 34s - loss: 4.8856 - acc: 0.00 - ETA: 34s - loss: 4.8854 - acc: 0.00 - ETA: 34s - loss: 4.8854 - acc: 0.00 - ETA: 34s - loss: 4.8852 - acc: 0.00 - ETA: 33s - loss: 4.8852 - acc: 0.00 - ETA: 33s - loss: 4.8852 - acc: 0.00 - ETA: 33s - loss: 4.8852 - acc: 0.00 - ETA: 33s - loss: 4.8851 - acc: 0.00 - ETA: 33s - loss: 4.8853 - acc: 0.00 - ETA: 33s - loss: 4.8852 - acc: 0.00 - ETA: 32s - loss: 4.8853 - acc: 0.00 - ETA: 32s - loss: 4.8853 - acc: 0.00 - ETA: 32s - loss: 4.8853 - acc: 0.00 - ETA: 32s - loss: 4.8851 - acc: 0.00 - ETA: 32s - loss: 4.8851 - acc: 0.00 - ETA: 32s - loss: 4.8851 - acc: 0.00 - ETA: 32s - loss: 4.8850 - acc: 0.00 - ETA: 31s - loss: 4.8850 - acc: 0.00 - ETA: 31s - loss: 4.8851 - acc: 0.00 - ETA: 31s - loss: 4.8850 - acc: 0.00 - ETA: 31s - loss: 4.8850 - acc: 0.00 - ETA: 31s - loss: 4.8849 - acc: 0.00 - ETA: 31s - loss: 4.8848 - acc: 0.00 - ETA: 30s - loss: 4.8848 - acc: 0.00 - ETA: 30s - loss: 4.8850 - acc: 0.00 - ETA: 30s - loss: 4.8850 - acc: 0.00 - ETA: 30s - loss: 4.8850 - acc: 0.00 - ETA: 30s - loss: 4.8850 - acc: 0.00 - ETA: 30s - loss: 4.8851 - acc: 0.00 - ETA: 30s - loss: 4.8851 - acc: 0.00 - ETA: 29s - loss: 4.8851 - acc: 0.00 - ETA: 29s - loss: 4.8851 - acc: 0.00 - ETA: 29s - loss: 4.8852 - acc: 0.00 - ETA: 29s - loss: 4.8850 - acc: 0.0084"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 29s - loss: 4.8852 - acc: 0.00 - ETA: 29s - loss: 4.8852 - acc: 0.00 - ETA: 29s - loss: 4.8852 - acc: 0.00 - ETA: 28s - loss: 4.8850 - acc: 0.00 - ETA: 28s - loss: 4.8848 - acc: 0.00 - ETA: 28s - loss: 4.8850 - acc: 0.00 - ETA: 28s - loss: 4.8850 - acc: 0.00 - ETA: 28s - loss: 4.8850 - acc: 0.00 - ETA: 28s - loss: 4.8851 - acc: 0.00 - ETA: 27s - loss: 4.8850 - acc: 0.00 - ETA: 27s - loss: 4.8850 - acc: 0.00 - ETA: 27s - loss: 4.8850 - acc: 0.00 - ETA: 27s - loss: 4.8848 - acc: 0.00 - ETA: 27s - loss: 4.8849 - acc: 0.00 - ETA: 27s - loss: 4.8848 - acc: 0.00 - ETA: 27s - loss: 4.8848 - acc: 0.00 - ETA: 27s - loss: 4.8848 - acc: 0.00 - ETA: 26s - loss: 4.8848 - acc: 0.00 - ETA: 26s - loss: 4.8849 - acc: 0.00 - ETA: 26s - loss: 4.8849 - acc: 0.00 - ETA: 26s - loss: 4.8848 - acc: 0.00 - ETA: 26s - loss: 4.8850 - acc: 0.00 - ETA: 26s - loss: 4.8849 - acc: 0.00 - ETA: 26s - loss: 4.8851 - acc: 0.00 - ETA: 25s - loss: 4.8850 - acc: 0.00 - ETA: 25s - loss: 4.8850 - acc: 0.00 - ETA: 25s - loss: 4.8852 - acc: 0.00 - ETA: 25s - loss: 4.8853 - acc: 0.00 - ETA: 25s - loss: 4.8853 - acc: 0.00 - ETA: 25s - loss: 4.8853 - acc: 0.00 - ETA: 24s - loss: 4.8853 - acc: 0.00 - ETA: 24s - loss: 4.8852 - acc: 0.00 - ETA: 24s - loss: 4.8854 - acc: 0.00 - ETA: 24s - loss: 4.8855 - acc: 0.00 - ETA: 24s - loss: 4.8856 - acc: 0.00 - ETA: 24s - loss: 4.8856 - acc: 0.00 - ETA: 24s - loss: 4.8856 - acc: 0.00 - ETA: 24s - loss: 4.8856 - acc: 0.00 - ETA: 23s - loss: 4.8855 - acc: 0.00 - ETA: 23s - loss: 4.8855 - acc: 0.00 - ETA: 23s - loss: 4.8855 - acc: 0.00 - ETA: 23s - loss: 4.8856 - acc: 0.00 - ETA: 23s - loss: 4.8855 - acc: 0.00 - ETA: 23s - loss: 4.8855 - acc: 0.00 - ETA: 22s - loss: 4.8855 - acc: 0.00 - ETA: 22s - loss: 4.8855 - acc: 0.00 - ETA: 22s - loss: 4.8855 - acc: 0.00 - ETA: 22s - loss: 4.8856 - acc: 0.00 - ETA: 22s - loss: 4.8856 - acc: 0.00 - ETA: 22s - loss: 4.8855 - acc: 0.00 - ETA: 22s - loss: 4.8856 - acc: 0.00 - ETA: 21s - loss: 4.8855 - acc: 0.00 - ETA: 21s - loss: 4.8855 - acc: 0.00 - ETA: 21s - loss: 4.8854 - acc: 0.00 - ETA: 21s - loss: 4.8854 - acc: 0.00 - ETA: 21s - loss: 4.8854 - acc: 0.00 - ETA: 21s - loss: 4.8854 - acc: 0.00 - ETA: 20s - loss: 4.8852 - acc: 0.00 - ETA: 20s - loss: 4.8852 - acc: 0.00 - ETA: 20s - loss: 4.8852 - acc: 0.00 - ETA: 20s - loss: 4.8853 - acc: 0.00 - ETA: 20s - loss: 4.8853 - acc: 0.00 - ETA: 20s - loss: 4.8853 - acc: 0.00 - ETA: 20s - loss: 4.8853 - acc: 0.00 - ETA: 19s - loss: 4.8853 - acc: 0.00 - ETA: 19s - loss: 4.8854 - acc: 0.00 - ETA: 19s - loss: 4.8855 - acc: 0.00 - ETA: 19s - loss: 4.8855 - acc: 0.00 - ETA: 19s - loss: 4.8855 - acc: 0.00 - ETA: 19s - loss: 4.8856 - acc: 0.00 - ETA: 19s - loss: 4.8857 - acc: 0.00 - ETA: 18s - loss: 4.8858 - acc: 0.00 - ETA: 18s - loss: 4.8858 - acc: 0.00 - ETA: 18s - loss: 4.8857 - acc: 0.00 - ETA: 18s - loss: 4.8859 - acc: 0.00 - ETA: 18s - loss: 4.8859 - acc: 0.00 - ETA: 18s - loss: 4.8860 - acc: 0.00 - ETA: 18s - loss: 4.8860 - acc: 0.00 - ETA: 17s - loss: 4.8860 - acc: 0.00 - ETA: 17s - loss: 4.8860 - acc: 0.00 - ETA: 17s - loss: 4.8859 - acc: 0.00 - ETA: 17s - loss: 4.8859 - acc: 0.00 - ETA: 17s - loss: 4.8859 - acc: 0.00 - ETA: 17s - loss: 4.8859 - acc: 0.00 - ETA: 16s - loss: 4.8859 - acc: 0.00 - ETA: 16s - loss: 4.8860 - acc: 0.00 - ETA: 16s - loss: 4.8860 - acc: 0.00 - ETA: 16s - loss: 4.8861 - acc: 0.00 - ETA: 16s - loss: 4.8861 - acc: 0.00 - ETA: 16s - loss: 4.8860 - acc: 0.00 - ETA: 16s - loss: 4.8859 - acc: 0.00 - ETA: 15s - loss: 4.8858 - acc: 0.00 - ETA: 15s - loss: 4.8858 - acc: 0.00 - ETA: 15s - loss: 4.8858 - acc: 0.00 - ETA: 15s - loss: 4.8859 - acc: 0.00 - ETA: 15s - loss: 4.8858 - acc: 0.00 - ETA: 15s - loss: 4.8858 - acc: 0.00 - ETA: 14s - loss: 4.8859 - acc: 0.00 - ETA: 14s - loss: 4.8858 - acc: 0.00 - ETA: 14s - loss: 4.8857 - acc: 0.00 - ETA: 14s - loss: 4.8857 - acc: 0.00 - ETA: 14s - loss: 4.8856 - acc: 0.00 - ETA: 14s - loss: 4.8856 - acc: 0.00 - ETA: 14s - loss: 4.8856 - acc: 0.00 - ETA: 13s - loss: 4.8855 - acc: 0.00 - ETA: 13s - loss: 4.8855 - acc: 0.00 - ETA: 13s - loss: 4.8855 - acc: 0.00 - ETA: 13s - loss: 4.8856 - acc: 0.00 - ETA: 13s - loss: 4.8855 - acc: 0.00 - ETA: 13s - loss: 4.8855 - acc: 0.00 - ETA: 12s - loss: 4.8855 - acc: 0.00 - ETA: 12s - loss: 4.8854 - acc: 0.00 - ETA: 12s - loss: 4.8854 - acc: 0.00 - ETA: 12s - loss: 4.8854 - acc: 0.00 - ETA: 12s - loss: 4.8855 - acc: 0.00 - ETA: 12s - loss: 4.8854 - acc: 0.00 - ETA: 12s - loss: 4.8854 - acc: 0.00 - ETA: 11s - loss: 4.8854 - acc: 0.00 - ETA: 11s - loss: 4.8854 - acc: 0.00 - ETA: 11s - loss: 4.8854 - acc: 0.00 - ETA: 11s - loss: 4.8854 - acc: 0.00 - ETA: 11s - loss: 4.8853 - acc: 0.00 - ETA: 11s - loss: 4.8853 - acc: 0.00 - ETA: 10s - loss: 4.8853 - acc: 0.00 - ETA: 10s - loss: 4.8854 - acc: 0.00 - ETA: 10s - loss: 4.8853 - acc: 0.01 - ETA: 10s - loss: 4.8852 - acc: 0.01 - ETA: 10s - loss: 4.8851 - acc: 0.01 - ETA: 10s - loss: 4.8851 - acc: 0.00 - ETA: 10s - loss: 4.8851 - acc: 0.00 - ETA: 9s - loss: 4.8852 - acc: 0.0101 - ETA: 9s - loss: 4.8852 - acc: 0.010 - ETA: 9s - loss: 4.8853 - acc: 0.010 - ETA: 9s - loss: 4.8852 - acc: 0.010 - ETA: 9s - loss: 4.8853 - acc: 0.010 - ETA: 9s - loss: 4.8853 - acc: 0.009 - ETA: 8s - loss: 4.8853 - acc: 0.009 - ETA: 8s - loss: 4.8854 - acc: 0.009 - ETA: 8s - loss: 4.8854 - acc: 0.009 - ETA: 8s - loss: 4.8854 - acc: 0.009 - ETA: 8s - loss: 4.8854 - acc: 0.010 - ETA: 8s - loss: 4.8854 - acc: 0.009 - ETA: 7s - loss: 4.8854 - acc: 0.010 - ETA: 7s - loss: 4.8853 - acc: 0.010 - ETA: 7s - loss: 4.8854 - acc: 0.010 - ETA: 7s - loss: 4.8854 - acc: 0.010 - ETA: 7s - loss: 4.8853 - acc: 0.010 - ETA: 7s - loss: 4.8853 - acc: 0.010 - ETA: 7s - loss: 4.8853 - acc: 0.010 - ETA: 6s - loss: 4.8854 - acc: 0.010 - ETA: 6s - loss: 4.8855 - acc: 0.010 - ETA: 6s - loss: 4.8854 - acc: 0.010 - ETA: 6s - loss: 4.8854 - acc: 0.010 - ETA: 6s - loss: 4.8854 - acc: 0.009 - ETA: 6s - loss: 4.8854 - acc: 0.010 - ETA: 5s - loss: 4.8853 - acc: 0.010 - ETA: 5s - loss: 4.8853 - acc: 0.010 - ETA: 5s - loss: 4.8852 - acc: 0.010 - ETA: 5s - loss: 4.8853 - acc: 0.010 - ETA: 5s - loss: 4.8853 - acc: 0.010 - ETA: 5s - loss: 4.8853 - acc: 0.010 - ETA: 5s - loss: 4.8853 - acc: 0.010 - ETA: 4s - loss: 4.8853 - acc: 0.010 - ETA: 4s - loss: 4.8853 - acc: 0.010 - ETA: 4s - loss: 4.8852 - acc: 0.010 - ETA: 4s - loss: 4.8852 - acc: 0.010 - ETA: 4s - loss: 4.8852 - acc: 0.010 - ETA: 4s - loss: 4.8853 - acc: 0.010 - ETA: 3s - loss: 4.8852 - acc: 0.010 - ETA: 3s - loss: 4.8853 - acc: 0.010 - ETA: 3s - loss: 4.8854 - acc: 0.010 - ETA: 3s - loss: 4.8853 - acc: 0.010 - ETA: 3s - loss: 4.8854 - acc: 0.010 - ETA: 3s - loss: 4.8854 - acc: 0.010 - ETA: 2s - loss: 4.8855 - acc: 0.010 - ETA: 2s - loss: 4.8854 - acc: 0.010 - ETA: 2s - loss: 4.8854 - acc: 0.010 - ETA: 2s - loss: 4.8854 - acc: 0.010 - ETA: 2s - loss: 4.8854 - acc: 0.010 - ETA: 2s - loss: 4.8853 - acc: 0.010 - ETA: 2s - loss: 4.8853 - acc: 0.010 - ETA: 1s - loss: 4.8853 - acc: 0.010 - ETA: 1s - loss: 4.8854 - acc: 0.010 - ETA: 1s - loss: 4.8855 - acc: 0.010 - ETA: 1s - loss: 4.8855 - acc: 0.010 - ETA: 1s - loss: 4.8855 - acc: 0.010 - ETA: 1s - loss: 4.8856 - acc: 0.010 - ETA: 0s - loss: 4.8855 - acc: 0.010 - ETA: 0s - loss: 4.8855 - acc: 0.010 - ETA: 0s - loss: 4.8855 - acc: 0.010 - ETA: 0s - loss: 4.8854 - acc: 0.010 - ETA: 0s - loss: 4.8855 - acc: 0.010 - ETA: 0s - loss: 4.8856 - acc: 0.010 - 70s 167ms/step - loss: 4.8856 - acc: 0.0103 - val_loss: 4.8820 - val_acc: 0.0085\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.88351 to 4.88204, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/417 [==============>...............] - ETA: 7s - loss: 4.8600 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8747 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8779 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8810 - acc: 0.0000e+0 - ETA: 11s - loss: 4.8852 - acc: 0.0000e+ - ETA: 15s - loss: 4.8862 - acc: 0.0000e+ - ETA: 17s - loss: 4.8868 - acc: 0.0000e+ - ETA: 23s - loss: 4.8851 - acc: 0.0000e+ - ETA: 25s - loss: 4.8855 - acc: 0.0000e+ - ETA: 29s - loss: 4.8859 - acc: 0.0000e+ - ETA: 30s - loss: 4.8856 - acc: 0.0000e+ - ETA: 31s - loss: 4.8850 - acc: 0.0063   - ETA: 32s - loss: 4.8843 - acc: 0.00 - ETA: 33s - loss: 4.8842 - acc: 0.00 - ETA: 36s - loss: 4.8858 - acc: 0.00 - ETA: 37s - loss: 4.8864 - acc: 0.00 - ETA: 37s - loss: 4.8859 - acc: 0.00 - ETA: 40s - loss: 4.8859 - acc: 0.00 - ETA: 40s - loss: 4.8862 - acc: 0.00 - ETA: 41s - loss: 4.8860 - acc: 0.00 - ETA: 41s - loss: 4.8867 - acc: 0.00 - ETA: 42s - loss: 4.8873 - acc: 0.00 - ETA: 43s - loss: 4.8872 - acc: 0.00 - ETA: 43s - loss: 4.8872 - acc: 0.00 - ETA: 43s - loss: 4.8874 - acc: 0.00 - ETA: 43s - loss: 4.8873 - acc: 0.00 - ETA: 43s - loss: 4.8868 - acc: 0.00 - ETA: 43s - loss: 4.8872 - acc: 0.00 - ETA: 45s - loss: 4.8870 - acc: 0.00 - ETA: 44s - loss: 4.8874 - acc: 0.00 - ETA: 45s - loss: 4.8875 - acc: 0.00 - ETA: 45s - loss: 4.8879 - acc: 0.00 - ETA: 46s - loss: 4.8878 - acc: 0.00 - ETA: 46s - loss: 4.8873 - acc: 0.00 - ETA: 46s - loss: 4.8869 - acc: 0.00 - ETA: 46s - loss: 4.8874 - acc: 0.00 - ETA: 46s - loss: 4.8872 - acc: 0.00 - ETA: 47s - loss: 4.8876 - acc: 0.00 - ETA: 47s - loss: 4.8880 - acc: 0.00 - ETA: 47s - loss: 4.8882 - acc: 0.00 - ETA: 49s - loss: 4.8882 - acc: 0.00 - ETA: 48s - loss: 4.8879 - acc: 0.00 - ETA: 48s - loss: 4.8881 - acc: 0.00 - ETA: 48s - loss: 4.8876 - acc: 0.00 - ETA: 48s - loss: 4.8877 - acc: 0.00 - ETA: 48s - loss: 4.8874 - acc: 0.00 - ETA: 48s - loss: 4.8875 - acc: 0.00 - ETA: 48s - loss: 4.8876 - acc: 0.00 - ETA: 48s - loss: 4.8869 - acc: 0.00 - ETA: 48s - loss: 4.8867 - acc: 0.00 - ETA: 47s - loss: 4.8863 - acc: 0.00 - ETA: 47s - loss: 4.8865 - acc: 0.01 - ETA: 48s - loss: 4.8865 - acc: 0.01 - ETA: 47s - loss: 4.8862 - acc: 0.01 - ETA: 48s - loss: 4.8860 - acc: 0.00 - ETA: 48s - loss: 4.8863 - acc: 0.00 - ETA: 48s - loss: 4.8866 - acc: 0.00 - ETA: 48s - loss: 4.8862 - acc: 0.01 - ETA: 48s - loss: 4.8864 - acc: 0.01 - ETA: 48s - loss: 4.8864 - acc: 0.01 - ETA: 48s - loss: 4.8870 - acc: 0.01 - ETA: 48s - loss: 4.8870 - acc: 0.01 - ETA: 47s - loss: 4.8876 - acc: 0.01 - ETA: 47s - loss: 4.8876 - acc: 0.01 - ETA: 47s - loss: 4.8875 - acc: 0.01 - ETA: 47s - loss: 4.8870 - acc: 0.01 - ETA: 47s - loss: 4.8867 - acc: 0.01 - ETA: 47s - loss: 4.8866 - acc: 0.01 - ETA: 47s - loss: 4.8863 - acc: 0.01 - ETA: 46s - loss: 4.8860 - acc: 0.01 - ETA: 46s - loss: 4.8861 - acc: 0.01 - ETA: 46s - loss: 4.8860 - acc: 0.01 - ETA: 46s - loss: 4.8862 - acc: 0.01 - ETA: 46s - loss: 4.8861 - acc: 0.00 - ETA: 46s - loss: 4.8860 - acc: 0.00 - ETA: 46s - loss: 4.8857 - acc: 0.00 - ETA: 46s - loss: 4.8860 - acc: 0.00 - ETA: 46s - loss: 4.8859 - acc: 0.00 - ETA: 46s - loss: 4.8856 - acc: 0.01 - ETA: 46s - loss: 4.8853 - acc: 0.00 - ETA: 46s - loss: 4.8855 - acc: 0.00 - ETA: 45s - loss: 4.8854 - acc: 0.00 - ETA: 45s - loss: 4.8855 - acc: 0.00 - ETA: 45s - loss: 4.8854 - acc: 0.00 - ETA: 45s - loss: 4.8853 - acc: 0.00 - ETA: 45s - loss: 4.8852 - acc: 0.00 - ETA: 46s - loss: 4.8854 - acc: 0.00 - ETA: 46s - loss: 4.8855 - acc: 0.00 - ETA: 46s - loss: 4.8852 - acc: 0.00 - ETA: 46s - loss: 4.8852 - acc: 0.00 - ETA: 46s - loss: 4.8853 - acc: 0.00 - ETA: 46s - loss: 4.8852 - acc: 0.01 - ETA: 45s - loss: 4.8854 - acc: 0.00 - ETA: 45s - loss: 4.8857 - acc: 0.00 - ETA: 46s - loss: 4.8858 - acc: 0.00 - ETA: 45s - loss: 4.8857 - acc: 0.00 - ETA: 46s - loss: 4.8858 - acc: 0.00 - ETA: 46s - loss: 4.8857 - acc: 0.00 - ETA: 45s - loss: 4.8857 - acc: 0.00 - ETA: 45s - loss: 4.8855 - acc: 0.00 - ETA: 45s - loss: 4.8854 - acc: 0.00 - ETA: 45s - loss: 4.8853 - acc: 0.00 - ETA: 45s - loss: 4.8851 - acc: 0.00 - ETA: 45s - loss: 4.8852 - acc: 0.00 - ETA: 45s - loss: 4.8852 - acc: 0.00 - ETA: 45s - loss: 4.8848 - acc: 0.00 - ETA: 45s - loss: 4.8849 - acc: 0.00 - ETA: 44s - loss: 4.8850 - acc: 0.00 - ETA: 44s - loss: 4.8849 - acc: 0.00 - ETA: 44s - loss: 4.8848 - acc: 0.00 - ETA: 44s - loss: 4.8842 - acc: 0.01 - ETA: 44s - loss: 4.8840 - acc: 0.01 - ETA: 44s - loss: 4.8838 - acc: 0.01 - ETA: 44s - loss: 4.8837 - acc: 0.01 - ETA: 43s - loss: 4.8838 - acc: 0.01 - ETA: 43s - loss: 4.8838 - acc: 0.01 - ETA: 43s - loss: 4.8838 - acc: 0.01 - ETA: 43s - loss: 4.8836 - acc: 0.01 - ETA: 43s - loss: 4.8835 - acc: 0.01 - ETA: 42s - loss: 4.8837 - acc: 0.01 - ETA: 43s - loss: 4.8837 - acc: 0.01 - ETA: 43s - loss: 4.8836 - acc: 0.01 - ETA: 42s - loss: 4.8838 - acc: 0.01 - ETA: 42s - loss: 4.8836 - acc: 0.01 - ETA: 42s - loss: 4.8838 - acc: 0.01 - ETA: 42s - loss: 4.8839 - acc: 0.01 - ETA: 42s - loss: 4.8837 - acc: 0.01 - ETA: 42s - loss: 4.8837 - acc: 0.01 - ETA: 41s - loss: 4.8838 - acc: 0.01 - ETA: 41s - loss: 4.8837 - acc: 0.01 - ETA: 41s - loss: 4.8837 - acc: 0.01 - ETA: 41s - loss: 4.8836 - acc: 0.01 - ETA: 41s - loss: 4.8834 - acc: 0.01 - ETA: 41s - loss: 4.8836 - acc: 0.01 - ETA: 41s - loss: 4.8837 - acc: 0.01 - ETA: 41s - loss: 4.8838 - acc: 0.01 - ETA: 40s - loss: 4.8837 - acc: 0.01 - ETA: 40s - loss: 4.8836 - acc: 0.01 - ETA: 40s - loss: 4.8835 - acc: 0.01 - ETA: 40s - loss: 4.8832 - acc: 0.01 - ETA: 40s - loss: 4.8833 - acc: 0.01 - ETA: 40s - loss: 4.8830 - acc: 0.01 - ETA: 40s - loss: 4.8831 - acc: 0.01 - ETA: 39s - loss: 4.8829 - acc: 0.01 - ETA: 39s - loss: 4.8831 - acc: 0.01 - ETA: 39s - loss: 4.8831 - acc: 0.01 - ETA: 39s - loss: 4.8832 - acc: 0.01 - ETA: 39s - loss: 4.8832 - acc: 0.01 - ETA: 39s - loss: 4.8835 - acc: 0.01 - ETA: 39s - loss: 4.8836 - acc: 0.01 - ETA: 39s - loss: 4.8834 - acc: 0.01 - ETA: 38s - loss: 4.8835 - acc: 0.01 - ETA: 38s - loss: 4.8836 - acc: 0.01 - ETA: 38s - loss: 4.8837 - acc: 0.01 - ETA: 38s - loss: 4.8838 - acc: 0.01 - ETA: 38s - loss: 4.8839 - acc: 0.01 - ETA: 38s - loss: 4.8839 - acc: 0.01 - ETA: 38s - loss: 4.8838 - acc: 0.01 - ETA: 37s - loss: 4.8838 - acc: 0.01 - ETA: 37s - loss: 4.8837 - acc: 0.01 - ETA: 37s - loss: 4.8836 - acc: 0.01 - ETA: 37s - loss: 4.8834 - acc: 0.00 - ETA: 37s - loss: 4.8833 - acc: 0.01 - ETA: 37s - loss: 4.8832 - acc: 0.01 - ETA: 36s - loss: 4.8834 - acc: 0.01 - ETA: 36s - loss: 4.8833 - acc: 0.01 - ETA: 36s - loss: 4.8831 - acc: 0.01 - ETA: 36s - loss: 4.8833 - acc: 0.00 - ETA: 36s - loss: 4.8832 - acc: 0.00 - ETA: 36s - loss: 4.8829 - acc: 0.01 - ETA: 36s - loss: 4.8831 - acc: 0.01 - ETA: 36s - loss: 4.8831 - acc: 0.01 - ETA: 36s - loss: 4.8830 - acc: 0.01 - ETA: 36s - loss: 4.8834 - acc: 0.01 - ETA: 36s - loss: 4.8834 - acc: 0.01 - ETA: 35s - loss: 4.8833 - acc: 0.01 - ETA: 35s - loss: 4.8833 - acc: 0.01 - ETA: 35s - loss: 4.8833 - acc: 0.01 - ETA: 35s - loss: 4.8831 - acc: 0.01 - ETA: 35s - loss: 4.8829 - acc: 0.01 - ETA: 35s - loss: 4.8829 - acc: 0.01 - ETA: 35s - loss: 4.8830 - acc: 0.01 - ETA: 34s - loss: 4.8830 - acc: 0.01 - ETA: 34s - loss: 4.8832 - acc: 0.01 - ETA: 34s - loss: 4.8831 - acc: 0.01 - ETA: 34s - loss: 4.8829 - acc: 0.01 - ETA: 34s - loss: 4.8829 - acc: 0.01 - ETA: 34s - loss: 4.8829 - acc: 0.01 - ETA: 34s - loss: 4.8830 - acc: 0.01 - ETA: 33s - loss: 4.8828 - acc: 0.01 - ETA: 33s - loss: 4.8827 - acc: 0.01 - ETA: 33s - loss: 4.8826 - acc: 0.01 - ETA: 33s - loss: 4.8827 - acc: 0.01 - ETA: 33s - loss: 4.8826 - acc: 0.01 - ETA: 33s - loss: 4.8827 - acc: 0.01 - ETA: 33s - loss: 4.8826 - acc: 0.01 - ETA: 32s - loss: 4.8823 - acc: 0.01 - ETA: 32s - loss: 4.8822 - acc: 0.01 - ETA: 32s - loss: 4.8823 - acc: 0.01 - ETA: 32s - loss: 4.8822 - acc: 0.01 - ETA: 32s - loss: 4.8823 - acc: 0.01 - ETA: 32s - loss: 4.8824 - acc: 0.01 - ETA: 32s - loss: 4.8823 - acc: 0.01 - ETA: 31s - loss: 4.8823 - acc: 0.01 - ETA: 31s - loss: 4.8824 - acc: 0.01 - ETA: 31s - loss: 4.8822 - acc: 0.01 - ETA: 31s - loss: 4.8820 - acc: 0.01 - ETA: 31s - loss: 4.8820 - acc: 0.01 - ETA: 31s - loss: 4.8820 - acc: 0.01 - ETA: 30s - loss: 4.8819 - acc: 0.01 - ETA: 30s - loss: 4.8818 - acc: 0.01 - ETA: 30s - loss: 4.8817 - acc: 0.01 - ETA: 30s - loss: 4.8818 - acc: 0.01 - ETA: 30s - loss: 4.8818 - acc: 0.0107"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8819 - acc: 0.01 - ETA: 29s - loss: 4.8820 - acc: 0.01 - ETA: 29s - loss: 4.8820 - acc: 0.01 - ETA: 29s - loss: 4.8820 - acc: 0.01 - ETA: 29s - loss: 4.8819 - acc: 0.01 - ETA: 29s - loss: 4.8819 - acc: 0.01 - ETA: 29s - loss: 4.8819 - acc: 0.01 - ETA: 29s - loss: 4.8819 - acc: 0.01 - ETA: 29s - loss: 4.8820 - acc: 0.01 - ETA: 28s - loss: 4.8819 - acc: 0.01 - ETA: 28s - loss: 4.8819 - acc: 0.01 - ETA: 28s - loss: 4.8820 - acc: 0.01 - ETA: 28s - loss: 4.8819 - acc: 0.01 - ETA: 28s - loss: 4.8821 - acc: 0.01 - ETA: 28s - loss: 4.8820 - acc: 0.01 - ETA: 27s - loss: 4.8821 - acc: 0.01 - ETA: 27s - loss: 4.8822 - acc: 0.00 - ETA: 27s - loss: 4.8822 - acc: 0.00 - ETA: 27s - loss: 4.8821 - acc: 0.00 - ETA: 27s - loss: 4.8819 - acc: 0.00 - ETA: 27s - loss: 4.8819 - acc: 0.00 - ETA: 27s - loss: 4.8818 - acc: 0.00 - ETA: 26s - loss: 4.8818 - acc: 0.00 - ETA: 26s - loss: 4.8818 - acc: 0.00 - ETA: 26s - loss: 4.8819 - acc: 0.00 - ETA: 26s - loss: 4.8817 - acc: 0.00 - ETA: 26s - loss: 4.8817 - acc: 0.00 - ETA: 26s - loss: 4.8817 - acc: 0.00 - ETA: 25s - loss: 4.8816 - acc: 0.00 - ETA: 25s - loss: 4.8816 - acc: 0.00 - ETA: 25s - loss: 4.8817 - acc: 0.00 - ETA: 25s - loss: 4.8815 - acc: 0.00 - ETA: 25s - loss: 4.8815 - acc: 0.00 - ETA: 25s - loss: 4.8815 - acc: 0.00 - ETA: 25s - loss: 4.8817 - acc: 0.00 - ETA: 24s - loss: 4.8816 - acc: 0.00 - ETA: 24s - loss: 4.8817 - acc: 0.00 - ETA: 24s - loss: 4.8819 - acc: 0.00 - ETA: 24s - loss: 4.8819 - acc: 0.00 - ETA: 24s - loss: 4.8819 - acc: 0.00 - ETA: 24s - loss: 4.8820 - acc: 0.00 - ETA: 23s - loss: 4.8820 - acc: 0.00 - ETA: 23s - loss: 4.8820 - acc: 0.00 - ETA: 23s - loss: 4.8819 - acc: 0.00 - ETA: 23s - loss: 4.8820 - acc: 0.00 - ETA: 23s - loss: 4.8819 - acc: 0.00 - ETA: 23s - loss: 4.8820 - acc: 0.00 - ETA: 23s - loss: 4.8822 - acc: 0.00 - ETA: 22s - loss: 4.8822 - acc: 0.00 - ETA: 22s - loss: 4.8823 - acc: 0.00 - ETA: 22s - loss: 4.8822 - acc: 0.00 - ETA: 22s - loss: 4.8822 - acc: 0.00 - ETA: 22s - loss: 4.8821 - acc: 0.00 - ETA: 22s - loss: 4.8821 - acc: 0.00 - ETA: 22s - loss: 4.8822 - acc: 0.00 - ETA: 21s - loss: 4.8823 - acc: 0.00 - ETA: 21s - loss: 4.8825 - acc: 0.00 - ETA: 21s - loss: 4.8825 - acc: 0.00 - ETA: 21s - loss: 4.8824 - acc: 0.00 - ETA: 21s - loss: 4.8825 - acc: 0.00 - ETA: 21s - loss: 4.8824 - acc: 0.00 - ETA: 21s - loss: 4.8825 - acc: 0.00 - ETA: 20s - loss: 4.8826 - acc: 0.00 - ETA: 20s - loss: 4.8827 - acc: 0.00 - ETA: 20s - loss: 4.8826 - acc: 0.00 - ETA: 20s - loss: 4.8826 - acc: 0.00 - ETA: 20s - loss: 4.8826 - acc: 0.00 - ETA: 20s - loss: 4.8825 - acc: 0.00 - ETA: 20s - loss: 4.8825 - acc: 0.00 - ETA: 19s - loss: 4.8827 - acc: 0.00 - ETA: 19s - loss: 4.8828 - acc: 0.00 - ETA: 19s - loss: 4.8829 - acc: 0.00 - ETA: 19s - loss: 4.8829 - acc: 0.00 - ETA: 19s - loss: 4.8829 - acc: 0.00 - ETA: 19s - loss: 4.8828 - acc: 0.00 - ETA: 18s - loss: 4.8827 - acc: 0.00 - ETA: 18s - loss: 4.8827 - acc: 0.00 - ETA: 18s - loss: 4.8827 - acc: 0.00 - ETA: 18s - loss: 4.8827 - acc: 0.00 - ETA: 18s - loss: 4.8828 - acc: 0.00 - ETA: 18s - loss: 4.8827 - acc: 0.00 - ETA: 17s - loss: 4.8826 - acc: 0.00 - ETA: 17s - loss: 4.8826 - acc: 0.00 - ETA: 17s - loss: 4.8827 - acc: 0.00 - ETA: 17s - loss: 4.8826 - acc: 0.00 - ETA: 17s - loss: 4.8826 - acc: 0.00 - ETA: 17s - loss: 4.8826 - acc: 0.00 - ETA: 17s - loss: 4.8825 - acc: 0.00 - ETA: 16s - loss: 4.8824 - acc: 0.00 - ETA: 16s - loss: 4.8825 - acc: 0.00 - ETA: 16s - loss: 4.8825 - acc: 0.00 - ETA: 16s - loss: 4.8824 - acc: 0.00 - ETA: 16s - loss: 4.8824 - acc: 0.00 - ETA: 16s - loss: 4.8824 - acc: 0.00 - ETA: 15s - loss: 4.8824 - acc: 0.00 - ETA: 15s - loss: 4.8823 - acc: 0.00 - ETA: 15s - loss: 4.8823 - acc: 0.00 - ETA: 15s - loss: 4.8824 - acc: 0.00 - ETA: 15s - loss: 4.8824 - acc: 0.00 - ETA: 15s - loss: 4.8824 - acc: 0.00 - ETA: 14s - loss: 4.8825 - acc: 0.00 - ETA: 14s - loss: 4.8825 - acc: 0.00 - ETA: 14s - loss: 4.8826 - acc: 0.00 - ETA: 14s - loss: 4.8825 - acc: 0.00 - ETA: 14s - loss: 4.8825 - acc: 0.00 - ETA: 14s - loss: 4.8825 - acc: 0.00 - ETA: 14s - loss: 4.8824 - acc: 0.00 - ETA: 13s - loss: 4.8825 - acc: 0.00 - ETA: 13s - loss: 4.8824 - acc: 0.00 - ETA: 13s - loss: 4.8824 - acc: 0.00 - ETA: 13s - loss: 4.8824 - acc: 0.00 - ETA: 13s - loss: 4.8826 - acc: 0.00 - ETA: 13s - loss: 4.8825 - acc: 0.00 - ETA: 12s - loss: 4.8826 - acc: 0.00 - ETA: 12s - loss: 4.8826 - acc: 0.00 - ETA: 12s - loss: 4.8825 - acc: 0.00 - ETA: 12s - loss: 4.8826 - acc: 0.00 - ETA: 12s - loss: 4.8826 - acc: 0.00 - ETA: 12s - loss: 4.8825 - acc: 0.00 - ETA: 11s - loss: 4.8825 - acc: 0.00 - ETA: 11s - loss: 4.8825 - acc: 0.00 - ETA: 11s - loss: 4.8826 - acc: 0.00 - ETA: 11s - loss: 4.8826 - acc: 0.00 - ETA: 11s - loss: 4.8826 - acc: 0.00 - ETA: 11s - loss: 4.8825 - acc: 0.00 - ETA: 10s - loss: 4.8826 - acc: 0.00 - ETA: 10s - loss: 4.8825 - acc: 0.00 - ETA: 10s - loss: 4.8825 - acc: 0.00 - ETA: 10s - loss: 4.8825 - acc: 0.00 - ETA: 10s - loss: 4.8826 - acc: 0.00 - ETA: 10s - loss: 4.8827 - acc: 0.00 - ETA: 10s - loss: 4.8826 - acc: 0.00 - ETA: 9s - loss: 4.8826 - acc: 0.0093 - ETA: 9s - loss: 4.8826 - acc: 0.009 - ETA: 9s - loss: 4.8825 - acc: 0.009 - ETA: 9s - loss: 4.8824 - acc: 0.009 - ETA: 9s - loss: 4.8825 - acc: 0.009 - ETA: 9s - loss: 4.8826 - acc: 0.009 - ETA: 8s - loss: 4.8825 - acc: 0.009 - ETA: 8s - loss: 4.8826 - acc: 0.009 - ETA: 8s - loss: 4.8826 - acc: 0.009 - ETA: 8s - loss: 4.8827 - acc: 0.009 - ETA: 8s - loss: 4.8827 - acc: 0.009 - ETA: 8s - loss: 4.8827 - acc: 0.009 - ETA: 7s - loss: 4.8828 - acc: 0.009 - ETA: 7s - loss: 4.8828 - acc: 0.009 - ETA: 7s - loss: 4.8828 - acc: 0.009 - ETA: 7s - loss: 4.8829 - acc: 0.009 - ETA: 7s - loss: 4.8830 - acc: 0.009 - ETA: 7s - loss: 4.8830 - acc: 0.009 - ETA: 7s - loss: 4.8830 - acc: 0.009 - ETA: 6s - loss: 4.8829 - acc: 0.009 - ETA: 6s - loss: 4.8829 - acc: 0.009 - ETA: 6s - loss: 4.8828 - acc: 0.010 - ETA: 6s - loss: 4.8828 - acc: 0.010 - ETA: 6s - loss: 4.8827 - acc: 0.010 - ETA: 6s - loss: 4.8827 - acc: 0.010 - ETA: 5s - loss: 4.8828 - acc: 0.010 - ETA: 5s - loss: 4.8827 - acc: 0.010 - ETA: 5s - loss: 4.8826 - acc: 0.010 - ETA: 5s - loss: 4.8825 - acc: 0.010 - ETA: 5s - loss: 4.8825 - acc: 0.010 - ETA: 5s - loss: 4.8826 - acc: 0.010 - ETA: 4s - loss: 4.8827 - acc: 0.010 - ETA: 4s - loss: 4.8825 - acc: 0.010 - ETA: 4s - loss: 4.8825 - acc: 0.010 - ETA: 4s - loss: 4.8826 - acc: 0.010 - ETA: 4s - loss: 4.8826 - acc: 0.010 - ETA: 4s - loss: 4.8826 - acc: 0.010 - ETA: 3s - loss: 4.8827 - acc: 0.010 - ETA: 3s - loss: 4.8827 - acc: 0.010 - ETA: 3s - loss: 4.8827 - acc: 0.010 - ETA: 3s - loss: 4.8827 - acc: 0.010 - ETA: 3s - loss: 4.8828 - acc: 0.010 - ETA: 3s - loss: 4.8827 - acc: 0.010 - ETA: 3s - loss: 4.8827 - acc: 0.010 - ETA: 2s - loss: 4.8826 - acc: 0.010 - ETA: 2s - loss: 4.8827 - acc: 0.010 - ETA: 2s - loss: 4.8828 - acc: 0.010 - ETA: 2s - loss: 4.8828 - acc: 0.010 - ETA: 2s - loss: 4.8828 - acc: 0.010 - ETA: 2s - loss: 4.8828 - acc: 0.010 - ETA: 1s - loss: 4.8828 - acc: 0.010 - ETA: 1s - loss: 4.8828 - acc: 0.010 - ETA: 1s - loss: 4.8828 - acc: 0.010 - ETA: 1s - loss: 4.8830 - acc: 0.010 - ETA: 1s - loss: 4.8830 - acc: 0.010 - ETA: 1s - loss: 4.8831 - acc: 0.010 - ETA: 0s - loss: 4.8831 - acc: 0.010 - ETA: 0s - loss: 4.8831 - acc: 0.010 - ETA: 0s - loss: 4.8831 - acc: 0.010 - ETA: 0s - loss: 4.8830 - acc: 0.010 - ETA: 0s - loss: 4.8830 - acc: 0.009 - ETA: 0s - loss: 4.8829 - acc: 0.009 - 70s 168ms/step - loss: 4.8828 - acc: 0.0099 - val_loss: 4.8811 - val_acc: 0.0098\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.88204 to 4.88109, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 7s - loss: 4.8749 - acc: 0.0000e+0 - ETA: 6s - loss: 4.9025 - acc: 0.0000e+0 - ETA: 6s - loss: 4.9110 - acc: 0.0000e+0 - ETA: 9s - loss: 4.9047 - acc: 0.0052    - ETA: 14s - loss: 4.8990 - acc: 0.00 - ETA: 16s - loss: 4.8960 - acc: 0.00 - ETA: 23s - loss: 4.8937 - acc: 0.00 - ETA: 25s - loss: 4.8941 - acc: 0.00 - ETA: 27s - loss: 4.8919 - acc: 0.00 - ETA: 28s - loss: 4.8920 - acc: 0.00 - ETA: 30s - loss: 4.8919 - acc: 0.00 - ETA: 31s - loss: 4.8890 - acc: 0.00 - ETA: 32s - loss: 4.8898 - acc: 0.00 - ETA: 33s - loss: 4.8885 - acc: 0.00 - ETA: 33s - loss: 4.8891 - acc: 0.00 - ETA: 35s - loss: 4.8888 - acc: 0.00 - ETA: 37s - loss: 4.8888 - acc: 0.00 - ETA: 39s - loss: 4.8879 - acc: 0.00 - ETA: 40s - loss: 4.8902 - acc: 0.00 - ETA: 41s - loss: 4.8897 - acc: 0.00 - ETA: 43s - loss: 4.8878 - acc: 0.00 - ETA: 43s - loss: 4.8871 - acc: 0.00 - ETA: 43s - loss: 4.8872 - acc: 0.00 - ETA: 44s - loss: 4.8859 - acc: 0.00 - ETA: 45s - loss: 4.8852 - acc: 0.00 - ETA: 45s - loss: 4.8853 - acc: 0.00 - ETA: 45s - loss: 4.8842 - acc: 0.00 - ETA: 45s - loss: 4.8835 - acc: 0.00 - ETA: 45s - loss: 4.8830 - acc: 0.00 - ETA: 46s - loss: 4.8837 - acc: 0.00 - ETA: 46s - loss: 4.8839 - acc: 0.00 - ETA: 46s - loss: 4.8831 - acc: 0.00 - ETA: 46s - loss: 4.8828 - acc: 0.00 - ETA: 47s - loss: 4.8827 - acc: 0.00 - ETA: 49s - loss: 4.8829 - acc: 0.00 - ETA: 50s - loss: 4.8825 - acc: 0.00 - ETA: 49s - loss: 4.8837 - acc: 0.00 - ETA: 49s - loss: 4.8838 - acc: 0.00 - ETA: 50s - loss: 4.8831 - acc: 0.00 - ETA: 50s - loss: 4.8829 - acc: 0.00 - ETA: 50s - loss: 4.8819 - acc: 0.00 - ETA: 50s - loss: 4.8821 - acc: 0.00 - ETA: 51s - loss: 4.8821 - acc: 0.00 - ETA: 51s - loss: 4.8825 - acc: 0.00 - ETA: 51s - loss: 4.8833 - acc: 0.00 - ETA: 51s - loss: 4.8831 - acc: 0.00 - ETA: 51s - loss: 4.8829 - acc: 0.00 - ETA: 51s - loss: 4.8839 - acc: 0.00 - ETA: 51s - loss: 4.8836 - acc: 0.00 - ETA: 51s - loss: 4.8835 - acc: 0.00 - ETA: 51s - loss: 4.8834 - acc: 0.00 - ETA: 51s - loss: 4.8832 - acc: 0.00 - ETA: 51s - loss: 4.8838 - acc: 0.00 - ETA: 51s - loss: 4.8829 - acc: 0.00 - ETA: 51s - loss: 4.8830 - acc: 0.00 - ETA: 51s - loss: 4.8832 - acc: 0.00 - ETA: 51s - loss: 4.8838 - acc: 0.00 - ETA: 50s - loss: 4.8833 - acc: 0.01 - ETA: 51s - loss: 4.8834 - acc: 0.01 - ETA: 51s - loss: 4.8840 - acc: 0.01 - ETA: 51s - loss: 4.8837 - acc: 0.01 - ETA: 51s - loss: 4.8835 - acc: 0.01 - ETA: 51s - loss: 4.8846 - acc: 0.01 - ETA: 51s - loss: 4.8846 - acc: 0.01 - ETA: 50s - loss: 4.8844 - acc: 0.01 - ETA: 51s - loss: 4.8845 - acc: 0.01 - ETA: 51s - loss: 4.8846 - acc: 0.01 - ETA: 51s - loss: 4.8851 - acc: 0.01 - ETA: 51s - loss: 4.8842 - acc: 0.01 - ETA: 51s - loss: 4.8838 - acc: 0.01 - ETA: 51s - loss: 4.8838 - acc: 0.01 - ETA: 50s - loss: 4.8835 - acc: 0.01 - ETA: 50s - loss: 4.8837 - acc: 0.01 - ETA: 50s - loss: 4.8837 - acc: 0.01 - ETA: 50s - loss: 4.8839 - acc: 0.01 - ETA: 50s - loss: 4.8843 - acc: 0.01 - ETA: 50s - loss: 4.8841 - acc: 0.01 - ETA: 50s - loss: 4.8838 - acc: 0.01 - ETA: 50s - loss: 4.8842 - acc: 0.01 - ETA: 49s - loss: 4.8839 - acc: 0.01 - ETA: 49s - loss: 4.8837 - acc: 0.01 - ETA: 49s - loss: 4.8841 - acc: 0.01 - ETA: 49s - loss: 4.8842 - acc: 0.01 - ETA: 49s - loss: 4.8841 - acc: 0.01 - ETA: 49s - loss: 4.8845 - acc: 0.01 - ETA: 49s - loss: 4.8845 - acc: 0.01 - ETA: 49s - loss: 4.8843 - acc: 0.01 - ETA: 49s - loss: 4.8843 - acc: 0.01 - ETA: 49s - loss: 4.8842 - acc: 0.01 - ETA: 49s - loss: 4.8845 - acc: 0.01 - ETA: 48s - loss: 4.8843 - acc: 0.01 - ETA: 48s - loss: 4.8841 - acc: 0.01 - ETA: 48s - loss: 4.8839 - acc: 0.01 - ETA: 48s - loss: 4.8838 - acc: 0.01 - ETA: 48s - loss: 4.8843 - acc: 0.01 - ETA: 47s - loss: 4.8840 - acc: 0.01 - ETA: 47s - loss: 4.8840 - acc: 0.01 - ETA: 47s - loss: 4.8840 - acc: 0.01 - ETA: 47s - loss: 4.8837 - acc: 0.01 - ETA: 47s - loss: 4.8836 - acc: 0.01 - ETA: 47s - loss: 4.8834 - acc: 0.01 - ETA: 47s - loss: 4.8836 - acc: 0.01 - ETA: 46s - loss: 4.8837 - acc: 0.01 - ETA: 46s - loss: 4.8835 - acc: 0.01 - ETA: 46s - loss: 4.8834 - acc: 0.01 - ETA: 46s - loss: 4.8836 - acc: 0.01 - ETA: 46s - loss: 4.8838 - acc: 0.01 - ETA: 46s - loss: 4.8837 - acc: 0.01 - ETA: 45s - loss: 4.8838 - acc: 0.01 - ETA: 45s - loss: 4.8834 - acc: 0.01 - ETA: 45s - loss: 4.8836 - acc: 0.01 - ETA: 45s - loss: 4.8834 - acc: 0.01 - ETA: 45s - loss: 4.8834 - acc: 0.01 - ETA: 45s - loss: 4.8834 - acc: 0.01 - ETA: 44s - loss: 4.8834 - acc: 0.01 - ETA: 44s - loss: 4.8832 - acc: 0.01 - ETA: 44s - loss: 4.8834 - acc: 0.01 - ETA: 44s - loss: 4.8832 - acc: 0.01 - ETA: 44s - loss: 4.8836 - acc: 0.01 - ETA: 44s - loss: 4.8836 - acc: 0.01 - ETA: 44s - loss: 4.8837 - acc: 0.01 - ETA: 44s - loss: 4.8838 - acc: 0.01 - ETA: 43s - loss: 4.8835 - acc: 0.01 - ETA: 43s - loss: 4.8835 - acc: 0.01 - ETA: 43s - loss: 4.8835 - acc: 0.01 - ETA: 43s - loss: 4.8839 - acc: 0.01 - ETA: 43s - loss: 4.8837 - acc: 0.01 - ETA: 43s - loss: 4.8840 - acc: 0.01 - ETA: 43s - loss: 4.8839 - acc: 0.01 - ETA: 43s - loss: 4.8841 - acc: 0.01 - ETA: 43s - loss: 4.8838 - acc: 0.01 - ETA: 43s - loss: 4.8840 - acc: 0.01 - ETA: 42s - loss: 4.8839 - acc: 0.01 - ETA: 42s - loss: 4.8837 - acc: 0.01 - ETA: 43s - loss: 4.8837 - acc: 0.01 - ETA: 43s - loss: 4.8837 - acc: 0.01 - ETA: 42s - loss: 4.8839 - acc: 0.01 - ETA: 42s - loss: 4.8837 - acc: 0.01 - ETA: 42s - loss: 4.8838 - acc: 0.01 - ETA: 42s - loss: 4.8836 - acc: 0.01 - ETA: 42s - loss: 4.8835 - acc: 0.01 - ETA: 41s - loss: 4.8833 - acc: 0.01 - ETA: 41s - loss: 4.8835 - acc: 0.01 - ETA: 41s - loss: 4.8834 - acc: 0.01 - ETA: 41s - loss: 4.8837 - acc: 0.01 - ETA: 41s - loss: 4.8839 - acc: 0.01 - ETA: 41s - loss: 4.8839 - acc: 0.01 - ETA: 41s - loss: 4.8837 - acc: 0.01 - ETA: 40s - loss: 4.8836 - acc: 0.01 - ETA: 40s - loss: 4.8837 - acc: 0.00 - ETA: 40s - loss: 4.8837 - acc: 0.00 - ETA: 40s - loss: 4.8840 - acc: 0.00 - ETA: 40s - loss: 4.8839 - acc: 0.00 - ETA: 40s - loss: 4.8842 - acc: 0.00 - ETA: 40s - loss: 4.8842 - acc: 0.00 - ETA: 39s - loss: 4.8844 - acc: 0.00 - ETA: 39s - loss: 4.8843 - acc: 0.00 - ETA: 39s - loss: 4.8844 - acc: 0.00 - ETA: 39s - loss: 4.8843 - acc: 0.00 - ETA: 39s - loss: 4.8843 - acc: 0.00 - ETA: 39s - loss: 4.8844 - acc: 0.00 - ETA: 39s - loss: 4.8845 - acc: 0.00 - ETA: 39s - loss: 4.8847 - acc: 0.00 - ETA: 38s - loss: 4.8846 - acc: 0.00 - ETA: 38s - loss: 4.8846 - acc: 0.00 - ETA: 38s - loss: 4.8846 - acc: 0.01 - ETA: 38s - loss: 4.8844 - acc: 0.01 - ETA: 38s - loss: 4.8846 - acc: 0.01 - ETA: 38s - loss: 4.8846 - acc: 0.01 - ETA: 37s - loss: 4.8846 - acc: 0.01 - ETA: 37s - loss: 4.8845 - acc: 0.01 - ETA: 37s - loss: 4.8845 - acc: 0.01 - ETA: 37s - loss: 4.8847 - acc: 0.01 - ETA: 37s - loss: 4.8845 - acc: 0.01 - ETA: 37s - loss: 4.8847 - acc: 0.00 - ETA: 37s - loss: 4.8845 - acc: 0.00 - ETA: 36s - loss: 4.8847 - acc: 0.00 - ETA: 36s - loss: 4.8848 - acc: 0.00 - ETA: 36s - loss: 4.8846 - acc: 0.00 - ETA: 36s - loss: 4.8844 - acc: 0.01 - ETA: 36s - loss: 4.8843 - acc: 0.01 - ETA: 36s - loss: 4.8844 - acc: 0.01 - ETA: 35s - loss: 4.8844 - acc: 0.01 - ETA: 35s - loss: 4.8842 - acc: 0.01 - ETA: 35s - loss: 4.8843 - acc: 0.01 - ETA: 35s - loss: 4.8845 - acc: 0.01 - ETA: 35s - loss: 4.8844 - acc: 0.01 - ETA: 35s - loss: 4.8844 - acc: 0.01 - ETA: 34s - loss: 4.8844 - acc: 0.01 - ETA: 34s - loss: 4.8845 - acc: 0.01 - ETA: 34s - loss: 4.8845 - acc: 0.01 - ETA: 34s - loss: 4.8844 - acc: 0.01 - ETA: 34s - loss: 4.8844 - acc: 0.01 - ETA: 34s - loss: 4.8843 - acc: 0.01 - ETA: 33s - loss: 4.8844 - acc: 0.01 - ETA: 33s - loss: 4.8845 - acc: 0.01 - ETA: 33s - loss: 4.8844 - acc: 0.01 - ETA: 33s - loss: 4.8843 - acc: 0.01 - ETA: 33s - loss: 4.8844 - acc: 0.01 - ETA: 33s - loss: 4.8844 - acc: 0.01 - ETA: 32s - loss: 4.8844 - acc: 0.01 - ETA: 32s - loss: 4.8843 - acc: 0.01 - ETA: 32s - loss: 4.8843 - acc: 0.01 - ETA: 32s - loss: 4.8841 - acc: 0.01 - ETA: 32s - loss: 4.8841 - acc: 0.01 - ETA: 32s - loss: 4.8842 - acc: 0.01 - ETA: 32s - loss: 4.8842 - acc: 0.01 - ETA: 32s - loss: 4.8843 - acc: 0.01 - ETA: 31s - loss: 4.8842 - acc: 0.01 - ETA: 31s - loss: 4.8843 - acc: 0.01 - ETA: 31s - loss: 4.8843 - acc: 0.01 - ETA: 31s - loss: 4.8842 - acc: 0.01 - ETA: 31s - loss: 4.8840 - acc: 0.01 - ETA: 31s - loss: 4.8841 - acc: 0.01 - ETA: 30s - loss: 4.8840 - acc: 0.0109"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8841 - acc: 0.01 - ETA: 30s - loss: 4.8840 - acc: 0.01 - ETA: 30s - loss: 4.8840 - acc: 0.01 - ETA: 30s - loss: 4.8842 - acc: 0.01 - ETA: 30s - loss: 4.8842 - acc: 0.01 - ETA: 30s - loss: 4.8840 - acc: 0.01 - ETA: 29s - loss: 4.8840 - acc: 0.01 - ETA: 29s - loss: 4.8840 - acc: 0.01 - ETA: 29s - loss: 4.8839 - acc: 0.01 - ETA: 29s - loss: 4.8839 - acc: 0.01 - ETA: 29s - loss: 4.8840 - acc: 0.01 - ETA: 29s - loss: 4.8841 - acc: 0.01 - ETA: 29s - loss: 4.8843 - acc: 0.01 - ETA: 28s - loss: 4.8844 - acc: 0.01 - ETA: 28s - loss: 4.8843 - acc: 0.01 - ETA: 28s - loss: 4.8844 - acc: 0.01 - ETA: 28s - loss: 4.8845 - acc: 0.01 - ETA: 28s - loss: 4.8845 - acc: 0.01 - ETA: 28s - loss: 4.8845 - acc: 0.01 - ETA: 27s - loss: 4.8845 - acc: 0.01 - ETA: 27s - loss: 4.8847 - acc: 0.01 - ETA: 27s - loss: 4.8848 - acc: 0.01 - ETA: 27s - loss: 4.8848 - acc: 0.01 - ETA: 27s - loss: 4.8848 - acc: 0.01 - ETA: 27s - loss: 4.8850 - acc: 0.01 - ETA: 26s - loss: 4.8850 - acc: 0.01 - ETA: 26s - loss: 4.8850 - acc: 0.01 - ETA: 26s - loss: 4.8849 - acc: 0.01 - ETA: 26s - loss: 4.8848 - acc: 0.01 - ETA: 26s - loss: 4.8848 - acc: 0.01 - ETA: 26s - loss: 4.8848 - acc: 0.01 - ETA: 26s - loss: 4.8849 - acc: 0.01 - ETA: 25s - loss: 4.8848 - acc: 0.01 - ETA: 25s - loss: 4.8849 - acc: 0.01 - ETA: 25s - loss: 4.8849 - acc: 0.01 - ETA: 25s - loss: 4.8848 - acc: 0.01 - ETA: 25s - loss: 4.8848 - acc: 0.01 - ETA: 25s - loss: 4.8846 - acc: 0.01 - ETA: 24s - loss: 4.8848 - acc: 0.01 - ETA: 24s - loss: 4.8848 - acc: 0.01 - ETA: 24s - loss: 4.8847 - acc: 0.01 - ETA: 24s - loss: 4.8845 - acc: 0.01 - ETA: 24s - loss: 4.8844 - acc: 0.01 - ETA: 24s - loss: 4.8845 - acc: 0.01 - ETA: 24s - loss: 4.8846 - acc: 0.01 - ETA: 23s - loss: 4.8845 - acc: 0.01 - ETA: 23s - loss: 4.8845 - acc: 0.01 - ETA: 23s - loss: 4.8845 - acc: 0.01 - ETA: 23s - loss: 4.8845 - acc: 0.01 - ETA: 23s - loss: 4.8844 - acc: 0.01 - ETA: 23s - loss: 4.8845 - acc: 0.01 - ETA: 22s - loss: 4.8845 - acc: 0.01 - ETA: 22s - loss: 4.8845 - acc: 0.01 - ETA: 22s - loss: 4.8843 - acc: 0.01 - ETA: 22s - loss: 4.8843 - acc: 0.01 - ETA: 22s - loss: 4.8841 - acc: 0.01 - ETA: 22s - loss: 4.8841 - acc: 0.01 - ETA: 21s - loss: 4.8841 - acc: 0.01 - ETA: 21s - loss: 4.8840 - acc: 0.01 - ETA: 21s - loss: 4.8841 - acc: 0.01 - ETA: 21s - loss: 4.8840 - acc: 0.01 - ETA: 21s - loss: 4.8841 - acc: 0.01 - ETA: 21s - loss: 4.8839 - acc: 0.01 - ETA: 21s - loss: 4.8838 - acc: 0.01 - ETA: 20s - loss: 4.8839 - acc: 0.01 - ETA: 20s - loss: 4.8838 - acc: 0.01 - ETA: 20s - loss: 4.8837 - acc: 0.01 - ETA: 20s - loss: 4.8838 - acc: 0.01 - ETA: 20s - loss: 4.8839 - acc: 0.01 - ETA: 20s - loss: 4.8838 - acc: 0.01 - ETA: 19s - loss: 4.8838 - acc: 0.01 - ETA: 19s - loss: 4.8837 - acc: 0.01 - ETA: 19s - loss: 4.8837 - acc: 0.01 - ETA: 19s - loss: 4.8839 - acc: 0.01 - ETA: 19s - loss: 4.8838 - acc: 0.01 - ETA: 19s - loss: 4.8838 - acc: 0.01 - ETA: 19s - loss: 4.8838 - acc: 0.01 - ETA: 18s - loss: 4.8840 - acc: 0.01 - ETA: 18s - loss: 4.8840 - acc: 0.01 - ETA: 18s - loss: 4.8839 - acc: 0.01 - ETA: 18s - loss: 4.8840 - acc: 0.01 - ETA: 18s - loss: 4.8840 - acc: 0.01 - ETA: 18s - loss: 4.8841 - acc: 0.01 - ETA: 17s - loss: 4.8842 - acc: 0.01 - ETA: 17s - loss: 4.8840 - acc: 0.01 - ETA: 17s - loss: 4.8841 - acc: 0.01 - ETA: 17s - loss: 4.8842 - acc: 0.01 - ETA: 17s - loss: 4.8843 - acc: 0.01 - ETA: 17s - loss: 4.8842 - acc: 0.01 - ETA: 16s - loss: 4.8843 - acc: 0.01 - ETA: 16s - loss: 4.8842 - acc: 0.01 - ETA: 16s - loss: 4.8841 - acc: 0.01 - ETA: 16s - loss: 4.8841 - acc: 0.01 - ETA: 16s - loss: 4.8840 - acc: 0.01 - ETA: 16s - loss: 4.8840 - acc: 0.01 - ETA: 15s - loss: 4.8839 - acc: 0.01 - ETA: 15s - loss: 4.8838 - acc: 0.01 - ETA: 15s - loss: 4.8838 - acc: 0.01 - ETA: 15s - loss: 4.8839 - acc: 0.01 - ETA: 15s - loss: 4.8839 - acc: 0.01 - ETA: 15s - loss: 4.8840 - acc: 0.01 - ETA: 14s - loss: 4.8841 - acc: 0.01 - ETA: 14s - loss: 4.8840 - acc: 0.01 - ETA: 14s - loss: 4.8841 - acc: 0.01 - ETA: 14s - loss: 4.8841 - acc: 0.01 - ETA: 14s - loss: 4.8840 - acc: 0.01 - ETA: 14s - loss: 4.8839 - acc: 0.01 - ETA: 13s - loss: 4.8839 - acc: 0.01 - ETA: 13s - loss: 4.8841 - acc: 0.01 - ETA: 13s - loss: 4.8839 - acc: 0.01 - ETA: 13s - loss: 4.8839 - acc: 0.01 - ETA: 13s - loss: 4.8839 - acc: 0.01 - ETA: 13s - loss: 4.8838 - acc: 0.01 - ETA: 12s - loss: 4.8838 - acc: 0.01 - ETA: 12s - loss: 4.8838 - acc: 0.01 - ETA: 12s - loss: 4.8838 - acc: 0.01 - ETA: 12s - loss: 4.8838 - acc: 0.01 - ETA: 12s - loss: 4.8840 - acc: 0.01 - ETA: 12s - loss: 4.8839 - acc: 0.01 - ETA: 11s - loss: 4.8840 - acc: 0.01 - ETA: 11s - loss: 4.8838 - acc: 0.01 - ETA: 11s - loss: 4.8839 - acc: 0.01 - ETA: 11s - loss: 4.8838 - acc: 0.01 - ETA: 11s - loss: 4.8839 - acc: 0.01 - ETA: 11s - loss: 4.8839 - acc: 0.01 - ETA: 10s - loss: 4.8840 - acc: 0.01 - ETA: 10s - loss: 4.8839 - acc: 0.01 - ETA: 10s - loss: 4.8839 - acc: 0.01 - ETA: 10s - loss: 4.8839 - acc: 0.01 - ETA: 10s - loss: 4.8839 - acc: 0.01 - ETA: 10s - loss: 4.8839 - acc: 0.01 - ETA: 9s - loss: 4.8839 - acc: 0.0109 - ETA: 9s - loss: 4.8839 - acc: 0.011 - ETA: 9s - loss: 4.8838 - acc: 0.011 - ETA: 9s - loss: 4.8840 - acc: 0.011 - ETA: 9s - loss: 4.8840 - acc: 0.011 - ETA: 9s - loss: 4.8839 - acc: 0.010 - ETA: 9s - loss: 4.8839 - acc: 0.010 - ETA: 8s - loss: 4.8840 - acc: 0.010 - ETA: 8s - loss: 4.8839 - acc: 0.010 - ETA: 8s - loss: 4.8840 - acc: 0.010 - ETA: 8s - loss: 4.8839 - acc: 0.010 - ETA: 8s - loss: 4.8838 - acc: 0.010 - ETA: 8s - loss: 4.8839 - acc: 0.010 - ETA: 7s - loss: 4.8839 - acc: 0.010 - ETA: 7s - loss: 4.8839 - acc: 0.010 - ETA: 7s - loss: 4.8840 - acc: 0.010 - ETA: 7s - loss: 4.8841 - acc: 0.010 - ETA: 7s - loss: 4.8841 - acc: 0.010 - ETA: 7s - loss: 4.8842 - acc: 0.010 - ETA: 6s - loss: 4.8843 - acc: 0.010 - ETA: 6s - loss: 4.8842 - acc: 0.010 - ETA: 6s - loss: 4.8842 - acc: 0.010 - ETA: 6s - loss: 4.8842 - acc: 0.010 - ETA: 6s - loss: 4.8841 - acc: 0.010 - ETA: 6s - loss: 4.8840 - acc: 0.010 - ETA: 5s - loss: 4.8842 - acc: 0.010 - ETA: 5s - loss: 4.8841 - acc: 0.010 - ETA: 5s - loss: 4.8841 - acc: 0.010 - ETA: 5s - loss: 4.8840 - acc: 0.010 - ETA: 5s - loss: 4.8839 - acc: 0.010 - ETA: 5s - loss: 4.8838 - acc: 0.010 - ETA: 4s - loss: 4.8839 - acc: 0.010 - ETA: 4s - loss: 4.8838 - acc: 0.010 - ETA: 4s - loss: 4.8838 - acc: 0.010 - ETA: 4s - loss: 4.8837 - acc: 0.010 - ETA: 4s - loss: 4.8837 - acc: 0.010 - ETA: 4s - loss: 4.8837 - acc: 0.010 - ETA: 4s - loss: 4.8837 - acc: 0.010 - ETA: 3s - loss: 4.8838 - acc: 0.010 - ETA: 3s - loss: 4.8837 - acc: 0.010 - ETA: 3s - loss: 4.8837 - acc: 0.010 - ETA: 3s - loss: 4.8837 - acc: 0.010 - ETA: 3s - loss: 4.8838 - acc: 0.010 - ETA: 3s - loss: 4.8838 - acc: 0.010 - ETA: 2s - loss: 4.8837 - acc: 0.010 - ETA: 2s - loss: 4.8837 - acc: 0.010 - ETA: 2s - loss: 4.8837 - acc: 0.010 - ETA: 2s - loss: 4.8838 - acc: 0.010 - ETA: 2s - loss: 4.8837 - acc: 0.010 - ETA: 2s - loss: 4.8838 - acc: 0.010 - ETA: 1s - loss: 4.8839 - acc: 0.010 - ETA: 1s - loss: 4.8839 - acc: 0.010 - ETA: 1s - loss: 4.8838 - acc: 0.010 - ETA: 1s - loss: 4.8839 - acc: 0.010 - ETA: 1s - loss: 4.8838 - acc: 0.010 - ETA: 1s - loss: 4.8839 - acc: 0.010 - ETA: 0s - loss: 4.8839 - acc: 0.010 - ETA: 0s - loss: 4.8839 - acc: 0.010 - ETA: 0s - loss: 4.8839 - acc: 0.010 - ETA: 0s - loss: 4.8839 - acc: 0.010 - ETA: 0s - loss: 4.8839 - acc: 0.010 - ETA: 0s - loss: 4.8841 - acc: 0.010 - 71s 170ms/step - loss: 4.8841 - acc: 0.0103 - val_loss: 4.8792 - val_acc: 0.0134\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.88109 to 4.87918, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/417 [===============>..............] - ETA: 5s - loss: 4.8693 - acc: 0.0000e+0 - ETA: 5s - loss: 4.8736 - acc: 0.0125    - ETA: 5s - loss: 4.8867 - acc: 0.006 - ETA: 9s - loss: 4.8858 - acc: 0.004 - ETA: 15s - loss: 4.8862 - acc: 0.00 - ETA: 17s - loss: 4.8851 - acc: 0.00 - ETA: 19s - loss: 4.8842 - acc: 0.00 - ETA: 22s - loss: 4.8831 - acc: 0.00 - ETA: 24s - loss: 4.8820 - acc: 0.00 - ETA: 27s - loss: 4.8811 - acc: 0.00 - ETA: 36s - loss: 4.8806 - acc: 0.00 - ETA: 35s - loss: 4.8821 - acc: 0.00 - ETA: 37s - loss: 4.8819 - acc: 0.00 - ETA: 40s - loss: 4.8815 - acc: 0.00 - ETA: 41s - loss: 4.8824 - acc: 0.00 - ETA: 41s - loss: 4.8819 - acc: 0.00 - ETA: 42s - loss: 4.8813 - acc: 0.00 - ETA: 43s - loss: 4.8818 - acc: 0.00 - ETA: 43s - loss: 4.8815 - acc: 0.00 - ETA: 44s - loss: 4.8823 - acc: 0.00 - ETA: 44s - loss: 4.8811 - acc: 0.01 - ETA: 44s - loss: 4.8814 - acc: 0.00 - ETA: 45s - loss: 4.8824 - acc: 0.00 - ETA: 45s - loss: 4.8807 - acc: 0.01 - ETA: 45s - loss: 4.8797 - acc: 0.01 - ETA: 46s - loss: 4.8793 - acc: 0.01 - ETA: 46s - loss: 4.8784 - acc: 0.01 - ETA: 46s - loss: 4.8794 - acc: 0.00 - ETA: 46s - loss: 4.8798 - acc: 0.00 - ETA: 46s - loss: 4.8791 - acc: 0.01 - ETA: 46s - loss: 4.8792 - acc: 0.01 - ETA: 46s - loss: 4.8794 - acc: 0.01 - ETA: 47s - loss: 4.8802 - acc: 0.01 - ETA: 46s - loss: 4.8813 - acc: 0.00 - ETA: 46s - loss: 4.8809 - acc: 0.00 - ETA: 46s - loss: 4.8808 - acc: 0.01 - ETA: 46s - loss: 4.8799 - acc: 0.01 - ETA: 46s - loss: 4.8795 - acc: 0.01 - ETA: 47s - loss: 4.8792 - acc: 0.01 - ETA: 47s - loss: 4.8791 - acc: 0.01 - ETA: 47s - loss: 4.8791 - acc: 0.01 - ETA: 47s - loss: 4.8791 - acc: 0.01 - ETA: 47s - loss: 4.8803 - acc: 0.01 - ETA: 47s - loss: 4.8812 - acc: 0.01 - ETA: 47s - loss: 4.8813 - acc: 0.01 - ETA: 46s - loss: 4.8799 - acc: 0.01 - ETA: 46s - loss: 4.8806 - acc: 0.01 - ETA: 46s - loss: 4.8811 - acc: 0.01 - ETA: 46s - loss: 4.8812 - acc: 0.01 - ETA: 46s - loss: 4.8818 - acc: 0.01 - ETA: 46s - loss: 4.8817 - acc: 0.01 - ETA: 46s - loss: 4.8817 - acc: 0.01 - ETA: 46s - loss: 4.8820 - acc: 0.01 - ETA: 46s - loss: 4.8819 - acc: 0.01 - ETA: 46s - loss: 4.8818 - acc: 0.01 - ETA: 46s - loss: 4.8818 - acc: 0.01 - ETA: 46s - loss: 4.8817 - acc: 0.01 - ETA: 46s - loss: 4.8812 - acc: 0.01 - ETA: 46s - loss: 4.8814 - acc: 0.01 - ETA: 46s - loss: 4.8816 - acc: 0.01 - ETA: 46s - loss: 4.8819 - acc: 0.01 - ETA: 46s - loss: 4.8823 - acc: 0.01 - ETA: 45s - loss: 4.8823 - acc: 0.01 - ETA: 45s - loss: 4.8819 - acc: 0.01 - ETA: 46s - loss: 4.8821 - acc: 0.01 - ETA: 46s - loss: 4.8822 - acc: 0.00 - ETA: 46s - loss: 4.8823 - acc: 0.00 - ETA: 46s - loss: 4.8822 - acc: 0.00 - ETA: 45s - loss: 4.8822 - acc: 0.00 - ETA: 45s - loss: 4.8824 - acc: 0.00 - ETA: 45s - loss: 4.8822 - acc: 0.00 - ETA: 46s - loss: 4.8816 - acc: 0.00 - ETA: 46s - loss: 4.8816 - acc: 0.00 - ETA: 46s - loss: 4.8820 - acc: 0.00 - ETA: 46s - loss: 4.8823 - acc: 0.00 - ETA: 46s - loss: 4.8821 - acc: 0.00 - ETA: 45s - loss: 4.8817 - acc: 0.00 - ETA: 46s - loss: 4.8817 - acc: 0.00 - ETA: 46s - loss: 4.8817 - acc: 0.00 - ETA: 46s - loss: 4.8814 - acc: 0.00 - ETA: 46s - loss: 4.8818 - acc: 0.00 - ETA: 45s - loss: 4.8819 - acc: 0.00 - ETA: 45s - loss: 4.8818 - acc: 0.00 - ETA: 45s - loss: 4.8824 - acc: 0.00 - ETA: 45s - loss: 4.8823 - acc: 0.00 - ETA: 45s - loss: 4.8822 - acc: 0.00 - ETA: 45s - loss: 4.8819 - acc: 0.00 - ETA: 45s - loss: 4.8820 - acc: 0.00 - ETA: 45s - loss: 4.8820 - acc: 0.00 - ETA: 45s - loss: 4.8822 - acc: 0.00 - ETA: 44s - loss: 4.8822 - acc: 0.00 - ETA: 44s - loss: 4.8827 - acc: 0.00 - ETA: 44s - loss: 4.8828 - acc: 0.01 - ETA: 44s - loss: 4.8827 - acc: 0.01 - ETA: 44s - loss: 4.8830 - acc: 0.01 - ETA: 44s - loss: 4.8833 - acc: 0.01 - ETA: 43s - loss: 4.8833 - acc: 0.00 - ETA: 43s - loss: 4.8826 - acc: 0.01 - ETA: 43s - loss: 4.8828 - acc: 0.01 - ETA: 43s - loss: 4.8827 - acc: 0.01 - ETA: 43s - loss: 4.8824 - acc: 0.01 - ETA: 43s - loss: 4.8824 - acc: 0.01 - ETA: 43s - loss: 4.8830 - acc: 0.01 - ETA: 42s - loss: 4.8829 - acc: 0.00 - ETA: 42s - loss: 4.8831 - acc: 0.00 - ETA: 42s - loss: 4.8833 - acc: 0.00 - ETA: 42s - loss: 4.8836 - acc: 0.00 - ETA: 43s - loss: 4.8835 - acc: 0.01 - ETA: 43s - loss: 4.8832 - acc: 0.01 - ETA: 43s - loss: 4.8832 - acc: 0.01 - ETA: 43s - loss: 4.8830 - acc: 0.01 - ETA: 42s - loss: 4.8829 - acc: 0.01 - ETA: 42s - loss: 4.8831 - acc: 0.01 - ETA: 42s - loss: 4.8831 - acc: 0.01 - ETA: 42s - loss: 4.8829 - acc: 0.01 - ETA: 42s - loss: 4.8830 - acc: 0.01 - ETA: 42s - loss: 4.8829 - acc: 0.01 - ETA: 42s - loss: 4.8830 - acc: 0.01 - ETA: 42s - loss: 4.8831 - acc: 0.01 - ETA: 41s - loss: 4.8827 - acc: 0.01 - ETA: 41s - loss: 4.8826 - acc: 0.01 - ETA: 41s - loss: 4.8827 - acc: 0.01 - ETA: 41s - loss: 4.8827 - acc: 0.01 - ETA: 41s - loss: 4.8825 - acc: 0.01 - ETA: 41s - loss: 4.8827 - acc: 0.01 - ETA: 41s - loss: 4.8827 - acc: 0.01 - ETA: 40s - loss: 4.8824 - acc: 0.01 - ETA: 40s - loss: 4.8824 - acc: 0.01 - ETA: 40s - loss: 4.8827 - acc: 0.00 - ETA: 40s - loss: 4.8830 - acc: 0.00 - ETA: 40s - loss: 4.8829 - acc: 0.00 - ETA: 40s - loss: 4.8825 - acc: 0.01 - ETA: 40s - loss: 4.8825 - acc: 0.01 - ETA: 39s - loss: 4.8828 - acc: 0.01 - ETA: 39s - loss: 4.8827 - acc: 0.01 - ETA: 39s - loss: 4.8827 - acc: 0.01 - ETA: 39s - loss: 4.8825 - acc: 0.01 - ETA: 39s - loss: 4.8824 - acc: 0.01 - ETA: 39s - loss: 4.8825 - acc: 0.01 - ETA: 39s - loss: 4.8827 - acc: 0.01 - ETA: 38s - loss: 4.8827 - acc: 0.01 - ETA: 38s - loss: 4.8828 - acc: 0.01 - ETA: 38s - loss: 4.8830 - acc: 0.01 - ETA: 38s - loss: 4.8830 - acc: 0.01 - ETA: 38s - loss: 4.8829 - acc: 0.01 - ETA: 38s - loss: 4.8828 - acc: 0.01 - ETA: 38s - loss: 4.8828 - acc: 0.01 - ETA: 38s - loss: 4.8825 - acc: 0.01 - ETA: 37s - loss: 4.8825 - acc: 0.01 - ETA: 37s - loss: 4.8827 - acc: 0.01 - ETA: 37s - loss: 4.8826 - acc: 0.01 - ETA: 37s - loss: 4.8826 - acc: 0.01 - ETA: 37s - loss: 4.8826 - acc: 0.01 - ETA: 37s - loss: 4.8823 - acc: 0.01 - ETA: 37s - loss: 4.8823 - acc: 0.01 - ETA: 37s - loss: 4.8823 - acc: 0.01 - ETA: 37s - loss: 4.8825 - acc: 0.01 - ETA: 37s - loss: 4.8825 - acc: 0.01 - ETA: 36s - loss: 4.8825 - acc: 0.01 - ETA: 36s - loss: 4.8826 - acc: 0.01 - ETA: 36s - loss: 4.8826 - acc: 0.01 - ETA: 36s - loss: 4.8824 - acc: 0.01 - ETA: 36s - loss: 4.8821 - acc: 0.01 - ETA: 36s - loss: 4.8819 - acc: 0.01 - ETA: 36s - loss: 4.8821 - acc: 0.01 - ETA: 36s - loss: 4.8821 - acc: 0.01 - ETA: 35s - loss: 4.8819 - acc: 0.01 - ETA: 35s - loss: 4.8821 - acc: 0.01 - ETA: 35s - loss: 4.8821 - acc: 0.01 - ETA: 35s - loss: 4.8819 - acc: 0.01 - ETA: 35s - loss: 4.8820 - acc: 0.01 - ETA: 35s - loss: 4.8820 - acc: 0.01 - ETA: 35s - loss: 4.8820 - acc: 0.01 - ETA: 34s - loss: 4.8821 - acc: 0.01 - ETA: 34s - loss: 4.8820 - acc: 0.01 - ETA: 34s - loss: 4.8818 - acc: 0.01 - ETA: 34s - loss: 4.8820 - acc: 0.01 - ETA: 34s - loss: 4.8820 - acc: 0.01 - ETA: 34s - loss: 4.8819 - acc: 0.01 - ETA: 34s - loss: 4.8819 - acc: 0.01 - ETA: 33s - loss: 4.8820 - acc: 0.01 - ETA: 33s - loss: 4.8819 - acc: 0.01 - ETA: 33s - loss: 4.8819 - acc: 0.01 - ETA: 33s - loss: 4.8820 - acc: 0.01 - ETA: 33s - loss: 4.8821 - acc: 0.01 - ETA: 33s - loss: 4.8818 - acc: 0.01 - ETA: 32s - loss: 4.8818 - acc: 0.01 - ETA: 32s - loss: 4.8819 - acc: 0.01 - ETA: 32s - loss: 4.8820 - acc: 0.01 - ETA: 32s - loss: 4.8820 - acc: 0.01 - ETA: 32s - loss: 4.8821 - acc: 0.01 - ETA: 32s - loss: 4.8821 - acc: 0.01 - ETA: 32s - loss: 4.8822 - acc: 0.01 - ETA: 32s - loss: 4.8823 - acc: 0.01 - ETA: 32s - loss: 4.8823 - acc: 0.01 - ETA: 31s - loss: 4.8823 - acc: 0.01 - ETA: 31s - loss: 4.8822 - acc: 0.01 - ETA: 31s - loss: 4.8823 - acc: 0.01 - ETA: 31s - loss: 4.8823 - acc: 0.01 - ETA: 31s - loss: 4.8821 - acc: 0.01 - ETA: 31s - loss: 4.8820 - acc: 0.01 - ETA: 30s - loss: 4.8820 - acc: 0.01 - ETA: 30s - loss: 4.8819 - acc: 0.01 - ETA: 30s - loss: 4.8819 - acc: 0.01 - ETA: 30s - loss: 4.8817 - acc: 0.01 - ETA: 30s - loss: 4.8815 - acc: 0.01 - ETA: 30s - loss: 4.8814 - acc: 0.01 - ETA: 30s - loss: 4.8812 - acc: 0.01 - ETA: 29s - loss: 4.8813 - acc: 0.01 - ETA: 29s - loss: 4.8813 - acc: 0.01 - ETA: 29s - loss: 4.8813 - acc: 0.01 - ETA: 29s - loss: 4.8812 - acc: 0.01 - ETA: 29s - loss: 4.8813 - acc: 0.01 - ETA: 29s - loss: 4.8813 - acc: 0.01 - ETA: 29s - loss: 4.8811 - acc: 0.0111"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8810 - acc: 0.01 - ETA: 28s - loss: 4.8812 - acc: 0.01 - ETA: 28s - loss: 4.8811 - acc: 0.01 - ETA: 28s - loss: 4.8811 - acc: 0.01 - ETA: 28s - loss: 4.8813 - acc: 0.01 - ETA: 28s - loss: 4.8814 - acc: 0.01 - ETA: 28s - loss: 4.8813 - acc: 0.01 - ETA: 27s - loss: 4.8813 - acc: 0.01 - ETA: 27s - loss: 4.8813 - acc: 0.01 - ETA: 27s - loss: 4.8811 - acc: 0.01 - ETA: 27s - loss: 4.8811 - acc: 0.01 - ETA: 27s - loss: 4.8809 - acc: 0.01 - ETA: 27s - loss: 4.8811 - acc: 0.01 - ETA: 27s - loss: 4.8812 - acc: 0.01 - ETA: 27s - loss: 4.8813 - acc: 0.01 - ETA: 26s - loss: 4.8814 - acc: 0.01 - ETA: 26s - loss: 4.8815 - acc: 0.01 - ETA: 26s - loss: 4.8815 - acc: 0.01 - ETA: 26s - loss: 4.8815 - acc: 0.01 - ETA: 26s - loss: 4.8816 - acc: 0.01 - ETA: 26s - loss: 4.8816 - acc: 0.01 - ETA: 26s - loss: 4.8816 - acc: 0.01 - ETA: 25s - loss: 4.8814 - acc: 0.01 - ETA: 25s - loss: 4.8815 - acc: 0.01 - ETA: 25s - loss: 4.8815 - acc: 0.01 - ETA: 25s - loss: 4.8814 - acc: 0.01 - ETA: 25s - loss: 4.8815 - acc: 0.01 - ETA: 25s - loss: 4.8816 - acc: 0.01 - ETA: 25s - loss: 4.8817 - acc: 0.01 - ETA: 24s - loss: 4.8817 - acc: 0.01 - ETA: 24s - loss: 4.8819 - acc: 0.01 - ETA: 24s - loss: 4.8818 - acc: 0.01 - ETA: 24s - loss: 4.8818 - acc: 0.01 - ETA: 24s - loss: 4.8819 - acc: 0.01 - ETA: 24s - loss: 4.8819 - acc: 0.01 - ETA: 24s - loss: 4.8818 - acc: 0.01 - ETA: 24s - loss: 4.8817 - acc: 0.01 - ETA: 23s - loss: 4.8818 - acc: 0.01 - ETA: 23s - loss: 4.8816 - acc: 0.01 - ETA: 23s - loss: 4.8816 - acc: 0.01 - ETA: 23s - loss: 4.8817 - acc: 0.01 - ETA: 23s - loss: 4.8817 - acc: 0.01 - ETA: 23s - loss: 4.8817 - acc: 0.01 - ETA: 23s - loss: 4.8817 - acc: 0.01 - ETA: 22s - loss: 4.8816 - acc: 0.01 - ETA: 22s - loss: 4.8815 - acc: 0.01 - ETA: 22s - loss: 4.8816 - acc: 0.01 - ETA: 22s - loss: 4.8816 - acc: 0.01 - ETA: 22s - loss: 4.8817 - acc: 0.01 - ETA: 22s - loss: 4.8816 - acc: 0.01 - ETA: 22s - loss: 4.8815 - acc: 0.01 - ETA: 21s - loss: 4.8815 - acc: 0.01 - ETA: 21s - loss: 4.8817 - acc: 0.01 - ETA: 21s - loss: 4.8816 - acc: 0.01 - ETA: 21s - loss: 4.8817 - acc: 0.01 - ETA: 21s - loss: 4.8818 - acc: 0.01 - ETA: 21s - loss: 4.8818 - acc: 0.01 - ETA: 20s - loss: 4.8818 - acc: 0.01 - ETA: 20s - loss: 4.8817 - acc: 0.01 - ETA: 20s - loss: 4.8818 - acc: 0.01 - ETA: 20s - loss: 4.8819 - acc: 0.01 - ETA: 20s - loss: 4.8818 - acc: 0.01 - ETA: 20s - loss: 4.8817 - acc: 0.01 - ETA: 19s - loss: 4.8816 - acc: 0.01 - ETA: 19s - loss: 4.8817 - acc: 0.01 - ETA: 19s - loss: 4.8817 - acc: 0.01 - ETA: 19s - loss: 4.8816 - acc: 0.01 - ETA: 19s - loss: 4.8816 - acc: 0.01 - ETA: 19s - loss: 4.8815 - acc: 0.01 - ETA: 19s - loss: 4.8815 - acc: 0.01 - ETA: 18s - loss: 4.8815 - acc: 0.01 - ETA: 18s - loss: 4.8814 - acc: 0.01 - ETA: 18s - loss: 4.8816 - acc: 0.01 - ETA: 18s - loss: 4.8815 - acc: 0.01 - ETA: 18s - loss: 4.8815 - acc: 0.01 - ETA: 18s - loss: 4.8816 - acc: 0.01 - ETA: 17s - loss: 4.8817 - acc: 0.01 - ETA: 17s - loss: 4.8818 - acc: 0.01 - ETA: 17s - loss: 4.8818 - acc: 0.01 - ETA: 17s - loss: 4.8818 - acc: 0.01 - ETA: 17s - loss: 4.8819 - acc: 0.01 - ETA: 17s - loss: 4.8820 - acc: 0.01 - ETA: 17s - loss: 4.8820 - acc: 0.01 - ETA: 16s - loss: 4.8819 - acc: 0.01 - ETA: 16s - loss: 4.8820 - acc: 0.01 - ETA: 16s - loss: 4.8820 - acc: 0.01 - ETA: 16s - loss: 4.8820 - acc: 0.01 - ETA: 16s - loss: 4.8819 - acc: 0.01 - ETA: 16s - loss: 4.8819 - acc: 0.01 - ETA: 15s - loss: 4.8820 - acc: 0.01 - ETA: 15s - loss: 4.8819 - acc: 0.01 - ETA: 15s - loss: 4.8820 - acc: 0.01 - ETA: 15s - loss: 4.8819 - acc: 0.01 - ETA: 15s - loss: 4.8822 - acc: 0.01 - ETA: 15s - loss: 4.8821 - acc: 0.01 - ETA: 15s - loss: 4.8821 - acc: 0.01 - ETA: 14s - loss: 4.8821 - acc: 0.01 - ETA: 14s - loss: 4.8822 - acc: 0.01 - ETA: 14s - loss: 4.8823 - acc: 0.01 - ETA: 14s - loss: 4.8823 - acc: 0.01 - ETA: 14s - loss: 4.8823 - acc: 0.01 - ETA: 14s - loss: 4.8823 - acc: 0.01 - ETA: 14s - loss: 4.8824 - acc: 0.01 - ETA: 13s - loss: 4.8823 - acc: 0.01 - ETA: 13s - loss: 4.8824 - acc: 0.01 - ETA: 13s - loss: 4.8824 - acc: 0.01 - ETA: 13s - loss: 4.8824 - acc: 0.01 - ETA: 13s - loss: 4.8824 - acc: 0.01 - ETA: 13s - loss: 4.8825 - acc: 0.01 - ETA: 12s - loss: 4.8825 - acc: 0.01 - ETA: 12s - loss: 4.8825 - acc: 0.01 - ETA: 12s - loss: 4.8825 - acc: 0.01 - ETA: 12s - loss: 4.8825 - acc: 0.01 - ETA: 12s - loss: 4.8825 - acc: 0.01 - ETA: 12s - loss: 4.8823 - acc: 0.01 - ETA: 11s - loss: 4.8823 - acc: 0.01 - ETA: 11s - loss: 4.8821 - acc: 0.01 - ETA: 11s - loss: 4.8821 - acc: 0.01 - ETA: 11s - loss: 4.8820 - acc: 0.01 - ETA: 11s - loss: 4.8820 - acc: 0.01 - ETA: 11s - loss: 4.8820 - acc: 0.01 - ETA: 11s - loss: 4.8818 - acc: 0.01 - ETA: 10s - loss: 4.8818 - acc: 0.01 - ETA: 10s - loss: 4.8818 - acc: 0.01 - ETA: 10s - loss: 4.8816 - acc: 0.01 - ETA: 10s - loss: 4.8816 - acc: 0.01 - ETA: 10s - loss: 4.8816 - acc: 0.01 - ETA: 10s - loss: 4.8817 - acc: 0.01 - ETA: 9s - loss: 4.8817 - acc: 0.0115 - ETA: 9s - loss: 4.8818 - acc: 0.011 - ETA: 9s - loss: 4.8818 - acc: 0.011 - ETA: 9s - loss: 4.8818 - acc: 0.011 - ETA: 9s - loss: 4.8819 - acc: 0.011 - ETA: 9s - loss: 4.8821 - acc: 0.011 - ETA: 8s - loss: 4.8822 - acc: 0.011 - ETA: 8s - loss: 4.8822 - acc: 0.011 - ETA: 8s - loss: 4.8822 - acc: 0.011 - ETA: 8s - loss: 4.8822 - acc: 0.011 - ETA: 8s - loss: 4.8821 - acc: 0.011 - ETA: 8s - loss: 4.8821 - acc: 0.011 - ETA: 8s - loss: 4.8822 - acc: 0.011 - ETA: 7s - loss: 4.8822 - acc: 0.011 - ETA: 7s - loss: 4.8822 - acc: 0.011 - ETA: 7s - loss: 4.8822 - acc: 0.011 - ETA: 7s - loss: 4.8823 - acc: 0.011 - ETA: 7s - loss: 4.8823 - acc: 0.011 - ETA: 7s - loss: 4.8822 - acc: 0.011 - ETA: 6s - loss: 4.8822 - acc: 0.011 - ETA: 6s - loss: 4.8823 - acc: 0.011 - ETA: 6s - loss: 4.8824 - acc: 0.011 - ETA: 6s - loss: 4.8824 - acc: 0.011 - ETA: 6s - loss: 4.8824 - acc: 0.011 - ETA: 6s - loss: 4.8824 - acc: 0.011 - ETA: 6s - loss: 4.8823 - acc: 0.011 - ETA: 5s - loss: 4.8823 - acc: 0.011 - ETA: 5s - loss: 4.8822 - acc: 0.011 - ETA: 5s - loss: 4.8823 - acc: 0.011 - ETA: 5s - loss: 4.8823 - acc: 0.011 - ETA: 5s - loss: 4.8823 - acc: 0.011 - ETA: 5s - loss: 4.8823 - acc: 0.011 - ETA: 4s - loss: 4.8824 - acc: 0.011 - ETA: 4s - loss: 4.8823 - acc: 0.011 - ETA: 4s - loss: 4.8824 - acc: 0.011 - ETA: 4s - loss: 4.8824 - acc: 0.011 - ETA: 4s - loss: 4.8825 - acc: 0.011 - ETA: 4s - loss: 4.8825 - acc: 0.011 - ETA: 3s - loss: 4.8825 - acc: 0.011 - ETA: 3s - loss: 4.8825 - acc: 0.011 - ETA: 3s - loss: 4.8826 - acc: 0.011 - ETA: 3s - loss: 4.8827 - acc: 0.011 - ETA: 3s - loss: 4.8826 - acc: 0.011 - ETA: 3s - loss: 4.8826 - acc: 0.011 - ETA: 3s - loss: 4.8826 - acc: 0.011 - ETA: 2s - loss: 4.8826 - acc: 0.011 - ETA: 2s - loss: 4.8826 - acc: 0.011 - ETA: 2s - loss: 4.8826 - acc: 0.011 - ETA: 2s - loss: 4.8826 - acc: 0.011 - ETA: 2s - loss: 4.8826 - acc: 0.011 - ETA: 2s - loss: 4.8826 - acc: 0.011 - ETA: 1s - loss: 4.8827 - acc: 0.011 - ETA: 1s - loss: 4.8826 - acc: 0.011 - ETA: 1s - loss: 4.8826 - acc: 0.011 - ETA: 1s - loss: 4.8825 - acc: 0.011 - ETA: 1s - loss: 4.8825 - acc: 0.011 - ETA: 1s - loss: 4.8824 - acc: 0.011 - ETA: 0s - loss: 4.8825 - acc: 0.011 - ETA: 0s - loss: 4.8825 - acc: 0.011 - ETA: 0s - loss: 4.8826 - acc: 0.011 - ETA: 0s - loss: 4.8827 - acc: 0.011 - ETA: 0s - loss: 4.8826 - acc: 0.011 - ETA: 0s - loss: 4.8826 - acc: 0.011 - 70s 168ms/step - loss: 4.8827 - acc: 0.0114 - val_loss: 4.8797 - val_acc: 0.0098\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 4.87918\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 7s - loss: 4.8525 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8839 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8778 - acc: 0.0069    - ETA: 6s - loss: 4.8746 - acc: 0.005 - ETA: 14s - loss: 4.8770 - acc: 0.00 - ETA: 18s - loss: 4.8782 - acc: 0.00 - ETA: 25s - loss: 4.8777 - acc: 0.00 - ETA: 30s - loss: 4.8765 - acc: 0.00 - ETA: 31s - loss: 4.8750 - acc: 0.00 - ETA: 32s - loss: 4.8736 - acc: 0.00 - ETA: 33s - loss: 4.8727 - acc: 0.00 - ETA: 35s - loss: 4.8735 - acc: 0.00 - ETA: 36s - loss: 4.8736 - acc: 0.00 - ETA: 36s - loss: 4.8733 - acc: 0.00 - ETA: 38s - loss: 4.8742 - acc: 0.00 - ETA: 39s - loss: 4.8742 - acc: 0.00 - ETA: 40s - loss: 4.8759 - acc: 0.00 - ETA: 40s - loss: 4.8757 - acc: 0.00 - ETA: 45s - loss: 4.8755 - acc: 0.00 - ETA: 45s - loss: 4.8750 - acc: 0.00 - ETA: 46s - loss: 4.8751 - acc: 0.00 - ETA: 46s - loss: 4.8762 - acc: 0.00 - ETA: 46s - loss: 4.8776 - acc: 0.00 - ETA: 46s - loss: 4.8782 - acc: 0.00 - ETA: 47s - loss: 4.8780 - acc: 0.00 - ETA: 47s - loss: 4.8783 - acc: 0.00 - ETA: 47s - loss: 4.8782 - acc: 0.00 - ETA: 47s - loss: 4.8797 - acc: 0.00 - ETA: 47s - loss: 4.8795 - acc: 0.00 - ETA: 47s - loss: 4.8793 - acc: 0.00 - ETA: 47s - loss: 4.8792 - acc: 0.00 - ETA: 47s - loss: 4.8796 - acc: 0.00 - ETA: 49s - loss: 4.8795 - acc: 0.00 - ETA: 49s - loss: 4.8791 - acc: 0.00 - ETA: 49s - loss: 4.8791 - acc: 0.00 - ETA: 49s - loss: 4.8795 - acc: 0.00 - ETA: 49s - loss: 4.8797 - acc: 0.00 - ETA: 50s - loss: 4.8791 - acc: 0.00 - ETA: 50s - loss: 4.8795 - acc: 0.00 - ETA: 49s - loss: 4.8792 - acc: 0.00 - ETA: 49s - loss: 4.8790 - acc: 0.00 - ETA: 49s - loss: 4.8787 - acc: 0.00 - ETA: 49s - loss: 4.8791 - acc: 0.00 - ETA: 49s - loss: 4.8802 - acc: 0.00 - ETA: 49s - loss: 4.8801 - acc: 0.00 - ETA: 49s - loss: 4.8797 - acc: 0.00 - ETA: 49s - loss: 4.8796 - acc: 0.00 - ETA: 49s - loss: 4.8800 - acc: 0.00 - ETA: 49s - loss: 4.8799 - acc: 0.00 - ETA: 49s - loss: 4.8804 - acc: 0.00 - ETA: 48s - loss: 4.8805 - acc: 0.00 - ETA: 48s - loss: 4.8804 - acc: 0.00 - ETA: 48s - loss: 4.8796 - acc: 0.00 - ETA: 49s - loss: 4.8793 - acc: 0.00 - ETA: 49s - loss: 4.8793 - acc: 0.00 - ETA: 49s - loss: 4.8796 - acc: 0.00 - ETA: 49s - loss: 4.8792 - acc: 0.00 - ETA: 49s - loss: 4.8793 - acc: 0.00 - ETA: 49s - loss: 4.8785 - acc: 0.00 - ETA: 49s - loss: 4.8783 - acc: 0.00 - ETA: 49s - loss: 4.8783 - acc: 0.00 - ETA: 49s - loss: 4.8787 - acc: 0.00 - ETA: 49s - loss: 4.8786 - acc: 0.00 - ETA: 49s - loss: 4.8786 - acc: 0.00 - ETA: 48s - loss: 4.8781 - acc: 0.00 - ETA: 48s - loss: 4.8783 - acc: 0.00 - ETA: 48s - loss: 4.8781 - acc: 0.00 - ETA: 48s - loss: 4.8783 - acc: 0.00 - ETA: 48s - loss: 4.8783 - acc: 0.00 - ETA: 48s - loss: 4.8785 - acc: 0.00 - ETA: 49s - loss: 4.8785 - acc: 0.00 - ETA: 48s - loss: 4.8785 - acc: 0.00 - ETA: 48s - loss: 4.8776 - acc: 0.00 - ETA: 48s - loss: 4.8774 - acc: 0.00 - ETA: 48s - loss: 4.8772 - acc: 0.00 - ETA: 48s - loss: 4.8774 - acc: 0.00 - ETA: 48s - loss: 4.8772 - acc: 0.00 - ETA: 48s - loss: 4.8770 - acc: 0.00 - ETA: 48s - loss: 4.8773 - acc: 0.00 - ETA: 48s - loss: 4.8776 - acc: 0.00 - ETA: 48s - loss: 4.8770 - acc: 0.00 - ETA: 48s - loss: 4.8769 - acc: 0.00 - ETA: 48s - loss: 4.8765 - acc: 0.00 - ETA: 48s - loss: 4.8764 - acc: 0.00 - ETA: 47s - loss: 4.8765 - acc: 0.00 - ETA: 47s - loss: 4.8765 - acc: 0.00 - ETA: 47s - loss: 4.8769 - acc: 0.00 - ETA: 47s - loss: 4.8771 - acc: 0.00 - ETA: 47s - loss: 4.8770 - acc: 0.00 - ETA: 47s - loss: 4.8774 - acc: 0.00 - ETA: 47s - loss: 4.8774 - acc: 0.00 - ETA: 47s - loss: 4.8771 - acc: 0.00 - ETA: 47s - loss: 4.8775 - acc: 0.00 - ETA: 47s - loss: 4.8777 - acc: 0.00 - ETA: 46s - loss: 4.8776 - acc: 0.00 - ETA: 46s - loss: 4.8775 - acc: 0.00 - ETA: 46s - loss: 4.8777 - acc: 0.00 - ETA: 46s - loss: 4.8778 - acc: 0.00 - ETA: 46s - loss: 4.8776 - acc: 0.00 - ETA: 46s - loss: 4.8774 - acc: 0.00 - ETA: 46s - loss: 4.8775 - acc: 0.00 - ETA: 46s - loss: 4.8778 - acc: 0.00 - ETA: 45s - loss: 4.8779 - acc: 0.00 - ETA: 45s - loss: 4.8778 - acc: 0.00 - ETA: 45s - loss: 4.8778 - acc: 0.00 - ETA: 45s - loss: 4.8779 - acc: 0.00 - ETA: 45s - loss: 4.8779 - acc: 0.00 - ETA: 45s - loss: 4.8781 - acc: 0.00 - ETA: 45s - loss: 4.8782 - acc: 0.00 - ETA: 45s - loss: 4.8780 - acc: 0.00 - ETA: 45s - loss: 4.8780 - acc: 0.00 - ETA: 45s - loss: 4.8786 - acc: 0.00 - ETA: 45s - loss: 4.8785 - acc: 0.00 - ETA: 45s - loss: 4.8785 - acc: 0.00 - ETA: 45s - loss: 4.8788 - acc: 0.00 - ETA: 44s - loss: 4.8787 - acc: 0.00 - ETA: 44s - loss: 4.8791 - acc: 0.00 - ETA: 44s - loss: 4.8789 - acc: 0.00 - ETA: 44s - loss: 4.8789 - acc: 0.00 - ETA: 44s - loss: 4.8787 - acc: 0.00 - ETA: 44s - loss: 4.8787 - acc: 0.00 - ETA: 43s - loss: 4.8788 - acc: 0.00 - ETA: 43s - loss: 4.8784 - acc: 0.00 - ETA: 43s - loss: 4.8783 - acc: 0.00 - ETA: 43s - loss: 4.8784 - acc: 0.00 - ETA: 43s - loss: 4.8787 - acc: 0.00 - ETA: 43s - loss: 4.8786 - acc: 0.00 - ETA: 42s - loss: 4.8788 - acc: 0.00 - ETA: 42s - loss: 4.8788 - acc: 0.00 - ETA: 42s - loss: 4.8790 - acc: 0.00 - ETA: 42s - loss: 4.8792 - acc: 0.00 - ETA: 42s - loss: 4.8794 - acc: 0.00 - ETA: 42s - loss: 4.8795 - acc: 0.00 - ETA: 42s - loss: 4.8795 - acc: 0.00 - ETA: 41s - loss: 4.8796 - acc: 0.00 - ETA: 41s - loss: 4.8798 - acc: 0.00 - ETA: 41s - loss: 4.8797 - acc: 0.00 - ETA: 41s - loss: 4.8797 - acc: 0.00 - ETA: 41s - loss: 4.8798 - acc: 0.00 - ETA: 41s - loss: 4.8799 - acc: 0.00 - ETA: 40s - loss: 4.8798 - acc: 0.00 - ETA: 40s - loss: 4.8799 - acc: 0.00 - ETA: 40s - loss: 4.8799 - acc: 0.00 - ETA: 40s - loss: 4.8799 - acc: 0.00 - ETA: 40s - loss: 4.8800 - acc: 0.00 - ETA: 40s - loss: 4.8802 - acc: 0.00 - ETA: 40s - loss: 4.8800 - acc: 0.00 - ETA: 40s - loss: 4.8799 - acc: 0.00 - ETA: 40s - loss: 4.8794 - acc: 0.00 - ETA: 40s - loss: 4.8795 - acc: 0.00 - ETA: 39s - loss: 4.8795 - acc: 0.00 - ETA: 39s - loss: 4.8794 - acc: 0.00 - ETA: 39s - loss: 4.8793 - acc: 0.00 - ETA: 39s - loss: 4.8793 - acc: 0.00 - ETA: 39s - loss: 4.8792 - acc: 0.00 - ETA: 39s - loss: 4.8794 - acc: 0.00 - ETA: 39s - loss: 4.8792 - acc: 0.00 - ETA: 39s - loss: 4.8791 - acc: 0.00 - ETA: 38s - loss: 4.8792 - acc: 0.00 - ETA: 38s - loss: 4.8790 - acc: 0.00 - ETA: 38s - loss: 4.8791 - acc: 0.00 - ETA: 38s - loss: 4.8790 - acc: 0.00 - ETA: 38s - loss: 4.8790 - acc: 0.00 - ETA: 38s - loss: 4.8788 - acc: 0.00 - ETA: 38s - loss: 4.8787 - acc: 0.00 - ETA: 37s - loss: 4.8786 - acc: 0.00 - ETA: 37s - loss: 4.8788 - acc: 0.00 - ETA: 37s - loss: 4.8786 - acc: 0.00 - ETA: 37s - loss: 4.8786 - acc: 0.00 - ETA: 37s - loss: 4.8785 - acc: 0.00 - ETA: 37s - loss: 4.8784 - acc: 0.00 - ETA: 37s - loss: 4.8783 - acc: 0.00 - ETA: 37s - loss: 4.8783 - acc: 0.00 - ETA: 36s - loss: 4.8784 - acc: 0.00 - ETA: 36s - loss: 4.8784 - acc: 0.00 - ETA: 36s - loss: 4.8784 - acc: 0.00 - ETA: 36s - loss: 4.8784 - acc: 0.00 - ETA: 36s - loss: 4.8786 - acc: 0.00 - ETA: 36s - loss: 4.8782 - acc: 0.00 - ETA: 35s - loss: 4.8783 - acc: 0.00 - ETA: 35s - loss: 4.8783 - acc: 0.00 - ETA: 35s - loss: 4.8785 - acc: 0.00 - ETA: 35s - loss: 4.8784 - acc: 0.00 - ETA: 35s - loss: 4.8786 - acc: 0.00 - ETA: 35s - loss: 4.8785 - acc: 0.00 - ETA: 34s - loss: 4.8786 - acc: 0.00 - ETA: 34s - loss: 4.8786 - acc: 0.00 - ETA: 34s - loss: 4.8785 - acc: 0.00 - ETA: 34s - loss: 4.8784 - acc: 0.00 - ETA: 34s - loss: 4.8783 - acc: 0.00 - ETA: 34s - loss: 4.8783 - acc: 0.00 - ETA: 34s - loss: 4.8783 - acc: 0.00 - ETA: 33s - loss: 4.8785 - acc: 0.00 - ETA: 33s - loss: 4.8788 - acc: 0.00 - ETA: 33s - loss: 4.8789 - acc: 0.00 - ETA: 33s - loss: 4.8788 - acc: 0.00 - ETA: 33s - loss: 4.8788 - acc: 0.00 - ETA: 33s - loss: 4.8787 - acc: 0.00 - ETA: 33s - loss: 4.8787 - acc: 0.00 - ETA: 32s - loss: 4.8785 - acc: 0.00 - ETA: 32s - loss: 4.8787 - acc: 0.00 - ETA: 32s - loss: 4.8784 - acc: 0.00 - ETA: 32s - loss: 4.8783 - acc: 0.00 - ETA: 32s - loss: 4.8785 - acc: 0.00 - ETA: 32s - loss: 4.8785 - acc: 0.00 - ETA: 31s - loss: 4.8784 - acc: 0.00 - ETA: 31s - loss: 4.8784 - acc: 0.00 - ETA: 31s - loss: 4.8786 - acc: 0.00 - ETA: 31s - loss: 4.8786 - acc: 0.00 - ETA: 31s - loss: 4.8784 - acc: 0.00 - ETA: 31s - loss: 4.8784 - acc: 0.00 - ETA: 31s - loss: 4.8784 - acc: 0.00 - ETA: 30s - loss: 4.8782 - acc: 0.00 - ETA: 30s - loss: 4.8783 - acc: 0.00 - ETA: 30s - loss: 4.8784 - acc: 0.0087"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8782 - acc: 0.00 - ETA: 30s - loss: 4.8784 - acc: 0.00 - ETA: 30s - loss: 4.8786 - acc: 0.00 - ETA: 29s - loss: 4.8787 - acc: 0.00 - ETA: 29s - loss: 4.8787 - acc: 0.00 - ETA: 29s - loss: 4.8788 - acc: 0.00 - ETA: 29s - loss: 4.8791 - acc: 0.00 - ETA: 29s - loss: 4.8789 - acc: 0.00 - ETA: 29s - loss: 4.8790 - acc: 0.00 - ETA: 29s - loss: 4.8791 - acc: 0.00 - ETA: 28s - loss: 4.8792 - acc: 0.00 - ETA: 28s - loss: 4.8792 - acc: 0.00 - ETA: 28s - loss: 4.8793 - acc: 0.00 - ETA: 28s - loss: 4.8792 - acc: 0.00 - ETA: 28s - loss: 4.8792 - acc: 0.00 - ETA: 28s - loss: 4.8792 - acc: 0.00 - ETA: 27s - loss: 4.8792 - acc: 0.00 - ETA: 27s - loss: 4.8792 - acc: 0.00 - ETA: 27s - loss: 4.8792 - acc: 0.00 - ETA: 27s - loss: 4.8791 - acc: 0.00 - ETA: 27s - loss: 4.8792 - acc: 0.00 - ETA: 27s - loss: 4.8792 - acc: 0.00 - ETA: 27s - loss: 4.8792 - acc: 0.00 - ETA: 26s - loss: 4.8793 - acc: 0.00 - ETA: 26s - loss: 4.8793 - acc: 0.00 - ETA: 26s - loss: 4.8795 - acc: 0.00 - ETA: 26s - loss: 4.8796 - acc: 0.00 - ETA: 26s - loss: 4.8799 - acc: 0.00 - ETA: 26s - loss: 4.8799 - acc: 0.00 - ETA: 25s - loss: 4.8800 - acc: 0.00 - ETA: 25s - loss: 4.8802 - acc: 0.00 - ETA: 25s - loss: 4.8800 - acc: 0.00 - ETA: 25s - loss: 4.8799 - acc: 0.00 - ETA: 25s - loss: 4.8800 - acc: 0.00 - ETA: 25s - loss: 4.8801 - acc: 0.00 - ETA: 24s - loss: 4.8802 - acc: 0.00 - ETA: 24s - loss: 4.8801 - acc: 0.00 - ETA: 24s - loss: 4.8801 - acc: 0.00 - ETA: 24s - loss: 4.8800 - acc: 0.00 - ETA: 24s - loss: 4.8800 - acc: 0.00 - ETA: 24s - loss: 4.8800 - acc: 0.00 - ETA: 23s - loss: 4.8801 - acc: 0.00 - ETA: 23s - loss: 4.8801 - acc: 0.00 - ETA: 23s - loss: 4.8802 - acc: 0.00 - ETA: 23s - loss: 4.8802 - acc: 0.00 - ETA: 23s - loss: 4.8802 - acc: 0.00 - ETA: 23s - loss: 4.8801 - acc: 0.00 - ETA: 23s - loss: 4.8800 - acc: 0.00 - ETA: 22s - loss: 4.8801 - acc: 0.00 - ETA: 22s - loss: 4.8800 - acc: 0.00 - ETA: 22s - loss: 4.8800 - acc: 0.00 - ETA: 22s - loss: 4.8801 - acc: 0.00 - ETA: 22s - loss: 4.8803 - acc: 0.00 - ETA: 22s - loss: 4.8803 - acc: 0.00 - ETA: 21s - loss: 4.8802 - acc: 0.00 - ETA: 21s - loss: 4.8801 - acc: 0.00 - ETA: 21s - loss: 4.8801 - acc: 0.00 - ETA: 21s - loss: 4.8801 - acc: 0.00 - ETA: 21s - loss: 4.8801 - acc: 0.00 - ETA: 21s - loss: 4.8801 - acc: 0.00 - ETA: 20s - loss: 4.8801 - acc: 0.00 - ETA: 20s - loss: 4.8801 - acc: 0.00 - ETA: 20s - loss: 4.8801 - acc: 0.00 - ETA: 20s - loss: 4.8803 - acc: 0.00 - ETA: 20s - loss: 4.8803 - acc: 0.00 - ETA: 20s - loss: 4.8801 - acc: 0.00 - ETA: 19s - loss: 4.8799 - acc: 0.00 - ETA: 19s - loss: 4.8798 - acc: 0.00 - ETA: 19s - loss: 4.8798 - acc: 0.00 - ETA: 19s - loss: 4.8797 - acc: 0.00 - ETA: 19s - loss: 4.8797 - acc: 0.00 - ETA: 19s - loss: 4.8799 - acc: 0.00 - ETA: 19s - loss: 4.8799 - acc: 0.00 - ETA: 18s - loss: 4.8798 - acc: 0.00 - ETA: 18s - loss: 4.8796 - acc: 0.00 - ETA: 18s - loss: 4.8796 - acc: 0.00 - ETA: 18s - loss: 4.8795 - acc: 0.00 - ETA: 18s - loss: 4.8794 - acc: 0.00 - ETA: 18s - loss: 4.8794 - acc: 0.00 - ETA: 17s - loss: 4.8795 - acc: 0.00 - ETA: 17s - loss: 4.8795 - acc: 0.00 - ETA: 17s - loss: 4.8794 - acc: 0.00 - ETA: 17s - loss: 4.8794 - acc: 0.00 - ETA: 17s - loss: 4.8796 - acc: 0.00 - ETA: 17s - loss: 4.8798 - acc: 0.00 - ETA: 16s - loss: 4.8797 - acc: 0.00 - ETA: 16s - loss: 4.8798 - acc: 0.00 - ETA: 16s - loss: 4.8799 - acc: 0.00 - ETA: 16s - loss: 4.8799 - acc: 0.00 - ETA: 16s - loss: 4.8800 - acc: 0.00 - ETA: 16s - loss: 4.8800 - acc: 0.00 - ETA: 16s - loss: 4.8799 - acc: 0.00 - ETA: 15s - loss: 4.8799 - acc: 0.00 - ETA: 15s - loss: 4.8800 - acc: 0.00 - ETA: 15s - loss: 4.8800 - acc: 0.00 - ETA: 15s - loss: 4.8800 - acc: 0.00 - ETA: 15s - loss: 4.8800 - acc: 0.01 - ETA: 15s - loss: 4.8799 - acc: 0.00 - ETA: 14s - loss: 4.8798 - acc: 0.00 - ETA: 14s - loss: 4.8797 - acc: 0.00 - ETA: 14s - loss: 4.8798 - acc: 0.00 - ETA: 14s - loss: 4.8797 - acc: 0.00 - ETA: 14s - loss: 4.8797 - acc: 0.00 - ETA: 14s - loss: 4.8796 - acc: 0.00 - ETA: 14s - loss: 4.8797 - acc: 0.00 - ETA: 13s - loss: 4.8796 - acc: 0.00 - ETA: 13s - loss: 4.8797 - acc: 0.00 - ETA: 13s - loss: 4.8797 - acc: 0.00 - ETA: 13s - loss: 4.8796 - acc: 0.00 - ETA: 13s - loss: 4.8795 - acc: 0.00 - ETA: 13s - loss: 4.8795 - acc: 0.00 - ETA: 12s - loss: 4.8796 - acc: 0.00 - ETA: 12s - loss: 4.8795 - acc: 0.00 - ETA: 12s - loss: 4.8795 - acc: 0.00 - ETA: 12s - loss: 4.8795 - acc: 0.00 - ETA: 12s - loss: 4.8795 - acc: 0.00 - ETA: 12s - loss: 4.8796 - acc: 0.00 - ETA: 11s - loss: 4.8795 - acc: 0.00 - ETA: 11s - loss: 4.8795 - acc: 0.00 - ETA: 11s - loss: 4.8794 - acc: 0.00 - ETA: 11s - loss: 4.8794 - acc: 0.00 - ETA: 11s - loss: 4.8795 - acc: 0.00 - ETA: 11s - loss: 4.8795 - acc: 0.00 - ETA: 11s - loss: 4.8794 - acc: 0.00 - ETA: 10s - loss: 4.8794 - acc: 0.00 - ETA: 10s - loss: 4.8794 - acc: 0.00 - ETA: 10s - loss: 4.8793 - acc: 0.01 - ETA: 10s - loss: 4.8793 - acc: 0.01 - ETA: 10s - loss: 4.8791 - acc: 0.00 - ETA: 10s - loss: 4.8791 - acc: 0.01 - ETA: 9s - loss: 4.8790 - acc: 0.0101 - ETA: 9s - loss: 4.8791 - acc: 0.010 - ETA: 9s - loss: 4.8791 - acc: 0.010 - ETA: 9s - loss: 4.8791 - acc: 0.010 - ETA: 9s - loss: 4.8791 - acc: 0.010 - ETA: 9s - loss: 4.8790 - acc: 0.010 - ETA: 9s - loss: 4.8790 - acc: 0.010 - ETA: 8s - loss: 4.8790 - acc: 0.010 - ETA: 8s - loss: 4.8790 - acc: 0.010 - ETA: 8s - loss: 4.8790 - acc: 0.010 - ETA: 8s - loss: 4.8790 - acc: 0.010 - ETA: 8s - loss: 4.8790 - acc: 0.009 - ETA: 8s - loss: 4.8791 - acc: 0.009 - ETA: 7s - loss: 4.8792 - acc: 0.009 - ETA: 7s - loss: 4.8793 - acc: 0.009 - ETA: 7s - loss: 4.8792 - acc: 0.009 - ETA: 7s - loss: 4.8792 - acc: 0.009 - ETA: 7s - loss: 4.8792 - acc: 0.009 - ETA: 7s - loss: 4.8792 - acc: 0.009 - ETA: 6s - loss: 4.8792 - acc: 0.009 - ETA: 6s - loss: 4.8792 - acc: 0.009 - ETA: 6s - loss: 4.8791 - acc: 0.009 - ETA: 6s - loss: 4.8791 - acc: 0.009 - ETA: 6s - loss: 4.8791 - acc: 0.009 - ETA: 6s - loss: 4.8791 - acc: 0.009 - ETA: 6s - loss: 4.8790 - acc: 0.009 - ETA: 5s - loss: 4.8790 - acc: 0.009 - ETA: 5s - loss: 4.8790 - acc: 0.009 - ETA: 5s - loss: 4.8790 - acc: 0.009 - ETA: 5s - loss: 4.8790 - acc: 0.009 - ETA: 5s - loss: 4.8790 - acc: 0.009 - ETA: 5s - loss: 4.8790 - acc: 0.009 - ETA: 4s - loss: 4.8790 - acc: 0.009 - ETA: 4s - loss: 4.8790 - acc: 0.009 - ETA: 4s - loss: 4.8789 - acc: 0.009 - ETA: 4s - loss: 4.8789 - acc: 0.009 - ETA: 4s - loss: 4.8788 - acc: 0.009 - ETA: 4s - loss: 4.8789 - acc: 0.009 - ETA: 3s - loss: 4.8788 - acc: 0.009 - ETA: 3s - loss: 4.8787 - acc: 0.009 - ETA: 3s - loss: 4.8787 - acc: 0.009 - ETA: 3s - loss: 4.8787 - acc: 0.009 - ETA: 3s - loss: 4.8788 - acc: 0.009 - ETA: 3s - loss: 4.8789 - acc: 0.009 - ETA: 3s - loss: 4.8791 - acc: 0.009 - ETA: 2s - loss: 4.8791 - acc: 0.009 - ETA: 2s - loss: 4.8791 - acc: 0.009 - ETA: 2s - loss: 4.8792 - acc: 0.009 - ETA: 2s - loss: 4.8791 - acc: 0.009 - ETA: 2s - loss: 4.8790 - acc: 0.009 - ETA: 2s - loss: 4.8791 - acc: 0.009 - ETA: 1s - loss: 4.8790 - acc: 0.009 - ETA: 1s - loss: 4.8789 - acc: 0.009 - ETA: 1s - loss: 4.8790 - acc: 0.009 - ETA: 1s - loss: 4.8789 - acc: 0.009 - ETA: 1s - loss: 4.8788 - acc: 0.009 - ETA: 1s - loss: 4.8788 - acc: 0.009 - ETA: 0s - loss: 4.8788 - acc: 0.009 - ETA: 0s - loss: 4.8788 - acc: 0.009 - ETA: 0s - loss: 4.8790 - acc: 0.009 - ETA: 0s - loss: 4.8791 - acc: 0.009 - ETA: 0s - loss: 4.8790 - acc: 0.009 - ETA: 0s - loss: 4.8789 - acc: 0.009 - 70s 169ms/step - loss: 4.8789 - acc: 0.0091 - val_loss: 4.8765 - val_acc: 0.0134\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.87918 to 4.87646, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 6s - loss: 4.8662 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8923 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8974 - acc: 0.0139    - ETA: 8s - loss: 4.8917 - acc: 0.028 - ETA: 13s - loss: 4.8955 - acc: 0.02 - ETA: 17s - loss: 4.8947 - acc: 0.02 - ETA: 20s - loss: 4.8942 - acc: 0.02 - ETA: 23s - loss: 4.8945 - acc: 0.02 - ETA: 24s - loss: 4.8923 - acc: 0.02 - ETA: 26s - loss: 4.8910 - acc: 0.02 - ETA: 27s - loss: 4.8900 - acc: 0.02 - ETA: 29s - loss: 4.8878 - acc: 0.02 - ETA: 30s - loss: 4.8875 - acc: 0.02 - ETA: 32s - loss: 4.8869 - acc: 0.02 - ETA: 33s - loss: 4.8840 - acc: 0.02 - ETA: 35s - loss: 4.8836 - acc: 0.02 - ETA: 36s - loss: 4.8815 - acc: 0.02 - ETA: 36s - loss: 4.8836 - acc: 0.02 - ETA: 37s - loss: 4.8844 - acc: 0.02 - ETA: 38s - loss: 4.8831 - acc: 0.01 - ETA: 39s - loss: 4.8823 - acc: 0.01 - ETA: 40s - loss: 4.8826 - acc: 0.01 - ETA: 41s - loss: 4.8819 - acc: 0.01 - ETA: 41s - loss: 4.8820 - acc: 0.01 - ETA: 41s - loss: 4.8821 - acc: 0.01 - ETA: 42s - loss: 4.8822 - acc: 0.01 - ETA: 42s - loss: 4.8834 - acc: 0.01 - ETA: 42s - loss: 4.8838 - acc: 0.01 - ETA: 43s - loss: 4.8843 - acc: 0.01 - ETA: 44s - loss: 4.8847 - acc: 0.01 - ETA: 44s - loss: 4.8852 - acc: 0.01 - ETA: 45s - loss: 4.8850 - acc: 0.01 - ETA: 45s - loss: 4.8839 - acc: 0.01 - ETA: 45s - loss: 4.8838 - acc: 0.01 - ETA: 45s - loss: 4.8837 - acc: 0.01 - ETA: 45s - loss: 4.8826 - acc: 0.01 - ETA: 45s - loss: 4.8826 - acc: 0.01 - ETA: 45s - loss: 4.8821 - acc: 0.01 - ETA: 46s - loss: 4.8819 - acc: 0.01 - ETA: 46s - loss: 4.8822 - acc: 0.01 - ETA: 46s - loss: 4.8817 - acc: 0.01 - ETA: 47s - loss: 4.8821 - acc: 0.01 - ETA: 46s - loss: 4.8817 - acc: 0.01 - ETA: 47s - loss: 4.8798 - acc: 0.01 - ETA: 47s - loss: 4.8800 - acc: 0.01 - ETA: 47s - loss: 4.8792 - acc: 0.01 - ETA: 47s - loss: 4.8800 - acc: 0.01 - ETA: 48s - loss: 4.8799 - acc: 0.01 - ETA: 48s - loss: 4.8796 - acc: 0.01 - ETA: 48s - loss: 4.8802 - acc: 0.01 - ETA: 48s - loss: 4.8799 - acc: 0.01 - ETA: 48s - loss: 4.8799 - acc: 0.01 - ETA: 48s - loss: 4.8795 - acc: 0.01 - ETA: 48s - loss: 4.8790 - acc: 0.01 - ETA: 48s - loss: 4.8789 - acc: 0.01 - ETA: 48s - loss: 4.8788 - acc: 0.01 - ETA: 48s - loss: 4.8784 - acc: 0.01 - ETA: 49s - loss: 4.8780 - acc: 0.01 - ETA: 49s - loss: 4.8786 - acc: 0.01 - ETA: 49s - loss: 4.8787 - acc: 0.01 - ETA: 49s - loss: 4.8791 - acc: 0.01 - ETA: 48s - loss: 4.8789 - acc: 0.01 - ETA: 48s - loss: 4.8787 - acc: 0.01 - ETA: 48s - loss: 4.8788 - acc: 0.01 - ETA: 48s - loss: 4.8782 - acc: 0.01 - ETA: 49s - loss: 4.8794 - acc: 0.01 - ETA: 48s - loss: 4.8793 - acc: 0.01 - ETA: 49s - loss: 4.8791 - acc: 0.01 - ETA: 49s - loss: 4.8793 - acc: 0.01 - ETA: 49s - loss: 4.8792 - acc: 0.01 - ETA: 49s - loss: 4.8797 - acc: 0.01 - ETA: 49s - loss: 4.8794 - acc: 0.01 - ETA: 48s - loss: 4.8792 - acc: 0.01 - ETA: 48s - loss: 4.8793 - acc: 0.01 - ETA: 48s - loss: 4.8791 - acc: 0.01 - ETA: 48s - loss: 4.8790 - acc: 0.01 - ETA: 48s - loss: 4.8787 - acc: 0.01 - ETA: 48s - loss: 4.8788 - acc: 0.01 - ETA: 47s - loss: 4.8793 - acc: 0.01 - ETA: 47s - loss: 4.8794 - acc: 0.01 - ETA: 47s - loss: 4.8792 - acc: 0.01 - ETA: 48s - loss: 4.8798 - acc: 0.01 - ETA: 48s - loss: 4.8800 - acc: 0.01 - ETA: 48s - loss: 4.8800 - acc: 0.01 - ETA: 48s - loss: 4.8799 - acc: 0.01 - ETA: 47s - loss: 4.8806 - acc: 0.01 - ETA: 47s - loss: 4.8806 - acc: 0.01 - ETA: 47s - loss: 4.8808 - acc: 0.01 - ETA: 47s - loss: 4.8809 - acc: 0.01 - ETA: 47s - loss: 4.8813 - acc: 0.01 - ETA: 47s - loss: 4.8812 - acc: 0.01 - ETA: 47s - loss: 4.8811 - acc: 0.01 - ETA: 47s - loss: 4.8813 - acc: 0.01 - ETA: 47s - loss: 4.8817 - acc: 0.01 - ETA: 46s - loss: 4.8818 - acc: 0.01 - ETA: 46s - loss: 4.8814 - acc: 0.01 - ETA: 46s - loss: 4.8816 - acc: 0.01 - ETA: 46s - loss: 4.8817 - acc: 0.01 - ETA: 46s - loss: 4.8816 - acc: 0.01 - ETA: 46s - loss: 4.8814 - acc: 0.01 - ETA: 46s - loss: 4.8813 - acc: 0.01 - ETA: 46s - loss: 4.8813 - acc: 0.01 - ETA: 46s - loss: 4.8810 - acc: 0.01 - ETA: 46s - loss: 4.8812 - acc: 0.01 - ETA: 46s - loss: 4.8808 - acc: 0.01 - ETA: 46s - loss: 4.8809 - acc: 0.01 - ETA: 46s - loss: 4.8808 - acc: 0.01 - ETA: 46s - loss: 4.8809 - acc: 0.01 - ETA: 45s - loss: 4.8805 - acc: 0.01 - ETA: 45s - loss: 4.8807 - acc: 0.01 - ETA: 45s - loss: 4.8805 - acc: 0.01 - ETA: 45s - loss: 4.8805 - acc: 0.01 - ETA: 45s - loss: 4.8805 - acc: 0.01 - ETA: 45s - loss: 4.8805 - acc: 0.01 - ETA: 44s - loss: 4.8803 - acc: 0.01 - ETA: 44s - loss: 4.8800 - acc: 0.01 - ETA: 44s - loss: 4.8798 - acc: 0.01 - ETA: 44s - loss: 4.8797 - acc: 0.01 - ETA: 44s - loss: 4.8800 - acc: 0.01 - ETA: 44s - loss: 4.8801 - acc: 0.01 - ETA: 44s - loss: 4.8800 - acc: 0.01 - ETA: 43s - loss: 4.8798 - acc: 0.01 - ETA: 43s - loss: 4.8801 - acc: 0.01 - ETA: 43s - loss: 4.8801 - acc: 0.01 - ETA: 43s - loss: 4.8803 - acc: 0.01 - ETA: 43s - loss: 4.8802 - acc: 0.01 - ETA: 43s - loss: 4.8802 - acc: 0.01 - ETA: 43s - loss: 4.8802 - acc: 0.01 - ETA: 42s - loss: 4.8805 - acc: 0.01 - ETA: 42s - loss: 4.8807 - acc: 0.01 - ETA: 42s - loss: 4.8807 - acc: 0.01 - ETA: 42s - loss: 4.8805 - acc: 0.01 - ETA: 42s - loss: 4.8806 - acc: 0.01 - ETA: 41s - loss: 4.8805 - acc: 0.01 - ETA: 41s - loss: 4.8807 - acc: 0.01 - ETA: 41s - loss: 4.8805 - acc: 0.01 - ETA: 41s - loss: 4.8808 - acc: 0.01 - ETA: 41s - loss: 4.8806 - acc: 0.01 - ETA: 41s - loss: 4.8808 - acc: 0.01 - ETA: 40s - loss: 4.8808 - acc: 0.01 - ETA: 40s - loss: 4.8805 - acc: 0.01 - ETA: 40s - loss: 4.8805 - acc: 0.01 - ETA: 40s - loss: 4.8804 - acc: 0.01 - ETA: 40s - loss: 4.8807 - acc: 0.01 - ETA: 40s - loss: 4.8808 - acc: 0.01 - ETA: 39s - loss: 4.8804 - acc: 0.01 - ETA: 39s - loss: 4.8804 - acc: 0.01 - ETA: 39s - loss: 4.8803 - acc: 0.01 - ETA: 39s - loss: 4.8801 - acc: 0.01 - ETA: 39s - loss: 4.8802 - acc: 0.01 - ETA: 39s - loss: 4.8799 - acc: 0.01 - ETA: 39s - loss: 4.8798 - acc: 0.01 - ETA: 39s - loss: 4.8799 - acc: 0.01 - ETA: 38s - loss: 4.8801 - acc: 0.01 - ETA: 38s - loss: 4.8803 - acc: 0.01 - ETA: 38s - loss: 4.8800 - acc: 0.01 - ETA: 38s - loss: 4.8801 - acc: 0.01 - ETA: 38s - loss: 4.8799 - acc: 0.01 - ETA: 38s - loss: 4.8799 - acc: 0.01 - ETA: 38s - loss: 4.8797 - acc: 0.01 - ETA: 38s - loss: 4.8794 - acc: 0.01 - ETA: 38s - loss: 4.8794 - acc: 0.01 - ETA: 37s - loss: 4.8793 - acc: 0.01 - ETA: 37s - loss: 4.8794 - acc: 0.01 - ETA: 37s - loss: 4.8796 - acc: 0.01 - ETA: 37s - loss: 4.8796 - acc: 0.01 - ETA: 37s - loss: 4.8793 - acc: 0.01 - ETA: 37s - loss: 4.8791 - acc: 0.01 - ETA: 37s - loss: 4.8790 - acc: 0.01 - ETA: 36s - loss: 4.8789 - acc: 0.01 - ETA: 36s - loss: 4.8790 - acc: 0.01 - ETA: 36s - loss: 4.8787 - acc: 0.01 - ETA: 36s - loss: 4.8788 - acc: 0.01 - ETA: 36s - loss: 4.8787 - acc: 0.01 - ETA: 36s - loss: 4.8788 - acc: 0.01 - ETA: 36s - loss: 4.8792 - acc: 0.01 - ETA: 35s - loss: 4.8791 - acc: 0.01 - ETA: 35s - loss: 4.8792 - acc: 0.01 - ETA: 35s - loss: 4.8794 - acc: 0.01 - ETA: 35s - loss: 4.8796 - acc: 0.01 - ETA: 35s - loss: 4.8798 - acc: 0.01 - ETA: 35s - loss: 4.8798 - acc: 0.01 - ETA: 35s - loss: 4.8796 - acc: 0.01 - ETA: 35s - loss: 4.8794 - acc: 0.01 - ETA: 34s - loss: 4.8797 - acc: 0.01 - ETA: 34s - loss: 4.8795 - acc: 0.01 - ETA: 34s - loss: 4.8797 - acc: 0.01 - ETA: 34s - loss: 4.8798 - acc: 0.01 - ETA: 34s - loss: 4.8796 - acc: 0.01 - ETA: 34s - loss: 4.8794 - acc: 0.01 - ETA: 34s - loss: 4.8795 - acc: 0.01 - ETA: 33s - loss: 4.8796 - acc: 0.01 - ETA: 33s - loss: 4.8799 - acc: 0.01 - ETA: 33s - loss: 4.8800 - acc: 0.01 - ETA: 33s - loss: 4.8799 - acc: 0.01 - ETA: 33s - loss: 4.8796 - acc: 0.01 - ETA: 33s - loss: 4.8795 - acc: 0.01 - ETA: 33s - loss: 4.8797 - acc: 0.01 - ETA: 32s - loss: 4.8797 - acc: 0.01 - ETA: 32s - loss: 4.8800 - acc: 0.01 - ETA: 32s - loss: 4.8799 - acc: 0.01 - ETA: 32s - loss: 4.8799 - acc: 0.01 - ETA: 32s - loss: 4.8799 - acc: 0.01 - ETA: 32s - loss: 4.8799 - acc: 0.01 - ETA: 32s - loss: 4.8799 - acc: 0.01 - ETA: 31s - loss: 4.8798 - acc: 0.01 - ETA: 31s - loss: 4.8798 - acc: 0.01 - ETA: 31s - loss: 4.8797 - acc: 0.01 - ETA: 31s - loss: 4.8797 - acc: 0.01 - ETA: 31s - loss: 4.8799 - acc: 0.01 - ETA: 31s - loss: 4.8800 - acc: 0.01 - ETA: 31s - loss: 4.8801 - acc: 0.01 - ETA: 30s - loss: 4.8799 - acc: 0.01 - ETA: 30s - loss: 4.8799 - acc: 0.01 - ETA: 30s - loss: 4.8800 - acc: 0.0112"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8802 - acc: 0.01 - ETA: 30s - loss: 4.8802 - acc: 0.01 - ETA: 30s - loss: 4.8803 - acc: 0.01 - ETA: 29s - loss: 4.8802 - acc: 0.01 - ETA: 29s - loss: 4.8803 - acc: 0.01 - ETA: 29s - loss: 4.8803 - acc: 0.01 - ETA: 29s - loss: 4.8803 - acc: 0.01 - ETA: 29s - loss: 4.8802 - acc: 0.01 - ETA: 29s - loss: 4.8803 - acc: 0.01 - ETA: 29s - loss: 4.8802 - acc: 0.01 - ETA: 28s - loss: 4.8801 - acc: 0.01 - ETA: 28s - loss: 4.8800 - acc: 0.01 - ETA: 28s - loss: 4.8802 - acc: 0.01 - ETA: 28s - loss: 4.8803 - acc: 0.01 - ETA: 28s - loss: 4.8802 - acc: 0.01 - ETA: 28s - loss: 4.8802 - acc: 0.01 - ETA: 27s - loss: 4.8802 - acc: 0.01 - ETA: 27s - loss: 4.8804 - acc: 0.01 - ETA: 27s - loss: 4.8805 - acc: 0.01 - ETA: 27s - loss: 4.8806 - acc: 0.01 - ETA: 27s - loss: 4.8802 - acc: 0.01 - ETA: 27s - loss: 4.8803 - acc: 0.01 - ETA: 27s - loss: 4.8801 - acc: 0.01 - ETA: 26s - loss: 4.8801 - acc: 0.01 - ETA: 26s - loss: 4.8800 - acc: 0.01 - ETA: 26s - loss: 4.8799 - acc: 0.01 - ETA: 26s - loss: 4.8799 - acc: 0.01 - ETA: 26s - loss: 4.8800 - acc: 0.01 - ETA: 26s - loss: 4.8799 - acc: 0.01 - ETA: 26s - loss: 4.8798 - acc: 0.01 - ETA: 25s - loss: 4.8797 - acc: 0.01 - ETA: 25s - loss: 4.8797 - acc: 0.01 - ETA: 25s - loss: 4.8797 - acc: 0.01 - ETA: 25s - loss: 4.8798 - acc: 0.01 - ETA: 25s - loss: 4.8798 - acc: 0.01 - ETA: 25s - loss: 4.8797 - acc: 0.01 - ETA: 25s - loss: 4.8799 - acc: 0.01 - ETA: 24s - loss: 4.8799 - acc: 0.01 - ETA: 24s - loss: 4.8799 - acc: 0.01 - ETA: 24s - loss: 4.8800 - acc: 0.01 - ETA: 24s - loss: 4.8800 - acc: 0.01 - ETA: 24s - loss: 4.8800 - acc: 0.01 - ETA: 24s - loss: 4.8799 - acc: 0.01 - ETA: 23s - loss: 4.8798 - acc: 0.01 - ETA: 23s - loss: 4.8798 - acc: 0.01 - ETA: 23s - loss: 4.8798 - acc: 0.01 - ETA: 23s - loss: 4.8797 - acc: 0.01 - ETA: 23s - loss: 4.8799 - acc: 0.01 - ETA: 23s - loss: 4.8798 - acc: 0.01 - ETA: 23s - loss: 4.8797 - acc: 0.01 - ETA: 22s - loss: 4.8797 - acc: 0.01 - ETA: 22s - loss: 4.8797 - acc: 0.01 - ETA: 22s - loss: 4.8798 - acc: 0.01 - ETA: 22s - loss: 4.8798 - acc: 0.01 - ETA: 22s - loss: 4.8799 - acc: 0.01 - ETA: 22s - loss: 4.8800 - acc: 0.01 - ETA: 21s - loss: 4.8802 - acc: 0.01 - ETA: 21s - loss: 4.8802 - acc: 0.01 - ETA: 21s - loss: 4.8802 - acc: 0.01 - ETA: 21s - loss: 4.8802 - acc: 0.01 - ETA: 21s - loss: 4.8802 - acc: 0.01 - ETA: 21s - loss: 4.8803 - acc: 0.01 - ETA: 20s - loss: 4.8801 - acc: 0.01 - ETA: 20s - loss: 4.8802 - acc: 0.01 - ETA: 20s - loss: 4.8801 - acc: 0.01 - ETA: 20s - loss: 4.8800 - acc: 0.01 - ETA: 20s - loss: 4.8800 - acc: 0.01 - ETA: 20s - loss: 4.8800 - acc: 0.01 - ETA: 20s - loss: 4.8799 - acc: 0.01 - ETA: 19s - loss: 4.8798 - acc: 0.01 - ETA: 19s - loss: 4.8798 - acc: 0.01 - ETA: 19s - loss: 4.8798 - acc: 0.01 - ETA: 19s - loss: 4.8797 - acc: 0.01 - ETA: 19s - loss: 4.8797 - acc: 0.01 - ETA: 19s - loss: 4.8797 - acc: 0.01 - ETA: 18s - loss: 4.8796 - acc: 0.01 - ETA: 18s - loss: 4.8796 - acc: 0.01 - ETA: 18s - loss: 4.8797 - acc: 0.01 - ETA: 18s - loss: 4.8797 - acc: 0.01 - ETA: 18s - loss: 4.8797 - acc: 0.01 - ETA: 18s - loss: 4.8796 - acc: 0.01 - ETA: 17s - loss: 4.8796 - acc: 0.01 - ETA: 17s - loss: 4.8795 - acc: 0.01 - ETA: 17s - loss: 4.8795 - acc: 0.01 - ETA: 17s - loss: 4.8796 - acc: 0.01 - ETA: 17s - loss: 4.8795 - acc: 0.01 - ETA: 17s - loss: 4.8794 - acc: 0.01 - ETA: 16s - loss: 4.8795 - acc: 0.01 - ETA: 16s - loss: 4.8795 - acc: 0.01 - ETA: 16s - loss: 4.8796 - acc: 0.01 - ETA: 16s - loss: 4.8796 - acc: 0.01 - ETA: 16s - loss: 4.8797 - acc: 0.01 - ETA: 16s - loss: 4.8797 - acc: 0.01 - ETA: 15s - loss: 4.8797 - acc: 0.01 - ETA: 15s - loss: 4.8797 - acc: 0.01 - ETA: 15s - loss: 4.8797 - acc: 0.01 - ETA: 15s - loss: 4.8798 - acc: 0.01 - ETA: 15s - loss: 4.8797 - acc: 0.01 - ETA: 15s - loss: 4.8797 - acc: 0.01 - ETA: 14s - loss: 4.8796 - acc: 0.01 - ETA: 14s - loss: 4.8797 - acc: 0.01 - ETA: 14s - loss: 4.8797 - acc: 0.01 - ETA: 14s - loss: 4.8797 - acc: 0.01 - ETA: 14s - loss: 4.8797 - acc: 0.01 - ETA: 14s - loss: 4.8799 - acc: 0.01 - ETA: 13s - loss: 4.8800 - acc: 0.01 - ETA: 13s - loss: 4.8800 - acc: 0.01 - ETA: 13s - loss: 4.8800 - acc: 0.01 - ETA: 13s - loss: 4.8798 - acc: 0.01 - ETA: 13s - loss: 4.8797 - acc: 0.01 - ETA: 13s - loss: 4.8797 - acc: 0.01 - ETA: 13s - loss: 4.8797 - acc: 0.01 - ETA: 12s - loss: 4.8796 - acc: 0.01 - ETA: 12s - loss: 4.8796 - acc: 0.01 - ETA: 12s - loss: 4.8795 - acc: 0.01 - ETA: 12s - loss: 4.8798 - acc: 0.01 - ETA: 12s - loss: 4.8797 - acc: 0.01 - ETA: 12s - loss: 4.8796 - acc: 0.01 - ETA: 11s - loss: 4.8796 - acc: 0.01 - ETA: 11s - loss: 4.8795 - acc: 0.01 - ETA: 11s - loss: 4.8795 - acc: 0.01 - ETA: 11s - loss: 4.8795 - acc: 0.01 - ETA: 11s - loss: 4.8794 - acc: 0.01 - ETA: 11s - loss: 4.8793 - acc: 0.01 - ETA: 10s - loss: 4.8794 - acc: 0.01 - ETA: 10s - loss: 4.8793 - acc: 0.01 - ETA: 10s - loss: 4.8794 - acc: 0.01 - ETA: 10s - loss: 4.8794 - acc: 0.01 - ETA: 10s - loss: 4.8794 - acc: 0.01 - ETA: 10s - loss: 4.8793 - acc: 0.01 - ETA: 9s - loss: 4.8794 - acc: 0.0107 - ETA: 9s - loss: 4.8794 - acc: 0.010 - ETA: 9s - loss: 4.8793 - acc: 0.010 - ETA: 9s - loss: 4.8794 - acc: 0.010 - ETA: 9s - loss: 4.8793 - acc: 0.010 - ETA: 9s - loss: 4.8792 - acc: 0.010 - ETA: 8s - loss: 4.8791 - acc: 0.010 - ETA: 8s - loss: 4.8791 - acc: 0.010 - ETA: 8s - loss: 4.8791 - acc: 0.010 - ETA: 8s - loss: 4.8791 - acc: 0.010 - ETA: 8s - loss: 4.8791 - acc: 0.010 - ETA: 8s - loss: 4.8792 - acc: 0.010 - ETA: 8s - loss: 4.8792 - acc: 0.010 - ETA: 7s - loss: 4.8794 - acc: 0.010 - ETA: 7s - loss: 4.8794 - acc: 0.010 - ETA: 7s - loss: 4.8795 - acc: 0.010 - ETA: 7s - loss: 4.8795 - acc: 0.010 - ETA: 7s - loss: 4.8795 - acc: 0.010 - ETA: 7s - loss: 4.8796 - acc: 0.010 - ETA: 6s - loss: 4.8795 - acc: 0.010 - ETA: 6s - loss: 4.8795 - acc: 0.010 - ETA: 6s - loss: 4.8794 - acc: 0.010 - ETA: 6s - loss: 4.8795 - acc: 0.010 - ETA: 6s - loss: 4.8794 - acc: 0.010 - ETA: 6s - loss: 4.8794 - acc: 0.010 - ETA: 5s - loss: 4.8794 - acc: 0.010 - ETA: 5s - loss: 4.8793 - acc: 0.010 - ETA: 5s - loss: 4.8793 - acc: 0.010 - ETA: 5s - loss: 4.8794 - acc: 0.010 - ETA: 5s - loss: 4.8794 - acc: 0.010 - ETA: 5s - loss: 4.8795 - acc: 0.010 - ETA: 4s - loss: 4.8796 - acc: 0.010 - ETA: 4s - loss: 4.8795 - acc: 0.010 - ETA: 4s - loss: 4.8796 - acc: 0.010 - ETA: 4s - loss: 4.8796 - acc: 0.010 - ETA: 4s - loss: 4.8795 - acc: 0.010 - ETA: 4s - loss: 4.8795 - acc: 0.010 - ETA: 4s - loss: 4.8795 - acc: 0.010 - ETA: 3s - loss: 4.8795 - acc: 0.010 - ETA: 3s - loss: 4.8795 - acc: 0.010 - ETA: 3s - loss: 4.8794 - acc: 0.010 - ETA: 3s - loss: 4.8795 - acc: 0.010 - ETA: 3s - loss: 4.8795 - acc: 0.010 - ETA: 3s - loss: 4.8796 - acc: 0.010 - ETA: 2s - loss: 4.8796 - acc: 0.010 - ETA: 2s - loss: 4.8796 - acc: 0.010 - ETA: 2s - loss: 4.8796 - acc: 0.010 - ETA: 2s - loss: 4.8796 - acc: 0.010 - ETA: 2s - loss: 4.8796 - acc: 0.010 - ETA: 2s - loss: 4.8797 - acc: 0.010 - ETA: 1s - loss: 4.8797 - acc: 0.011 - ETA: 1s - loss: 4.8797 - acc: 0.010 - ETA: 1s - loss: 4.8797 - acc: 0.010 - ETA: 1s - loss: 4.8797 - acc: 0.010 - ETA: 1s - loss: 4.8797 - acc: 0.011 - ETA: 1s - loss: 4.8798 - acc: 0.011 - ETA: 0s - loss: 4.8797 - acc: 0.011 - ETA: 0s - loss: 4.8797 - acc: 0.011 - ETA: 0s - loss: 4.8796 - acc: 0.011 - ETA: 0s - loss: 4.8795 - acc: 0.011 - ETA: 0s - loss: 4.8797 - acc: 0.011 - ETA: 0s - loss: 4.8797 - acc: 0.011 - 71s 170ms/step - loss: 4.8797 - acc: 0.0109 - val_loss: 4.8757 - val_acc: 0.0134\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.87646 to 4.87575, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 6s - loss: 4.8770 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8709 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8775 - acc: 0.0078    - ETA: 6s - loss: 4.8754 - acc: 0.005 - ETA: 8s - loss: 4.8746 - acc: 0.004 - ETA: 14s - loss: 4.8744 - acc: 0.00 - ETA: 19s - loss: 4.8755 - acc: 0.00 - ETA: 22s - loss: 4.8765 - acc: 0.00 - ETA: 25s - loss: 4.8756 - acc: 0.00 - ETA: 26s - loss: 4.8742 - acc: 0.00 - ETA: 28s - loss: 4.8729 - acc: 0.00 - ETA: 29s - loss: 4.8745 - acc: 0.00 - ETA: 30s - loss: 4.8751 - acc: 0.00 - ETA: 34s - loss: 4.8756 - acc: 0.00 - ETA: 36s - loss: 4.8756 - acc: 0.00 - ETA: 37s - loss: 4.8759 - acc: 0.00 - ETA: 38s - loss: 4.8753 - acc: 0.00 - ETA: 38s - loss: 4.8764 - acc: 0.00 - ETA: 39s - loss: 4.8749 - acc: 0.00 - ETA: 40s - loss: 4.8746 - acc: 0.00 - ETA: 40s - loss: 4.8748 - acc: 0.00 - ETA: 41s - loss: 4.8739 - acc: 0.00 - ETA: 41s - loss: 4.8753 - acc: 0.00 - ETA: 42s - loss: 4.8766 - acc: 0.00 - ETA: 42s - loss: 4.8753 - acc: 0.00 - ETA: 42s - loss: 4.8757 - acc: 0.00 - ETA: 42s - loss: 4.8741 - acc: 0.00 - ETA: 44s - loss: 4.8741 - acc: 0.00 - ETA: 44s - loss: 4.8742 - acc: 0.00 - ETA: 44s - loss: 4.8738 - acc: 0.00 - ETA: 45s - loss: 4.8745 - acc: 0.00 - ETA: 45s - loss: 4.8743 - acc: 0.00 - ETA: 45s - loss: 4.8737 - acc: 0.00 - ETA: 46s - loss: 4.8731 - acc: 0.01 - ETA: 46s - loss: 4.8743 - acc: 0.01 - ETA: 46s - loss: 4.8749 - acc: 0.00 - ETA: 47s - loss: 4.8743 - acc: 0.00 - ETA: 47s - loss: 4.8736 - acc: 0.00 - ETA: 48s - loss: 4.8742 - acc: 0.00 - ETA: 48s - loss: 4.8740 - acc: 0.00 - ETA: 48s - loss: 4.8741 - acc: 0.00 - ETA: 48s - loss: 4.8757 - acc: 0.00 - ETA: 48s - loss: 4.8755 - acc: 0.00 - ETA: 48s - loss: 4.8764 - acc: 0.00 - ETA: 48s - loss: 4.8766 - acc: 0.00 - ETA: 48s - loss: 4.8773 - acc: 0.00 - ETA: 48s - loss: 4.8775 - acc: 0.00 - ETA: 48s - loss: 4.8780 - acc: 0.01 - ETA: 48s - loss: 4.8791 - acc: 0.00 - ETA: 48s - loss: 4.8799 - acc: 0.00 - ETA: 48s - loss: 4.8799 - acc: 0.00 - ETA: 48s - loss: 4.8801 - acc: 0.00 - ETA: 50s - loss: 4.8801 - acc: 0.01 - ETA: 50s - loss: 4.8793 - acc: 0.01 - ETA: 50s - loss: 4.8796 - acc: 0.00 - ETA: 50s - loss: 4.8791 - acc: 0.00 - ETA: 50s - loss: 4.8791 - acc: 0.00 - ETA: 50s - loss: 4.8791 - acc: 0.00 - ETA: 49s - loss: 4.8790 - acc: 0.01 - ETA: 50s - loss: 4.8785 - acc: 0.01 - ETA: 50s - loss: 4.8780 - acc: 0.01 - ETA: 50s - loss: 4.8773 - acc: 0.00 - ETA: 50s - loss: 4.8774 - acc: 0.01 - ETA: 50s - loss: 4.8777 - acc: 0.01 - ETA: 50s - loss: 4.8778 - acc: 0.01 - ETA: 50s - loss: 4.8778 - acc: 0.01 - ETA: 50s - loss: 4.8773 - acc: 0.01 - ETA: 49s - loss: 4.8767 - acc: 0.01 - ETA: 49s - loss: 4.8765 - acc: 0.01 - ETA: 49s - loss: 4.8763 - acc: 0.01 - ETA: 49s - loss: 4.8760 - acc: 0.01 - ETA: 49s - loss: 4.8762 - acc: 0.01 - ETA: 49s - loss: 4.8763 - acc: 0.01 - ETA: 49s - loss: 4.8763 - acc: 0.01 - ETA: 49s - loss: 4.8767 - acc: 0.01 - ETA: 49s - loss: 4.8771 - acc: 0.01 - ETA: 48s - loss: 4.8768 - acc: 0.01 - ETA: 48s - loss: 4.8769 - acc: 0.01 - ETA: 48s - loss: 4.8775 - acc: 0.01 - ETA: 48s - loss: 4.8777 - acc: 0.00 - ETA: 48s - loss: 4.8775 - acc: 0.00 - ETA: 48s - loss: 4.8774 - acc: 0.00 - ETA: 48s - loss: 4.8774 - acc: 0.00 - ETA: 48s - loss: 4.8774 - acc: 0.00 - ETA: 48s - loss: 4.8777 - acc: 0.00 - ETA: 48s - loss: 4.8784 - acc: 0.00 - ETA: 48s - loss: 4.8781 - acc: 0.00 - ETA: 47s - loss: 4.8780 - acc: 0.00 - ETA: 47s - loss: 4.8780 - acc: 0.00 - ETA: 48s - loss: 4.8782 - acc: 0.00 - ETA: 47s - loss: 4.8781 - acc: 0.00 - ETA: 47s - loss: 4.8780 - acc: 0.01 - ETA: 47s - loss: 4.8784 - acc: 0.01 - ETA: 47s - loss: 4.8783 - acc: 0.01 - ETA: 47s - loss: 4.8787 - acc: 0.01 - ETA: 46s - loss: 4.8786 - acc: 0.01 - ETA: 46s - loss: 4.8782 - acc: 0.01 - ETA: 46s - loss: 4.8782 - acc: 0.01 - ETA: 46s - loss: 4.8787 - acc: 0.01 - ETA: 46s - loss: 4.8790 - acc: 0.01 - ETA: 45s - loss: 4.8795 - acc: 0.01 - ETA: 45s - loss: 4.8796 - acc: 0.01 - ETA: 45s - loss: 4.8797 - acc: 0.01 - ETA: 45s - loss: 4.8800 - acc: 0.01 - ETA: 45s - loss: 4.8800 - acc: 0.01 - ETA: 45s - loss: 4.8802 - acc: 0.00 - ETA: 45s - loss: 4.8804 - acc: 0.00 - ETA: 45s - loss: 4.8802 - acc: 0.01 - ETA: 44s - loss: 4.8803 - acc: 0.01 - ETA: 44s - loss: 4.8804 - acc: 0.01 - ETA: 44s - loss: 4.8808 - acc: 0.01 - ETA: 44s - loss: 4.8808 - acc: 0.00 - ETA: 45s - loss: 4.8809 - acc: 0.00 - ETA: 44s - loss: 4.8811 - acc: 0.00 - ETA: 44s - loss: 4.8810 - acc: 0.00 - ETA: 44s - loss: 4.8808 - acc: 0.00 - ETA: 44s - loss: 4.8805 - acc: 0.00 - ETA: 44s - loss: 4.8801 - acc: 0.00 - ETA: 44s - loss: 4.8802 - acc: 0.00 - ETA: 43s - loss: 4.8798 - acc: 0.01 - ETA: 43s - loss: 4.8794 - acc: 0.01 - ETA: 43s - loss: 4.8789 - acc: 0.01 - ETA: 43s - loss: 4.8787 - acc: 0.01 - ETA: 43s - loss: 4.8789 - acc: 0.01 - ETA: 42s - loss: 4.8791 - acc: 0.01 - ETA: 42s - loss: 4.8793 - acc: 0.01 - ETA: 42s - loss: 4.8796 - acc: 0.01 - ETA: 42s - loss: 4.8796 - acc: 0.01 - ETA: 42s - loss: 4.8795 - acc: 0.01 - ETA: 42s - loss: 4.8794 - acc: 0.01 - ETA: 42s - loss: 4.8792 - acc: 0.01 - ETA: 42s - loss: 4.8792 - acc: 0.01 - ETA: 42s - loss: 4.8793 - acc: 0.01 - ETA: 41s - loss: 4.8794 - acc: 0.01 - ETA: 41s - loss: 4.8795 - acc: 0.01 - ETA: 41s - loss: 4.8795 - acc: 0.01 - ETA: 41s - loss: 4.8798 - acc: 0.01 - ETA: 41s - loss: 4.8798 - acc: 0.01 - ETA: 41s - loss: 4.8797 - acc: 0.01 - ETA: 41s - loss: 4.8797 - acc: 0.01 - ETA: 40s - loss: 4.8799 - acc: 0.01 - ETA: 40s - loss: 4.8799 - acc: 0.01 - ETA: 40s - loss: 4.8797 - acc: 0.01 - ETA: 40s - loss: 4.8795 - acc: 0.01 - ETA: 40s - loss: 4.8798 - acc: 0.01 - ETA: 40s - loss: 4.8799 - acc: 0.01 - ETA: 39s - loss: 4.8796 - acc: 0.01 - ETA: 39s - loss: 4.8799 - acc: 0.01 - ETA: 39s - loss: 4.8798 - acc: 0.01 - ETA: 39s - loss: 4.8798 - acc: 0.01 - ETA: 39s - loss: 4.8801 - acc: 0.01 - ETA: 39s - loss: 4.8802 - acc: 0.01 - ETA: 38s - loss: 4.8804 - acc: 0.01 - ETA: 38s - loss: 4.8807 - acc: 0.01 - ETA: 38s - loss: 4.8806 - acc: 0.01 - ETA: 38s - loss: 4.8803 - acc: 0.01 - ETA: 38s - loss: 4.8805 - acc: 0.01 - ETA: 37s - loss: 4.8804 - acc: 0.01 - ETA: 37s - loss: 4.8802 - acc: 0.01 - ETA: 37s - loss: 4.8803 - acc: 0.01 - ETA: 37s - loss: 4.8801 - acc: 0.01 - ETA: 37s - loss: 4.8800 - acc: 0.01 - ETA: 37s - loss: 4.8802 - acc: 0.01 - ETA: 37s - loss: 4.8804 - acc: 0.01 - ETA: 36s - loss: 4.8803 - acc: 0.01 - ETA: 36s - loss: 4.8802 - acc: 0.01 - ETA: 36s - loss: 4.8799 - acc: 0.01 - ETA: 36s - loss: 4.8803 - acc: 0.01 - ETA: 36s - loss: 4.8803 - acc: 0.01 - ETA: 36s - loss: 4.8804 - acc: 0.01 - ETA: 36s - loss: 4.8800 - acc: 0.01 - ETA: 36s - loss: 4.8800 - acc: 0.01 - ETA: 35s - loss: 4.8801 - acc: 0.01 - ETA: 35s - loss: 4.8800 - acc: 0.01 - ETA: 35s - loss: 4.8800 - acc: 0.01 - ETA: 35s - loss: 4.8800 - acc: 0.01 - ETA: 35s - loss: 4.8802 - acc: 0.01 - ETA: 35s - loss: 4.8802 - acc: 0.01 - ETA: 35s - loss: 4.8803 - acc: 0.01 - ETA: 35s - loss: 4.8803 - acc: 0.01 - ETA: 34s - loss: 4.8803 - acc: 0.01 - ETA: 34s - loss: 4.8805 - acc: 0.01 - ETA: 34s - loss: 4.8808 - acc: 0.01 - ETA: 34s - loss: 4.8806 - acc: 0.01 - ETA: 34s - loss: 4.8803 - acc: 0.01 - ETA: 34s - loss: 4.8803 - acc: 0.01 - ETA: 33s - loss: 4.8801 - acc: 0.01 - ETA: 33s - loss: 4.8800 - acc: 0.01 - ETA: 33s - loss: 4.8800 - acc: 0.01 - ETA: 33s - loss: 4.8801 - acc: 0.01 - ETA: 33s - loss: 4.8800 - acc: 0.01 - ETA: 33s - loss: 4.8800 - acc: 0.01 - ETA: 32s - loss: 4.8799 - acc: 0.01 - ETA: 32s - loss: 4.8799 - acc: 0.01 - ETA: 32s - loss: 4.8802 - acc: 0.01 - ETA: 32s - loss: 4.8804 - acc: 0.01 - ETA: 32s - loss: 4.8806 - acc: 0.01 - ETA: 32s - loss: 4.8806 - acc: 0.01 - ETA: 31s - loss: 4.8806 - acc: 0.01 - ETA: 31s - loss: 4.8806 - acc: 0.01 - ETA: 31s - loss: 4.8806 - acc: 0.01 - ETA: 31s - loss: 4.8806 - acc: 0.01 - ETA: 31s - loss: 4.8806 - acc: 0.01 - ETA: 31s - loss: 4.8809 - acc: 0.01 - ETA: 31s - loss: 4.8807 - acc: 0.01 - ETA: 31s - loss: 4.8809 - acc: 0.01 - ETA: 30s - loss: 4.8808 - acc: 0.01 - ETA: 30s - loss: 4.8808 - acc: 0.01 - ETA: 30s - loss: 4.8808 - acc: 0.01 - ETA: 30s - loss: 4.8809 - acc: 0.01 - ETA: 30s - loss: 4.8810 - acc: 0.01 - ETA: 30s - loss: 4.8810 - acc: 0.01 - ETA: 30s - loss: 4.8810 - acc: 0.01 - ETA: 30s - loss: 4.8810 - acc: 0.01 - ETA: 29s - loss: 4.8810 - acc: 0.0109"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 29s - loss: 4.8810 - acc: 0.01 - ETA: 29s - loss: 4.8810 - acc: 0.01 - ETA: 29s - loss: 4.8810 - acc: 0.01 - ETA: 29s - loss: 4.8808 - acc: 0.01 - ETA: 29s - loss: 4.8807 - acc: 0.01 - ETA: 28s - loss: 4.8807 - acc: 0.01 - ETA: 28s - loss: 4.8808 - acc: 0.01 - ETA: 28s - loss: 4.8806 - acc: 0.01 - ETA: 28s - loss: 4.8803 - acc: 0.01 - ETA: 28s - loss: 4.8802 - acc: 0.01 - ETA: 28s - loss: 4.8801 - acc: 0.01 - ETA: 27s - loss: 4.8801 - acc: 0.01 - ETA: 27s - loss: 4.8802 - acc: 0.01 - ETA: 27s - loss: 4.8805 - acc: 0.01 - ETA: 27s - loss: 4.8805 - acc: 0.01 - ETA: 27s - loss: 4.8806 - acc: 0.01 - ETA: 27s - loss: 4.8809 - acc: 0.01 - ETA: 27s - loss: 4.8808 - acc: 0.01 - ETA: 26s - loss: 4.8809 - acc: 0.01 - ETA: 26s - loss: 4.8810 - acc: 0.01 - ETA: 26s - loss: 4.8812 - acc: 0.01 - ETA: 26s - loss: 4.8813 - acc: 0.01 - ETA: 26s - loss: 4.8813 - acc: 0.01 - ETA: 26s - loss: 4.8813 - acc: 0.01 - ETA: 25s - loss: 4.8816 - acc: 0.01 - ETA: 25s - loss: 4.8816 - acc: 0.01 - ETA: 25s - loss: 4.8817 - acc: 0.01 - ETA: 25s - loss: 4.8817 - acc: 0.01 - ETA: 25s - loss: 4.8817 - acc: 0.01 - ETA: 25s - loss: 4.8817 - acc: 0.01 - ETA: 25s - loss: 4.8817 - acc: 0.01 - ETA: 24s - loss: 4.8818 - acc: 0.01 - ETA: 24s - loss: 4.8819 - acc: 0.01 - ETA: 24s - loss: 4.8820 - acc: 0.01 - ETA: 24s - loss: 4.8821 - acc: 0.01 - ETA: 24s - loss: 4.8821 - acc: 0.01 - ETA: 24s - loss: 4.8821 - acc: 0.01 - ETA: 24s - loss: 4.8821 - acc: 0.01 - ETA: 23s - loss: 4.8820 - acc: 0.01 - ETA: 23s - loss: 4.8820 - acc: 0.01 - ETA: 23s - loss: 4.8821 - acc: 0.01 - ETA: 23s - loss: 4.8821 - acc: 0.01 - ETA: 23s - loss: 4.8819 - acc: 0.01 - ETA: 23s - loss: 4.8820 - acc: 0.01 - ETA: 23s - loss: 4.8820 - acc: 0.01 - ETA: 22s - loss: 4.8820 - acc: 0.01 - ETA: 22s - loss: 4.8818 - acc: 0.01 - ETA: 22s - loss: 4.8818 - acc: 0.01 - ETA: 22s - loss: 4.8818 - acc: 0.01 - ETA: 22s - loss: 4.8815 - acc: 0.01 - ETA: 22s - loss: 4.8815 - acc: 0.01 - ETA: 22s - loss: 4.8814 - acc: 0.01 - ETA: 21s - loss: 4.8816 - acc: 0.01 - ETA: 21s - loss: 4.8817 - acc: 0.01 - ETA: 21s - loss: 4.8815 - acc: 0.01 - ETA: 21s - loss: 4.8815 - acc: 0.01 - ETA: 21s - loss: 4.8815 - acc: 0.01 - ETA: 21s - loss: 4.8816 - acc: 0.01 - ETA: 20s - loss: 4.8816 - acc: 0.01 - ETA: 20s - loss: 4.8816 - acc: 0.01 - ETA: 20s - loss: 4.8815 - acc: 0.01 - ETA: 20s - loss: 4.8814 - acc: 0.01 - ETA: 20s - loss: 4.8814 - acc: 0.01 - ETA: 20s - loss: 4.8814 - acc: 0.01 - ETA: 20s - loss: 4.8814 - acc: 0.01 - ETA: 19s - loss: 4.8815 - acc: 0.01 - ETA: 19s - loss: 4.8817 - acc: 0.01 - ETA: 19s - loss: 4.8817 - acc: 0.01 - ETA: 19s - loss: 4.8818 - acc: 0.01 - ETA: 19s - loss: 4.8817 - acc: 0.01 - ETA: 19s - loss: 4.8816 - acc: 0.01 - ETA: 18s - loss: 4.8816 - acc: 0.01 - ETA: 18s - loss: 4.8816 - acc: 0.01 - ETA: 18s - loss: 4.8816 - acc: 0.01 - ETA: 18s - loss: 4.8816 - acc: 0.01 - ETA: 18s - loss: 4.8816 - acc: 0.01 - ETA: 18s - loss: 4.8817 - acc: 0.01 - ETA: 18s - loss: 4.8819 - acc: 0.01 - ETA: 18s - loss: 4.8820 - acc: 0.01 - ETA: 17s - loss: 4.8820 - acc: 0.01 - ETA: 17s - loss: 4.8820 - acc: 0.01 - ETA: 17s - loss: 4.8821 - acc: 0.01 - ETA: 17s - loss: 4.8820 - acc: 0.01 - ETA: 17s - loss: 4.8820 - acc: 0.01 - ETA: 17s - loss: 4.8820 - acc: 0.01 - ETA: 16s - loss: 4.8820 - acc: 0.01 - ETA: 16s - loss: 4.8819 - acc: 0.01 - ETA: 16s - loss: 4.8821 - acc: 0.01 - ETA: 16s - loss: 4.8821 - acc: 0.01 - ETA: 16s - loss: 4.8821 - acc: 0.01 - ETA: 16s - loss: 4.8819 - acc: 0.01 - ETA: 16s - loss: 4.8818 - acc: 0.01 - ETA: 15s - loss: 4.8818 - acc: 0.01 - ETA: 15s - loss: 4.8817 - acc: 0.01 - ETA: 15s - loss: 4.8818 - acc: 0.01 - ETA: 15s - loss: 4.8819 - acc: 0.01 - ETA: 15s - loss: 4.8819 - acc: 0.01 - ETA: 15s - loss: 4.8818 - acc: 0.01 - ETA: 15s - loss: 4.8817 - acc: 0.01 - ETA: 14s - loss: 4.8818 - acc: 0.01 - ETA: 14s - loss: 4.8818 - acc: 0.01 - ETA: 14s - loss: 4.8818 - acc: 0.01 - ETA: 14s - loss: 4.8817 - acc: 0.01 - ETA: 14s - loss: 4.8817 - acc: 0.01 - ETA: 14s - loss: 4.8817 - acc: 0.01 - ETA: 13s - loss: 4.8818 - acc: 0.01 - ETA: 13s - loss: 4.8819 - acc: 0.01 - ETA: 13s - loss: 4.8820 - acc: 0.01 - ETA: 13s - loss: 4.8819 - acc: 0.01 - ETA: 13s - loss: 4.8818 - acc: 0.01 - ETA: 13s - loss: 4.8817 - acc: 0.01 - ETA: 12s - loss: 4.8816 - acc: 0.01 - ETA: 12s - loss: 4.8816 - acc: 0.01 - ETA: 12s - loss: 4.8814 - acc: 0.01 - ETA: 12s - loss: 4.8812 - acc: 0.01 - ETA: 12s - loss: 4.8812 - acc: 0.01 - ETA: 12s - loss: 4.8812 - acc: 0.01 - ETA: 12s - loss: 4.8811 - acc: 0.01 - ETA: 11s - loss: 4.8812 - acc: 0.01 - ETA: 11s - loss: 4.8811 - acc: 0.01 - ETA: 11s - loss: 4.8811 - acc: 0.01 - ETA: 11s - loss: 4.8811 - acc: 0.01 - ETA: 11s - loss: 4.8811 - acc: 0.01 - ETA: 11s - loss: 4.8811 - acc: 0.01 - ETA: 10s - loss: 4.8811 - acc: 0.01 - ETA: 10s - loss: 4.8809 - acc: 0.01 - ETA: 10s - loss: 4.8810 - acc: 0.01 - ETA: 10s - loss: 4.8810 - acc: 0.01 - ETA: 10s - loss: 4.8810 - acc: 0.01 - ETA: 10s - loss: 4.8810 - acc: 0.01 - ETA: 10s - loss: 4.8812 - acc: 0.01 - ETA: 9s - loss: 4.8811 - acc: 0.0109 - ETA: 9s - loss: 4.8811 - acc: 0.010 - ETA: 9s - loss: 4.8811 - acc: 0.010 - ETA: 9s - loss: 4.8812 - acc: 0.010 - ETA: 9s - loss: 4.8811 - acc: 0.011 - ETA: 9s - loss: 4.8810 - acc: 0.010 - ETA: 8s - loss: 4.8811 - acc: 0.010 - ETA: 8s - loss: 4.8811 - acc: 0.011 - ETA: 8s - loss: 4.8811 - acc: 0.011 - ETA: 8s - loss: 4.8811 - acc: 0.011 - ETA: 8s - loss: 4.8811 - acc: 0.011 - ETA: 8s - loss: 4.8811 - acc: 0.010 - ETA: 7s - loss: 4.8810 - acc: 0.011 - ETA: 7s - loss: 4.8809 - acc: 0.011 - ETA: 7s - loss: 4.8809 - acc: 0.011 - ETA: 7s - loss: 4.8809 - acc: 0.011 - ETA: 7s - loss: 4.8808 - acc: 0.011 - ETA: 7s - loss: 4.8807 - acc: 0.011 - ETA: 7s - loss: 4.8807 - acc: 0.011 - ETA: 6s - loss: 4.8807 - acc: 0.011 - ETA: 6s - loss: 4.8807 - acc: 0.011 - ETA: 6s - loss: 4.8807 - acc: 0.011 - ETA: 6s - loss: 4.8809 - acc: 0.011 - ETA: 6s - loss: 4.8807 - acc: 0.011 - ETA: 5s - loss: 4.8806 - acc: 0.011 - ETA: 5s - loss: 4.8806 - acc: 0.011 - ETA: 5s - loss: 4.8805 - acc: 0.011 - ETA: 5s - loss: 4.8805 - acc: 0.010 - ETA: 5s - loss: 4.8805 - acc: 0.010 - ETA: 5s - loss: 4.8805 - acc: 0.010 - ETA: 4s - loss: 4.8805 - acc: 0.010 - ETA: 4s - loss: 4.8803 - acc: 0.011 - ETA: 4s - loss: 4.8803 - acc: 0.011 - ETA: 4s - loss: 4.8803 - acc: 0.011 - ETA: 4s - loss: 4.8802 - acc: 0.011 - ETA: 4s - loss: 4.8802 - acc: 0.011 - ETA: 3s - loss: 4.8802 - acc: 0.011 - ETA: 3s - loss: 4.8802 - acc: 0.011 - ETA: 3s - loss: 4.8802 - acc: 0.010 - ETA: 3s - loss: 4.8803 - acc: 0.010 - ETA: 3s - loss: 4.8802 - acc: 0.010 - ETA: 3s - loss: 4.8802 - acc: 0.010 - ETA: 3s - loss: 4.8802 - acc: 0.010 - ETA: 2s - loss: 4.8802 - acc: 0.010 - ETA: 2s - loss: 4.8802 - acc: 0.010 - ETA: 2s - loss: 4.8801 - acc: 0.010 - ETA: 2s - loss: 4.8801 - acc: 0.010 - ETA: 2s - loss: 4.8801 - acc: 0.010 - ETA: 2s - loss: 4.8801 - acc: 0.010 - ETA: 1s - loss: 4.8800 - acc: 0.010 - ETA: 1s - loss: 4.8799 - acc: 0.010 - ETA: 1s - loss: 4.8799 - acc: 0.010 - ETA: 1s - loss: 4.8798 - acc: 0.010 - ETA: 1s - loss: 4.8798 - acc: 0.011 - ETA: 1s - loss: 4.8799 - acc: 0.011 - ETA: 0s - loss: 4.8799 - acc: 0.011 - ETA: 0s - loss: 4.8799 - acc: 0.011 - ETA: 0s - loss: 4.8798 - acc: 0.011 - ETA: 0s - loss: 4.8798 - acc: 0.011 - ETA: 0s - loss: 4.8798 - acc: 0.011 - ETA: 0s - loss: 4.8798 - acc: 0.011 - 71s 171ms/step - loss: 4.8798 - acc: 0.0109 - val_loss: 4.8757 - val_acc: 0.0195\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.87575 to 4.87569, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/417 [===============>..............] - ETA: 5s - loss: 4.9127 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8971 - acc: 0.0125    - ETA: 6s - loss: 4.8856 - acc: 0.006 - ETA: 8s - loss: 4.8816 - acc: 0.010 - ETA: 12s - loss: 4.8829 - acc: 0.00 - ETA: 14s - loss: 4.8803 - acc: 0.00 - ETA: 17s - loss: 4.8834 - acc: 0.00 - ETA: 21s - loss: 4.8832 - acc: 0.00 - ETA: 24s - loss: 4.8816 - acc: 0.01 - ETA: 25s - loss: 4.8802 - acc: 0.01 - ETA: 27s - loss: 4.8805 - acc: 0.00 - ETA: 28s - loss: 4.8813 - acc: 0.00 - ETA: 30s - loss: 4.8814 - acc: 0.00 - ETA: 31s - loss: 4.8797 - acc: 0.00 - ETA: 32s - loss: 4.8797 - acc: 0.00 - ETA: 33s - loss: 4.8795 - acc: 0.00 - ETA: 34s - loss: 4.8806 - acc: 0.01 - ETA: 34s - loss: 4.8784 - acc: 0.01 - ETA: 36s - loss: 4.8782 - acc: 0.01 - ETA: 37s - loss: 4.8777 - acc: 0.01 - ETA: 37s - loss: 4.8788 - acc: 0.01 - ETA: 37s - loss: 4.8785 - acc: 0.01 - ETA: 38s - loss: 4.8776 - acc: 0.01 - ETA: 38s - loss: 4.8781 - acc: 0.00 - ETA: 39s - loss: 4.8778 - acc: 0.00 - ETA: 39s - loss: 4.8784 - acc: 0.00 - ETA: 40s - loss: 4.8785 - acc: 0.00 - ETA: 40s - loss: 4.8783 - acc: 0.00 - ETA: 40s - loss: 4.8787 - acc: 0.00 - ETA: 41s - loss: 4.8792 - acc: 0.00 - ETA: 42s - loss: 4.8794 - acc: 0.00 - ETA: 42s - loss: 4.8790 - acc: 0.00 - ETA: 42s - loss: 4.8783 - acc: 0.00 - ETA: 42s - loss: 4.8773 - acc: 0.00 - ETA: 43s - loss: 4.8784 - acc: 0.00 - ETA: 45s - loss: 4.8785 - acc: 0.00 - ETA: 46s - loss: 4.8781 - acc: 0.00 - ETA: 47s - loss: 4.8783 - acc: 0.00 - ETA: 47s - loss: 4.8791 - acc: 0.00 - ETA: 47s - loss: 4.8786 - acc: 0.00 - ETA: 49s - loss: 4.8783 - acc: 0.00 - ETA: 48s - loss: 4.8780 - acc: 0.00 - ETA: 48s - loss: 4.8780 - acc: 0.00 - ETA: 48s - loss: 4.8782 - acc: 0.00 - ETA: 48s - loss: 4.8783 - acc: 0.00 - ETA: 48s - loss: 4.8783 - acc: 0.00 - ETA: 48s - loss: 4.8788 - acc: 0.00 - ETA: 48s - loss: 4.8796 - acc: 0.00 - ETA: 48s - loss: 4.8789 - acc: 0.00 - ETA: 48s - loss: 4.8794 - acc: 0.00 - ETA: 48s - loss: 4.8796 - acc: 0.00 - ETA: 48s - loss: 4.8805 - acc: 0.00 - ETA: 49s - loss: 4.8799 - acc: 0.00 - ETA: 48s - loss: 4.8790 - acc: 0.00 - ETA: 48s - loss: 4.8789 - acc: 0.00 - ETA: 48s - loss: 4.8794 - acc: 0.00 - ETA: 48s - loss: 4.8790 - acc: 0.00 - ETA: 48s - loss: 4.8792 - acc: 0.00 - ETA: 48s - loss: 4.8795 - acc: 0.00 - ETA: 48s - loss: 4.8795 - acc: 0.00 - ETA: 48s - loss: 4.8798 - acc: 0.00 - ETA: 48s - loss: 4.8796 - acc: 0.00 - ETA: 48s - loss: 4.8794 - acc: 0.00 - ETA: 49s - loss: 4.8798 - acc: 0.00 - ETA: 48s - loss: 4.8793 - acc: 0.00 - ETA: 49s - loss: 4.8787 - acc: 0.00 - ETA: 49s - loss: 4.8785 - acc: 0.00 - ETA: 50s - loss: 4.8782 - acc: 0.00 - ETA: 51s - loss: 4.8782 - acc: 0.01 - ETA: 50s - loss: 4.8785 - acc: 0.01 - ETA: 50s - loss: 4.8781 - acc: 0.01 - ETA: 50s - loss: 4.8776 - acc: 0.01 - ETA: 49s - loss: 4.8778 - acc: 0.01 - ETA: 49s - loss: 4.8774 - acc: 0.01 - ETA: 49s - loss: 4.8776 - acc: 0.01 - ETA: 49s - loss: 4.8772 - acc: 0.01 - ETA: 49s - loss: 4.8773 - acc: 0.01 - ETA: 48s - loss: 4.8775 - acc: 0.01 - ETA: 48s - loss: 4.8771 - acc: 0.01 - ETA: 48s - loss: 4.8772 - acc: 0.01 - ETA: 48s - loss: 4.8777 - acc: 0.01 - ETA: 48s - loss: 4.8775 - acc: 0.01 - ETA: 48s - loss: 4.8779 - acc: 0.01 - ETA: 48s - loss: 4.8779 - acc: 0.01 - ETA: 48s - loss: 4.8777 - acc: 0.01 - ETA: 48s - loss: 4.8779 - acc: 0.01 - ETA: 47s - loss: 4.8781 - acc: 0.01 - ETA: 47s - loss: 4.8782 - acc: 0.01 - ETA: 47s - loss: 4.8781 - acc: 0.01 - ETA: 47s - loss: 4.8783 - acc: 0.01 - ETA: 47s - loss: 4.8782 - acc: 0.01 - ETA: 47s - loss: 4.8777 - acc: 0.01 - ETA: 47s - loss: 4.8781 - acc: 0.01 - ETA: 46s - loss: 4.8775 - acc: 0.01 - ETA: 46s - loss: 4.8775 - acc: 0.01 - ETA: 46s - loss: 4.8773 - acc: 0.01 - ETA: 46s - loss: 4.8770 - acc: 0.01 - ETA: 46s - loss: 4.8764 - acc: 0.01 - ETA: 46s - loss: 4.8766 - acc: 0.01 - ETA: 46s - loss: 4.8765 - acc: 0.01 - ETA: 46s - loss: 4.8763 - acc: 0.01 - ETA: 46s - loss: 4.8764 - acc: 0.01 - ETA: 46s - loss: 4.8768 - acc: 0.01 - ETA: 45s - loss: 4.8772 - acc: 0.01 - ETA: 45s - loss: 4.8772 - acc: 0.01 - ETA: 45s - loss: 4.8780 - acc: 0.01 - ETA: 45s - loss: 4.8779 - acc: 0.01 - ETA: 45s - loss: 4.8782 - acc: 0.01 - ETA: 45s - loss: 4.8779 - acc: 0.01 - ETA: 44s - loss: 4.8781 - acc: 0.01 - ETA: 44s - loss: 4.8777 - acc: 0.01 - ETA: 44s - loss: 4.8779 - acc: 0.01 - ETA: 44s - loss: 4.8779 - acc: 0.01 - ETA: 44s - loss: 4.8776 - acc: 0.01 - ETA: 44s - loss: 4.8776 - acc: 0.01 - ETA: 44s - loss: 4.8777 - acc: 0.01 - ETA: 44s - loss: 4.8780 - acc: 0.01 - ETA: 44s - loss: 4.8781 - acc: 0.01 - ETA: 44s - loss: 4.8781 - acc: 0.01 - ETA: 44s - loss: 4.8781 - acc: 0.01 - ETA: 43s - loss: 4.8778 - acc: 0.01 - ETA: 43s - loss: 4.8776 - acc: 0.01 - ETA: 43s - loss: 4.8777 - acc: 0.01 - ETA: 43s - loss: 4.8772 - acc: 0.01 - ETA: 43s - loss: 4.8770 - acc: 0.01 - ETA: 43s - loss: 4.8768 - acc: 0.01 - ETA: 43s - loss: 4.8768 - acc: 0.01 - ETA: 43s - loss: 4.8766 - acc: 0.01 - ETA: 43s - loss: 4.8762 - acc: 0.01 - ETA: 43s - loss: 4.8763 - acc: 0.01 - ETA: 42s - loss: 4.8761 - acc: 0.01 - ETA: 42s - loss: 4.8765 - acc: 0.01 - ETA: 42s - loss: 4.8764 - acc: 0.01 - ETA: 42s - loss: 4.8765 - acc: 0.01 - ETA: 42s - loss: 4.8766 - acc: 0.01 - ETA: 42s - loss: 4.8766 - acc: 0.01 - ETA: 41s - loss: 4.8765 - acc: 0.01 - ETA: 41s - loss: 4.8764 - acc: 0.01 - ETA: 41s - loss: 4.8766 - acc: 0.01 - ETA: 41s - loss: 4.8765 - acc: 0.01 - ETA: 41s - loss: 4.8762 - acc: 0.01 - ETA: 41s - loss: 4.8763 - acc: 0.01 - ETA: 40s - loss: 4.8761 - acc: 0.01 - ETA: 40s - loss: 4.8759 - acc: 0.01 - ETA: 40s - loss: 4.8760 - acc: 0.01 - ETA: 40s - loss: 4.8758 - acc: 0.01 - ETA: 40s - loss: 4.8761 - acc: 0.01 - ETA: 40s - loss: 4.8762 - acc: 0.01 - ETA: 40s - loss: 4.8764 - acc: 0.01 - ETA: 39s - loss: 4.8765 - acc: 0.01 - ETA: 39s - loss: 4.8763 - acc: 0.01 - ETA: 39s - loss: 4.8761 - acc: 0.01 - ETA: 39s - loss: 4.8763 - acc: 0.01 - ETA: 39s - loss: 4.8764 - acc: 0.01 - ETA: 39s - loss: 4.8761 - acc: 0.01 - ETA: 39s - loss: 4.8761 - acc: 0.01 - ETA: 39s - loss: 4.8759 - acc: 0.01 - ETA: 39s - loss: 4.8761 - acc: 0.01 - ETA: 39s - loss: 4.8760 - acc: 0.01 - ETA: 38s - loss: 4.8758 - acc: 0.01 - ETA: 38s - loss: 4.8758 - acc: 0.01 - ETA: 38s - loss: 4.8757 - acc: 0.01 - ETA: 38s - loss: 4.8753 - acc: 0.01 - ETA: 38s - loss: 4.8755 - acc: 0.01 - ETA: 38s - loss: 4.8753 - acc: 0.01 - ETA: 37s - loss: 4.8752 - acc: 0.01 - ETA: 37s - loss: 4.8751 - acc: 0.01 - ETA: 37s - loss: 4.8747 - acc: 0.01 - ETA: 37s - loss: 4.8747 - acc: 0.01 - ETA: 37s - loss: 4.8748 - acc: 0.01 - ETA: 37s - loss: 4.8747 - acc: 0.01 - ETA: 37s - loss: 4.8748 - acc: 0.01 - ETA: 37s - loss: 4.8748 - acc: 0.01 - ETA: 37s - loss: 4.8752 - acc: 0.01 - ETA: 36s - loss: 4.8752 - acc: 0.01 - ETA: 36s - loss: 4.8755 - acc: 0.01 - ETA: 36s - loss: 4.8755 - acc: 0.01 - ETA: 36s - loss: 4.8756 - acc: 0.01 - ETA: 36s - loss: 4.8752 - acc: 0.01 - ETA: 36s - loss: 4.8749 - acc: 0.01 - ETA: 35s - loss: 4.8751 - acc: 0.01 - ETA: 35s - loss: 4.8751 - acc: 0.01 - ETA: 35s - loss: 4.8750 - acc: 0.01 - ETA: 35s - loss: 4.8753 - acc: 0.01 - ETA: 35s - loss: 4.8755 - acc: 0.01 - ETA: 35s - loss: 4.8755 - acc: 0.01 - ETA: 35s - loss: 4.8752 - acc: 0.01 - ETA: 34s - loss: 4.8753 - acc: 0.01 - ETA: 34s - loss: 4.8754 - acc: 0.01 - ETA: 34s - loss: 4.8755 - acc: 0.01 - ETA: 34s - loss: 4.8755 - acc: 0.01 - ETA: 34s - loss: 4.8755 - acc: 0.01 - ETA: 33s - loss: 4.8752 - acc: 0.01 - ETA: 33s - loss: 4.8752 - acc: 0.01 - ETA: 33s - loss: 4.8750 - acc: 0.01 - ETA: 33s - loss: 4.8748 - acc: 0.01 - ETA: 33s - loss: 4.8749 - acc: 0.01 - ETA: 33s - loss: 4.8749 - acc: 0.01 - ETA: 32s - loss: 4.8750 - acc: 0.01 - ETA: 32s - loss: 4.8749 - acc: 0.01 - ETA: 32s - loss: 4.8752 - acc: 0.01 - ETA: 32s - loss: 4.8750 - acc: 0.01 - ETA: 32s - loss: 4.8750 - acc: 0.01 - ETA: 32s - loss: 4.8749 - acc: 0.01 - ETA: 32s - loss: 4.8753 - acc: 0.01 - ETA: 31s - loss: 4.8753 - acc: 0.01 - ETA: 31s - loss: 4.8753 - acc: 0.01 - ETA: 31s - loss: 4.8754 - acc: 0.01 - ETA: 31s - loss: 4.8756 - acc: 0.01 - ETA: 31s - loss: 4.8756 - acc: 0.01 - ETA: 31s - loss: 4.8758 - acc: 0.01 - ETA: 30s - loss: 4.8758 - acc: 0.01 - ETA: 30s - loss: 4.8758 - acc: 0.01 - ETA: 30s - loss: 4.8754 - acc: 0.01 - ETA: 30s - loss: 4.8755 - acc: 0.0122"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8754 - acc: 0.01 - ETA: 30s - loss: 4.8755 - acc: 0.01 - ETA: 29s - loss: 4.8756 - acc: 0.01 - ETA: 29s - loss: 4.8757 - acc: 0.01 - ETA: 29s - loss: 4.8757 - acc: 0.01 - ETA: 29s - loss: 4.8759 - acc: 0.01 - ETA: 29s - loss: 4.8759 - acc: 0.01 - ETA: 29s - loss: 4.8760 - acc: 0.01 - ETA: 28s - loss: 4.8762 - acc: 0.01 - ETA: 28s - loss: 4.8761 - acc: 0.01 - ETA: 28s - loss: 4.8761 - acc: 0.01 - ETA: 28s - loss: 4.8760 - acc: 0.01 - ETA: 28s - loss: 4.8759 - acc: 0.01 - ETA: 28s - loss: 4.8759 - acc: 0.01 - ETA: 27s - loss: 4.8757 - acc: 0.01 - ETA: 27s - loss: 4.8756 - acc: 0.01 - ETA: 27s - loss: 4.8758 - acc: 0.01 - ETA: 27s - loss: 4.8758 - acc: 0.01 - ETA: 27s - loss: 4.8756 - acc: 0.01 - ETA: 26s - loss: 4.8758 - acc: 0.01 - ETA: 26s - loss: 4.8758 - acc: 0.01 - ETA: 26s - loss: 4.8758 - acc: 0.01 - ETA: 26s - loss: 4.8760 - acc: 0.01 - ETA: 26s - loss: 4.8762 - acc: 0.01 - ETA: 26s - loss: 4.8763 - acc: 0.01 - ETA: 26s - loss: 4.8762 - acc: 0.01 - ETA: 25s - loss: 4.8763 - acc: 0.01 - ETA: 25s - loss: 4.8761 - acc: 0.01 - ETA: 25s - loss: 4.8763 - acc: 0.01 - ETA: 25s - loss: 4.8762 - acc: 0.01 - ETA: 25s - loss: 4.8764 - acc: 0.01 - ETA: 25s - loss: 4.8763 - acc: 0.01 - ETA: 24s - loss: 4.8762 - acc: 0.01 - ETA: 24s - loss: 4.8763 - acc: 0.01 - ETA: 24s - loss: 4.8763 - acc: 0.01 - ETA: 24s - loss: 4.8762 - acc: 0.01 - ETA: 24s - loss: 4.8763 - acc: 0.01 - ETA: 24s - loss: 4.8764 - acc: 0.01 - ETA: 23s - loss: 4.8764 - acc: 0.01 - ETA: 23s - loss: 4.8765 - acc: 0.01 - ETA: 23s - loss: 4.8764 - acc: 0.01 - ETA: 23s - loss: 4.8763 - acc: 0.01 - ETA: 23s - loss: 4.8764 - acc: 0.01 - ETA: 23s - loss: 4.8764 - acc: 0.01 - ETA: 22s - loss: 4.8765 - acc: 0.01 - ETA: 22s - loss: 4.8763 - acc: 0.01 - ETA: 22s - loss: 4.8763 - acc: 0.01 - ETA: 22s - loss: 4.8764 - acc: 0.01 - ETA: 22s - loss: 4.8765 - acc: 0.01 - ETA: 21s - loss: 4.8765 - acc: 0.01 - ETA: 21s - loss: 4.8765 - acc: 0.01 - ETA: 21s - loss: 4.8764 - acc: 0.01 - ETA: 21s - loss: 4.8764 - acc: 0.01 - ETA: 21s - loss: 4.8764 - acc: 0.01 - ETA: 21s - loss: 4.8765 - acc: 0.01 - ETA: 20s - loss: 4.8766 - acc: 0.01 - ETA: 20s - loss: 4.8765 - acc: 0.01 - ETA: 20s - loss: 4.8765 - acc: 0.01 - ETA: 20s - loss: 4.8765 - acc: 0.01 - ETA: 20s - loss: 4.8767 - acc: 0.01 - ETA: 20s - loss: 4.8767 - acc: 0.01 - ETA: 19s - loss: 4.8767 - acc: 0.01 - ETA: 19s - loss: 4.8769 - acc: 0.01 - ETA: 19s - loss: 4.8770 - acc: 0.01 - ETA: 19s - loss: 4.8770 - acc: 0.01 - ETA: 19s - loss: 4.8769 - acc: 0.01 - ETA: 19s - loss: 4.8768 - acc: 0.01 - ETA: 19s - loss: 4.8768 - acc: 0.01 - ETA: 18s - loss: 4.8767 - acc: 0.01 - ETA: 18s - loss: 4.8769 - acc: 0.01 - ETA: 18s - loss: 4.8769 - acc: 0.01 - ETA: 18s - loss: 4.8768 - acc: 0.01 - ETA: 18s - loss: 4.8769 - acc: 0.01 - ETA: 18s - loss: 4.8767 - acc: 0.01 - ETA: 17s - loss: 4.8768 - acc: 0.01 - ETA: 17s - loss: 4.8767 - acc: 0.01 - ETA: 17s - loss: 4.8767 - acc: 0.01 - ETA: 17s - loss: 4.8765 - acc: 0.01 - ETA: 17s - loss: 4.8764 - acc: 0.01 - ETA: 17s - loss: 4.8764 - acc: 0.01 - ETA: 17s - loss: 4.8763 - acc: 0.01 - ETA: 16s - loss: 4.8763 - acc: 0.01 - ETA: 16s - loss: 4.8762 - acc: 0.01 - ETA: 16s - loss: 4.8763 - acc: 0.01 - ETA: 16s - loss: 4.8763 - acc: 0.01 - ETA: 16s - loss: 4.8764 - acc: 0.01 - ETA: 16s - loss: 4.8764 - acc: 0.01 - ETA: 15s - loss: 4.8763 - acc: 0.01 - ETA: 15s - loss: 4.8762 - acc: 0.01 - ETA: 15s - loss: 4.8762 - acc: 0.01 - ETA: 15s - loss: 4.8762 - acc: 0.01 - ETA: 15s - loss: 4.8763 - acc: 0.01 - ETA: 15s - loss: 4.8764 - acc: 0.01 - ETA: 14s - loss: 4.8765 - acc: 0.01 - ETA: 14s - loss: 4.8764 - acc: 0.01 - ETA: 14s - loss: 4.8764 - acc: 0.01 - ETA: 14s - loss: 4.8764 - acc: 0.01 - ETA: 14s - loss: 4.8762 - acc: 0.01 - ETA: 14s - loss: 4.8762 - acc: 0.01 - ETA: 13s - loss: 4.8762 - acc: 0.01 - ETA: 13s - loss: 4.8761 - acc: 0.01 - ETA: 13s - loss: 4.8761 - acc: 0.01 - ETA: 13s - loss: 4.8760 - acc: 0.01 - ETA: 13s - loss: 4.8761 - acc: 0.01 - ETA: 13s - loss: 4.8760 - acc: 0.01 - ETA: 13s - loss: 4.8761 - acc: 0.01 - ETA: 12s - loss: 4.8762 - acc: 0.01 - ETA: 12s - loss: 4.8761 - acc: 0.01 - ETA: 12s - loss: 4.8761 - acc: 0.01 - ETA: 12s - loss: 4.8760 - acc: 0.01 - ETA: 12s - loss: 4.8759 - acc: 0.01 - ETA: 12s - loss: 4.8758 - acc: 0.01 - ETA: 11s - loss: 4.8756 - acc: 0.01 - ETA: 11s - loss: 4.8756 - acc: 0.01 - ETA: 11s - loss: 4.8756 - acc: 0.01 - ETA: 11s - loss: 4.8758 - acc: 0.01 - ETA: 11s - loss: 4.8758 - acc: 0.01 - ETA: 11s - loss: 4.8758 - acc: 0.01 - ETA: 11s - loss: 4.8757 - acc: 0.01 - ETA: 10s - loss: 4.8756 - acc: 0.01 - ETA: 10s - loss: 4.8754 - acc: 0.01 - ETA: 10s - loss: 4.8757 - acc: 0.01 - ETA: 10s - loss: 4.8757 - acc: 0.01 - ETA: 10s - loss: 4.8757 - acc: 0.01 - ETA: 10s - loss: 4.8756 - acc: 0.01 - ETA: 9s - loss: 4.8756 - acc: 0.0138 - ETA: 9s - loss: 4.8756 - acc: 0.013 - ETA: 9s - loss: 4.8754 - acc: 0.013 - ETA: 9s - loss: 4.8752 - acc: 0.013 - ETA: 9s - loss: 4.8751 - acc: 0.013 - ETA: 9s - loss: 4.8750 - acc: 0.013 - ETA: 9s - loss: 4.8750 - acc: 0.013 - ETA: 8s - loss: 4.8749 - acc: 0.013 - ETA: 8s - loss: 4.8749 - acc: 0.013 - ETA: 8s - loss: 4.8749 - acc: 0.013 - ETA: 8s - loss: 4.8751 - acc: 0.013 - ETA: 8s - loss: 4.8749 - acc: 0.013 - ETA: 8s - loss: 4.8749 - acc: 0.013 - ETA: 7s - loss: 4.8751 - acc: 0.013 - ETA: 7s - loss: 4.8752 - acc: 0.013 - ETA: 7s - loss: 4.8753 - acc: 0.013 - ETA: 7s - loss: 4.8753 - acc: 0.013 - ETA: 7s - loss: 4.8752 - acc: 0.013 - ETA: 7s - loss: 4.8754 - acc: 0.013 - ETA: 7s - loss: 4.8755 - acc: 0.013 - ETA: 6s - loss: 4.8756 - acc: 0.013 - ETA: 6s - loss: 4.8758 - acc: 0.013 - ETA: 6s - loss: 4.8758 - acc: 0.013 - ETA: 6s - loss: 4.8759 - acc: 0.013 - ETA: 6s - loss: 4.8760 - acc: 0.013 - ETA: 6s - loss: 4.8759 - acc: 0.013 - ETA: 5s - loss: 4.8758 - acc: 0.013 - ETA: 5s - loss: 4.8759 - acc: 0.013 - ETA: 5s - loss: 4.8760 - acc: 0.013 - ETA: 5s - loss: 4.8761 - acc: 0.013 - ETA: 5s - loss: 4.8760 - acc: 0.013 - ETA: 4s - loss: 4.8760 - acc: 0.013 - ETA: 4s - loss: 4.8760 - acc: 0.013 - ETA: 4s - loss: 4.8760 - acc: 0.013 - ETA: 4s - loss: 4.8761 - acc: 0.013 - ETA: 4s - loss: 4.8761 - acc: 0.013 - ETA: 4s - loss: 4.8761 - acc: 0.013 - ETA: 4s - loss: 4.8760 - acc: 0.013 - ETA: 3s - loss: 4.8759 - acc: 0.013 - ETA: 3s - loss: 4.8760 - acc: 0.013 - ETA: 3s - loss: 4.8760 - acc: 0.013 - ETA: 3s - loss: 4.8760 - acc: 0.013 - ETA: 3s - loss: 4.8761 - acc: 0.013 - ETA: 3s - loss: 4.8761 - acc: 0.013 - ETA: 2s - loss: 4.8761 - acc: 0.013 - ETA: 2s - loss: 4.8761 - acc: 0.013 - ETA: 2s - loss: 4.8762 - acc: 0.013 - ETA: 2s - loss: 4.8762 - acc: 0.013 - ETA: 2s - loss: 4.8763 - acc: 0.013 - ETA: 2s - loss: 4.8764 - acc: 0.013 - ETA: 2s - loss: 4.8764 - acc: 0.013 - ETA: 1s - loss: 4.8765 - acc: 0.013 - ETA: 1s - loss: 4.8765 - acc: 0.013 - ETA: 1s - loss: 4.8765 - acc: 0.013 - ETA: 1s - loss: 4.8764 - acc: 0.013 - ETA: 1s - loss: 4.8764 - acc: 0.013 - ETA: 1s - loss: 4.8766 - acc: 0.013 - ETA: 0s - loss: 4.8766 - acc: 0.013 - ETA: 0s - loss: 4.8766 - acc: 0.013 - ETA: 0s - loss: 4.8766 - acc: 0.013 - ETA: 0s - loss: 4.8765 - acc: 0.013 - ETA: 0s - loss: 4.8765 - acc: 0.013 - ETA: 0s - loss: 4.8764 - acc: 0.013 - 69s 164ms/step - loss: 4.8765 - acc: 0.0132 - val_loss: 4.8712 - val_acc: 0.0171\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.87569 to 4.87120, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/417 [===============>..............] - ETA: 6s - loss: 4.8845 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8763 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8743 - acc: 0.0089    - ETA: 6s - loss: 4.8736 - acc: 0.011 - ETA: 15s - loss: 4.8736 - acc: 0.00 - ETA: 18s - loss: 4.8680 - acc: 0.01 - ETA: 19s - loss: 4.8704 - acc: 0.01 - ETA: 21s - loss: 4.8683 - acc: 0.01 - ETA: 22s - loss: 4.8716 - acc: 0.01 - ETA: 24s - loss: 4.8711 - acc: 0.01 - ETA: 25s - loss: 4.8732 - acc: 0.01 - ETA: 27s - loss: 4.8731 - acc: 0.01 - ETA: 29s - loss: 4.8703 - acc: 0.01 - ETA: 30s - loss: 4.8705 - acc: 0.01 - ETA: 31s - loss: 4.8684 - acc: 0.01 - ETA: 32s - loss: 4.8692 - acc: 0.01 - ETA: 33s - loss: 4.8680 - acc: 0.01 - ETA: 34s - loss: 4.8664 - acc: 0.01 - ETA: 36s - loss: 4.8656 - acc: 0.01 - ETA: 36s - loss: 4.8675 - acc: 0.01 - ETA: 37s - loss: 4.8676 - acc: 0.01 - ETA: 38s - loss: 4.8676 - acc: 0.01 - ETA: 38s - loss: 4.8666 - acc: 0.01 - ETA: 39s - loss: 4.8667 - acc: 0.01 - ETA: 39s - loss: 4.8673 - acc: 0.01 - ETA: 40s - loss: 4.8678 - acc: 0.01 - ETA: 40s - loss: 4.8675 - acc: 0.01 - ETA: 41s - loss: 4.8667 - acc: 0.01 - ETA: 41s - loss: 4.8654 - acc: 0.01 - ETA: 41s - loss: 4.8650 - acc: 0.01 - ETA: 41s - loss: 4.8652 - acc: 0.01 - ETA: 41s - loss: 4.8675 - acc: 0.01 - ETA: 41s - loss: 4.8676 - acc: 0.01 - ETA: 41s - loss: 4.8666 - acc: 0.01 - ETA: 41s - loss: 4.8659 - acc: 0.01 - ETA: 41s - loss: 4.8648 - acc: 0.01 - ETA: 41s - loss: 4.8645 - acc: 0.01 - ETA: 42s - loss: 4.8643 - acc: 0.01 - ETA: 42s - loss: 4.8639 - acc: 0.01 - ETA: 42s - loss: 4.8647 - acc: 0.01 - ETA: 42s - loss: 4.8655 - acc: 0.01 - ETA: 43s - loss: 4.8663 - acc: 0.01 - ETA: 43s - loss: 4.8667 - acc: 0.01 - ETA: 43s - loss: 4.8667 - acc: 0.01 - ETA: 43s - loss: 4.8673 - acc: 0.01 - ETA: 43s - loss: 4.8675 - acc: 0.01 - ETA: 43s - loss: 4.8671 - acc: 0.01 - ETA: 43s - loss: 4.8681 - acc: 0.01 - ETA: 43s - loss: 4.8673 - acc: 0.01 - ETA: 44s - loss: 4.8686 - acc: 0.01 - ETA: 44s - loss: 4.8691 - acc: 0.01 - ETA: 44s - loss: 4.8684 - acc: 0.01 - ETA: 44s - loss: 4.8683 - acc: 0.01 - ETA: 44s - loss: 4.8692 - acc: 0.01 - ETA: 44s - loss: 4.8691 - acc: 0.01 - ETA: 44s - loss: 4.8703 - acc: 0.01 - ETA: 44s - loss: 4.8707 - acc: 0.01 - ETA: 44s - loss: 4.8706 - acc: 0.01 - ETA: 44s - loss: 4.8708 - acc: 0.01 - ETA: 44s - loss: 4.8714 - acc: 0.01 - ETA: 44s - loss: 4.8716 - acc: 0.01 - ETA: 44s - loss: 4.8718 - acc: 0.01 - ETA: 44s - loss: 4.8712 - acc: 0.01 - ETA: 44s - loss: 4.8721 - acc: 0.01 - ETA: 44s - loss: 4.8720 - acc: 0.01 - ETA: 44s - loss: 4.8724 - acc: 0.01 - ETA: 44s - loss: 4.8727 - acc: 0.01 - ETA: 45s - loss: 4.8722 - acc: 0.01 - ETA: 45s - loss: 4.8719 - acc: 0.01 - ETA: 45s - loss: 4.8717 - acc: 0.01 - ETA: 45s - loss: 4.8711 - acc: 0.01 - ETA: 45s - loss: 4.8712 - acc: 0.01 - ETA: 45s - loss: 4.8710 - acc: 0.01 - ETA: 45s - loss: 4.8706 - acc: 0.01 - ETA: 45s - loss: 4.8704 - acc: 0.01 - ETA: 44s - loss: 4.8704 - acc: 0.01 - ETA: 45s - loss: 4.8714 - acc: 0.01 - ETA: 45s - loss: 4.8720 - acc: 0.01 - ETA: 44s - loss: 4.8721 - acc: 0.01 - ETA: 44s - loss: 4.8720 - acc: 0.01 - ETA: 44s - loss: 4.8715 - acc: 0.01 - ETA: 44s - loss: 4.8720 - acc: 0.01 - ETA: 44s - loss: 4.8725 - acc: 0.01 - ETA: 44s - loss: 4.8725 - acc: 0.01 - ETA: 44s - loss: 4.8725 - acc: 0.01 - ETA: 44s - loss: 4.8724 - acc: 0.01 - ETA: 44s - loss: 4.8726 - acc: 0.01 - ETA: 44s - loss: 4.8726 - acc: 0.01 - ETA: 44s - loss: 4.8730 - acc: 0.01 - ETA: 44s - loss: 4.8735 - acc: 0.01 - ETA: 44s - loss: 4.8737 - acc: 0.01 - ETA: 43s - loss: 4.8736 - acc: 0.01 - ETA: 43s - loss: 4.8729 - acc: 0.00 - ETA: 43s - loss: 4.8730 - acc: 0.00 - ETA: 43s - loss: 4.8738 - acc: 0.00 - ETA: 43s - loss: 4.8736 - acc: 0.00 - ETA: 43s - loss: 4.8732 - acc: 0.01 - ETA: 43s - loss: 4.8729 - acc: 0.01 - ETA: 42s - loss: 4.8729 - acc: 0.00 - ETA: 42s - loss: 4.8725 - acc: 0.00 - ETA: 42s - loss: 4.8732 - acc: 0.00 - ETA: 42s - loss: 4.8735 - acc: 0.00 - ETA: 42s - loss: 4.8736 - acc: 0.00 - ETA: 42s - loss: 4.8733 - acc: 0.01 - ETA: 42s - loss: 4.8740 - acc: 0.01 - ETA: 42s - loss: 4.8742 - acc: 0.01 - ETA: 42s - loss: 4.8741 - acc: 0.01 - ETA: 41s - loss: 4.8740 - acc: 0.01 - ETA: 41s - loss: 4.8742 - acc: 0.01 - ETA: 41s - loss: 4.8742 - acc: 0.01 - ETA: 41s - loss: 4.8740 - acc: 0.01 - ETA: 41s - loss: 4.8743 - acc: 0.01 - ETA: 41s - loss: 4.8744 - acc: 0.01 - ETA: 41s - loss: 4.8738 - acc: 0.01 - ETA: 41s - loss: 4.8739 - acc: 0.01 - ETA: 41s - loss: 4.8740 - acc: 0.01 - ETA: 41s - loss: 4.8737 - acc: 0.01 - ETA: 40s - loss: 4.8739 - acc: 0.01 - ETA: 40s - loss: 4.8742 - acc: 0.01 - ETA: 40s - loss: 4.8745 - acc: 0.01 - ETA: 40s - loss: 4.8745 - acc: 0.01 - ETA: 40s - loss: 4.8750 - acc: 0.01 - ETA: 41s - loss: 4.8746 - acc: 0.01 - ETA: 41s - loss: 4.8748 - acc: 0.00 - ETA: 40s - loss: 4.8748 - acc: 0.00 - ETA: 40s - loss: 4.8747 - acc: 0.00 - ETA: 40s - loss: 4.8750 - acc: 0.00 - ETA: 40s - loss: 4.8750 - acc: 0.00 - ETA: 40s - loss: 4.8751 - acc: 0.00 - ETA: 40s - loss: 4.8754 - acc: 0.00 - ETA: 40s - loss: 4.8751 - acc: 0.00 - ETA: 40s - loss: 4.8755 - acc: 0.00 - ETA: 40s - loss: 4.8754 - acc: 0.00 - ETA: 40s - loss: 4.8756 - acc: 0.00 - ETA: 39s - loss: 4.8756 - acc: 0.00 - ETA: 39s - loss: 4.8756 - acc: 0.00 - ETA: 39s - loss: 4.8755 - acc: 0.00 - ETA: 39s - loss: 4.8753 - acc: 0.00 - ETA: 39s - loss: 4.8749 - acc: 0.00 - ETA: 39s - loss: 4.8745 - acc: 0.00 - ETA: 38s - loss: 4.8745 - acc: 0.00 - ETA: 39s - loss: 4.8747 - acc: 0.00 - ETA: 38s - loss: 4.8743 - acc: 0.00 - ETA: 38s - loss: 4.8743 - acc: 0.00 - ETA: 38s - loss: 4.8746 - acc: 0.00 - ETA: 38s - loss: 4.8744 - acc: 0.00 - ETA: 38s - loss: 4.8746 - acc: 0.00 - ETA: 38s - loss: 4.8745 - acc: 0.00 - ETA: 37s - loss: 4.8745 - acc: 0.00 - ETA: 37s - loss: 4.8747 - acc: 0.00 - ETA: 37s - loss: 4.8748 - acc: 0.00 - ETA: 37s - loss: 4.8746 - acc: 0.00 - ETA: 37s - loss: 4.8743 - acc: 0.00 - ETA: 37s - loss: 4.8742 - acc: 0.00 - ETA: 37s - loss: 4.8744 - acc: 0.00 - ETA: 37s - loss: 4.8746 - acc: 0.00 - ETA: 36s - loss: 4.8750 - acc: 0.00 - ETA: 36s - loss: 4.8750 - acc: 0.00 - ETA: 36s - loss: 4.8754 - acc: 0.00 - ETA: 36s - loss: 4.8753 - acc: 0.00 - ETA: 36s - loss: 4.8755 - acc: 0.00 - ETA: 36s - loss: 4.8757 - acc: 0.00 - ETA: 36s - loss: 4.8761 - acc: 0.00 - ETA: 36s - loss: 4.8758 - acc: 0.00 - ETA: 36s - loss: 4.8761 - acc: 0.00 - ETA: 35s - loss: 4.8762 - acc: 0.00 - ETA: 35s - loss: 4.8764 - acc: 0.00 - ETA: 35s - loss: 4.8763 - acc: 0.00 - ETA: 35s - loss: 4.8764 - acc: 0.00 - ETA: 35s - loss: 4.8764 - acc: 0.00 - ETA: 34s - loss: 4.8761 - acc: 0.00 - ETA: 34s - loss: 4.8761 - acc: 0.00 - ETA: 34s - loss: 4.8762 - acc: 0.00 - ETA: 34s - loss: 4.8761 - acc: 0.00 - ETA: 34s - loss: 4.8762 - acc: 0.00 - ETA: 34s - loss: 4.8760 - acc: 0.00 - ETA: 34s - loss: 4.8759 - acc: 0.00 - ETA: 34s - loss: 4.8758 - acc: 0.00 - ETA: 34s - loss: 4.8756 - acc: 0.01 - ETA: 33s - loss: 4.8757 - acc: 0.01 - ETA: 33s - loss: 4.8757 - acc: 0.01 - ETA: 33s - loss: 4.8758 - acc: 0.01 - ETA: 33s - loss: 4.8757 - acc: 0.01 - ETA: 33s - loss: 4.8757 - acc: 0.01 - ETA: 33s - loss: 4.8754 - acc: 0.01 - ETA: 33s - loss: 4.8754 - acc: 0.01 - ETA: 33s - loss: 4.8752 - acc: 0.01 - ETA: 32s - loss: 4.8751 - acc: 0.01 - ETA: 32s - loss: 4.8751 - acc: 0.01 - ETA: 32s - loss: 4.8750 - acc: 0.01 - ETA: 32s - loss: 4.8750 - acc: 0.01 - ETA: 32s - loss: 4.8750 - acc: 0.01 - ETA: 32s - loss: 4.8752 - acc: 0.01 - ETA: 32s - loss: 4.8750 - acc: 0.01 - ETA: 31s - loss: 4.8749 - acc: 0.01 - ETA: 31s - loss: 4.8749 - acc: 0.01 - ETA: 31s - loss: 4.8748 - acc: 0.01 - ETA: 31s - loss: 4.8747 - acc: 0.01 - ETA: 31s - loss: 4.8747 - acc: 0.01 - ETA: 31s - loss: 4.8744 - acc: 0.01 - ETA: 31s - loss: 4.8746 - acc: 0.01 - ETA: 31s - loss: 4.8746 - acc: 0.01 - ETA: 30s - loss: 4.8748 - acc: 0.01 - ETA: 30s - loss: 4.8748 - acc: 0.01 - ETA: 30s - loss: 4.8747 - acc: 0.01 - ETA: 30s - loss: 4.8747 - acc: 0.01 - ETA: 30s - loss: 4.8747 - acc: 0.01 - ETA: 30s - loss: 4.8748 - acc: 0.01 - ETA: 29s - loss: 4.8749 - acc: 0.01 - ETA: 29s - loss: 4.8747 - acc: 0.01 - ETA: 29s - loss: 4.8746 - acc: 0.01 - ETA: 29s - loss: 4.8749 - acc: 0.01 - ETA: 29s - loss: 4.8749 - acc: 0.01 - ETA: 29s - loss: 4.8750 - acc: 0.01 - ETA: 28s - loss: 4.8749 - acc: 0.0108"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8750 - acc: 0.01 - ETA: 28s - loss: 4.8751 - acc: 0.01 - ETA: 28s - loss: 4.8751 - acc: 0.01 - ETA: 28s - loss: 4.8749 - acc: 0.01 - ETA: 28s - loss: 4.8750 - acc: 0.01 - ETA: 28s - loss: 4.8749 - acc: 0.01 - ETA: 27s - loss: 4.8750 - acc: 0.01 - ETA: 27s - loss: 4.8749 - acc: 0.01 - ETA: 27s - loss: 4.8748 - acc: 0.01 - ETA: 27s - loss: 4.8747 - acc: 0.01 - ETA: 27s - loss: 4.8746 - acc: 0.01 - ETA: 27s - loss: 4.8746 - acc: 0.01 - ETA: 26s - loss: 4.8745 - acc: 0.01 - ETA: 26s - loss: 4.8745 - acc: 0.01 - ETA: 26s - loss: 4.8747 - acc: 0.01 - ETA: 26s - loss: 4.8746 - acc: 0.01 - ETA: 26s - loss: 4.8747 - acc: 0.01 - ETA: 26s - loss: 4.8749 - acc: 0.01 - ETA: 26s - loss: 4.8748 - acc: 0.01 - ETA: 25s - loss: 4.8749 - acc: 0.01 - ETA: 25s - loss: 4.8751 - acc: 0.01 - ETA: 25s - loss: 4.8750 - acc: 0.01 - ETA: 25s - loss: 4.8750 - acc: 0.01 - ETA: 25s - loss: 4.8750 - acc: 0.01 - ETA: 25s - loss: 4.8749 - acc: 0.01 - ETA: 25s - loss: 4.8748 - acc: 0.01 - ETA: 24s - loss: 4.8746 - acc: 0.01 - ETA: 24s - loss: 4.8745 - acc: 0.01 - ETA: 24s - loss: 4.8744 - acc: 0.01 - ETA: 24s - loss: 4.8742 - acc: 0.01 - ETA: 24s - loss: 4.8744 - acc: 0.01 - ETA: 24s - loss: 4.8746 - acc: 0.01 - ETA: 23s - loss: 4.8745 - acc: 0.01 - ETA: 23s - loss: 4.8746 - acc: 0.01 - ETA: 23s - loss: 4.8745 - acc: 0.01 - ETA: 23s - loss: 4.8746 - acc: 0.01 - ETA: 23s - loss: 4.8746 - acc: 0.01 - ETA: 23s - loss: 4.8747 - acc: 0.01 - ETA: 23s - loss: 4.8749 - acc: 0.01 - ETA: 22s - loss: 4.8747 - acc: 0.01 - ETA: 22s - loss: 4.8747 - acc: 0.01 - ETA: 22s - loss: 4.8747 - acc: 0.01 - ETA: 22s - loss: 4.8747 - acc: 0.01 - ETA: 22s - loss: 4.8747 - acc: 0.01 - ETA: 22s - loss: 4.8747 - acc: 0.01 - ETA: 21s - loss: 4.8749 - acc: 0.01 - ETA: 21s - loss: 4.8750 - acc: 0.01 - ETA: 21s - loss: 4.8752 - acc: 0.01 - ETA: 21s - loss: 4.8753 - acc: 0.01 - ETA: 21s - loss: 4.8752 - acc: 0.01 - ETA: 21s - loss: 4.8753 - acc: 0.01 - ETA: 21s - loss: 4.8754 - acc: 0.01 - ETA: 21s - loss: 4.8754 - acc: 0.01 - ETA: 20s - loss: 4.8755 - acc: 0.01 - ETA: 20s - loss: 4.8755 - acc: 0.01 - ETA: 20s - loss: 4.8753 - acc: 0.01 - ETA: 20s - loss: 4.8753 - acc: 0.01 - ETA: 20s - loss: 4.8753 - acc: 0.01 - ETA: 20s - loss: 4.8755 - acc: 0.01 - ETA: 20s - loss: 4.8756 - acc: 0.01 - ETA: 19s - loss: 4.8757 - acc: 0.01 - ETA: 19s - loss: 4.8758 - acc: 0.01 - ETA: 19s - loss: 4.8757 - acc: 0.01 - ETA: 19s - loss: 4.8757 - acc: 0.01 - ETA: 19s - loss: 4.8759 - acc: 0.01 - ETA: 19s - loss: 4.8758 - acc: 0.01 - ETA: 19s - loss: 4.8759 - acc: 0.01 - ETA: 18s - loss: 4.8759 - acc: 0.01 - ETA: 18s - loss: 4.8759 - acc: 0.01 - ETA: 18s - loss: 4.8759 - acc: 0.01 - ETA: 18s - loss: 4.8758 - acc: 0.01 - ETA: 18s - loss: 4.8760 - acc: 0.01 - ETA: 18s - loss: 4.8761 - acc: 0.01 - ETA: 17s - loss: 4.8761 - acc: 0.01 - ETA: 17s - loss: 4.8760 - acc: 0.01 - ETA: 17s - loss: 4.8758 - acc: 0.01 - ETA: 17s - loss: 4.8758 - acc: 0.01 - ETA: 17s - loss: 4.8756 - acc: 0.01 - ETA: 17s - loss: 4.8755 - acc: 0.01 - ETA: 17s - loss: 4.8755 - acc: 0.01 - ETA: 16s - loss: 4.8756 - acc: 0.01 - ETA: 16s - loss: 4.8754 - acc: 0.01 - ETA: 16s - loss: 4.8754 - acc: 0.01 - ETA: 16s - loss: 4.8754 - acc: 0.01 - ETA: 16s - loss: 4.8754 - acc: 0.01 - ETA: 16s - loss: 4.8754 - acc: 0.01 - ETA: 16s - loss: 4.8756 - acc: 0.01 - ETA: 15s - loss: 4.8757 - acc: 0.01 - ETA: 15s - loss: 4.8757 - acc: 0.01 - ETA: 15s - loss: 4.8754 - acc: 0.01 - ETA: 15s - loss: 4.8754 - acc: 0.01 - ETA: 15s - loss: 4.8754 - acc: 0.01 - ETA: 15s - loss: 4.8754 - acc: 0.01 - ETA: 14s - loss: 4.8754 - acc: 0.01 - ETA: 14s - loss: 4.8757 - acc: 0.01 - ETA: 14s - loss: 4.8757 - acc: 0.01 - ETA: 14s - loss: 4.8756 - acc: 0.01 - ETA: 14s - loss: 4.8757 - acc: 0.01 - ETA: 14s - loss: 4.8757 - acc: 0.01 - ETA: 14s - loss: 4.8757 - acc: 0.01 - ETA: 13s - loss: 4.8756 - acc: 0.01 - ETA: 13s - loss: 4.8756 - acc: 0.01 - ETA: 13s - loss: 4.8756 - acc: 0.01 - ETA: 13s - loss: 4.8757 - acc: 0.01 - ETA: 13s - loss: 4.8757 - acc: 0.01 - ETA: 13s - loss: 4.8758 - acc: 0.01 - ETA: 12s - loss: 4.8760 - acc: 0.01 - ETA: 12s - loss: 4.8761 - acc: 0.01 - ETA: 12s - loss: 4.8760 - acc: 0.01 - ETA: 12s - loss: 4.8760 - acc: 0.01 - ETA: 12s - loss: 4.8760 - acc: 0.01 - ETA: 12s - loss: 4.8760 - acc: 0.01 - ETA: 12s - loss: 4.8759 - acc: 0.01 - ETA: 11s - loss: 4.8760 - acc: 0.01 - ETA: 11s - loss: 4.8761 - acc: 0.01 - ETA: 11s - loss: 4.8760 - acc: 0.01 - ETA: 11s - loss: 4.8760 - acc: 0.01 - ETA: 11s - loss: 4.8760 - acc: 0.01 - ETA: 11s - loss: 4.8759 - acc: 0.01 - ETA: 10s - loss: 4.8759 - acc: 0.01 - ETA: 10s - loss: 4.8758 - acc: 0.01 - ETA: 10s - loss: 4.8758 - acc: 0.01 - ETA: 10s - loss: 4.8759 - acc: 0.01 - ETA: 10s - loss: 4.8759 - acc: 0.01 - ETA: 10s - loss: 4.8757 - acc: 0.01 - ETA: 10s - loss: 4.8756 - acc: 0.01 - ETA: 9s - loss: 4.8757 - acc: 0.0115 - ETA: 9s - loss: 4.8756 - acc: 0.011 - ETA: 9s - loss: 4.8757 - acc: 0.011 - ETA: 9s - loss: 4.8756 - acc: 0.011 - ETA: 9s - loss: 4.8756 - acc: 0.011 - ETA: 9s - loss: 4.8755 - acc: 0.011 - ETA: 8s - loss: 4.8755 - acc: 0.011 - ETA: 8s - loss: 4.8757 - acc: 0.011 - ETA: 8s - loss: 4.8756 - acc: 0.011 - ETA: 8s - loss: 4.8755 - acc: 0.011 - ETA: 8s - loss: 4.8757 - acc: 0.011 - ETA: 8s - loss: 4.8755 - acc: 0.011 - ETA: 8s - loss: 4.8754 - acc: 0.012 - ETA: 7s - loss: 4.8755 - acc: 0.012 - ETA: 7s - loss: 4.8756 - acc: 0.012 - ETA: 7s - loss: 4.8756 - acc: 0.012 - ETA: 7s - loss: 4.8756 - acc: 0.012 - ETA: 7s - loss: 4.8755 - acc: 0.012 - ETA: 7s - loss: 4.8754 - acc: 0.012 - ETA: 7s - loss: 4.8755 - acc: 0.012 - ETA: 6s - loss: 4.8753 - acc: 0.012 - ETA: 6s - loss: 4.8754 - acc: 0.012 - ETA: 6s - loss: 4.8755 - acc: 0.012 - ETA: 6s - loss: 4.8753 - acc: 0.012 - ETA: 6s - loss: 4.8754 - acc: 0.012 - ETA: 6s - loss: 4.8754 - acc: 0.012 - ETA: 5s - loss: 4.8752 - acc: 0.012 - ETA: 5s - loss: 4.8752 - acc: 0.012 - ETA: 5s - loss: 4.8752 - acc: 0.012 - ETA: 5s - loss: 4.8751 - acc: 0.012 - ETA: 5s - loss: 4.8750 - acc: 0.012 - ETA: 5s - loss: 4.8751 - acc: 0.012 - ETA: 5s - loss: 4.8750 - acc: 0.012 - ETA: 4s - loss: 4.8751 - acc: 0.012 - ETA: 4s - loss: 4.8751 - acc: 0.012 - ETA: 4s - loss: 4.8750 - acc: 0.012 - ETA: 4s - loss: 4.8749 - acc: 0.012 - ETA: 4s - loss: 4.8749 - acc: 0.012 - ETA: 4s - loss: 4.8747 - acc: 0.012 - ETA: 4s - loss: 4.8749 - acc: 0.012 - ETA: 3s - loss: 4.8749 - acc: 0.012 - ETA: 3s - loss: 4.8751 - acc: 0.012 - ETA: 3s - loss: 4.8751 - acc: 0.012 - ETA: 3s - loss: 4.8751 - acc: 0.012 - ETA: 3s - loss: 4.8751 - acc: 0.012 - ETA: 3s - loss: 4.8751 - acc: 0.012 - ETA: 2s - loss: 4.8750 - acc: 0.012 - ETA: 2s - loss: 4.8751 - acc: 0.012 - ETA: 2s - loss: 4.8751 - acc: 0.012 - ETA: 2s - loss: 4.8750 - acc: 0.012 - ETA: 2s - loss: 4.8750 - acc: 0.012 - ETA: 2s - loss: 4.8749 - acc: 0.012 - ETA: 2s - loss: 4.8750 - acc: 0.012 - ETA: 1s - loss: 4.8750 - acc: 0.012 - ETA: 1s - loss: 4.8749 - acc: 0.012 - ETA: 1s - loss: 4.8750 - acc: 0.011 - ETA: 1s - loss: 4.8751 - acc: 0.012 - ETA: 1s - loss: 4.8750 - acc: 0.012 - ETA: 0s - loss: 4.8750 - acc: 0.012 - ETA: 0s - loss: 4.8750 - acc: 0.012 - ETA: 0s - loss: 4.8751 - acc: 0.012 - ETA: 0s - loss: 4.8751 - acc: 0.011 - ETA: 0s - loss: 4.8753 - acc: 0.011 - ETA: 0s - loss: 4.8752 - acc: 0.011 - 68s 163ms/step - loss: 4.8751 - acc: 0.0118 - val_loss: 4.8715 - val_acc: 0.0183\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 4.87120\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/417 [===============>..............] - ETA: 5s - loss: 4.8731 - acc: 0.0000e+0 - ETA: 5s - loss: 4.8946 - acc: 0.0125    - ETA: 5s - loss: 4.8962 - acc: 0.006 - ETA: 8s - loss: 4.8876 - acc: 0.010 - ETA: 12s - loss: 4.8880 - acc: 0.00 - ETA: 19s - loss: 4.8917 - acc: 0.00 - ETA: 22s - loss: 4.8887 - acc: 0.00 - ETA: 22s - loss: 4.8924 - acc: 0.00 - ETA: 25s - loss: 4.8924 - acc: 0.00 - ETA: 26s - loss: 4.8898 - acc: 0.00 - ETA: 28s - loss: 4.8862 - acc: 0.00 - ETA: 30s - loss: 4.8849 - acc: 0.00 - ETA: 31s - loss: 4.8836 - acc: 0.01 - ETA: 32s - loss: 4.8828 - acc: 0.01 - ETA: 33s - loss: 4.8823 - acc: 0.01 - ETA: 34s - loss: 4.8810 - acc: 0.01 - ETA: 35s - loss: 4.8813 - acc: 0.01 - ETA: 36s - loss: 4.8822 - acc: 0.01 - ETA: 37s - loss: 4.8815 - acc: 0.01 - ETA: 37s - loss: 4.8810 - acc: 0.01 - ETA: 38s - loss: 4.8829 - acc: 0.01 - ETA: 39s - loss: 4.8842 - acc: 0.01 - ETA: 39s - loss: 4.8845 - acc: 0.01 - ETA: 39s - loss: 4.8824 - acc: 0.01 - ETA: 39s - loss: 4.8825 - acc: 0.01 - ETA: 40s - loss: 4.8816 - acc: 0.01 - ETA: 41s - loss: 4.8825 - acc: 0.01 - ETA: 41s - loss: 4.8818 - acc: 0.01 - ETA: 41s - loss: 4.8804 - acc: 0.01 - ETA: 43s - loss: 4.8804 - acc: 0.01 - ETA: 43s - loss: 4.8808 - acc: 0.01 - ETA: 43s - loss: 4.8817 - acc: 0.01 - ETA: 44s - loss: 4.8822 - acc: 0.01 - ETA: 44s - loss: 4.8816 - acc: 0.01 - ETA: 44s - loss: 4.8813 - acc: 0.01 - ETA: 44s - loss: 4.8814 - acc: 0.01 - ETA: 44s - loss: 4.8813 - acc: 0.01 - ETA: 44s - loss: 4.8829 - acc: 0.01 - ETA: 44s - loss: 4.8828 - acc: 0.01 - ETA: 45s - loss: 4.8832 - acc: 0.01 - ETA: 44s - loss: 4.8833 - acc: 0.01 - ETA: 44s - loss: 4.8830 - acc: 0.01 - ETA: 44s - loss: 4.8833 - acc: 0.01 - ETA: 45s - loss: 4.8825 - acc: 0.01 - ETA: 45s - loss: 4.8826 - acc: 0.01 - ETA: 45s - loss: 4.8828 - acc: 0.01 - ETA: 46s - loss: 4.8830 - acc: 0.01 - ETA: 46s - loss: 4.8830 - acc: 0.01 - ETA: 46s - loss: 4.8821 - acc: 0.01 - ETA: 46s - loss: 4.8822 - acc: 0.01 - ETA: 46s - loss: 4.8822 - acc: 0.01 - ETA: 46s - loss: 4.8815 - acc: 0.01 - ETA: 46s - loss: 4.8809 - acc: 0.01 - ETA: 46s - loss: 4.8814 - acc: 0.01 - ETA: 46s - loss: 4.8813 - acc: 0.01 - ETA: 46s - loss: 4.8812 - acc: 0.01 - ETA: 46s - loss: 4.8815 - acc: 0.01 - ETA: 46s - loss: 4.8813 - acc: 0.01 - ETA: 46s - loss: 4.8810 - acc: 0.01 - ETA: 46s - loss: 4.8799 - acc: 0.01 - ETA: 46s - loss: 4.8796 - acc: 0.01 - ETA: 46s - loss: 4.8789 - acc: 0.01 - ETA: 46s - loss: 4.8789 - acc: 0.01 - ETA: 46s - loss: 4.8790 - acc: 0.01 - ETA: 46s - loss: 4.8790 - acc: 0.01 - ETA: 46s - loss: 4.8793 - acc: 0.01 - ETA: 46s - loss: 4.8794 - acc: 0.01 - ETA: 46s - loss: 4.8796 - acc: 0.01 - ETA: 46s - loss: 4.8798 - acc: 0.01 - ETA: 46s - loss: 4.8793 - acc: 0.01 - ETA: 46s - loss: 4.8790 - acc: 0.01 - ETA: 46s - loss: 4.8787 - acc: 0.01 - ETA: 46s - loss: 4.8784 - acc: 0.01 - ETA: 46s - loss: 4.8785 - acc: 0.01 - ETA: 46s - loss: 4.8785 - acc: 0.01 - ETA: 46s - loss: 4.8780 - acc: 0.01 - ETA: 46s - loss: 4.8780 - acc: 0.01 - ETA: 45s - loss: 4.8779 - acc: 0.01 - ETA: 45s - loss: 4.8780 - acc: 0.01 - ETA: 45s - loss: 4.8779 - acc: 0.01 - ETA: 45s - loss: 4.8775 - acc: 0.01 - ETA: 45s - loss: 4.8775 - acc: 0.01 - ETA: 45s - loss: 4.8780 - acc: 0.01 - ETA: 45s - loss: 4.8778 - acc: 0.01 - ETA: 46s - loss: 4.8778 - acc: 0.01 - ETA: 46s - loss: 4.8775 - acc: 0.01 - ETA: 45s - loss: 4.8776 - acc: 0.01 - ETA: 45s - loss: 4.8773 - acc: 0.01 - ETA: 45s - loss: 4.8772 - acc: 0.01 - ETA: 45s - loss: 4.8771 - acc: 0.01 - ETA: 45s - loss: 4.8771 - acc: 0.01 - ETA: 45s - loss: 4.8775 - acc: 0.01 - ETA: 45s - loss: 4.8779 - acc: 0.01 - ETA: 44s - loss: 4.8777 - acc: 0.01 - ETA: 44s - loss: 4.8776 - acc: 0.01 - ETA: 44s - loss: 4.8774 - acc: 0.01 - ETA: 44s - loss: 4.8772 - acc: 0.01 - ETA: 44s - loss: 4.8769 - acc: 0.01 - ETA: 44s - loss: 4.8768 - acc: 0.01 - ETA: 44s - loss: 4.8767 - acc: 0.01 - ETA: 44s - loss: 4.8765 - acc: 0.01 - ETA: 44s - loss: 4.8763 - acc: 0.01 - ETA: 43s - loss: 4.8767 - acc: 0.01 - ETA: 44s - loss: 4.8767 - acc: 0.01 - ETA: 44s - loss: 4.8762 - acc: 0.01 - ETA: 43s - loss: 4.8761 - acc: 0.01 - ETA: 43s - loss: 4.8756 - acc: 0.01 - ETA: 43s - loss: 4.8755 - acc: 0.01 - ETA: 43s - loss: 4.8752 - acc: 0.01 - ETA: 43s - loss: 4.8754 - acc: 0.01 - ETA: 43s - loss: 4.8749 - acc: 0.01 - ETA: 43s - loss: 4.8746 - acc: 0.01 - ETA: 43s - loss: 4.8743 - acc: 0.01 - ETA: 43s - loss: 4.8739 - acc: 0.01 - ETA: 43s - loss: 4.8738 - acc: 0.01 - ETA: 43s - loss: 4.8735 - acc: 0.01 - ETA: 43s - loss: 4.8736 - acc: 0.01 - ETA: 43s - loss: 4.8732 - acc: 0.01 - ETA: 43s - loss: 4.8734 - acc: 0.01 - ETA: 43s - loss: 4.8733 - acc: 0.01 - ETA: 43s - loss: 4.8729 - acc: 0.01 - ETA: 42s - loss: 4.8728 - acc: 0.01 - ETA: 42s - loss: 4.8728 - acc: 0.01 - ETA: 42s - loss: 4.8726 - acc: 0.01 - ETA: 42s - loss: 4.8730 - acc: 0.01 - ETA: 42s - loss: 4.8722 - acc: 0.01 - ETA: 42s - loss: 4.8718 - acc: 0.01 - ETA: 41s - loss: 4.8717 - acc: 0.01 - ETA: 41s - loss: 4.8717 - acc: 0.01 - ETA: 41s - loss: 4.8719 - acc: 0.01 - ETA: 41s - loss: 4.8725 - acc: 0.01 - ETA: 41s - loss: 4.8723 - acc: 0.01 - ETA: 41s - loss: 4.8724 - acc: 0.01 - ETA: 41s - loss: 4.8723 - acc: 0.01 - ETA: 40s - loss: 4.8731 - acc: 0.01 - ETA: 40s - loss: 4.8737 - acc: 0.01 - ETA: 40s - loss: 4.8738 - acc: 0.01 - ETA: 40s - loss: 4.8741 - acc: 0.01 - ETA: 40s - loss: 4.8744 - acc: 0.01 - ETA: 40s - loss: 4.8746 - acc: 0.01 - ETA: 40s - loss: 4.8741 - acc: 0.01 - ETA: 39s - loss: 4.8738 - acc: 0.01 - ETA: 39s - loss: 4.8734 - acc: 0.01 - ETA: 39s - loss: 4.8735 - acc: 0.01 - ETA: 39s - loss: 4.8736 - acc: 0.01 - ETA: 39s - loss: 4.8734 - acc: 0.01 - ETA: 38s - loss: 4.8735 - acc: 0.01 - ETA: 38s - loss: 4.8735 - acc: 0.01 - ETA: 38s - loss: 4.8734 - acc: 0.01 - ETA: 38s - loss: 4.8736 - acc: 0.01 - ETA: 38s - loss: 4.8735 - acc: 0.01 - ETA: 38s - loss: 4.8735 - acc: 0.01 - ETA: 38s - loss: 4.8735 - acc: 0.01 - ETA: 37s - loss: 4.8735 - acc: 0.01 - ETA: 37s - loss: 4.8735 - acc: 0.01 - ETA: 37s - loss: 4.8736 - acc: 0.01 - ETA: 37s - loss: 4.8736 - acc: 0.01 - ETA: 37s - loss: 4.8733 - acc: 0.01 - ETA: 37s - loss: 4.8733 - acc: 0.01 - ETA: 36s - loss: 4.8737 - acc: 0.01 - ETA: 36s - loss: 4.8736 - acc: 0.01 - ETA: 36s - loss: 4.8739 - acc: 0.01 - ETA: 36s - loss: 4.8737 - acc: 0.01 - ETA: 36s - loss: 4.8737 - acc: 0.01 - ETA: 36s - loss: 4.8738 - acc: 0.01 - ETA: 36s - loss: 4.8736 - acc: 0.01 - ETA: 35s - loss: 4.8736 - acc: 0.01 - ETA: 35s - loss: 4.8739 - acc: 0.01 - ETA: 35s - loss: 4.8736 - acc: 0.01 - ETA: 35s - loss: 4.8734 - acc: 0.01 - ETA: 35s - loss: 4.8737 - acc: 0.01 - ETA: 35s - loss: 4.8735 - acc: 0.01 - ETA: 35s - loss: 4.8732 - acc: 0.01 - ETA: 34s - loss: 4.8730 - acc: 0.01 - ETA: 34s - loss: 4.8727 - acc: 0.01 - ETA: 34s - loss: 4.8727 - acc: 0.01 - ETA: 34s - loss: 4.8726 - acc: 0.01 - ETA: 34s - loss: 4.8724 - acc: 0.01 - ETA: 34s - loss: 4.8724 - acc: 0.01 - ETA: 34s - loss: 4.8723 - acc: 0.01 - ETA: 34s - loss: 4.8721 - acc: 0.01 - ETA: 33s - loss: 4.8725 - acc: 0.01 - ETA: 33s - loss: 4.8726 - acc: 0.01 - ETA: 33s - loss: 4.8725 - acc: 0.01 - ETA: 33s - loss: 4.8723 - acc: 0.01 - ETA: 33s - loss: 4.8723 - acc: 0.01 - ETA: 33s - loss: 4.8727 - acc: 0.01 - ETA: 33s - loss: 4.8725 - acc: 0.01 - ETA: 32s - loss: 4.8722 - acc: 0.01 - ETA: 32s - loss: 4.8723 - acc: 0.01 - ETA: 32s - loss: 4.8725 - acc: 0.01 - ETA: 32s - loss: 4.8727 - acc: 0.01 - ETA: 32s - loss: 4.8728 - acc: 0.01 - ETA: 32s - loss: 4.8727 - acc: 0.01 - ETA: 32s - loss: 4.8725 - acc: 0.01 - ETA: 31s - loss: 4.8725 - acc: 0.01 - ETA: 31s - loss: 4.8722 - acc: 0.01 - ETA: 31s - loss: 4.8720 - acc: 0.01 - ETA: 31s - loss: 4.8720 - acc: 0.01 - ETA: 31s - loss: 4.8721 - acc: 0.01 - ETA: 31s - loss: 4.8718 - acc: 0.01 - ETA: 30s - loss: 4.8718 - acc: 0.01 - ETA: 30s - loss: 4.8717 - acc: 0.01 - ETA: 30s - loss: 4.8720 - acc: 0.01 - ETA: 30s - loss: 4.8718 - acc: 0.01 - ETA: 30s - loss: 4.8720 - acc: 0.01 - ETA: 30s - loss: 4.8722 - acc: 0.01 - ETA: 29s - loss: 4.8723 - acc: 0.01 - ETA: 29s - loss: 4.8723 - acc: 0.01 - ETA: 29s - loss: 4.8721 - acc: 0.01 - ETA: 29s - loss: 4.8720 - acc: 0.01 - ETA: 29s - loss: 4.8717 - acc: 0.01 - ETA: 29s - loss: 4.8719 - acc: 0.01 - ETA: 29s - loss: 4.8722 - acc: 0.01 - ETA: 29s - loss: 4.8720 - acc: 0.0158"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8719 - acc: 0.01 - ETA: 28s - loss: 4.8720 - acc: 0.01 - ETA: 28s - loss: 4.8721 - acc: 0.01 - ETA: 28s - loss: 4.8720 - acc: 0.01 - ETA: 28s - loss: 4.8720 - acc: 0.01 - ETA: 28s - loss: 4.8723 - acc: 0.01 - ETA: 28s - loss: 4.8720 - acc: 0.01 - ETA: 27s - loss: 4.8719 - acc: 0.01 - ETA: 27s - loss: 4.8722 - acc: 0.01 - ETA: 27s - loss: 4.8725 - acc: 0.01 - ETA: 27s - loss: 4.8726 - acc: 0.01 - ETA: 27s - loss: 4.8725 - acc: 0.01 - ETA: 27s - loss: 4.8724 - acc: 0.01 - ETA: 27s - loss: 4.8727 - acc: 0.01 - ETA: 26s - loss: 4.8729 - acc: 0.01 - ETA: 26s - loss: 4.8729 - acc: 0.01 - ETA: 26s - loss: 4.8731 - acc: 0.01 - ETA: 26s - loss: 4.8731 - acc: 0.01 - ETA: 26s - loss: 4.8729 - acc: 0.01 - ETA: 26s - loss: 4.8727 - acc: 0.01 - ETA: 25s - loss: 4.8730 - acc: 0.01 - ETA: 25s - loss: 4.8730 - acc: 0.01 - ETA: 25s - loss: 4.8730 - acc: 0.01 - ETA: 25s - loss: 4.8729 - acc: 0.01 - ETA: 25s - loss: 4.8730 - acc: 0.01 - ETA: 25s - loss: 4.8730 - acc: 0.01 - ETA: 25s - loss: 4.8730 - acc: 0.01 - ETA: 25s - loss: 4.8731 - acc: 0.01 - ETA: 24s - loss: 4.8729 - acc: 0.01 - ETA: 24s - loss: 4.8729 - acc: 0.01 - ETA: 24s - loss: 4.8729 - acc: 0.01 - ETA: 24s - loss: 4.8731 - acc: 0.01 - ETA: 24s - loss: 4.8730 - acc: 0.01 - ETA: 23s - loss: 4.8731 - acc: 0.01 - ETA: 23s - loss: 4.8731 - acc: 0.01 - ETA: 23s - loss: 4.8730 - acc: 0.01 - ETA: 23s - loss: 4.8731 - acc: 0.01 - ETA: 23s - loss: 4.8735 - acc: 0.01 - ETA: 23s - loss: 4.8734 - acc: 0.01 - ETA: 22s - loss: 4.8732 - acc: 0.01 - ETA: 22s - loss: 4.8730 - acc: 0.01 - ETA: 22s - loss: 4.8731 - acc: 0.01 - ETA: 22s - loss: 4.8732 - acc: 0.01 - ETA: 22s - loss: 4.8733 - acc: 0.01 - ETA: 22s - loss: 4.8733 - acc: 0.01 - ETA: 21s - loss: 4.8734 - acc: 0.01 - ETA: 21s - loss: 4.8734 - acc: 0.01 - ETA: 21s - loss: 4.8734 - acc: 0.01 - ETA: 21s - loss: 4.8730 - acc: 0.01 - ETA: 21s - loss: 4.8728 - acc: 0.01 - ETA: 21s - loss: 4.8728 - acc: 0.01 - ETA: 21s - loss: 4.8728 - acc: 0.01 - ETA: 20s - loss: 4.8727 - acc: 0.01 - ETA: 20s - loss: 4.8728 - acc: 0.01 - ETA: 20s - loss: 4.8729 - acc: 0.01 - ETA: 20s - loss: 4.8728 - acc: 0.01 - ETA: 20s - loss: 4.8729 - acc: 0.01 - ETA: 20s - loss: 4.8731 - acc: 0.01 - ETA: 19s - loss: 4.8731 - acc: 0.01 - ETA: 19s - loss: 4.8732 - acc: 0.01 - ETA: 19s - loss: 4.8731 - acc: 0.01 - ETA: 19s - loss: 4.8731 - acc: 0.01 - ETA: 19s - loss: 4.8731 - acc: 0.01 - ETA: 19s - loss: 4.8731 - acc: 0.01 - ETA: 19s - loss: 4.8730 - acc: 0.01 - ETA: 18s - loss: 4.8730 - acc: 0.01 - ETA: 18s - loss: 4.8730 - acc: 0.01 - ETA: 18s - loss: 4.8732 - acc: 0.01 - ETA: 18s - loss: 4.8733 - acc: 0.01 - ETA: 18s - loss: 4.8731 - acc: 0.01 - ETA: 18s - loss: 4.8732 - acc: 0.01 - ETA: 17s - loss: 4.8733 - acc: 0.01 - ETA: 17s - loss: 4.8733 - acc: 0.01 - ETA: 17s - loss: 4.8734 - acc: 0.01 - ETA: 17s - loss: 4.8733 - acc: 0.01 - ETA: 17s - loss: 4.8733 - acc: 0.01 - ETA: 17s - loss: 4.8733 - acc: 0.01 - ETA: 17s - loss: 4.8733 - acc: 0.01 - ETA: 16s - loss: 4.8731 - acc: 0.01 - ETA: 16s - loss: 4.8730 - acc: 0.01 - ETA: 16s - loss: 4.8730 - acc: 0.01 - ETA: 16s - loss: 4.8732 - acc: 0.01 - ETA: 16s - loss: 4.8730 - acc: 0.01 - ETA: 16s - loss: 4.8730 - acc: 0.01 - ETA: 15s - loss: 4.8729 - acc: 0.01 - ETA: 15s - loss: 4.8727 - acc: 0.01 - ETA: 15s - loss: 4.8729 - acc: 0.01 - ETA: 15s - loss: 4.8728 - acc: 0.01 - ETA: 15s - loss: 4.8727 - acc: 0.01 - ETA: 15s - loss: 4.8727 - acc: 0.01 - ETA: 15s - loss: 4.8730 - acc: 0.01 - ETA: 14s - loss: 4.8730 - acc: 0.01 - ETA: 14s - loss: 4.8732 - acc: 0.01 - ETA: 14s - loss: 4.8731 - acc: 0.01 - ETA: 14s - loss: 4.8732 - acc: 0.01 - ETA: 14s - loss: 4.8730 - acc: 0.01 - ETA: 14s - loss: 4.8731 - acc: 0.01 - ETA: 13s - loss: 4.8729 - acc: 0.01 - ETA: 13s - loss: 4.8731 - acc: 0.01 - ETA: 13s - loss: 4.8732 - acc: 0.01 - ETA: 13s - loss: 4.8731 - acc: 0.01 - ETA: 13s - loss: 4.8731 - acc: 0.01 - ETA: 13s - loss: 4.8730 - acc: 0.01 - ETA: 13s - loss: 4.8729 - acc: 0.01 - ETA: 12s - loss: 4.8727 - acc: 0.01 - ETA: 12s - loss: 4.8727 - acc: 0.01 - ETA: 12s - loss: 4.8726 - acc: 0.01 - ETA: 12s - loss: 4.8725 - acc: 0.01 - ETA: 12s - loss: 4.8725 - acc: 0.01 - ETA: 12s - loss: 4.8726 - acc: 0.01 - ETA: 12s - loss: 4.8725 - acc: 0.01 - ETA: 11s - loss: 4.8725 - acc: 0.01 - ETA: 11s - loss: 4.8725 - acc: 0.01 - ETA: 11s - loss: 4.8724 - acc: 0.01 - ETA: 11s - loss: 4.8725 - acc: 0.01 - ETA: 11s - loss: 4.8725 - acc: 0.01 - ETA: 11s - loss: 4.8725 - acc: 0.01 - ETA: 10s - loss: 4.8726 - acc: 0.01 - ETA: 10s - loss: 4.8724 - acc: 0.01 - ETA: 10s - loss: 4.8725 - acc: 0.01 - ETA: 10s - loss: 4.8724 - acc: 0.01 - ETA: 10s - loss: 4.8725 - acc: 0.01 - ETA: 10s - loss: 4.8725 - acc: 0.01 - ETA: 10s - loss: 4.8726 - acc: 0.01 - ETA: 9s - loss: 4.8725 - acc: 0.0133 - ETA: 9s - loss: 4.8727 - acc: 0.013 - ETA: 9s - loss: 4.8728 - acc: 0.013 - ETA: 9s - loss: 4.8728 - acc: 0.013 - ETA: 9s - loss: 4.8727 - acc: 0.013 - ETA: 9s - loss: 4.8727 - acc: 0.013 - ETA: 9s - loss: 4.8727 - acc: 0.013 - ETA: 8s - loss: 4.8727 - acc: 0.013 - ETA: 8s - loss: 4.8729 - acc: 0.013 - ETA: 8s - loss: 4.8727 - acc: 0.013 - ETA: 8s - loss: 4.8726 - acc: 0.013 - ETA: 8s - loss: 4.8724 - acc: 0.013 - ETA: 8s - loss: 4.8724 - acc: 0.013 - ETA: 7s - loss: 4.8725 - acc: 0.013 - ETA: 7s - loss: 4.8725 - acc: 0.013 - ETA: 7s - loss: 4.8724 - acc: 0.013 - ETA: 7s - loss: 4.8724 - acc: 0.013 - ETA: 7s - loss: 4.8724 - acc: 0.013 - ETA: 7s - loss: 4.8723 - acc: 0.013 - ETA: 7s - loss: 4.8723 - acc: 0.013 - ETA: 6s - loss: 4.8725 - acc: 0.013 - ETA: 6s - loss: 4.8726 - acc: 0.013 - ETA: 6s - loss: 4.8725 - acc: 0.013 - ETA: 6s - loss: 4.8726 - acc: 0.013 - ETA: 6s - loss: 4.8726 - acc: 0.013 - ETA: 6s - loss: 4.8726 - acc: 0.013 - ETA: 6s - loss: 4.8726 - acc: 0.013 - ETA: 5s - loss: 4.8726 - acc: 0.013 - ETA: 5s - loss: 4.8725 - acc: 0.013 - ETA: 5s - loss: 4.8725 - acc: 0.013 - ETA: 5s - loss: 4.8725 - acc: 0.013 - ETA: 5s - loss: 4.8725 - acc: 0.013 - ETA: 5s - loss: 4.8725 - acc: 0.013 - ETA: 4s - loss: 4.8723 - acc: 0.013 - ETA: 4s - loss: 4.8723 - acc: 0.013 - ETA: 4s - loss: 4.8723 - acc: 0.013 - ETA: 4s - loss: 4.8722 - acc: 0.013 - ETA: 4s - loss: 4.8722 - acc: 0.013 - ETA: 4s - loss: 4.8723 - acc: 0.013 - ETA: 4s - loss: 4.8722 - acc: 0.013 - ETA: 3s - loss: 4.8722 - acc: 0.013 - ETA: 3s - loss: 4.8721 - acc: 0.013 - ETA: 3s - loss: 4.8719 - acc: 0.013 - ETA: 3s - loss: 4.8721 - acc: 0.013 - ETA: 3s - loss: 4.8721 - acc: 0.013 - ETA: 3s - loss: 4.8721 - acc: 0.014 - ETA: 2s - loss: 4.8720 - acc: 0.014 - ETA: 2s - loss: 4.8722 - acc: 0.013 - ETA: 2s - loss: 4.8721 - acc: 0.013 - ETA: 2s - loss: 4.8720 - acc: 0.013 - ETA: 2s - loss: 4.8720 - acc: 0.014 - ETA: 2s - loss: 4.8719 - acc: 0.014 - ETA: 2s - loss: 4.8721 - acc: 0.013 - ETA: 1s - loss: 4.8722 - acc: 0.013 - ETA: 1s - loss: 4.8724 - acc: 0.013 - ETA: 1s - loss: 4.8724 - acc: 0.013 - ETA: 1s - loss: 4.8724 - acc: 0.013 - ETA: 1s - loss: 4.8724 - acc: 0.013 - ETA: 1s - loss: 4.8724 - acc: 0.013 - ETA: 0s - loss: 4.8723 - acc: 0.013 - ETA: 0s - loss: 4.8726 - acc: 0.013 - ETA: 0s - loss: 4.8727 - acc: 0.013 - ETA: 0s - loss: 4.8727 - acc: 0.013 - ETA: 0s - loss: 4.8729 - acc: 0.013 - ETA: 0s - loss: 4.8729 - acc: 0.013 - 69s 165ms/step - loss: 4.8729 - acc: 0.0138 - val_loss: 4.8697 - val_acc: 0.0195\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.87120 to 4.86967, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 7s - loss: 4.8755 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8745 - acc: 0.0125    - ETA: 6s - loss: 4.8707 - acc: 0.007 - ETA: 6s - loss: 4.8636 - acc: 0.005 - ETA: 10s - loss: 4.8618 - acc: 0.00 - ETA: 15s - loss: 4.8642 - acc: 0.00 - ETA: 19s - loss: 4.8622 - acc: 0.01 - ETA: 23s - loss: 4.8665 - acc: 0.01 - ETA: 23s - loss: 4.8687 - acc: 0.01 - ETA: 25s - loss: 4.8704 - acc: 0.01 - ETA: 28s - loss: 4.8686 - acc: 0.01 - ETA: 31s - loss: 4.8679 - acc: 0.01 - ETA: 33s - loss: 4.8672 - acc: 0.01 - ETA: 34s - loss: 4.8667 - acc: 0.01 - ETA: 34s - loss: 4.8663 - acc: 0.01 - ETA: 35s - loss: 4.8659 - acc: 0.01 - ETA: 37s - loss: 4.8660 - acc: 0.01 - ETA: 40s - loss: 4.8651 - acc: 0.01 - ETA: 40s - loss: 4.8643 - acc: 0.01 - ETA: 40s - loss: 4.8633 - acc: 0.01 - ETA: 40s - loss: 4.8635 - acc: 0.01 - ETA: 40s - loss: 4.8643 - acc: 0.01 - ETA: 43s - loss: 4.8629 - acc: 0.01 - ETA: 44s - loss: 4.8622 - acc: 0.01 - ETA: 44s - loss: 4.8636 - acc: 0.01 - ETA: 45s - loss: 4.8652 - acc: 0.01 - ETA: 45s - loss: 4.8664 - acc: 0.01 - ETA: 45s - loss: 4.8671 - acc: 0.01 - ETA: 45s - loss: 4.8675 - acc: 0.01 - ETA: 47s - loss: 4.8655 - acc: 0.01 - ETA: 47s - loss: 4.8647 - acc: 0.01 - ETA: 47s - loss: 4.8633 - acc: 0.01 - ETA: 48s - loss: 4.8605 - acc: 0.01 - ETA: 48s - loss: 4.8605 - acc: 0.01 - ETA: 48s - loss: 4.8598 - acc: 0.01 - ETA: 48s - loss: 4.8613 - acc: 0.01 - ETA: 48s - loss: 4.8617 - acc: 0.01 - ETA: 48s - loss: 4.8621 - acc: 0.01 - ETA: 49s - loss: 4.8614 - acc: 0.01 - ETA: 49s - loss: 4.8627 - acc: 0.01 - ETA: 49s - loss: 4.8627 - acc: 0.01 - ETA: 49s - loss: 4.8629 - acc: 0.01 - ETA: 49s - loss: 4.8634 - acc: 0.01 - ETA: 49s - loss: 4.8637 - acc: 0.01 - ETA: 49s - loss: 4.8622 - acc: 0.01 - ETA: 49s - loss: 4.8613 - acc: 0.01 - ETA: 49s - loss: 4.8622 - acc: 0.01 - ETA: 50s - loss: 4.8614 - acc: 0.01 - ETA: 49s - loss: 4.8609 - acc: 0.01 - ETA: 49s - loss: 4.8614 - acc: 0.01 - ETA: 49s - loss: 4.8624 - acc: 0.01 - ETA: 49s - loss: 4.8622 - acc: 0.01 - ETA: 49s - loss: 4.8617 - acc: 0.01 - ETA: 49s - loss: 4.8619 - acc: 0.01 - ETA: 49s - loss: 4.8618 - acc: 0.01 - ETA: 48s - loss: 4.8623 - acc: 0.01 - ETA: 48s - loss: 4.8619 - acc: 0.01 - ETA: 49s - loss: 4.8621 - acc: 0.01 - ETA: 48s - loss: 4.8636 - acc: 0.01 - ETA: 49s - loss: 4.8641 - acc: 0.01 - ETA: 49s - loss: 4.8643 - acc: 0.01 - ETA: 48s - loss: 4.8647 - acc: 0.01 - ETA: 48s - loss: 4.8640 - acc: 0.01 - ETA: 48s - loss: 4.8647 - acc: 0.01 - ETA: 48s - loss: 4.8646 - acc: 0.01 - ETA: 48s - loss: 4.8651 - acc: 0.01 - ETA: 48s - loss: 4.8652 - acc: 0.01 - ETA: 48s - loss: 4.8657 - acc: 0.01 - ETA: 48s - loss: 4.8662 - acc: 0.01 - ETA: 48s - loss: 4.8667 - acc: 0.01 - ETA: 48s - loss: 4.8664 - acc: 0.01 - ETA: 47s - loss: 4.8664 - acc: 0.01 - ETA: 47s - loss: 4.8664 - acc: 0.01 - ETA: 47s - loss: 4.8657 - acc: 0.01 - ETA: 47s - loss: 4.8663 - acc: 0.01 - ETA: 47s - loss: 4.8659 - acc: 0.01 - ETA: 47s - loss: 4.8667 - acc: 0.01 - ETA: 47s - loss: 4.8672 - acc: 0.01 - ETA: 47s - loss: 4.8672 - acc: 0.01 - ETA: 47s - loss: 4.8677 - acc: 0.01 - ETA: 47s - loss: 4.8682 - acc: 0.01 - ETA: 47s - loss: 4.8680 - acc: 0.01 - ETA: 47s - loss: 4.8672 - acc: 0.01 - ETA: 47s - loss: 4.8680 - acc: 0.01 - ETA: 47s - loss: 4.8675 - acc: 0.01 - ETA: 47s - loss: 4.8669 - acc: 0.01 - ETA: 46s - loss: 4.8666 - acc: 0.01 - ETA: 46s - loss: 4.8671 - acc: 0.01 - ETA: 46s - loss: 4.8661 - acc: 0.01 - ETA: 46s - loss: 4.8660 - acc: 0.01 - ETA: 46s - loss: 4.8662 - acc: 0.01 - ETA: 46s - loss: 4.8661 - acc: 0.01 - ETA: 45s - loss: 4.8662 - acc: 0.01 - ETA: 45s - loss: 4.8667 - acc: 0.01 - ETA: 45s - loss: 4.8666 - acc: 0.01 - ETA: 45s - loss: 4.8664 - acc: 0.01 - ETA: 45s - loss: 4.8666 - acc: 0.01 - ETA: 45s - loss: 4.8667 - acc: 0.01 - ETA: 44s - loss: 4.8667 - acc: 0.01 - ETA: 45s - loss: 4.8666 - acc: 0.01 - ETA: 45s - loss: 4.8674 - acc: 0.01 - ETA: 45s - loss: 4.8666 - acc: 0.01 - ETA: 44s - loss: 4.8670 - acc: 0.01 - ETA: 44s - loss: 4.8666 - acc: 0.01 - ETA: 44s - loss: 4.8668 - acc: 0.01 - ETA: 44s - loss: 4.8668 - acc: 0.01 - ETA: 44s - loss: 4.8668 - acc: 0.01 - ETA: 44s - loss: 4.8667 - acc: 0.01 - ETA: 44s - loss: 4.8667 - acc: 0.01 - ETA: 44s - loss: 4.8668 - acc: 0.01 - ETA: 44s - loss: 4.8668 - acc: 0.01 - ETA: 43s - loss: 4.8667 - acc: 0.01 - ETA: 43s - loss: 4.8663 - acc: 0.01 - ETA: 43s - loss: 4.8662 - acc: 0.01 - ETA: 43s - loss: 4.8665 - acc: 0.01 - ETA: 42s - loss: 4.8662 - acc: 0.01 - ETA: 43s - loss: 4.8660 - acc: 0.01 - ETA: 42s - loss: 4.8660 - acc: 0.01 - ETA: 42s - loss: 4.8656 - acc: 0.01 - ETA: 42s - loss: 4.8652 - acc: 0.01 - ETA: 42s - loss: 4.8653 - acc: 0.01 - ETA: 42s - loss: 4.8652 - acc: 0.01 - ETA: 42s - loss: 4.8654 - acc: 0.01 - ETA: 42s - loss: 4.8657 - acc: 0.01 - ETA: 42s - loss: 4.8650 - acc: 0.01 - ETA: 42s - loss: 4.8650 - acc: 0.01 - ETA: 41s - loss: 4.8655 - acc: 0.01 - ETA: 41s - loss: 4.8653 - acc: 0.01 - ETA: 41s - loss: 4.8656 - acc: 0.01 - ETA: 41s - loss: 4.8652 - acc: 0.01 - ETA: 41s - loss: 4.8653 - acc: 0.01 - ETA: 41s - loss: 4.8652 - acc: 0.01 - ETA: 41s - loss: 4.8657 - acc: 0.01 - ETA: 40s - loss: 4.8657 - acc: 0.01 - ETA: 40s - loss: 4.8660 - acc: 0.01 - ETA: 40s - loss: 4.8659 - acc: 0.01 - ETA: 40s - loss: 4.8663 - acc: 0.01 - ETA: 40s - loss: 4.8666 - acc: 0.01 - ETA: 40s - loss: 4.8672 - acc: 0.01 - ETA: 40s - loss: 4.8676 - acc: 0.01 - ETA: 40s - loss: 4.8679 - acc: 0.01 - ETA: 40s - loss: 4.8682 - acc: 0.01 - ETA: 39s - loss: 4.8685 - acc: 0.01 - ETA: 39s - loss: 4.8689 - acc: 0.01 - ETA: 39s - loss: 4.8681 - acc: 0.01 - ETA: 39s - loss: 4.8683 - acc: 0.01 - ETA: 39s - loss: 4.8684 - acc: 0.01 - ETA: 39s - loss: 4.8687 - acc: 0.01 - ETA: 39s - loss: 4.8688 - acc: 0.01 - ETA: 38s - loss: 4.8692 - acc: 0.01 - ETA: 38s - loss: 4.8694 - acc: 0.01 - ETA: 38s - loss: 4.8690 - acc: 0.01 - ETA: 38s - loss: 4.8693 - acc: 0.01 - ETA: 38s - loss: 4.8695 - acc: 0.01 - ETA: 38s - loss: 4.8691 - acc: 0.01 - ETA: 37s - loss: 4.8688 - acc: 0.01 - ETA: 37s - loss: 4.8691 - acc: 0.01 - ETA: 37s - loss: 4.8691 - acc: 0.01 - ETA: 38s - loss: 4.8693 - acc: 0.01 - ETA: 37s - loss: 4.8690 - acc: 0.01 - ETA: 37s - loss: 4.8692 - acc: 0.01 - ETA: 37s - loss: 4.8693 - acc: 0.01 - ETA: 37s - loss: 4.8692 - acc: 0.01 - ETA: 37s - loss: 4.8694 - acc: 0.01 - ETA: 37s - loss: 4.8695 - acc: 0.01 - ETA: 37s - loss: 4.8695 - acc: 0.01 - ETA: 36s - loss: 4.8699 - acc: 0.01 - ETA: 36s - loss: 4.8697 - acc: 0.01 - ETA: 36s - loss: 4.8699 - acc: 0.01 - ETA: 36s - loss: 4.8696 - acc: 0.01 - ETA: 36s - loss: 4.8698 - acc: 0.01 - ETA: 36s - loss: 4.8698 - acc: 0.01 - ETA: 36s - loss: 4.8697 - acc: 0.01 - ETA: 36s - loss: 4.8697 - acc: 0.01 - ETA: 35s - loss: 4.8695 - acc: 0.01 - ETA: 35s - loss: 4.8692 - acc: 0.01 - ETA: 35s - loss: 4.8690 - acc: 0.01 - ETA: 35s - loss: 4.8689 - acc: 0.01 - ETA: 35s - loss: 4.8687 - acc: 0.01 - ETA: 35s - loss: 4.8688 - acc: 0.01 - ETA: 35s - loss: 4.8690 - acc: 0.01 - ETA: 34s - loss: 4.8689 - acc: 0.01 - ETA: 34s - loss: 4.8686 - acc: 0.01 - ETA: 34s - loss: 4.8686 - acc: 0.01 - ETA: 34s - loss: 4.8689 - acc: 0.01 - ETA: 34s - loss: 4.8686 - acc: 0.01 - ETA: 34s - loss: 4.8687 - acc: 0.01 - ETA: 33s - loss: 4.8686 - acc: 0.01 - ETA: 33s - loss: 4.8683 - acc: 0.01 - ETA: 33s - loss: 4.8682 - acc: 0.01 - ETA: 33s - loss: 4.8683 - acc: 0.01 - ETA: 33s - loss: 4.8682 - acc: 0.01 - ETA: 33s - loss: 4.8682 - acc: 0.01 - ETA: 32s - loss: 4.8681 - acc: 0.01 - ETA: 32s - loss: 4.8682 - acc: 0.01 - ETA: 32s - loss: 4.8685 - acc: 0.01 - ETA: 32s - loss: 4.8686 - acc: 0.01 - ETA: 32s - loss: 4.8690 - acc: 0.01 - ETA: 32s - loss: 4.8688 - acc: 0.01 - ETA: 32s - loss: 4.8689 - acc: 0.01 - ETA: 32s - loss: 4.8690 - acc: 0.01 - ETA: 31s - loss: 4.8693 - acc: 0.01 - ETA: 31s - loss: 4.8691 - acc: 0.01 - ETA: 31s - loss: 4.8692 - acc: 0.01 - ETA: 31s - loss: 4.8693 - acc: 0.01 - ETA: 31s - loss: 4.8693 - acc: 0.01 - ETA: 30s - loss: 4.8695 - acc: 0.01 - ETA: 30s - loss: 4.8694 - acc: 0.01 - ETA: 30s - loss: 4.8697 - acc: 0.01 - ETA: 30s - loss: 4.8696 - acc: 0.01 - ETA: 30s - loss: 4.8698 - acc: 0.01 - ETA: 30s - loss: 4.8695 - acc: 0.01 - ETA: 30s - loss: 4.8695 - acc: 0.01 - ETA: 29s - loss: 4.8694 - acc: 0.01 - ETA: 29s - loss: 4.8693 - acc: 0.0131"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 29s - loss: 4.8696 - acc: 0.01 - ETA: 29s - loss: 4.8697 - acc: 0.01 - ETA: 29s - loss: 4.8696 - acc: 0.01 - ETA: 29s - loss: 4.8697 - acc: 0.01 - ETA: 28s - loss: 4.8697 - acc: 0.01 - ETA: 28s - loss: 4.8698 - acc: 0.01 - ETA: 28s - loss: 4.8698 - acc: 0.01 - ETA: 28s - loss: 4.8699 - acc: 0.01 - ETA: 28s - loss: 4.8700 - acc: 0.01 - ETA: 28s - loss: 4.8700 - acc: 0.01 - ETA: 27s - loss: 4.8701 - acc: 0.01 - ETA: 27s - loss: 4.8703 - acc: 0.01 - ETA: 27s - loss: 4.8698 - acc: 0.01 - ETA: 27s - loss: 4.8696 - acc: 0.01 - ETA: 27s - loss: 4.8698 - acc: 0.01 - ETA: 27s - loss: 4.8700 - acc: 0.01 - ETA: 27s - loss: 4.8703 - acc: 0.01 - ETA: 26s - loss: 4.8702 - acc: 0.01 - ETA: 26s - loss: 4.8701 - acc: 0.01 - ETA: 26s - loss: 4.8701 - acc: 0.01 - ETA: 26s - loss: 4.8704 - acc: 0.01 - ETA: 26s - loss: 4.8704 - acc: 0.01 - ETA: 26s - loss: 4.8707 - acc: 0.01 - ETA: 26s - loss: 4.8706 - acc: 0.01 - ETA: 25s - loss: 4.8705 - acc: 0.01 - ETA: 25s - loss: 4.8704 - acc: 0.01 - ETA: 25s - loss: 4.8707 - acc: 0.01 - ETA: 25s - loss: 4.8706 - acc: 0.01 - ETA: 25s - loss: 4.8708 - acc: 0.01 - ETA: 25s - loss: 4.8706 - acc: 0.01 - ETA: 25s - loss: 4.8706 - acc: 0.01 - ETA: 24s - loss: 4.8705 - acc: 0.01 - ETA: 24s - loss: 4.8706 - acc: 0.01 - ETA: 24s - loss: 4.8704 - acc: 0.01 - ETA: 24s - loss: 4.8705 - acc: 0.01 - ETA: 24s - loss: 4.8706 - acc: 0.01 - ETA: 24s - loss: 4.8706 - acc: 0.01 - ETA: 24s - loss: 4.8706 - acc: 0.01 - ETA: 23s - loss: 4.8702 - acc: 0.01 - ETA: 23s - loss: 4.8703 - acc: 0.01 - ETA: 23s - loss: 4.8704 - acc: 0.01 - ETA: 23s - loss: 4.8703 - acc: 0.01 - ETA: 23s - loss: 4.8703 - acc: 0.01 - ETA: 23s - loss: 4.8702 - acc: 0.01 - ETA: 23s - loss: 4.8703 - acc: 0.01 - ETA: 22s - loss: 4.8702 - acc: 0.01 - ETA: 22s - loss: 4.8702 - acc: 0.01 - ETA: 22s - loss: 4.8702 - acc: 0.01 - ETA: 22s - loss: 4.8702 - acc: 0.01 - ETA: 22s - loss: 4.8703 - acc: 0.01 - ETA: 22s - loss: 4.8703 - acc: 0.01 - ETA: 21s - loss: 4.8705 - acc: 0.01 - ETA: 21s - loss: 4.8704 - acc: 0.01 - ETA: 21s - loss: 4.8706 - acc: 0.01 - ETA: 21s - loss: 4.8705 - acc: 0.01 - ETA: 21s - loss: 4.8704 - acc: 0.01 - ETA: 21s - loss: 4.8706 - acc: 0.01 - ETA: 21s - loss: 4.8707 - acc: 0.01 - ETA: 20s - loss: 4.8706 - acc: 0.01 - ETA: 20s - loss: 4.8706 - acc: 0.01 - ETA: 20s - loss: 4.8705 - acc: 0.01 - ETA: 20s - loss: 4.8705 - acc: 0.01 - ETA: 20s - loss: 4.8707 - acc: 0.01 - ETA: 20s - loss: 4.8707 - acc: 0.01 - ETA: 20s - loss: 4.8710 - acc: 0.01 - ETA: 19s - loss: 4.8711 - acc: 0.01 - ETA: 19s - loss: 4.8712 - acc: 0.01 - ETA: 19s - loss: 4.8708 - acc: 0.01 - ETA: 19s - loss: 4.8707 - acc: 0.01 - ETA: 19s - loss: 4.8707 - acc: 0.01 - ETA: 19s - loss: 4.8707 - acc: 0.01 - ETA: 18s - loss: 4.8709 - acc: 0.01 - ETA: 18s - loss: 4.8708 - acc: 0.01 - ETA: 18s - loss: 4.8710 - acc: 0.01 - ETA: 18s - loss: 4.8708 - acc: 0.01 - ETA: 18s - loss: 4.8706 - acc: 0.01 - ETA: 18s - loss: 4.8708 - acc: 0.01 - ETA: 18s - loss: 4.8709 - acc: 0.01 - ETA: 17s - loss: 4.8708 - acc: 0.01 - ETA: 17s - loss: 4.8708 - acc: 0.01 - ETA: 17s - loss: 4.8708 - acc: 0.01 - ETA: 17s - loss: 4.8708 - acc: 0.01 - ETA: 17s - loss: 4.8706 - acc: 0.01 - ETA: 17s - loss: 4.8710 - acc: 0.01 - ETA: 16s - loss: 4.8707 - acc: 0.01 - ETA: 16s - loss: 4.8709 - acc: 0.01 - ETA: 16s - loss: 4.8714 - acc: 0.01 - ETA: 16s - loss: 4.8715 - acc: 0.01 - ETA: 16s - loss: 4.8715 - acc: 0.01 - ETA: 16s - loss: 4.8715 - acc: 0.01 - ETA: 15s - loss: 4.8714 - acc: 0.01 - ETA: 15s - loss: 4.8714 - acc: 0.01 - ETA: 15s - loss: 4.8715 - acc: 0.01 - ETA: 15s - loss: 4.8714 - acc: 0.01 - ETA: 15s - loss: 4.8713 - acc: 0.01 - ETA: 15s - loss: 4.8712 - acc: 0.01 - ETA: 15s - loss: 4.8715 - acc: 0.01 - ETA: 14s - loss: 4.8716 - acc: 0.01 - ETA: 14s - loss: 4.8716 - acc: 0.01 - ETA: 14s - loss: 4.8715 - acc: 0.01 - ETA: 14s - loss: 4.8712 - acc: 0.01 - ETA: 14s - loss: 4.8711 - acc: 0.01 - ETA: 14s - loss: 4.8712 - acc: 0.01 - ETA: 13s - loss: 4.8711 - acc: 0.01 - ETA: 13s - loss: 4.8710 - acc: 0.01 - ETA: 13s - loss: 4.8712 - acc: 0.01 - ETA: 13s - loss: 4.8712 - acc: 0.01 - ETA: 13s - loss: 4.8713 - acc: 0.01 - ETA: 13s - loss: 4.8713 - acc: 0.01 - ETA: 13s - loss: 4.8715 - acc: 0.01 - ETA: 12s - loss: 4.8715 - acc: 0.01 - ETA: 12s - loss: 4.8716 - acc: 0.01 - ETA: 12s - loss: 4.8715 - acc: 0.01 - ETA: 12s - loss: 4.8717 - acc: 0.01 - ETA: 12s - loss: 4.8717 - acc: 0.01 - ETA: 12s - loss: 4.8718 - acc: 0.01 - ETA: 11s - loss: 4.8718 - acc: 0.01 - ETA: 11s - loss: 4.8718 - acc: 0.01 - ETA: 11s - loss: 4.8718 - acc: 0.01 - ETA: 11s - loss: 4.8718 - acc: 0.01 - ETA: 11s - loss: 4.8721 - acc: 0.01 - ETA: 11s - loss: 4.8721 - acc: 0.01 - ETA: 11s - loss: 4.8720 - acc: 0.01 - ETA: 10s - loss: 4.8722 - acc: 0.01 - ETA: 10s - loss: 4.8723 - acc: 0.01 - ETA: 10s - loss: 4.8723 - acc: 0.01 - ETA: 10s - loss: 4.8724 - acc: 0.01 - ETA: 10s - loss: 4.8724 - acc: 0.01 - ETA: 10s - loss: 4.8724 - acc: 0.01 - ETA: 9s - loss: 4.8723 - acc: 0.0138 - ETA: 9s - loss: 4.8723 - acc: 0.013 - ETA: 9s - loss: 4.8721 - acc: 0.013 - ETA: 9s - loss: 4.8721 - acc: 0.013 - ETA: 9s - loss: 4.8722 - acc: 0.013 - ETA: 9s - loss: 4.8722 - acc: 0.013 - ETA: 9s - loss: 4.8722 - acc: 0.013 - ETA: 8s - loss: 4.8723 - acc: 0.013 - ETA: 8s - loss: 4.8724 - acc: 0.013 - ETA: 8s - loss: 4.8723 - acc: 0.013 - ETA: 8s - loss: 4.8723 - acc: 0.013 - ETA: 8s - loss: 4.8723 - acc: 0.013 - ETA: 8s - loss: 4.8724 - acc: 0.013 - ETA: 7s - loss: 4.8724 - acc: 0.013 - ETA: 7s - loss: 4.8724 - acc: 0.013 - ETA: 7s - loss: 4.8724 - acc: 0.013 - ETA: 7s - loss: 4.8725 - acc: 0.013 - ETA: 7s - loss: 4.8725 - acc: 0.013 - ETA: 7s - loss: 4.8725 - acc: 0.013 - ETA: 6s - loss: 4.8726 - acc: 0.013 - ETA: 6s - loss: 4.8725 - acc: 0.013 - ETA: 6s - loss: 4.8724 - acc: 0.013 - ETA: 6s - loss: 4.8724 - acc: 0.013 - ETA: 6s - loss: 4.8723 - acc: 0.013 - ETA: 6s - loss: 4.8724 - acc: 0.013 - ETA: 6s - loss: 4.8725 - acc: 0.013 - ETA: 5s - loss: 4.8726 - acc: 0.013 - ETA: 5s - loss: 4.8726 - acc: 0.013 - ETA: 5s - loss: 4.8724 - acc: 0.013 - ETA: 5s - loss: 4.8724 - acc: 0.013 - ETA: 5s - loss: 4.8725 - acc: 0.013 - ETA: 5s - loss: 4.8725 - acc: 0.013 - ETA: 4s - loss: 4.8725 - acc: 0.013 - ETA: 4s - loss: 4.8726 - acc: 0.013 - ETA: 4s - loss: 4.8726 - acc: 0.013 - ETA: 4s - loss: 4.8727 - acc: 0.013 - ETA: 4s - loss: 4.8727 - acc: 0.013 - ETA: 4s - loss: 4.8727 - acc: 0.013 - ETA: 3s - loss: 4.8727 - acc: 0.014 - ETA: 3s - loss: 4.8728 - acc: 0.014 - ETA: 3s - loss: 4.8727 - acc: 0.014 - ETA: 3s - loss: 4.8727 - acc: 0.013 - ETA: 3s - loss: 4.8727 - acc: 0.013 - ETA: 3s - loss: 4.8728 - acc: 0.013 - ETA: 3s - loss: 4.8729 - acc: 0.013 - ETA: 2s - loss: 4.8729 - acc: 0.013 - ETA: 2s - loss: 4.8728 - acc: 0.013 - ETA: 2s - loss: 4.8729 - acc: 0.013 - ETA: 2s - loss: 4.8729 - acc: 0.013 - ETA: 2s - loss: 4.8730 - acc: 0.013 - ETA: 2s - loss: 4.8730 - acc: 0.013 - ETA: 1s - loss: 4.8731 - acc: 0.013 - ETA: 1s - loss: 4.8731 - acc: 0.013 - ETA: 1s - loss: 4.8731 - acc: 0.013 - ETA: 1s - loss: 4.8732 - acc: 0.013 - ETA: 1s - loss: 4.8732 - acc: 0.013 - ETA: 1s - loss: 4.8731 - acc: 0.013 - ETA: 0s - loss: 4.8731 - acc: 0.013 - ETA: 0s - loss: 4.8731 - acc: 0.013 - ETA: 0s - loss: 4.8731 - acc: 0.013 - ETA: 0s - loss: 4.8731 - acc: 0.013 - ETA: 0s - loss: 4.8732 - acc: 0.013 - ETA: 0s - loss: 4.8731 - acc: 0.013 - 70s 168ms/step - loss: 4.8731 - acc: 0.0133 - val_loss: 4.8676 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.86967 to 4.86765, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 5s - loss: 4.8863 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8708 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8709 - acc: 0.0069    - ETA: 6s - loss: 4.8785 - acc: 0.005 - ETA: 10s - loss: 4.8819 - acc: 0.00 - ETA: 13s - loss: 4.8794 - acc: 0.00 - ETA: 18s - loss: 4.8812 - acc: 0.00 - ETA: 21s - loss: 4.8835 - acc: 0.00 - ETA: 24s - loss: 4.8841 - acc: 0.00 - ETA: 24s - loss: 4.8805 - acc: 0.00 - ETA: 26s - loss: 4.8783 - acc: 0.00 - ETA: 27s - loss: 4.8783 - acc: 0.00 - ETA: 29s - loss: 4.8775 - acc: 0.00 - ETA: 31s - loss: 4.8775 - acc: 0.00 - ETA: 32s - loss: 4.8780 - acc: 0.00 - ETA: 32s - loss: 4.8766 - acc: 0.01 - ETA: 33s - loss: 4.8779 - acc: 0.01 - ETA: 33s - loss: 4.8761 - acc: 0.01 - ETA: 34s - loss: 4.8761 - acc: 0.01 - ETA: 34s - loss: 4.8765 - acc: 0.01 - ETA: 35s - loss: 4.8761 - acc: 0.01 - ETA: 36s - loss: 4.8757 - acc: 0.01 - ETA: 36s - loss: 4.8767 - acc: 0.01 - ETA: 38s - loss: 4.8774 - acc: 0.01 - ETA: 38s - loss: 4.8778 - acc: 0.01 - ETA: 40s - loss: 4.8769 - acc: 0.01 - ETA: 40s - loss: 4.8759 - acc: 0.01 - ETA: 40s - loss: 4.8749 - acc: 0.01 - ETA: 41s - loss: 4.8733 - acc: 0.01 - ETA: 41s - loss: 4.8735 - acc: 0.01 - ETA: 41s - loss: 4.8730 - acc: 0.01 - ETA: 42s - loss: 4.8735 - acc: 0.01 - ETA: 42s - loss: 4.8728 - acc: 0.01 - ETA: 42s - loss: 4.8736 - acc: 0.01 - ETA: 43s - loss: 4.8738 - acc: 0.01 - ETA: 43s - loss: 4.8719 - acc: 0.01 - ETA: 43s - loss: 4.8711 - acc: 0.01 - ETA: 43s - loss: 4.8713 - acc: 0.01 - ETA: 43s - loss: 4.8709 - acc: 0.01 - ETA: 44s - loss: 4.8712 - acc: 0.01 - ETA: 45s - loss: 4.8717 - acc: 0.01 - ETA: 45s - loss: 4.8720 - acc: 0.01 - ETA: 46s - loss: 4.8726 - acc: 0.01 - ETA: 46s - loss: 4.8725 - acc: 0.01 - ETA: 46s - loss: 4.8730 - acc: 0.01 - ETA: 47s - loss: 4.8729 - acc: 0.01 - ETA: 47s - loss: 4.8725 - acc: 0.01 - ETA: 46s - loss: 4.8727 - acc: 0.01 - ETA: 46s - loss: 4.8738 - acc: 0.01 - ETA: 47s - loss: 4.8748 - acc: 0.01 - ETA: 47s - loss: 4.8749 - acc: 0.01 - ETA: 47s - loss: 4.8747 - acc: 0.01 - ETA: 47s - loss: 4.8744 - acc: 0.01 - ETA: 47s - loss: 4.8744 - acc: 0.01 - ETA: 46s - loss: 4.8736 - acc: 0.01 - ETA: 47s - loss: 4.8735 - acc: 0.01 - ETA: 47s - loss: 4.8739 - acc: 0.01 - ETA: 46s - loss: 4.8739 - acc: 0.01 - ETA: 46s - loss: 4.8736 - acc: 0.01 - ETA: 46s - loss: 4.8740 - acc: 0.01 - ETA: 46s - loss: 4.8739 - acc: 0.01 - ETA: 46s - loss: 4.8746 - acc: 0.01 - ETA: 46s - loss: 4.8742 - acc: 0.01 - ETA: 46s - loss: 4.8745 - acc: 0.01 - ETA: 46s - loss: 4.8747 - acc: 0.01 - ETA: 46s - loss: 4.8749 - acc: 0.01 - ETA: 46s - loss: 4.8749 - acc: 0.01 - ETA: 46s - loss: 4.8753 - acc: 0.01 - ETA: 46s - loss: 4.8752 - acc: 0.01 - ETA: 46s - loss: 4.8750 - acc: 0.01 - ETA: 46s - loss: 4.8752 - acc: 0.01 - ETA: 46s - loss: 4.8761 - acc: 0.01 - ETA: 46s - loss: 4.8765 - acc: 0.01 - ETA: 46s - loss: 4.8770 - acc: 0.01 - ETA: 46s - loss: 4.8769 - acc: 0.01 - ETA: 46s - loss: 4.8762 - acc: 0.01 - ETA: 46s - loss: 4.8763 - acc: 0.01 - ETA: 46s - loss: 4.8765 - acc: 0.01 - ETA: 46s - loss: 4.8765 - acc: 0.01 - ETA: 46s - loss: 4.8762 - acc: 0.01 - ETA: 46s - loss: 4.8762 - acc: 0.01 - ETA: 46s - loss: 4.8763 - acc: 0.01 - ETA: 45s - loss: 4.8760 - acc: 0.01 - ETA: 46s - loss: 4.8758 - acc: 0.01 - ETA: 46s - loss: 4.8767 - acc: 0.01 - ETA: 46s - loss: 4.8760 - acc: 0.01 - ETA: 46s - loss: 4.8753 - acc: 0.01 - ETA: 46s - loss: 4.8750 - acc: 0.01 - ETA: 46s - loss: 4.8748 - acc: 0.01 - ETA: 46s - loss: 4.8747 - acc: 0.01 - ETA: 46s - loss: 4.8736 - acc: 0.01 - ETA: 46s - loss: 4.8734 - acc: 0.01 - ETA: 45s - loss: 4.8732 - acc: 0.01 - ETA: 45s - loss: 4.8735 - acc: 0.01 - ETA: 45s - loss: 4.8739 - acc: 0.01 - ETA: 46s - loss: 4.8737 - acc: 0.01 - ETA: 46s - loss: 4.8733 - acc: 0.01 - ETA: 45s - loss: 4.8735 - acc: 0.01 - ETA: 45s - loss: 4.8734 - acc: 0.01 - ETA: 45s - loss: 4.8737 - acc: 0.01 - ETA: 45s - loss: 4.8743 - acc: 0.01 - ETA: 45s - loss: 4.8744 - acc: 0.01 - ETA: 45s - loss: 4.8741 - acc: 0.01 - ETA: 45s - loss: 4.8737 - acc: 0.01 - ETA: 45s - loss: 4.8737 - acc: 0.01 - ETA: 44s - loss: 4.8740 - acc: 0.01 - ETA: 44s - loss: 4.8741 - acc: 0.01 - ETA: 44s - loss: 4.8745 - acc: 0.01 - ETA: 44s - loss: 4.8746 - acc: 0.01 - ETA: 44s - loss: 4.8742 - acc: 0.01 - ETA: 44s - loss: 4.8741 - acc: 0.01 - ETA: 44s - loss: 4.8745 - acc: 0.01 - ETA: 44s - loss: 4.8744 - acc: 0.01 - ETA: 43s - loss: 4.8742 - acc: 0.01 - ETA: 43s - loss: 4.8742 - acc: 0.01 - ETA: 43s - loss: 4.8746 - acc: 0.01 - ETA: 43s - loss: 4.8742 - acc: 0.01 - ETA: 43s - loss: 4.8738 - acc: 0.01 - ETA: 43s - loss: 4.8739 - acc: 0.01 - ETA: 43s - loss: 4.8737 - acc: 0.01 - ETA: 42s - loss: 4.8738 - acc: 0.01 - ETA: 42s - loss: 4.8738 - acc: 0.01 - ETA: 42s - loss: 4.8731 - acc: 0.01 - ETA: 42s - loss: 4.8730 - acc: 0.01 - ETA: 42s - loss: 4.8735 - acc: 0.01 - ETA: 42s - loss: 4.8734 - acc: 0.01 - ETA: 42s - loss: 4.8738 - acc: 0.01 - ETA: 42s - loss: 4.8739 - acc: 0.01 - ETA: 42s - loss: 4.8739 - acc: 0.01 - ETA: 42s - loss: 4.8738 - acc: 0.01 - ETA: 42s - loss: 4.8735 - acc: 0.01 - ETA: 41s - loss: 4.8737 - acc: 0.01 - ETA: 41s - loss: 4.8738 - acc: 0.01 - ETA: 41s - loss: 4.8741 - acc: 0.01 - ETA: 41s - loss: 4.8738 - acc: 0.01 - ETA: 41s - loss: 4.8739 - acc: 0.01 - ETA: 41s - loss: 4.8740 - acc: 0.01 - ETA: 41s - loss: 4.8740 - acc: 0.01 - ETA: 41s - loss: 4.8739 - acc: 0.01 - ETA: 41s - loss: 4.8737 - acc: 0.01 - ETA: 41s - loss: 4.8740 - acc: 0.01 - ETA: 41s - loss: 4.8737 - acc: 0.01 - ETA: 40s - loss: 4.8737 - acc: 0.01 - ETA: 40s - loss: 4.8739 - acc: 0.01 - ETA: 40s - loss: 4.8742 - acc: 0.01 - ETA: 40s - loss: 4.8742 - acc: 0.01 - ETA: 40s - loss: 4.8741 - acc: 0.01 - ETA: 40s - loss: 4.8740 - acc: 0.01 - ETA: 40s - loss: 4.8742 - acc: 0.01 - ETA: 39s - loss: 4.8742 - acc: 0.01 - ETA: 39s - loss: 4.8742 - acc: 0.01 - ETA: 39s - loss: 4.8741 - acc: 0.01 - ETA: 39s - loss: 4.8739 - acc: 0.01 - ETA: 39s - loss: 4.8741 - acc: 0.01 - ETA: 39s - loss: 4.8742 - acc: 0.01 - ETA: 38s - loss: 4.8742 - acc: 0.01 - ETA: 38s - loss: 4.8744 - acc: 0.01 - ETA: 38s - loss: 4.8744 - acc: 0.01 - ETA: 38s - loss: 4.8743 - acc: 0.01 - ETA: 38s - loss: 4.8745 - acc: 0.01 - ETA: 38s - loss: 4.8744 - acc: 0.01 - ETA: 38s - loss: 4.8746 - acc: 0.01 - ETA: 37s - loss: 4.8744 - acc: 0.01 - ETA: 37s - loss: 4.8742 - acc: 0.01 - ETA: 37s - loss: 4.8741 - acc: 0.01 - ETA: 37s - loss: 4.8741 - acc: 0.01 - ETA: 37s - loss: 4.8743 - acc: 0.01 - ETA: 37s - loss: 4.8741 - acc: 0.01 - ETA: 37s - loss: 4.8741 - acc: 0.01 - ETA: 36s - loss: 4.8741 - acc: 0.01 - ETA: 36s - loss: 4.8738 - acc: 0.01 - ETA: 36s - loss: 4.8740 - acc: 0.01 - ETA: 36s - loss: 4.8739 - acc: 0.01 - ETA: 36s - loss: 4.8739 - acc: 0.01 - ETA: 36s - loss: 4.8739 - acc: 0.01 - ETA: 36s - loss: 4.8737 - acc: 0.01 - ETA: 35s - loss: 4.8740 - acc: 0.01 - ETA: 35s - loss: 4.8742 - acc: 0.01 - ETA: 35s - loss: 4.8741 - acc: 0.01 - ETA: 35s - loss: 4.8745 - acc: 0.01 - ETA: 35s - loss: 4.8743 - acc: 0.01 - ETA: 35s - loss: 4.8741 - acc: 0.01 - ETA: 35s - loss: 4.8740 - acc: 0.01 - ETA: 35s - loss: 4.8738 - acc: 0.01 - ETA: 34s - loss: 4.8739 - acc: 0.01 - ETA: 34s - loss: 4.8740 - acc: 0.01 - ETA: 34s - loss: 4.8740 - acc: 0.01 - ETA: 34s - loss: 4.8744 - acc: 0.01 - ETA: 34s - loss: 4.8745 - acc: 0.01 - ETA: 34s - loss: 4.8747 - acc: 0.01 - ETA: 34s - loss: 4.8746 - acc: 0.01 - ETA: 34s - loss: 4.8743 - acc: 0.01 - ETA: 33s - loss: 4.8745 - acc: 0.01 - ETA: 33s - loss: 4.8748 - acc: 0.01 - ETA: 33s - loss: 4.8747 - acc: 0.01 - ETA: 33s - loss: 4.8747 - acc: 0.01 - ETA: 33s - loss: 4.8746 - acc: 0.01 - ETA: 33s - loss: 4.8744 - acc: 0.01 - ETA: 32s - loss: 4.8743 - acc: 0.01 - ETA: 32s - loss: 4.8744 - acc: 0.01 - ETA: 32s - loss: 4.8746 - acc: 0.01 - ETA: 32s - loss: 4.8747 - acc: 0.01 - ETA: 32s - loss: 4.8747 - acc: 0.01 - ETA: 32s - loss: 4.8744 - acc: 0.01 - ETA: 32s - loss: 4.8746 - acc: 0.01 - ETA: 31s - loss: 4.8747 - acc: 0.01 - ETA: 31s - loss: 4.8751 - acc: 0.01 - ETA: 31s - loss: 4.8751 - acc: 0.01 - ETA: 31s - loss: 4.8752 - acc: 0.01 - ETA: 31s - loss: 4.8754 - acc: 0.01 - ETA: 31s - loss: 4.8753 - acc: 0.01 - ETA: 31s - loss: 4.8753 - acc: 0.01 - ETA: 31s - loss: 4.8753 - acc: 0.01 - ETA: 30s - loss: 4.8754 - acc: 0.01 - ETA: 30s - loss: 4.8753 - acc: 0.0126"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8752 - acc: 0.01 - ETA: 30s - loss: 4.8751 - acc: 0.01 - ETA: 30s - loss: 4.8753 - acc: 0.01 - ETA: 30s - loss: 4.8752 - acc: 0.01 - ETA: 30s - loss: 4.8752 - acc: 0.01 - ETA: 29s - loss: 4.8751 - acc: 0.01 - ETA: 29s - loss: 4.8753 - acc: 0.01 - ETA: 29s - loss: 4.8753 - acc: 0.01 - ETA: 29s - loss: 4.8755 - acc: 0.01 - ETA: 29s - loss: 4.8751 - acc: 0.01 - ETA: 29s - loss: 4.8750 - acc: 0.01 - ETA: 29s - loss: 4.8750 - acc: 0.01 - ETA: 28s - loss: 4.8749 - acc: 0.01 - ETA: 28s - loss: 4.8749 - acc: 0.01 - ETA: 28s - loss: 4.8750 - acc: 0.01 - ETA: 28s - loss: 4.8748 - acc: 0.01 - ETA: 28s - loss: 4.8748 - acc: 0.01 - ETA: 28s - loss: 4.8748 - acc: 0.01 - ETA: 28s - loss: 4.8748 - acc: 0.01 - ETA: 27s - loss: 4.8748 - acc: 0.01 - ETA: 27s - loss: 4.8750 - acc: 0.01 - ETA: 27s - loss: 4.8752 - acc: 0.01 - ETA: 27s - loss: 4.8752 - acc: 0.01 - ETA: 27s - loss: 4.8755 - acc: 0.01 - ETA: 26s - loss: 4.8758 - acc: 0.01 - ETA: 26s - loss: 4.8759 - acc: 0.01 - ETA: 26s - loss: 4.8760 - acc: 0.01 - ETA: 26s - loss: 4.8761 - acc: 0.01 - ETA: 26s - loss: 4.8762 - acc: 0.01 - ETA: 26s - loss: 4.8762 - acc: 0.01 - ETA: 25s - loss: 4.8763 - acc: 0.01 - ETA: 25s - loss: 4.8762 - acc: 0.01 - ETA: 25s - loss: 4.8762 - acc: 0.01 - ETA: 25s - loss: 4.8762 - acc: 0.01 - ETA: 25s - loss: 4.8762 - acc: 0.01 - ETA: 25s - loss: 4.8762 - acc: 0.01 - ETA: 24s - loss: 4.8761 - acc: 0.01 - ETA: 24s - loss: 4.8761 - acc: 0.01 - ETA: 24s - loss: 4.8762 - acc: 0.01 - ETA: 24s - loss: 4.8763 - acc: 0.01 - ETA: 24s - loss: 4.8764 - acc: 0.01 - ETA: 24s - loss: 4.8764 - acc: 0.01 - ETA: 24s - loss: 4.8764 - acc: 0.01 - ETA: 23s - loss: 4.8765 - acc: 0.01 - ETA: 23s - loss: 4.8765 - acc: 0.01 - ETA: 23s - loss: 4.8765 - acc: 0.01 - ETA: 23s - loss: 4.8766 - acc: 0.01 - ETA: 23s - loss: 4.8767 - acc: 0.01 - ETA: 23s - loss: 4.8767 - acc: 0.01 - ETA: 23s - loss: 4.8767 - acc: 0.01 - ETA: 22s - loss: 4.8768 - acc: 0.01 - ETA: 22s - loss: 4.8768 - acc: 0.01 - ETA: 22s - loss: 4.8768 - acc: 0.01 - ETA: 22s - loss: 4.8767 - acc: 0.01 - ETA: 22s - loss: 4.8766 - acc: 0.01 - ETA: 22s - loss: 4.8766 - acc: 0.01 - ETA: 21s - loss: 4.8763 - acc: 0.01 - ETA: 21s - loss: 4.8763 - acc: 0.01 - ETA: 21s - loss: 4.8763 - acc: 0.01 - ETA: 21s - loss: 4.8764 - acc: 0.01 - ETA: 21s - loss: 4.8765 - acc: 0.01 - ETA: 21s - loss: 4.8763 - acc: 0.01 - ETA: 20s - loss: 4.8764 - acc: 0.01 - ETA: 20s - loss: 4.8763 - acc: 0.01 - ETA: 20s - loss: 4.8762 - acc: 0.01 - ETA: 20s - loss: 4.8762 - acc: 0.01 - ETA: 20s - loss: 4.8763 - acc: 0.01 - ETA: 20s - loss: 4.8762 - acc: 0.01 - ETA: 20s - loss: 4.8763 - acc: 0.01 - ETA: 19s - loss: 4.8762 - acc: 0.01 - ETA: 19s - loss: 4.8762 - acc: 0.01 - ETA: 19s - loss: 4.8761 - acc: 0.01 - ETA: 19s - loss: 4.8762 - acc: 0.01 - ETA: 19s - loss: 4.8763 - acc: 0.01 - ETA: 19s - loss: 4.8763 - acc: 0.01 - ETA: 18s - loss: 4.8764 - acc: 0.01 - ETA: 18s - loss: 4.8763 - acc: 0.01 - ETA: 18s - loss: 4.8763 - acc: 0.01 - ETA: 18s - loss: 4.8763 - acc: 0.01 - ETA: 18s - loss: 4.8763 - acc: 0.01 - ETA: 18s - loss: 4.8763 - acc: 0.01 - ETA: 17s - loss: 4.8761 - acc: 0.01 - ETA: 17s - loss: 4.8760 - acc: 0.01 - ETA: 17s - loss: 4.8760 - acc: 0.01 - ETA: 17s - loss: 4.8761 - acc: 0.01 - ETA: 17s - loss: 4.8759 - acc: 0.01 - ETA: 17s - loss: 4.8759 - acc: 0.01 - ETA: 16s - loss: 4.8759 - acc: 0.01 - ETA: 16s - loss: 4.8758 - acc: 0.01 - ETA: 16s - loss: 4.8757 - acc: 0.01 - ETA: 16s - loss: 4.8758 - acc: 0.01 - ETA: 16s - loss: 4.8758 - acc: 0.01 - ETA: 16s - loss: 4.8757 - acc: 0.01 - ETA: 16s - loss: 4.8756 - acc: 0.01 - ETA: 15s - loss: 4.8755 - acc: 0.01 - ETA: 15s - loss: 4.8754 - acc: 0.01 - ETA: 15s - loss: 4.8753 - acc: 0.01 - ETA: 15s - loss: 4.8754 - acc: 0.01 - ETA: 15s - loss: 4.8754 - acc: 0.01 - ETA: 15s - loss: 4.8753 - acc: 0.01 - ETA: 14s - loss: 4.8753 - acc: 0.01 - ETA: 14s - loss: 4.8753 - acc: 0.01 - ETA: 14s - loss: 4.8752 - acc: 0.01 - ETA: 14s - loss: 4.8752 - acc: 0.01 - ETA: 14s - loss: 4.8752 - acc: 0.01 - ETA: 14s - loss: 4.8752 - acc: 0.01 - ETA: 13s - loss: 4.8752 - acc: 0.01 - ETA: 13s - loss: 4.8752 - acc: 0.01 - ETA: 13s - loss: 4.8753 - acc: 0.01 - ETA: 13s - loss: 4.8753 - acc: 0.01 - ETA: 13s - loss: 4.8754 - acc: 0.01 - ETA: 13s - loss: 4.8755 - acc: 0.01 - ETA: 12s - loss: 4.8755 - acc: 0.01 - ETA: 12s - loss: 4.8754 - acc: 0.01 - ETA: 12s - loss: 4.8756 - acc: 0.01 - ETA: 12s - loss: 4.8757 - acc: 0.01 - ETA: 12s - loss: 4.8758 - acc: 0.01 - ETA: 12s - loss: 4.8758 - acc: 0.01 - ETA: 12s - loss: 4.8758 - acc: 0.01 - ETA: 11s - loss: 4.8758 - acc: 0.01 - ETA: 11s - loss: 4.8757 - acc: 0.01 - ETA: 11s - loss: 4.8756 - acc: 0.01 - ETA: 11s - loss: 4.8757 - acc: 0.01 - ETA: 11s - loss: 4.8757 - acc: 0.01 - ETA: 11s - loss: 4.8756 - acc: 0.01 - ETA: 10s - loss: 4.8757 - acc: 0.01 - ETA: 10s - loss: 4.8756 - acc: 0.01 - ETA: 10s - loss: 4.8758 - acc: 0.01 - ETA: 10s - loss: 4.8757 - acc: 0.01 - ETA: 10s - loss: 4.8756 - acc: 0.01 - ETA: 10s - loss: 4.8757 - acc: 0.01 - ETA: 9s - loss: 4.8757 - acc: 0.0129 - ETA: 9s - loss: 4.8758 - acc: 0.012 - ETA: 9s - loss: 4.8757 - acc: 0.013 - ETA: 9s - loss: 4.8756 - acc: 0.013 - ETA: 9s - loss: 4.8757 - acc: 0.013 - ETA: 9s - loss: 4.8756 - acc: 0.013 - ETA: 8s - loss: 4.8757 - acc: 0.013 - ETA: 8s - loss: 4.8756 - acc: 0.012 - ETA: 8s - loss: 4.8755 - acc: 0.012 - ETA: 8s - loss: 4.8756 - acc: 0.013 - ETA: 8s - loss: 4.8757 - acc: 0.013 - ETA: 8s - loss: 4.8757 - acc: 0.013 - ETA: 8s - loss: 4.8757 - acc: 0.012 - ETA: 7s - loss: 4.8758 - acc: 0.012 - ETA: 7s - loss: 4.8756 - acc: 0.013 - ETA: 7s - loss: 4.8757 - acc: 0.013 - ETA: 7s - loss: 4.8757 - acc: 0.013 - ETA: 7s - loss: 4.8757 - acc: 0.013 - ETA: 7s - loss: 4.8758 - acc: 0.013 - ETA: 6s - loss: 4.8756 - acc: 0.013 - ETA: 6s - loss: 4.8755 - acc: 0.013 - ETA: 6s - loss: 4.8755 - acc: 0.013 - ETA: 6s - loss: 4.8755 - acc: 0.013 - ETA: 6s - loss: 4.8755 - acc: 0.013 - ETA: 6s - loss: 4.8755 - acc: 0.013 - ETA: 5s - loss: 4.8753 - acc: 0.013 - ETA: 5s - loss: 4.8752 - acc: 0.013 - ETA: 5s - loss: 4.8749 - acc: 0.014 - ETA: 5s - loss: 4.8748 - acc: 0.014 - ETA: 5s - loss: 4.8748 - acc: 0.014 - ETA: 5s - loss: 4.8748 - acc: 0.014 - ETA: 4s - loss: 4.8747 - acc: 0.014 - ETA: 4s - loss: 4.8747 - acc: 0.014 - ETA: 4s - loss: 4.8748 - acc: 0.014 - ETA: 4s - loss: 4.8747 - acc: 0.014 - ETA: 4s - loss: 4.8747 - acc: 0.014 - ETA: 4s - loss: 4.8749 - acc: 0.014 - ETA: 3s - loss: 4.8749 - acc: 0.014 - ETA: 3s - loss: 4.8750 - acc: 0.014 - ETA: 3s - loss: 4.8749 - acc: 0.014 - ETA: 3s - loss: 4.8750 - acc: 0.014 - ETA: 3s - loss: 4.8750 - acc: 0.014 - ETA: 3s - loss: 4.8752 - acc: 0.014 - ETA: 3s - loss: 4.8752 - acc: 0.014 - ETA: 2s - loss: 4.8752 - acc: 0.013 - ETA: 2s - loss: 4.8752 - acc: 0.013 - ETA: 2s - loss: 4.8753 - acc: 0.013 - ETA: 2s - loss: 4.8753 - acc: 0.013 - ETA: 2s - loss: 4.8752 - acc: 0.013 - ETA: 2s - loss: 4.8752 - acc: 0.013 - ETA: 1s - loss: 4.8753 - acc: 0.013 - ETA: 1s - loss: 4.8753 - acc: 0.013 - ETA: 1s - loss: 4.8753 - acc: 0.013 - ETA: 1s - loss: 4.8754 - acc: 0.013 - ETA: 1s - loss: 4.8754 - acc: 0.013 - ETA: 1s - loss: 4.8754 - acc: 0.013 - ETA: 0s - loss: 4.8754 - acc: 0.013 - ETA: 0s - loss: 4.8753 - acc: 0.013 - ETA: 0s - loss: 4.8753 - acc: 0.013 - ETA: 0s - loss: 4.8754 - acc: 0.013 - ETA: 0s - loss: 4.8754 - acc: 0.013 - ETA: 0s - loss: 4.8753 - acc: 0.013 - 71s 170ms/step - loss: 4.8754 - acc: 0.0135 - val_loss: 4.8669 - val_acc: 0.0168\n",
      "\n",
      "Epoch 00016: val_loss improved from 4.86765 to 4.86695, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/417 [===============>..............] - ETA: 7s - loss: 4.8906 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8700 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8619 - acc: 0.0156    - ETA: 8s - loss: 4.8724 - acc: 0.010 - ETA: 13s - loss: 4.8782 - acc: 0.00 - ETA: 19s - loss: 4.8797 - acc: 0.00 - ETA: 23s - loss: 4.8794 - acc: 0.01 - ETA: 27s - loss: 4.8775 - acc: 0.01 - ETA: 30s - loss: 4.8788 - acc: 0.01 - ETA: 31s - loss: 4.8760 - acc: 0.01 - ETA: 30s - loss: 4.8752 - acc: 0.01 - ETA: 31s - loss: 4.8754 - acc: 0.01 - ETA: 32s - loss: 4.8736 - acc: 0.01 - ETA: 33s - loss: 4.8735 - acc: 0.01 - ETA: 34s - loss: 4.8706 - acc: 0.01 - ETA: 37s - loss: 4.8714 - acc: 0.01 - ETA: 38s - loss: 4.8719 - acc: 0.01 - ETA: 40s - loss: 4.8701 - acc: 0.01 - ETA: 41s - loss: 4.8717 - acc: 0.01 - ETA: 41s - loss: 4.8713 - acc: 0.01 - ETA: 42s - loss: 4.8690 - acc: 0.01 - ETA: 42s - loss: 4.8680 - acc: 0.01 - ETA: 42s - loss: 4.8673 - acc: 0.01 - ETA: 42s - loss: 4.8674 - acc: 0.00 - ETA: 43s - loss: 4.8665 - acc: 0.00 - ETA: 44s - loss: 4.8672 - acc: 0.00 - ETA: 44s - loss: 4.8666 - acc: 0.01 - ETA: 45s - loss: 4.8661 - acc: 0.01 - ETA: 45s - loss: 4.8666 - acc: 0.01 - ETA: 46s - loss: 4.8660 - acc: 0.01 - ETA: 46s - loss: 4.8670 - acc: 0.01 - ETA: 46s - loss: 4.8672 - acc: 0.01 - ETA: 46s - loss: 4.8673 - acc: 0.01 - ETA: 49s - loss: 4.8664 - acc: 0.01 - ETA: 49s - loss: 4.8666 - acc: 0.01 - ETA: 49s - loss: 4.8659 - acc: 0.01 - ETA: 49s - loss: 4.8660 - acc: 0.01 - ETA: 49s - loss: 4.8659 - acc: 0.01 - ETA: 49s - loss: 4.8654 - acc: 0.01 - ETA: 50s - loss: 4.8657 - acc: 0.01 - ETA: 50s - loss: 4.8658 - acc: 0.01 - ETA: 50s - loss: 4.8648 - acc: 0.01 - ETA: 52s - loss: 4.8637 - acc: 0.01 - ETA: 52s - loss: 4.8632 - acc: 0.01 - ETA: 52s - loss: 4.8627 - acc: 0.01 - ETA: 52s - loss: 4.8631 - acc: 0.01 - ETA: 52s - loss: 4.8629 - acc: 0.01 - ETA: 52s - loss: 4.8636 - acc: 0.01 - ETA: 52s - loss: 4.8633 - acc: 0.01 - ETA: 52s - loss: 4.8637 - acc: 0.01 - ETA: 51s - loss: 4.8639 - acc: 0.01 - ETA: 51s - loss: 4.8637 - acc: 0.01 - ETA: 51s - loss: 4.8642 - acc: 0.01 - ETA: 51s - loss: 4.8652 - acc: 0.01 - ETA: 51s - loss: 4.8659 - acc: 0.01 - ETA: 51s - loss: 4.8663 - acc: 0.01 - ETA: 51s - loss: 4.8665 - acc: 0.01 - ETA: 51s - loss: 4.8664 - acc: 0.01 - ETA: 51s - loss: 4.8669 - acc: 0.01 - ETA: 51s - loss: 4.8669 - acc: 0.01 - ETA: 51s - loss: 4.8664 - acc: 0.01 - ETA: 51s - loss: 4.8662 - acc: 0.01 - ETA: 51s - loss: 4.8661 - acc: 0.01 - ETA: 51s - loss: 4.8663 - acc: 0.01 - ETA: 50s - loss: 4.8667 - acc: 0.01 - ETA: 50s - loss: 4.8670 - acc: 0.01 - ETA: 50s - loss: 4.8673 - acc: 0.01 - ETA: 50s - loss: 4.8681 - acc: 0.01 - ETA: 50s - loss: 4.8679 - acc: 0.01 - ETA: 50s - loss: 4.8671 - acc: 0.01 - ETA: 50s - loss: 4.8672 - acc: 0.01 - ETA: 50s - loss: 4.8676 - acc: 0.01 - ETA: 49s - loss: 4.8686 - acc: 0.01 - ETA: 49s - loss: 4.8680 - acc: 0.01 - ETA: 49s - loss: 4.8682 - acc: 0.01 - ETA: 49s - loss: 4.8691 - acc: 0.01 - ETA: 49s - loss: 4.8689 - acc: 0.01 - ETA: 48s - loss: 4.8694 - acc: 0.01 - ETA: 48s - loss: 4.8696 - acc: 0.01 - ETA: 48s - loss: 4.8696 - acc: 0.01 - ETA: 48s - loss: 4.8697 - acc: 0.01 - ETA: 48s - loss: 4.8698 - acc: 0.01 - ETA: 48s - loss: 4.8705 - acc: 0.01 - ETA: 48s - loss: 4.8713 - acc: 0.01 - ETA: 48s - loss: 4.8712 - acc: 0.01 - ETA: 47s - loss: 4.8710 - acc: 0.01 - ETA: 47s - loss: 4.8708 - acc: 0.01 - ETA: 47s - loss: 4.8706 - acc: 0.01 - ETA: 47s - loss: 4.8698 - acc: 0.01 - ETA: 47s - loss: 4.8697 - acc: 0.01 - ETA: 47s - loss: 4.8695 - acc: 0.01 - ETA: 47s - loss: 4.8696 - acc: 0.01 - ETA: 47s - loss: 4.8695 - acc: 0.01 - ETA: 47s - loss: 4.8695 - acc: 0.01 - ETA: 46s - loss: 4.8700 - acc: 0.01 - ETA: 46s - loss: 4.8706 - acc: 0.01 - ETA: 46s - loss: 4.8711 - acc: 0.01 - ETA: 46s - loss: 4.8715 - acc: 0.01 - ETA: 46s - loss: 4.8706 - acc: 0.01 - ETA: 46s - loss: 4.8704 - acc: 0.01 - ETA: 46s - loss: 4.8704 - acc: 0.01 - ETA: 46s - loss: 4.8704 - acc: 0.01 - ETA: 46s - loss: 4.8702 - acc: 0.01 - ETA: 46s - loss: 4.8704 - acc: 0.01 - ETA: 46s - loss: 4.8706 - acc: 0.01 - ETA: 45s - loss: 4.8706 - acc: 0.01 - ETA: 45s - loss: 4.8706 - acc: 0.01 - ETA: 45s - loss: 4.8702 - acc: 0.01 - ETA: 45s - loss: 4.8706 - acc: 0.01 - ETA: 45s - loss: 4.8702 - acc: 0.01 - ETA: 45s - loss: 4.8705 - acc: 0.01 - ETA: 45s - loss: 4.8704 - acc: 0.01 - ETA: 45s - loss: 4.8707 - acc: 0.01 - ETA: 45s - loss: 4.8704 - acc: 0.01 - ETA: 44s - loss: 4.8706 - acc: 0.01 - ETA: 44s - loss: 4.8708 - acc: 0.01 - ETA: 44s - loss: 4.8711 - acc: 0.01 - ETA: 44s - loss: 4.8710 - acc: 0.01 - ETA: 44s - loss: 4.8711 - acc: 0.01 - ETA: 44s - loss: 4.8711 - acc: 0.01 - ETA: 44s - loss: 4.8712 - acc: 0.01 - ETA: 43s - loss: 4.8711 - acc: 0.01 - ETA: 43s - loss: 4.8712 - acc: 0.01 - ETA: 43s - loss: 4.8710 - acc: 0.01 - ETA: 43s - loss: 4.8713 - acc: 0.01 - ETA: 43s - loss: 4.8709 - acc: 0.01 - ETA: 42s - loss: 4.8709 - acc: 0.01 - ETA: 42s - loss: 4.8707 - acc: 0.01 - ETA: 42s - loss: 4.8707 - acc: 0.01 - ETA: 42s - loss: 4.8703 - acc: 0.01 - ETA: 42s - loss: 4.8705 - acc: 0.01 - ETA: 42s - loss: 4.8705 - acc: 0.01 - ETA: 42s - loss: 4.8710 - acc: 0.01 - ETA: 42s - loss: 4.8708 - acc: 0.01 - ETA: 41s - loss: 4.8702 - acc: 0.01 - ETA: 41s - loss: 4.8702 - acc: 0.01 - ETA: 41s - loss: 4.8704 - acc: 0.01 - ETA: 41s - loss: 4.8705 - acc: 0.01 - ETA: 41s - loss: 4.8702 - acc: 0.01 - ETA: 41s - loss: 4.8703 - acc: 0.01 - ETA: 40s - loss: 4.8706 - acc: 0.01 - ETA: 41s - loss: 4.8705 - acc: 0.01 - ETA: 40s - loss: 4.8703 - acc: 0.01 - ETA: 40s - loss: 4.8707 - acc: 0.01 - ETA: 40s - loss: 4.8706 - acc: 0.01 - ETA: 40s - loss: 4.8708 - acc: 0.01 - ETA: 40s - loss: 4.8709 - acc: 0.01 - ETA: 40s - loss: 4.8709 - acc: 0.01 - ETA: 40s - loss: 4.8708 - acc: 0.01 - ETA: 39s - loss: 4.8710 - acc: 0.01 - ETA: 39s - loss: 4.8713 - acc: 0.01 - ETA: 39s - loss: 4.8711 - acc: 0.01 - ETA: 39s - loss: 4.8707 - acc: 0.01 - ETA: 38s - loss: 4.8706 - acc: 0.01 - ETA: 38s - loss: 4.8711 - acc: 0.01 - ETA: 38s - loss: 4.8710 - acc: 0.01 - ETA: 38s - loss: 4.8705 - acc: 0.01 - ETA: 38s - loss: 4.8706 - acc: 0.01 - ETA: 38s - loss: 4.8707 - acc: 0.01 - ETA: 38s - loss: 4.8706 - acc: 0.01 - ETA: 37s - loss: 4.8704 - acc: 0.01 - ETA: 37s - loss: 4.8705 - acc: 0.01 - ETA: 37s - loss: 4.8705 - acc: 0.01 - ETA: 37s - loss: 4.8705 - acc: 0.01 - ETA: 37s - loss: 4.8707 - acc: 0.01 - ETA: 36s - loss: 4.8706 - acc: 0.01 - ETA: 36s - loss: 4.8705 - acc: 0.01 - ETA: 36s - loss: 4.8703 - acc: 0.01 - ETA: 36s - loss: 4.8700 - acc: 0.01 - ETA: 36s - loss: 4.8698 - acc: 0.01 - ETA: 36s - loss: 4.8697 - acc: 0.01 - ETA: 36s - loss: 4.8696 - acc: 0.01 - ETA: 35s - loss: 4.8696 - acc: 0.01 - ETA: 35s - loss: 4.8696 - acc: 0.01 - ETA: 35s - loss: 4.8697 - acc: 0.01 - ETA: 35s - loss: 4.8697 - acc: 0.01 - ETA: 35s - loss: 4.8697 - acc: 0.01 - ETA: 35s - loss: 4.8696 - acc: 0.01 - ETA: 35s - loss: 4.8698 - acc: 0.01 - ETA: 35s - loss: 4.8695 - acc: 0.01 - ETA: 35s - loss: 4.8693 - acc: 0.01 - ETA: 35s - loss: 4.8692 - acc: 0.01 - ETA: 35s - loss: 4.8690 - acc: 0.01 - ETA: 34s - loss: 4.8691 - acc: 0.01 - ETA: 34s - loss: 4.8689 - acc: 0.01 - ETA: 34s - loss: 4.8693 - acc: 0.01 - ETA: 34s - loss: 4.8693 - acc: 0.01 - ETA: 34s - loss: 4.8696 - acc: 0.01 - ETA: 34s - loss: 4.8698 - acc: 0.01 - ETA: 34s - loss: 4.8698 - acc: 0.01 - ETA: 33s - loss: 4.8697 - acc: 0.01 - ETA: 33s - loss: 4.8698 - acc: 0.01 - ETA: 33s - loss: 4.8700 - acc: 0.01 - ETA: 33s - loss: 4.8701 - acc: 0.01 - ETA: 33s - loss: 4.8700 - acc: 0.01 - ETA: 33s - loss: 4.8702 - acc: 0.01 - ETA: 33s - loss: 4.8700 - acc: 0.01 - ETA: 32s - loss: 4.8701 - acc: 0.01 - ETA: 32s - loss: 4.8701 - acc: 0.01 - ETA: 32s - loss: 4.8702 - acc: 0.01 - ETA: 32s - loss: 4.8701 - acc: 0.01 - ETA: 32s - loss: 4.8699 - acc: 0.01 - ETA: 32s - loss: 4.8703 - acc: 0.01 - ETA: 31s - loss: 4.8702 - acc: 0.01 - ETA: 31s - loss: 4.8701 - acc: 0.01 - ETA: 31s - loss: 4.8700 - acc: 0.01 - ETA: 31s - loss: 4.8700 - acc: 0.01 - ETA: 31s - loss: 4.8704 - acc: 0.01 - ETA: 31s - loss: 4.8702 - acc: 0.01 - ETA: 30s - loss: 4.8703 - acc: 0.01 - ETA: 30s - loss: 4.8702 - acc: 0.01 - ETA: 30s - loss: 4.8702 - acc: 0.01 - ETA: 30s - loss: 4.8704 - acc: 0.01 - ETA: 30s - loss: 4.8704 - acc: 0.01 - ETA: 30s - loss: 4.8705 - acc: 0.0116"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8707 - acc: 0.01 - ETA: 29s - loss: 4.8706 - acc: 0.01 - ETA: 29s - loss: 4.8707 - acc: 0.01 - ETA: 29s - loss: 4.8708 - acc: 0.01 - ETA: 29s - loss: 4.8708 - acc: 0.01 - ETA: 29s - loss: 4.8707 - acc: 0.01 - ETA: 29s - loss: 4.8704 - acc: 0.01 - ETA: 28s - loss: 4.8706 - acc: 0.01 - ETA: 28s - loss: 4.8702 - acc: 0.01 - ETA: 28s - loss: 4.8701 - acc: 0.01 - ETA: 28s - loss: 4.8701 - acc: 0.01 - ETA: 28s - loss: 4.8701 - acc: 0.01 - ETA: 28s - loss: 4.8700 - acc: 0.01 - ETA: 27s - loss: 4.8701 - acc: 0.01 - ETA: 27s - loss: 4.8701 - acc: 0.01 - ETA: 27s - loss: 4.8699 - acc: 0.01 - ETA: 27s - loss: 4.8701 - acc: 0.01 - ETA: 27s - loss: 4.8702 - acc: 0.01 - ETA: 27s - loss: 4.8701 - acc: 0.01 - ETA: 26s - loss: 4.8703 - acc: 0.01 - ETA: 26s - loss: 4.8704 - acc: 0.01 - ETA: 26s - loss: 4.8705 - acc: 0.01 - ETA: 26s - loss: 4.8707 - acc: 0.01 - ETA: 26s - loss: 4.8707 - acc: 0.01 - ETA: 26s - loss: 4.8707 - acc: 0.01 - ETA: 25s - loss: 4.8707 - acc: 0.01 - ETA: 25s - loss: 4.8707 - acc: 0.01 - ETA: 25s - loss: 4.8708 - acc: 0.01 - ETA: 25s - loss: 4.8709 - acc: 0.01 - ETA: 25s - loss: 4.8709 - acc: 0.01 - ETA: 25s - loss: 4.8710 - acc: 0.01 - ETA: 25s - loss: 4.8710 - acc: 0.01 - ETA: 24s - loss: 4.8709 - acc: 0.01 - ETA: 24s - loss: 4.8708 - acc: 0.01 - ETA: 24s - loss: 4.8708 - acc: 0.01 - ETA: 24s - loss: 4.8709 - acc: 0.01 - ETA: 24s - loss: 4.8708 - acc: 0.01 - ETA: 24s - loss: 4.8710 - acc: 0.01 - ETA: 23s - loss: 4.8709 - acc: 0.01 - ETA: 23s - loss: 4.8712 - acc: 0.01 - ETA: 23s - loss: 4.8713 - acc: 0.01 - ETA: 23s - loss: 4.8712 - acc: 0.01 - ETA: 23s - loss: 4.8712 - acc: 0.01 - ETA: 23s - loss: 4.8711 - acc: 0.01 - ETA: 23s - loss: 4.8713 - acc: 0.01 - ETA: 22s - loss: 4.8714 - acc: 0.01 - ETA: 22s - loss: 4.8712 - acc: 0.01 - ETA: 22s - loss: 4.8709 - acc: 0.01 - ETA: 22s - loss: 4.8710 - acc: 0.01 - ETA: 22s - loss: 4.8712 - acc: 0.01 - ETA: 22s - loss: 4.8711 - acc: 0.01 - ETA: 21s - loss: 4.8713 - acc: 0.01 - ETA: 21s - loss: 4.8713 - acc: 0.01 - ETA: 21s - loss: 4.8714 - acc: 0.01 - ETA: 21s - loss: 4.8713 - acc: 0.01 - ETA: 21s - loss: 4.8713 - acc: 0.01 - ETA: 21s - loss: 4.8712 - acc: 0.01 - ETA: 21s - loss: 4.8711 - acc: 0.01 - ETA: 20s - loss: 4.8710 - acc: 0.01 - ETA: 20s - loss: 4.8708 - acc: 0.01 - ETA: 20s - loss: 4.8708 - acc: 0.01 - ETA: 20s - loss: 4.8707 - acc: 0.01 - ETA: 20s - loss: 4.8705 - acc: 0.01 - ETA: 20s - loss: 4.8705 - acc: 0.01 - ETA: 19s - loss: 4.8703 - acc: 0.01 - ETA: 19s - loss: 4.8703 - acc: 0.01 - ETA: 19s - loss: 4.8702 - acc: 0.01 - ETA: 19s - loss: 4.8702 - acc: 0.01 - ETA: 19s - loss: 4.8702 - acc: 0.01 - ETA: 19s - loss: 4.8700 - acc: 0.01 - ETA: 19s - loss: 4.8702 - acc: 0.01 - ETA: 18s - loss: 4.8700 - acc: 0.01 - ETA: 18s - loss: 4.8703 - acc: 0.01 - ETA: 18s - loss: 4.8702 - acc: 0.01 - ETA: 18s - loss: 4.8703 - acc: 0.01 - ETA: 18s - loss: 4.8703 - acc: 0.01 - ETA: 18s - loss: 4.8705 - acc: 0.01 - ETA: 17s - loss: 4.8703 - acc: 0.01 - ETA: 17s - loss: 4.8705 - acc: 0.01 - ETA: 17s - loss: 4.8706 - acc: 0.01 - ETA: 17s - loss: 4.8704 - acc: 0.01 - ETA: 17s - loss: 4.8704 - acc: 0.01 - ETA: 17s - loss: 4.8703 - acc: 0.01 - ETA: 17s - loss: 4.8704 - acc: 0.01 - ETA: 16s - loss: 4.8703 - acc: 0.01 - ETA: 16s - loss: 4.8701 - acc: 0.01 - ETA: 16s - loss: 4.8700 - acc: 0.01 - ETA: 16s - loss: 4.8702 - acc: 0.01 - ETA: 16s - loss: 4.8704 - acc: 0.01 - ETA: 16s - loss: 4.8702 - acc: 0.01 - ETA: 15s - loss: 4.8704 - acc: 0.01 - ETA: 15s - loss: 4.8703 - acc: 0.01 - ETA: 15s - loss: 4.8704 - acc: 0.01 - ETA: 15s - loss: 4.8705 - acc: 0.01 - ETA: 15s - loss: 4.8705 - acc: 0.01 - ETA: 15s - loss: 4.8706 - acc: 0.01 - ETA: 14s - loss: 4.8705 - acc: 0.01 - ETA: 14s - loss: 4.8703 - acc: 0.01 - ETA: 14s - loss: 4.8705 - acc: 0.01 - ETA: 14s - loss: 4.8705 - acc: 0.01 - ETA: 14s - loss: 4.8705 - acc: 0.01 - ETA: 14s - loss: 4.8705 - acc: 0.01 - ETA: 14s - loss: 4.8702 - acc: 0.01 - ETA: 13s - loss: 4.8703 - acc: 0.01 - ETA: 13s - loss: 4.8703 - acc: 0.01 - ETA: 13s - loss: 4.8704 - acc: 0.01 - ETA: 13s - loss: 4.8704 - acc: 0.01 - ETA: 13s - loss: 4.8703 - acc: 0.01 - ETA: 13s - loss: 4.8702 - acc: 0.01 - ETA: 12s - loss: 4.8703 - acc: 0.01 - ETA: 12s - loss: 4.8702 - acc: 0.01 - ETA: 12s - loss: 4.8700 - acc: 0.01 - ETA: 12s - loss: 4.8699 - acc: 0.01 - ETA: 12s - loss: 4.8698 - acc: 0.01 - ETA: 12s - loss: 4.8697 - acc: 0.01 - ETA: 11s - loss: 4.8698 - acc: 0.01 - ETA: 11s - loss: 4.8699 - acc: 0.01 - ETA: 11s - loss: 4.8699 - acc: 0.01 - ETA: 11s - loss: 4.8699 - acc: 0.01 - ETA: 11s - loss: 4.8698 - acc: 0.01 - ETA: 11s - loss: 4.8700 - acc: 0.01 - ETA: 10s - loss: 4.8699 - acc: 0.01 - ETA: 10s - loss: 4.8700 - acc: 0.01 - ETA: 10s - loss: 4.8701 - acc: 0.01 - ETA: 10s - loss: 4.8700 - acc: 0.01 - ETA: 10s - loss: 4.8701 - acc: 0.01 - ETA: 10s - loss: 4.8700 - acc: 0.01 - ETA: 9s - loss: 4.8701 - acc: 0.0136 - ETA: 9s - loss: 4.8700 - acc: 0.013 - ETA: 9s - loss: 4.8700 - acc: 0.013 - ETA: 9s - loss: 4.8699 - acc: 0.013 - ETA: 9s - loss: 4.8699 - acc: 0.013 - ETA: 9s - loss: 4.8698 - acc: 0.013 - ETA: 9s - loss: 4.8699 - acc: 0.013 - ETA: 8s - loss: 4.8699 - acc: 0.013 - ETA: 8s - loss: 4.8698 - acc: 0.013 - ETA: 8s - loss: 4.8698 - acc: 0.013 - ETA: 8s - loss: 4.8699 - acc: 0.013 - ETA: 8s - loss: 4.8699 - acc: 0.013 - ETA: 8s - loss: 4.8700 - acc: 0.013 - ETA: 7s - loss: 4.8701 - acc: 0.013 - ETA: 7s - loss: 4.8701 - acc: 0.013 - ETA: 7s - loss: 4.8699 - acc: 0.013 - ETA: 7s - loss: 4.8699 - acc: 0.013 - ETA: 7s - loss: 4.8699 - acc: 0.013 - ETA: 7s - loss: 4.8698 - acc: 0.013 - ETA: 6s - loss: 4.8697 - acc: 0.013 - ETA: 6s - loss: 4.8697 - acc: 0.014 - ETA: 6s - loss: 4.8697 - acc: 0.014 - ETA: 6s - loss: 4.8697 - acc: 0.014 - ETA: 6s - loss: 4.8696 - acc: 0.013 - ETA: 6s - loss: 4.8696 - acc: 0.013 - ETA: 6s - loss: 4.8695 - acc: 0.013 - ETA: 5s - loss: 4.8695 - acc: 0.013 - ETA: 5s - loss: 4.8696 - acc: 0.013 - ETA: 5s - loss: 4.8695 - acc: 0.013 - ETA: 5s - loss: 4.8695 - acc: 0.014 - ETA: 5s - loss: 4.8695 - acc: 0.014 - ETA: 5s - loss: 4.8695 - acc: 0.014 - ETA: 4s - loss: 4.8695 - acc: 0.014 - ETA: 4s - loss: 4.8694 - acc: 0.014 - ETA: 4s - loss: 4.8693 - acc: 0.014 - ETA: 4s - loss: 4.8693 - acc: 0.014 - ETA: 4s - loss: 4.8692 - acc: 0.013 - ETA: 4s - loss: 4.8691 - acc: 0.014 - ETA: 3s - loss: 4.8689 - acc: 0.014 - ETA: 3s - loss: 4.8688 - acc: 0.014 - ETA: 3s - loss: 4.8688 - acc: 0.014 - ETA: 3s - loss: 4.8689 - acc: 0.014 - ETA: 3s - loss: 4.8688 - acc: 0.014 - ETA: 3s - loss: 4.8689 - acc: 0.014 - ETA: 3s - loss: 4.8688 - acc: 0.014 - ETA: 2s - loss: 4.8690 - acc: 0.014 - ETA: 2s - loss: 4.8692 - acc: 0.014 - ETA: 2s - loss: 4.8693 - acc: 0.014 - ETA: 2s - loss: 4.8692 - acc: 0.014 - ETA: 2s - loss: 4.8692 - acc: 0.014 - ETA: 2s - loss: 4.8691 - acc: 0.014 - ETA: 1s - loss: 4.8691 - acc: 0.014 - ETA: 1s - loss: 4.8694 - acc: 0.014 - ETA: 1s - loss: 4.8693 - acc: 0.014 - ETA: 1s - loss: 4.8692 - acc: 0.014 - ETA: 1s - loss: 4.8694 - acc: 0.014 - ETA: 1s - loss: 4.8694 - acc: 0.014 - ETA: 0s - loss: 4.8694 - acc: 0.014 - ETA: 0s - loss: 4.8693 - acc: 0.014 - ETA: 0s - loss: 4.8693 - acc: 0.014 - ETA: 0s - loss: 4.8696 - acc: 0.014 - ETA: 0s - loss: 4.8696 - acc: 0.014 - ETA: 0s - loss: 4.8698 - acc: 0.014 - 71s 170ms/step - loss: 4.8698 - acc: 0.0142 - val_loss: 4.8654 - val_acc: 0.0183\n",
      "\n",
      "Epoch 00017: val_loss improved from 4.86695 to 4.86543, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 7s - loss: 4.9096 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8971 - acc: 0.0125    - ETA: 6s - loss: 4.8850 - acc: 0.006 - ETA: 6s - loss: 4.8854 - acc: 0.010 - ETA: 10s - loss: 4.8819 - acc: 0.00 - ETA: 16s - loss: 4.8823 - acc: 0.00 - ETA: 20s - loss: 4.8802 - acc: 0.00 - ETA: 22s - loss: 4.8769 - acc: 0.00 - ETA: 26s - loss: 4.8785 - acc: 0.00 - ETA: 28s - loss: 4.8780 - acc: 0.00 - ETA: 29s - loss: 4.8760 - acc: 0.00 - ETA: 29s - loss: 4.8749 - acc: 0.00 - ETA: 32s - loss: 4.8740 - acc: 0.00 - ETA: 33s - loss: 4.8776 - acc: 0.00 - ETA: 34s - loss: 4.8782 - acc: 0.00 - ETA: 36s - loss: 4.8775 - acc: 0.00 - ETA: 37s - loss: 4.8765 - acc: 0.00 - ETA: 37s - loss: 4.8771 - acc: 0.00 - ETA: 38s - loss: 4.8769 - acc: 0.00 - ETA: 38s - loss: 4.8763 - acc: 0.00 - ETA: 39s - loss: 4.8779 - acc: 0.00 - ETA: 40s - loss: 4.8785 - acc: 0.00 - ETA: 41s - loss: 4.8782 - acc: 0.00 - ETA: 41s - loss: 4.8749 - acc: 0.00 - ETA: 41s - loss: 4.8751 - acc: 0.00 - ETA: 42s - loss: 4.8743 - acc: 0.00 - ETA: 43s - loss: 4.8742 - acc: 0.00 - ETA: 43s - loss: 4.8777 - acc: 0.00 - ETA: 44s - loss: 4.8772 - acc: 0.00 - ETA: 45s - loss: 4.8764 - acc: 0.00 - ETA: 45s - loss: 4.8765 - acc: 0.00 - ETA: 45s - loss: 4.8760 - acc: 0.00 - ETA: 45s - loss: 4.8760 - acc: 0.00 - ETA: 45s - loss: 4.8754 - acc: 0.00 - ETA: 46s - loss: 4.8751 - acc: 0.00 - ETA: 46s - loss: 4.8754 - acc: 0.00 - ETA: 46s - loss: 4.8751 - acc: 0.00 - ETA: 48s - loss: 4.8745 - acc: 0.00 - ETA: 48s - loss: 4.8743 - acc: 0.01 - ETA: 48s - loss: 4.8741 - acc: 0.01 - ETA: 48s - loss: 4.8748 - acc: 0.01 - ETA: 48s - loss: 4.8758 - acc: 0.01 - ETA: 49s - loss: 4.8745 - acc: 0.01 - ETA: 49s - loss: 4.8738 - acc: 0.01 - ETA: 49s - loss: 4.8738 - acc: 0.01 - ETA: 49s - loss: 4.8754 - acc: 0.01 - ETA: 49s - loss: 4.8756 - acc: 0.01 - ETA: 49s - loss: 4.8776 - acc: 0.01 - ETA: 49s - loss: 4.8778 - acc: 0.01 - ETA: 49s - loss: 4.8781 - acc: 0.01 - ETA: 48s - loss: 4.8777 - acc: 0.01 - ETA: 48s - loss: 4.8776 - acc: 0.01 - ETA: 48s - loss: 4.8781 - acc: 0.01 - ETA: 48s - loss: 4.8786 - acc: 0.01 - ETA: 48s - loss: 4.8791 - acc: 0.01 - ETA: 48s - loss: 4.8787 - acc: 0.01 - ETA: 48s - loss: 4.8784 - acc: 0.01 - ETA: 48s - loss: 4.8784 - acc: 0.01 - ETA: 48s - loss: 4.8782 - acc: 0.01 - ETA: 47s - loss: 4.8778 - acc: 0.01 - ETA: 47s - loss: 4.8774 - acc: 0.01 - ETA: 47s - loss: 4.8766 - acc: 0.01 - ETA: 47s - loss: 4.8760 - acc: 0.01 - ETA: 47s - loss: 4.8761 - acc: 0.01 - ETA: 47s - loss: 4.8756 - acc: 0.01 - ETA: 47s - loss: 4.8745 - acc: 0.01 - ETA: 47s - loss: 4.8744 - acc: 0.01 - ETA: 47s - loss: 4.8747 - acc: 0.01 - ETA: 47s - loss: 4.8748 - acc: 0.01 - ETA: 47s - loss: 4.8757 - acc: 0.01 - ETA: 47s - loss: 4.8753 - acc: 0.01 - ETA: 46s - loss: 4.8744 - acc: 0.01 - ETA: 47s - loss: 4.8739 - acc: 0.01 - ETA: 46s - loss: 4.8743 - acc: 0.01 - ETA: 46s - loss: 4.8741 - acc: 0.01 - ETA: 46s - loss: 4.8731 - acc: 0.01 - ETA: 46s - loss: 4.8731 - acc: 0.01 - ETA: 46s - loss: 4.8731 - acc: 0.01 - ETA: 46s - loss: 4.8723 - acc: 0.01 - ETA: 46s - loss: 4.8722 - acc: 0.01 - ETA: 46s - loss: 4.8713 - acc: 0.01 - ETA: 46s - loss: 4.8711 - acc: 0.01 - ETA: 46s - loss: 4.8708 - acc: 0.01 - ETA: 45s - loss: 4.8713 - acc: 0.01 - ETA: 45s - loss: 4.8711 - acc: 0.01 - ETA: 45s - loss: 4.8703 - acc: 0.01 - ETA: 45s - loss: 4.8701 - acc: 0.01 - ETA: 45s - loss: 4.8703 - acc: 0.01 - ETA: 45s - loss: 4.8701 - acc: 0.01 - ETA: 45s - loss: 4.8704 - acc: 0.01 - ETA: 45s - loss: 4.8708 - acc: 0.01 - ETA: 45s - loss: 4.8711 - acc: 0.01 - ETA: 44s - loss: 4.8711 - acc: 0.01 - ETA: 44s - loss: 4.8715 - acc: 0.01 - ETA: 44s - loss: 4.8721 - acc: 0.01 - ETA: 44s - loss: 4.8722 - acc: 0.01 - ETA: 44s - loss: 4.8718 - acc: 0.01 - ETA: 44s - loss: 4.8720 - acc: 0.01 - ETA: 44s - loss: 4.8717 - acc: 0.01 - ETA: 43s - loss: 4.8716 - acc: 0.01 - ETA: 43s - loss: 4.8717 - acc: 0.01 - ETA: 43s - loss: 4.8715 - acc: 0.01 - ETA: 43s - loss: 4.8719 - acc: 0.01 - ETA: 43s - loss: 4.8722 - acc: 0.01 - ETA: 43s - loss: 4.8724 - acc: 0.01 - ETA: 43s - loss: 4.8724 - acc: 0.01 - ETA: 43s - loss: 4.8723 - acc: 0.01 - ETA: 43s - loss: 4.8728 - acc: 0.01 - ETA: 42s - loss: 4.8726 - acc: 0.01 - ETA: 42s - loss: 4.8729 - acc: 0.01 - ETA: 42s - loss: 4.8726 - acc: 0.01 - ETA: 42s - loss: 4.8725 - acc: 0.01 - ETA: 42s - loss: 4.8730 - acc: 0.01 - ETA: 42s - loss: 4.8731 - acc: 0.01 - ETA: 42s - loss: 4.8734 - acc: 0.01 - ETA: 42s - loss: 4.8737 - acc: 0.01 - ETA: 41s - loss: 4.8735 - acc: 0.01 - ETA: 41s - loss: 4.8732 - acc: 0.01 - ETA: 41s - loss: 4.8729 - acc: 0.01 - ETA: 41s - loss: 4.8726 - acc: 0.01 - ETA: 41s - loss: 4.8725 - acc: 0.01 - ETA: 41s - loss: 4.8726 - acc: 0.01 - ETA: 41s - loss: 4.8724 - acc: 0.01 - ETA: 41s - loss: 4.8724 - acc: 0.01 - ETA: 41s - loss: 4.8724 - acc: 0.01 - ETA: 41s - loss: 4.8725 - acc: 0.01 - ETA: 41s - loss: 4.8724 - acc: 0.01 - ETA: 41s - loss: 4.8726 - acc: 0.01 - ETA: 40s - loss: 4.8732 - acc: 0.01 - ETA: 40s - loss: 4.8730 - acc: 0.01 - ETA: 40s - loss: 4.8730 - acc: 0.01 - ETA: 40s - loss: 4.8728 - acc: 0.01 - ETA: 40s - loss: 4.8725 - acc: 0.01 - ETA: 41s - loss: 4.8727 - acc: 0.01 - ETA: 40s - loss: 4.8724 - acc: 0.01 - ETA: 40s - loss: 4.8727 - acc: 0.01 - ETA: 40s - loss: 4.8726 - acc: 0.01 - ETA: 40s - loss: 4.8722 - acc: 0.01 - ETA: 40s - loss: 4.8721 - acc: 0.01 - ETA: 40s - loss: 4.8717 - acc: 0.01 - ETA: 40s - loss: 4.8718 - acc: 0.01 - ETA: 40s - loss: 4.8716 - acc: 0.01 - ETA: 40s - loss: 4.8712 - acc: 0.01 - ETA: 40s - loss: 4.8710 - acc: 0.01 - ETA: 40s - loss: 4.8702 - acc: 0.01 - ETA: 39s - loss: 4.8697 - acc: 0.01 - ETA: 39s - loss: 4.8695 - acc: 0.01 - ETA: 39s - loss: 4.8693 - acc: 0.01 - ETA: 39s - loss: 4.8694 - acc: 0.01 - ETA: 39s - loss: 4.8694 - acc: 0.01 - ETA: 39s - loss: 4.8693 - acc: 0.01 - ETA: 39s - loss: 4.8692 - acc: 0.01 - ETA: 38s - loss: 4.8690 - acc: 0.01 - ETA: 38s - loss: 4.8691 - acc: 0.01 - ETA: 38s - loss: 4.8690 - acc: 0.01 - ETA: 38s - loss: 4.8694 - acc: 0.01 - ETA: 38s - loss: 4.8693 - acc: 0.01 - ETA: 38s - loss: 4.8691 - acc: 0.01 - ETA: 38s - loss: 4.8689 - acc: 0.01 - ETA: 37s - loss: 4.8690 - acc: 0.01 - ETA: 37s - loss: 4.8695 - acc: 0.01 - ETA: 37s - loss: 4.8692 - acc: 0.01 - ETA: 37s - loss: 4.8693 - acc: 0.01 - ETA: 37s - loss: 4.8694 - acc: 0.01 - ETA: 37s - loss: 4.8695 - acc: 0.01 - ETA: 37s - loss: 4.8695 - acc: 0.01 - ETA: 37s - loss: 4.8695 - acc: 0.01 - ETA: 37s - loss: 4.8695 - acc: 0.01 - ETA: 37s - loss: 4.8691 - acc: 0.01 - ETA: 36s - loss: 4.8689 - acc: 0.01 - ETA: 36s - loss: 4.8689 - acc: 0.01 - ETA: 36s - loss: 4.8690 - acc: 0.01 - ETA: 36s - loss: 4.8689 - acc: 0.01 - ETA: 36s - loss: 4.8687 - acc: 0.01 - ETA: 36s - loss: 4.8689 - acc: 0.01 - ETA: 35s - loss: 4.8691 - acc: 0.01 - ETA: 35s - loss: 4.8692 - acc: 0.01 - ETA: 35s - loss: 4.8690 - acc: 0.01 - ETA: 35s - loss: 4.8689 - acc: 0.01 - ETA: 35s - loss: 4.8687 - acc: 0.01 - ETA: 35s - loss: 4.8688 - acc: 0.01 - ETA: 35s - loss: 4.8692 - acc: 0.01 - ETA: 34s - loss: 4.8692 - acc: 0.01 - ETA: 34s - loss: 4.8695 - acc: 0.01 - ETA: 34s - loss: 4.8695 - acc: 0.01 - ETA: 34s - loss: 4.8694 - acc: 0.01 - ETA: 34s - loss: 4.8697 - acc: 0.01 - ETA: 34s - loss: 4.8698 - acc: 0.01 - ETA: 34s - loss: 4.8700 - acc: 0.01 - ETA: 33s - loss: 4.8697 - acc: 0.01 - ETA: 33s - loss: 4.8697 - acc: 0.01 - ETA: 33s - loss: 4.8698 - acc: 0.01 - ETA: 33s - loss: 4.8697 - acc: 0.01 - ETA: 33s - loss: 4.8696 - acc: 0.01 - ETA: 33s - loss: 4.8698 - acc: 0.01 - ETA: 33s - loss: 4.8697 - acc: 0.01 - ETA: 33s - loss: 4.8694 - acc: 0.01 - ETA: 32s - loss: 4.8696 - acc: 0.01 - ETA: 32s - loss: 4.8692 - acc: 0.01 - ETA: 32s - loss: 4.8692 - acc: 0.01 - ETA: 32s - loss: 4.8691 - acc: 0.01 - ETA: 32s - loss: 4.8689 - acc: 0.01 - ETA: 32s - loss: 4.8686 - acc: 0.01 - ETA: 32s - loss: 4.8685 - acc: 0.01 - ETA: 31s - loss: 4.8681 - acc: 0.01 - ETA: 31s - loss: 4.8682 - acc: 0.01 - ETA: 31s - loss: 4.8682 - acc: 0.01 - ETA: 31s - loss: 4.8677 - acc: 0.01 - ETA: 31s - loss: 4.8677 - acc: 0.01 - ETA: 31s - loss: 4.8677 - acc: 0.01 - ETA: 31s - loss: 4.8677 - acc: 0.01 - ETA: 30s - loss: 4.8676 - acc: 0.01 - ETA: 30s - loss: 4.8675 - acc: 0.01 - ETA: 30s - loss: 4.8677 - acc: 0.01 - ETA: 30s - loss: 4.8679 - acc: 0.0126"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8681 - acc: 0.01 - ETA: 30s - loss: 4.8684 - acc: 0.01 - ETA: 30s - loss: 4.8681 - acc: 0.01 - ETA: 29s - loss: 4.8678 - acc: 0.01 - ETA: 29s - loss: 4.8674 - acc: 0.01 - ETA: 29s - loss: 4.8674 - acc: 0.01 - ETA: 29s - loss: 4.8678 - acc: 0.01 - ETA: 29s - loss: 4.8679 - acc: 0.01 - ETA: 29s - loss: 4.8678 - acc: 0.01 - ETA: 29s - loss: 4.8675 - acc: 0.01 - ETA: 28s - loss: 4.8677 - acc: 0.01 - ETA: 28s - loss: 4.8679 - acc: 0.01 - ETA: 28s - loss: 4.8678 - acc: 0.01 - ETA: 28s - loss: 4.8680 - acc: 0.01 - ETA: 28s - loss: 4.8684 - acc: 0.01 - ETA: 28s - loss: 4.8684 - acc: 0.01 - ETA: 27s - loss: 4.8682 - acc: 0.01 - ETA: 27s - loss: 4.8679 - acc: 0.01 - ETA: 27s - loss: 4.8680 - acc: 0.01 - ETA: 27s - loss: 4.8678 - acc: 0.01 - ETA: 27s - loss: 4.8679 - acc: 0.01 - ETA: 27s - loss: 4.8678 - acc: 0.01 - ETA: 27s - loss: 4.8678 - acc: 0.01 - ETA: 26s - loss: 4.8677 - acc: 0.01 - ETA: 26s - loss: 4.8678 - acc: 0.01 - ETA: 26s - loss: 4.8678 - acc: 0.01 - ETA: 26s - loss: 4.8678 - acc: 0.01 - ETA: 26s - loss: 4.8677 - acc: 0.01 - ETA: 26s - loss: 4.8676 - acc: 0.01 - ETA: 26s - loss: 4.8674 - acc: 0.01 - ETA: 25s - loss: 4.8675 - acc: 0.01 - ETA: 25s - loss: 4.8676 - acc: 0.01 - ETA: 25s - loss: 4.8676 - acc: 0.01 - ETA: 25s - loss: 4.8676 - acc: 0.01 - ETA: 25s - loss: 4.8673 - acc: 0.01 - ETA: 25s - loss: 4.8675 - acc: 0.01 - ETA: 25s - loss: 4.8677 - acc: 0.01 - ETA: 24s - loss: 4.8675 - acc: 0.01 - ETA: 24s - loss: 4.8678 - acc: 0.01 - ETA: 24s - loss: 4.8682 - acc: 0.01 - ETA: 24s - loss: 4.8682 - acc: 0.01 - ETA: 24s - loss: 4.8682 - acc: 0.01 - ETA: 24s - loss: 4.8680 - acc: 0.01 - ETA: 23s - loss: 4.8683 - acc: 0.01 - ETA: 23s - loss: 4.8683 - acc: 0.01 - ETA: 23s - loss: 4.8685 - acc: 0.01 - ETA: 23s - loss: 4.8685 - acc: 0.01 - ETA: 23s - loss: 4.8686 - acc: 0.01 - ETA: 23s - loss: 4.8684 - acc: 0.01 - ETA: 22s - loss: 4.8684 - acc: 0.01 - ETA: 22s - loss: 4.8685 - acc: 0.01 - ETA: 22s - loss: 4.8686 - acc: 0.01 - ETA: 22s - loss: 4.8687 - acc: 0.01 - ETA: 22s - loss: 4.8688 - acc: 0.01 - ETA: 22s - loss: 4.8688 - acc: 0.01 - ETA: 21s - loss: 4.8687 - acc: 0.01 - ETA: 21s - loss: 4.8688 - acc: 0.01 - ETA: 21s - loss: 4.8688 - acc: 0.01 - ETA: 21s - loss: 4.8689 - acc: 0.01 - ETA: 21s - loss: 4.8688 - acc: 0.01 - ETA: 21s - loss: 4.8688 - acc: 0.01 - ETA: 20s - loss: 4.8690 - acc: 0.01 - ETA: 20s - loss: 4.8691 - acc: 0.01 - ETA: 20s - loss: 4.8692 - acc: 0.01 - ETA: 20s - loss: 4.8690 - acc: 0.01 - ETA: 20s - loss: 4.8691 - acc: 0.01 - ETA: 20s - loss: 4.8692 - acc: 0.01 - ETA: 20s - loss: 4.8694 - acc: 0.01 - ETA: 19s - loss: 4.8695 - acc: 0.01 - ETA: 19s - loss: 4.8694 - acc: 0.01 - ETA: 19s - loss: 4.8693 - acc: 0.01 - ETA: 19s - loss: 4.8694 - acc: 0.01 - ETA: 19s - loss: 4.8695 - acc: 0.01 - ETA: 19s - loss: 4.8698 - acc: 0.01 - ETA: 18s - loss: 4.8697 - acc: 0.01 - ETA: 18s - loss: 4.8698 - acc: 0.01 - ETA: 18s - loss: 4.8700 - acc: 0.01 - ETA: 18s - loss: 4.8699 - acc: 0.01 - ETA: 18s - loss: 4.8699 - acc: 0.01 - ETA: 18s - loss: 4.8699 - acc: 0.01 - ETA: 17s - loss: 4.8700 - acc: 0.01 - ETA: 17s - loss: 4.8700 - acc: 0.01 - ETA: 17s - loss: 4.8699 - acc: 0.01 - ETA: 17s - loss: 4.8699 - acc: 0.01 - ETA: 17s - loss: 4.8698 - acc: 0.01 - ETA: 17s - loss: 4.8699 - acc: 0.01 - ETA: 16s - loss: 4.8699 - acc: 0.01 - ETA: 16s - loss: 4.8700 - acc: 0.01 - ETA: 16s - loss: 4.8701 - acc: 0.01 - ETA: 16s - loss: 4.8701 - acc: 0.01 - ETA: 16s - loss: 4.8701 - acc: 0.01 - ETA: 16s - loss: 4.8702 - acc: 0.01 - ETA: 16s - loss: 4.8701 - acc: 0.01 - ETA: 15s - loss: 4.8702 - acc: 0.01 - ETA: 15s - loss: 4.8702 - acc: 0.01 - ETA: 15s - loss: 4.8702 - acc: 0.01 - ETA: 15s - loss: 4.8701 - acc: 0.01 - ETA: 15s - loss: 4.8701 - acc: 0.01 - ETA: 15s - loss: 4.8700 - acc: 0.01 - ETA: 14s - loss: 4.8699 - acc: 0.01 - ETA: 14s - loss: 4.8699 - acc: 0.01 - ETA: 14s - loss: 4.8698 - acc: 0.01 - ETA: 14s - loss: 4.8699 - acc: 0.01 - ETA: 14s - loss: 4.8698 - acc: 0.01 - ETA: 14s - loss: 4.8698 - acc: 0.01 - ETA: 14s - loss: 4.8698 - acc: 0.01 - ETA: 13s - loss: 4.8697 - acc: 0.01 - ETA: 13s - loss: 4.8696 - acc: 0.01 - ETA: 13s - loss: 4.8695 - acc: 0.01 - ETA: 13s - loss: 4.8694 - acc: 0.01 - ETA: 13s - loss: 4.8693 - acc: 0.01 - ETA: 13s - loss: 4.8694 - acc: 0.01 - ETA: 12s - loss: 4.8695 - acc: 0.01 - ETA: 12s - loss: 4.8695 - acc: 0.01 - ETA: 12s - loss: 4.8695 - acc: 0.01 - ETA: 12s - loss: 4.8695 - acc: 0.01 - ETA: 12s - loss: 4.8695 - acc: 0.01 - ETA: 12s - loss: 4.8694 - acc: 0.01 - ETA: 12s - loss: 4.8696 - acc: 0.01 - ETA: 11s - loss: 4.8697 - acc: 0.01 - ETA: 11s - loss: 4.8698 - acc: 0.01 - ETA: 11s - loss: 4.8698 - acc: 0.01 - ETA: 11s - loss: 4.8698 - acc: 0.01 - ETA: 11s - loss: 4.8697 - acc: 0.01 - ETA: 11s - loss: 4.8696 - acc: 0.01 - ETA: 10s - loss: 4.8695 - acc: 0.01 - ETA: 10s - loss: 4.8695 - acc: 0.01 - ETA: 10s - loss: 4.8692 - acc: 0.01 - ETA: 10s - loss: 4.8692 - acc: 0.01 - ETA: 10s - loss: 4.8692 - acc: 0.01 - ETA: 10s - loss: 4.8692 - acc: 0.01 - ETA: 9s - loss: 4.8692 - acc: 0.0120 - ETA: 9s - loss: 4.8692 - acc: 0.011 - ETA: 9s - loss: 4.8692 - acc: 0.011 - ETA: 9s - loss: 4.8692 - acc: 0.011 - ETA: 9s - loss: 4.8692 - acc: 0.011 - ETA: 9s - loss: 4.8695 - acc: 0.011 - ETA: 9s - loss: 4.8695 - acc: 0.011 - ETA: 8s - loss: 4.8696 - acc: 0.011 - ETA: 8s - loss: 4.8695 - acc: 0.011 - ETA: 8s - loss: 4.8695 - acc: 0.011 - ETA: 8s - loss: 4.8696 - acc: 0.011 - ETA: 8s - loss: 4.8694 - acc: 0.011 - ETA: 8s - loss: 4.8692 - acc: 0.011 - ETA: 7s - loss: 4.8693 - acc: 0.011 - ETA: 7s - loss: 4.8693 - acc: 0.011 - ETA: 7s - loss: 4.8693 - acc: 0.011 - ETA: 7s - loss: 4.8693 - acc: 0.011 - ETA: 7s - loss: 4.8695 - acc: 0.011 - ETA: 7s - loss: 4.8696 - acc: 0.011 - ETA: 6s - loss: 4.8697 - acc: 0.011 - ETA: 6s - loss: 4.8697 - acc: 0.011 - ETA: 6s - loss: 4.8698 - acc: 0.011 - ETA: 6s - loss: 4.8698 - acc: 0.011 - ETA: 6s - loss: 4.8697 - acc: 0.011 - ETA: 6s - loss: 4.8698 - acc: 0.011 - ETA: 5s - loss: 4.8698 - acc: 0.011 - ETA: 5s - loss: 4.8698 - acc: 0.011 - ETA: 5s - loss: 4.8698 - acc: 0.011 - ETA: 5s - loss: 4.8700 - acc: 0.011 - ETA: 5s - loss: 4.8701 - acc: 0.011 - ETA: 5s - loss: 4.8700 - acc: 0.011 - ETA: 4s - loss: 4.8697 - acc: 0.011 - ETA: 4s - loss: 4.8699 - acc: 0.011 - ETA: 4s - loss: 4.8700 - acc: 0.011 - ETA: 4s - loss: 4.8698 - acc: 0.011 - ETA: 4s - loss: 4.8697 - acc: 0.011 - ETA: 4s - loss: 4.8696 - acc: 0.012 - ETA: 4s - loss: 4.8696 - acc: 0.012 - ETA: 3s - loss: 4.8696 - acc: 0.011 - ETA: 3s - loss: 4.8696 - acc: 0.011 - ETA: 3s - loss: 4.8697 - acc: 0.011 - ETA: 3s - loss: 4.8695 - acc: 0.011 - ETA: 3s - loss: 4.8695 - acc: 0.011 - ETA: 3s - loss: 4.8695 - acc: 0.011 - ETA: 2s - loss: 4.8696 - acc: 0.011 - ETA: 2s - loss: 4.8694 - acc: 0.012 - ETA: 2s - loss: 4.8695 - acc: 0.012 - ETA: 2s - loss: 4.8694 - acc: 0.012 - ETA: 2s - loss: 4.8694 - acc: 0.012 - ETA: 2s - loss: 4.8693 - acc: 0.012 - ETA: 1s - loss: 4.8692 - acc: 0.012 - ETA: 1s - loss: 4.8692 - acc: 0.012 - ETA: 1s - loss: 4.8692 - acc: 0.012 - ETA: 1s - loss: 4.8692 - acc: 0.012 - ETA: 1s - loss: 4.8691 - acc: 0.012 - ETA: 1s - loss: 4.8691 - acc: 0.012 - ETA: 0s - loss: 4.8692 - acc: 0.012 - ETA: 0s - loss: 4.8692 - acc: 0.012 - ETA: 0s - loss: 4.8692 - acc: 0.012 - ETA: 0s - loss: 4.8693 - acc: 0.012 - ETA: 0s - loss: 4.8694 - acc: 0.012 - ETA: 0s - loss: 4.8693 - acc: 0.012 - 71s 170ms/step - loss: 4.8693 - acc: 0.0123 - val_loss: 4.8617 - val_acc: 0.0183\n",
      "\n",
      "Epoch 00018: val_loss improved from 4.86543 to 4.86173, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 6s - loss: 4.9716 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8893 - acc: 0.0469    - ETA: 6s - loss: 4.8710 - acc: 0.039 - ETA: 6s - loss: 4.8809 - acc: 0.028 - ETA: 19s - loss: 4.8753 - acc: 0.02 - ETA: 21s - loss: 4.8762 - acc: 0.02 - ETA: 24s - loss: 4.8787 - acc: 0.02 - ETA: 25s - loss: 4.8787 - acc: 0.02 - ETA: 31s - loss: 4.8738 - acc: 0.02 - ETA: 36s - loss: 4.8737 - acc: 0.02 - ETA: 39s - loss: 4.8714 - acc: 0.02 - ETA: 39s - loss: 4.8688 - acc: 0.02 - ETA: 41s - loss: 4.8682 - acc: 0.02 - ETA: 42s - loss: 4.8669 - acc: 0.02 - ETA: 43s - loss: 4.8658 - acc: 0.02 - ETA: 45s - loss: 4.8690 - acc: 0.02 - ETA: 45s - loss: 4.8676 - acc: 0.02 - ETA: 45s - loss: 4.8660 - acc: 0.02 - ETA: 45s - loss: 4.8638 - acc: 0.02 - ETA: 46s - loss: 4.8638 - acc: 0.02 - ETA: 46s - loss: 4.8650 - acc: 0.01 - ETA: 47s - loss: 4.8642 - acc: 0.01 - ETA: 47s - loss: 4.8658 - acc: 0.01 - ETA: 47s - loss: 4.8673 - acc: 0.01 - ETA: 48s - loss: 4.8654 - acc: 0.02 - ETA: 47s - loss: 4.8648 - acc: 0.02 - ETA: 47s - loss: 4.8659 - acc: 0.02 - ETA: 49s - loss: 4.8658 - acc: 0.02 - ETA: 48s - loss: 4.8650 - acc: 0.02 - ETA: 48s - loss: 4.8636 - acc: 0.02 - ETA: 48s - loss: 4.8639 - acc: 0.02 - ETA: 48s - loss: 4.8635 - acc: 0.02 - ETA: 48s - loss: 4.8644 - acc: 0.01 - ETA: 48s - loss: 4.8657 - acc: 0.01 - ETA: 47s - loss: 4.8668 - acc: 0.01 - ETA: 47s - loss: 4.8669 - acc: 0.01 - ETA: 47s - loss: 4.8683 - acc: 0.01 - ETA: 47s - loss: 4.8687 - acc: 0.01 - ETA: 48s - loss: 4.8691 - acc: 0.01 - ETA: 48s - loss: 4.8707 - acc: 0.01 - ETA: 48s - loss: 4.8716 - acc: 0.01 - ETA: 48s - loss: 4.8713 - acc: 0.01 - ETA: 48s - loss: 4.8698 - acc: 0.01 - ETA: 48s - loss: 4.8705 - acc: 0.01 - ETA: 48s - loss: 4.8691 - acc: 0.01 - ETA: 48s - loss: 4.8692 - acc: 0.01 - ETA: 48s - loss: 4.8681 - acc: 0.01 - ETA: 48s - loss: 4.8674 - acc: 0.01 - ETA: 48s - loss: 4.8672 - acc: 0.01 - ETA: 48s - loss: 4.8671 - acc: 0.01 - ETA: 48s - loss: 4.8670 - acc: 0.01 - ETA: 48s - loss: 4.8661 - acc: 0.01 - ETA: 49s - loss: 4.8663 - acc: 0.01 - ETA: 48s - loss: 4.8670 - acc: 0.01 - ETA: 48s - loss: 4.8668 - acc: 0.01 - ETA: 48s - loss: 4.8673 - acc: 0.01 - ETA: 48s - loss: 4.8681 - acc: 0.01 - ETA: 48s - loss: 4.8682 - acc: 0.01 - ETA: 49s - loss: 4.8676 - acc: 0.01 - ETA: 48s - loss: 4.8662 - acc: 0.01 - ETA: 49s - loss: 4.8670 - acc: 0.01 - ETA: 48s - loss: 4.8667 - acc: 0.01 - ETA: 48s - loss: 4.8665 - acc: 0.01 - ETA: 48s - loss: 4.8656 - acc: 0.01 - ETA: 48s - loss: 4.8658 - acc: 0.01 - ETA: 48s - loss: 4.8663 - acc: 0.01 - ETA: 48s - loss: 4.8661 - acc: 0.01 - ETA: 48s - loss: 4.8657 - acc: 0.01 - ETA: 48s - loss: 4.8662 - acc: 0.01 - ETA: 47s - loss: 4.8672 - acc: 0.01 - ETA: 47s - loss: 4.8673 - acc: 0.01 - ETA: 47s - loss: 4.8676 - acc: 0.01 - ETA: 47s - loss: 4.8680 - acc: 0.01 - ETA: 47s - loss: 4.8677 - acc: 0.01 - ETA: 47s - loss: 4.8676 - acc: 0.01 - ETA: 47s - loss: 4.8682 - acc: 0.01 - ETA: 46s - loss: 4.8691 - acc: 0.01 - ETA: 46s - loss: 4.8693 - acc: 0.01 - ETA: 46s - loss: 4.8692 - acc: 0.01 - ETA: 47s - loss: 4.8693 - acc: 0.01 - ETA: 47s - loss: 4.8692 - acc: 0.01 - ETA: 47s - loss: 4.8689 - acc: 0.01 - ETA: 47s - loss: 4.8690 - acc: 0.01 - ETA: 47s - loss: 4.8692 - acc: 0.01 - ETA: 47s - loss: 4.8692 - acc: 0.01 - ETA: 46s - loss: 4.8689 - acc: 0.01 - ETA: 46s - loss: 4.8691 - acc: 0.01 - ETA: 46s - loss: 4.8692 - acc: 0.01 - ETA: 46s - loss: 4.8694 - acc: 0.01 - ETA: 46s - loss: 4.8692 - acc: 0.01 - ETA: 46s - loss: 4.8697 - acc: 0.01 - ETA: 46s - loss: 4.8697 - acc: 0.01 - ETA: 46s - loss: 4.8698 - acc: 0.01 - ETA: 46s - loss: 4.8688 - acc: 0.01 - ETA: 46s - loss: 4.8687 - acc: 0.01 - ETA: 46s - loss: 4.8688 - acc: 0.01 - ETA: 46s - loss: 4.8688 - acc: 0.01 - ETA: 46s - loss: 4.8693 - acc: 0.01 - ETA: 46s - loss: 4.8691 - acc: 0.01 - ETA: 45s - loss: 4.8688 - acc: 0.01 - ETA: 45s - loss: 4.8689 - acc: 0.01 - ETA: 45s - loss: 4.8691 - acc: 0.01 - ETA: 45s - loss: 4.8692 - acc: 0.01 - ETA: 45s - loss: 4.8693 - acc: 0.01 - ETA: 44s - loss: 4.8695 - acc: 0.01 - ETA: 44s - loss: 4.8696 - acc: 0.01 - ETA: 44s - loss: 4.8698 - acc: 0.01 - ETA: 44s - loss: 4.8699 - acc: 0.01 - ETA: 44s - loss: 4.8704 - acc: 0.01 - ETA: 44s - loss: 4.8702 - acc: 0.01 - ETA: 44s - loss: 4.8705 - acc: 0.01 - ETA: 43s - loss: 4.8705 - acc: 0.01 - ETA: 43s - loss: 4.8703 - acc: 0.01 - ETA: 43s - loss: 4.8703 - acc: 0.01 - ETA: 43s - loss: 4.8705 - acc: 0.01 - ETA: 43s - loss: 4.8705 - acc: 0.01 - ETA: 43s - loss: 4.8701 - acc: 0.01 - ETA: 43s - loss: 4.8703 - acc: 0.01 - ETA: 42s - loss: 4.8706 - acc: 0.01 - ETA: 42s - loss: 4.8700 - acc: 0.01 - ETA: 42s - loss: 4.8700 - acc: 0.01 - ETA: 42s - loss: 4.8697 - acc: 0.01 - ETA: 42s - loss: 4.8703 - acc: 0.01 - ETA: 42s - loss: 4.8704 - acc: 0.01 - ETA: 42s - loss: 4.8702 - acc: 0.01 - ETA: 42s - loss: 4.8703 - acc: 0.01 - ETA: 42s - loss: 4.8701 - acc: 0.01 - ETA: 41s - loss: 4.8701 - acc: 0.01 - ETA: 41s - loss: 4.8703 - acc: 0.01 - ETA: 41s - loss: 4.8699 - acc: 0.01 - ETA: 41s - loss: 4.8702 - acc: 0.01 - ETA: 41s - loss: 4.8702 - acc: 0.01 - ETA: 41s - loss: 4.8699 - acc: 0.01 - ETA: 41s - loss: 4.8701 - acc: 0.01 - ETA: 41s - loss: 4.8699 - acc: 0.01 - ETA: 40s - loss: 4.8697 - acc: 0.01 - ETA: 40s - loss: 4.8699 - acc: 0.01 - ETA: 40s - loss: 4.8697 - acc: 0.01 - ETA: 40s - loss: 4.8695 - acc: 0.01 - ETA: 40s - loss: 4.8691 - acc: 0.01 - ETA: 40s - loss: 4.8690 - acc: 0.01 - ETA: 40s - loss: 4.8690 - acc: 0.01 - ETA: 40s - loss: 4.8689 - acc: 0.01 - ETA: 40s - loss: 4.8691 - acc: 0.01 - ETA: 40s - loss: 4.8691 - acc: 0.01 - ETA: 39s - loss: 4.8687 - acc: 0.01 - ETA: 39s - loss: 4.8688 - acc: 0.01 - ETA: 39s - loss: 4.8683 - acc: 0.01 - ETA: 39s - loss: 4.8683 - acc: 0.01 - ETA: 39s - loss: 4.8682 - acc: 0.01 - ETA: 39s - loss: 4.8680 - acc: 0.01 - ETA: 38s - loss: 4.8682 - acc: 0.01 - ETA: 38s - loss: 4.8683 - acc: 0.01 - ETA: 38s - loss: 4.8683 - acc: 0.01 - ETA: 38s - loss: 4.8687 - acc: 0.01 - ETA: 38s - loss: 4.8681 - acc: 0.01 - ETA: 38s - loss: 4.8684 - acc: 0.01 - ETA: 38s - loss: 4.8682 - acc: 0.01 - ETA: 38s - loss: 4.8684 - acc: 0.01 - ETA: 37s - loss: 4.8686 - acc: 0.01 - ETA: 37s - loss: 4.8687 - acc: 0.01 - ETA: 37s - loss: 4.8684 - acc: 0.01 - ETA: 37s - loss: 4.8686 - acc: 0.01 - ETA: 37s - loss: 4.8688 - acc: 0.01 - ETA: 37s - loss: 4.8686 - acc: 0.01 - ETA: 37s - loss: 4.8684 - acc: 0.01 - ETA: 36s - loss: 4.8682 - acc: 0.01 - ETA: 36s - loss: 4.8678 - acc: 0.01 - ETA: 36s - loss: 4.8678 - acc: 0.01 - ETA: 36s - loss: 4.8682 - acc: 0.01 - ETA: 36s - loss: 4.8679 - acc: 0.01 - ETA: 36s - loss: 4.8679 - acc: 0.01 - ETA: 36s - loss: 4.8679 - acc: 0.01 - ETA: 36s - loss: 4.8682 - acc: 0.01 - ETA: 35s - loss: 4.8684 - acc: 0.01 - ETA: 35s - loss: 4.8684 - acc: 0.01 - ETA: 35s - loss: 4.8687 - acc: 0.01 - ETA: 35s - loss: 4.8689 - acc: 0.01 - ETA: 35s - loss: 4.8688 - acc: 0.01 - ETA: 35s - loss: 4.8690 - acc: 0.01 - ETA: 35s - loss: 4.8691 - acc: 0.01 - ETA: 34s - loss: 4.8690 - acc: 0.01 - ETA: 34s - loss: 4.8690 - acc: 0.01 - ETA: 34s - loss: 4.8690 - acc: 0.01 - ETA: 34s - loss: 4.8690 - acc: 0.01 - ETA: 34s - loss: 4.8692 - acc: 0.01 - ETA: 34s - loss: 4.8692 - acc: 0.01 - ETA: 34s - loss: 4.8689 - acc: 0.01 - ETA: 33s - loss: 4.8692 - acc: 0.01 - ETA: 33s - loss: 4.8695 - acc: 0.01 - ETA: 33s - loss: 4.8693 - acc: 0.01 - ETA: 33s - loss: 4.8694 - acc: 0.01 - ETA: 33s - loss: 4.8693 - acc: 0.01 - ETA: 33s - loss: 4.8692 - acc: 0.01 - ETA: 33s - loss: 4.8697 - acc: 0.01 - ETA: 32s - loss: 4.8696 - acc: 0.01 - ETA: 32s - loss: 4.8696 - acc: 0.01 - ETA: 32s - loss: 4.8696 - acc: 0.01 - ETA: 32s - loss: 4.8697 - acc: 0.01 - ETA: 32s - loss: 4.8699 - acc: 0.01 - ETA: 32s - loss: 4.8701 - acc: 0.01 - ETA: 31s - loss: 4.8700 - acc: 0.01 - ETA: 31s - loss: 4.8700 - acc: 0.01 - ETA: 31s - loss: 4.8700 - acc: 0.01 - ETA: 31s - loss: 4.8704 - acc: 0.01 - ETA: 31s - loss: 4.8704 - acc: 0.01 - ETA: 31s - loss: 4.8703 - acc: 0.01 - ETA: 31s - loss: 4.8703 - acc: 0.01 - ETA: 31s - loss: 4.8705 - acc: 0.01 - ETA: 30s - loss: 4.8705 - acc: 0.01 - ETA: 30s - loss: 4.8705 - acc: 0.01 - ETA: 30s - loss: 4.8705 - acc: 0.01 - ETA: 30s - loss: 4.8707 - acc: 0.01 - ETA: 30s - loss: 4.8709 - acc: 0.01 - ETA: 30s - loss: 4.8709 - acc: 0.0149"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8712 - acc: 0.01 - ETA: 29s - loss: 4.8714 - acc: 0.01 - ETA: 29s - loss: 4.8713 - acc: 0.01 - ETA: 29s - loss: 4.8712 - acc: 0.01 - ETA: 29s - loss: 4.8711 - acc: 0.01 - ETA: 29s - loss: 4.8709 - acc: 0.01 - ETA: 29s - loss: 4.8708 - acc: 0.01 - ETA: 29s - loss: 4.8710 - acc: 0.01 - ETA: 28s - loss: 4.8709 - acc: 0.01 - ETA: 28s - loss: 4.8708 - acc: 0.01 - ETA: 28s - loss: 4.8706 - acc: 0.01 - ETA: 28s - loss: 4.8704 - acc: 0.01 - ETA: 28s - loss: 4.8704 - acc: 0.01 - ETA: 28s - loss: 4.8705 - acc: 0.01 - ETA: 28s - loss: 4.8706 - acc: 0.01 - ETA: 28s - loss: 4.8703 - acc: 0.01 - ETA: 27s - loss: 4.8702 - acc: 0.01 - ETA: 27s - loss: 4.8702 - acc: 0.01 - ETA: 27s - loss: 4.8704 - acc: 0.01 - ETA: 27s - loss: 4.8705 - acc: 0.01 - ETA: 27s - loss: 4.8706 - acc: 0.01 - ETA: 27s - loss: 4.8701 - acc: 0.01 - ETA: 27s - loss: 4.8700 - acc: 0.01 - ETA: 26s - loss: 4.8698 - acc: 0.01 - ETA: 26s - loss: 4.8698 - acc: 0.01 - ETA: 26s - loss: 4.8697 - acc: 0.01 - ETA: 26s - loss: 4.8697 - acc: 0.01 - ETA: 26s - loss: 4.8693 - acc: 0.01 - ETA: 26s - loss: 4.8689 - acc: 0.01 - ETA: 25s - loss: 4.8687 - acc: 0.01 - ETA: 25s - loss: 4.8686 - acc: 0.01 - ETA: 25s - loss: 4.8687 - acc: 0.01 - ETA: 25s - loss: 4.8688 - acc: 0.01 - ETA: 25s - loss: 4.8687 - acc: 0.01 - ETA: 25s - loss: 4.8685 - acc: 0.01 - ETA: 24s - loss: 4.8682 - acc: 0.01 - ETA: 24s - loss: 4.8680 - acc: 0.01 - ETA: 24s - loss: 4.8682 - acc: 0.01 - ETA: 24s - loss: 4.8682 - acc: 0.01 - ETA: 24s - loss: 4.8683 - acc: 0.01 - ETA: 24s - loss: 4.8683 - acc: 0.01 - ETA: 24s - loss: 4.8685 - acc: 0.01 - ETA: 23s - loss: 4.8688 - acc: 0.01 - ETA: 23s - loss: 4.8687 - acc: 0.01 - ETA: 23s - loss: 4.8684 - acc: 0.01 - ETA: 23s - loss: 4.8686 - acc: 0.01 - ETA: 23s - loss: 4.8688 - acc: 0.01 - ETA: 23s - loss: 4.8690 - acc: 0.01 - ETA: 23s - loss: 4.8691 - acc: 0.01 - ETA: 22s - loss: 4.8690 - acc: 0.01 - ETA: 22s - loss: 4.8689 - acc: 0.01 - ETA: 22s - loss: 4.8689 - acc: 0.01 - ETA: 22s - loss: 4.8686 - acc: 0.01 - ETA: 22s - loss: 4.8684 - acc: 0.01 - ETA: 22s - loss: 4.8685 - acc: 0.01 - ETA: 22s - loss: 4.8684 - acc: 0.01 - ETA: 21s - loss: 4.8684 - acc: 0.01 - ETA: 21s - loss: 4.8680 - acc: 0.01 - ETA: 21s - loss: 4.8679 - acc: 0.01 - ETA: 21s - loss: 4.8680 - acc: 0.01 - ETA: 21s - loss: 4.8681 - acc: 0.01 - ETA: 21s - loss: 4.8682 - acc: 0.01 - ETA: 20s - loss: 4.8684 - acc: 0.01 - ETA: 20s - loss: 4.8682 - acc: 0.01 - ETA: 20s - loss: 4.8683 - acc: 0.01 - ETA: 20s - loss: 4.8682 - acc: 0.01 - ETA: 20s - loss: 4.8685 - acc: 0.01 - ETA: 20s - loss: 4.8684 - acc: 0.01 - ETA: 19s - loss: 4.8684 - acc: 0.01 - ETA: 19s - loss: 4.8687 - acc: 0.01 - ETA: 19s - loss: 4.8688 - acc: 0.01 - ETA: 19s - loss: 4.8688 - acc: 0.01 - ETA: 19s - loss: 4.8689 - acc: 0.01 - ETA: 19s - loss: 4.8690 - acc: 0.01 - ETA: 19s - loss: 4.8689 - acc: 0.01 - ETA: 18s - loss: 4.8690 - acc: 0.01 - ETA: 18s - loss: 4.8691 - acc: 0.01 - ETA: 18s - loss: 4.8693 - acc: 0.01 - ETA: 18s - loss: 4.8692 - acc: 0.01 - ETA: 18s - loss: 4.8695 - acc: 0.01 - ETA: 18s - loss: 4.8696 - acc: 0.01 - ETA: 17s - loss: 4.8696 - acc: 0.01 - ETA: 17s - loss: 4.8697 - acc: 0.01 - ETA: 17s - loss: 4.8698 - acc: 0.01 - ETA: 17s - loss: 4.8698 - acc: 0.01 - ETA: 17s - loss: 4.8700 - acc: 0.01 - ETA: 17s - loss: 4.8697 - acc: 0.01 - ETA: 17s - loss: 4.8697 - acc: 0.01 - ETA: 16s - loss: 4.8699 - acc: 0.01 - ETA: 16s - loss: 4.8698 - acc: 0.01 - ETA: 16s - loss: 4.8698 - acc: 0.01 - ETA: 16s - loss: 4.8696 - acc: 0.01 - ETA: 16s - loss: 4.8695 - acc: 0.01 - ETA: 16s - loss: 4.8696 - acc: 0.01 - ETA: 15s - loss: 4.8697 - acc: 0.01 - ETA: 15s - loss: 4.8696 - acc: 0.01 - ETA: 15s - loss: 4.8697 - acc: 0.01 - ETA: 15s - loss: 4.8698 - acc: 0.01 - ETA: 15s - loss: 4.8697 - acc: 0.01 - ETA: 15s - loss: 4.8697 - acc: 0.01 - ETA: 14s - loss: 4.8699 - acc: 0.01 - ETA: 14s - loss: 4.8698 - acc: 0.01 - ETA: 14s - loss: 4.8696 - acc: 0.01 - ETA: 14s - loss: 4.8698 - acc: 0.01 - ETA: 14s - loss: 4.8699 - acc: 0.01 - ETA: 14s - loss: 4.8700 - acc: 0.01 - ETA: 13s - loss: 4.8701 - acc: 0.01 - ETA: 13s - loss: 4.8701 - acc: 0.01 - ETA: 13s - loss: 4.8703 - acc: 0.01 - ETA: 13s - loss: 4.8703 - acc: 0.01 - ETA: 13s - loss: 4.8701 - acc: 0.01 - ETA: 13s - loss: 4.8701 - acc: 0.01 - ETA: 12s - loss: 4.8702 - acc: 0.01 - ETA: 12s - loss: 4.8702 - acc: 0.01 - ETA: 12s - loss: 4.8702 - acc: 0.01 - ETA: 12s - loss: 4.8702 - acc: 0.01 - ETA: 12s - loss: 4.8703 - acc: 0.01 - ETA: 12s - loss: 4.8705 - acc: 0.01 - ETA: 12s - loss: 4.8704 - acc: 0.01 - ETA: 11s - loss: 4.8705 - acc: 0.01 - ETA: 11s - loss: 4.8704 - acc: 0.01 - ETA: 11s - loss: 4.8704 - acc: 0.01 - ETA: 11s - loss: 4.8706 - acc: 0.01 - ETA: 11s - loss: 4.8705 - acc: 0.01 - ETA: 11s - loss: 4.8703 - acc: 0.01 - ETA: 10s - loss: 4.8702 - acc: 0.01 - ETA: 10s - loss: 4.8704 - acc: 0.01 - ETA: 10s - loss: 4.8703 - acc: 0.01 - ETA: 10s - loss: 4.8702 - acc: 0.01 - ETA: 10s - loss: 4.8702 - acc: 0.01 - ETA: 10s - loss: 4.8701 - acc: 0.01 - ETA: 9s - loss: 4.8700 - acc: 0.0139 - ETA: 9s - loss: 4.8701 - acc: 0.013 - ETA: 9s - loss: 4.8701 - acc: 0.013 - ETA: 9s - loss: 4.8700 - acc: 0.013 - ETA: 9s - loss: 4.8699 - acc: 0.013 - ETA: 9s - loss: 4.8698 - acc: 0.013 - ETA: 8s - loss: 4.8696 - acc: 0.013 - ETA: 8s - loss: 4.8696 - acc: 0.013 - ETA: 8s - loss: 4.8694 - acc: 0.013 - ETA: 8s - loss: 4.8692 - acc: 0.013 - ETA: 8s - loss: 4.8693 - acc: 0.013 - ETA: 8s - loss: 4.8694 - acc: 0.013 - ETA: 8s - loss: 4.8695 - acc: 0.013 - ETA: 7s - loss: 4.8698 - acc: 0.013 - ETA: 7s - loss: 4.8696 - acc: 0.013 - ETA: 7s - loss: 4.8699 - acc: 0.013 - ETA: 7s - loss: 4.8699 - acc: 0.013 - ETA: 7s - loss: 4.8699 - acc: 0.013 - ETA: 7s - loss: 4.8699 - acc: 0.013 - ETA: 6s - loss: 4.8701 - acc: 0.013 - ETA: 6s - loss: 4.8702 - acc: 0.013 - ETA: 6s - loss: 4.8701 - acc: 0.013 - ETA: 6s - loss: 4.8701 - acc: 0.013 - ETA: 6s - loss: 4.8700 - acc: 0.013 - ETA: 6s - loss: 4.8697 - acc: 0.013 - ETA: 5s - loss: 4.8696 - acc: 0.013 - ETA: 5s - loss: 4.8693 - acc: 0.013 - ETA: 5s - loss: 4.8696 - acc: 0.013 - ETA: 5s - loss: 4.8693 - acc: 0.014 - ETA: 5s - loss: 4.8691 - acc: 0.014 - ETA: 5s - loss: 4.8690 - acc: 0.014 - ETA: 4s - loss: 4.8689 - acc: 0.014 - ETA: 4s - loss: 4.8687 - acc: 0.014 - ETA: 4s - loss: 4.8688 - acc: 0.014 - ETA: 4s - loss: 4.8687 - acc: 0.014 - ETA: 4s - loss: 4.8688 - acc: 0.014 - ETA: 4s - loss: 4.8689 - acc: 0.014 - ETA: 4s - loss: 4.8689 - acc: 0.014 - ETA: 3s - loss: 4.8689 - acc: 0.014 - ETA: 3s - loss: 4.8691 - acc: 0.014 - ETA: 3s - loss: 4.8690 - acc: 0.014 - ETA: 3s - loss: 4.8691 - acc: 0.014 - ETA: 3s - loss: 4.8689 - acc: 0.014 - ETA: 3s - loss: 4.8689 - acc: 0.014 - ETA: 2s - loss: 4.8689 - acc: 0.014 - ETA: 2s - loss: 4.8689 - acc: 0.014 - ETA: 2s - loss: 4.8688 - acc: 0.014 - ETA: 2s - loss: 4.8689 - acc: 0.014 - ETA: 2s - loss: 4.8690 - acc: 0.014 - ETA: 2s - loss: 4.8687 - acc: 0.015 - ETA: 1s - loss: 4.8688 - acc: 0.015 - ETA: 1s - loss: 4.8688 - acc: 0.014 - ETA: 1s - loss: 4.8686 - acc: 0.014 - ETA: 1s - loss: 4.8687 - acc: 0.014 - ETA: 1s - loss: 4.8685 - acc: 0.014 - ETA: 1s - loss: 4.8685 - acc: 0.014 - ETA: 0s - loss: 4.8687 - acc: 0.014 - ETA: 0s - loss: 4.8687 - acc: 0.014 - ETA: 0s - loss: 4.8688 - acc: 0.014 - ETA: 0s - loss: 4.8687 - acc: 0.014 - ETA: 0s - loss: 4.8688 - acc: 0.014 - ETA: 0s - loss: 4.8688 - acc: 0.014 - 71s 171ms/step - loss: 4.8691 - acc: 0.0147 - val_loss: 4.8618 - val_acc: 0.0171\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 4.86173\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 6s - loss: 4.8112 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8600 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8650 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8645 - acc: 0.0052    - ETA: 12s - loss: 4.8651 - acc: 0.00 - ETA: 18s - loss: 4.8618 - acc: 0.00 - ETA: 25s - loss: 4.8595 - acc: 0.01 - ETA: 28s - loss: 4.8616 - acc: 0.01 - ETA: 30s - loss: 4.8608 - acc: 0.01 - ETA: 32s - loss: 4.8566 - acc: 0.01 - ETA: 35s - loss: 4.8555 - acc: 0.00 - ETA: 37s - loss: 4.8575 - acc: 0.00 - ETA: 37s - loss: 4.8615 - acc: 0.00 - ETA: 37s - loss: 4.8597 - acc: 0.00 - ETA: 38s - loss: 4.8615 - acc: 0.00 - ETA: 39s - loss: 4.8632 - acc: 0.00 - ETA: 40s - loss: 4.8626 - acc: 0.00 - ETA: 41s - loss: 4.8644 - acc: 0.00 - ETA: 41s - loss: 4.8627 - acc: 0.01 - ETA: 42s - loss: 4.8610 - acc: 0.01 - ETA: 42s - loss: 4.8611 - acc: 0.01 - ETA: 43s - loss: 4.8615 - acc: 0.01 - ETA: 45s - loss: 4.8612 - acc: 0.01 - ETA: 46s - loss: 4.8636 - acc: 0.01 - ETA: 46s - loss: 4.8639 - acc: 0.01 - ETA: 46s - loss: 4.8664 - acc: 0.01 - ETA: 46s - loss: 4.8680 - acc: 0.01 - ETA: 47s - loss: 4.8692 - acc: 0.01 - ETA: 46s - loss: 4.8677 - acc: 0.01 - ETA: 47s - loss: 4.8678 - acc: 0.01 - ETA: 48s - loss: 4.8647 - acc: 0.01 - ETA: 48s - loss: 4.8647 - acc: 0.01 - ETA: 48s - loss: 4.8662 - acc: 0.01 - ETA: 48s - loss: 4.8631 - acc: 0.01 - ETA: 48s - loss: 4.8623 - acc: 0.01 - ETA: 48s - loss: 4.8614 - acc: 0.01 - ETA: 50s - loss: 4.8610 - acc: 0.01 - ETA: 50s - loss: 4.8617 - acc: 0.01 - ETA: 50s - loss: 4.8614 - acc: 0.01 - ETA: 50s - loss: 4.8622 - acc: 0.01 - ETA: 50s - loss: 4.8611 - acc: 0.01 - ETA: 50s - loss: 4.8619 - acc: 0.01 - ETA: 50s - loss: 4.8627 - acc: 0.01 - ETA: 50s - loss: 4.8618 - acc: 0.01 - ETA: 49s - loss: 4.8616 - acc: 0.01 - ETA: 49s - loss: 4.8621 - acc: 0.01 - ETA: 49s - loss: 4.8632 - acc: 0.01 - ETA: 50s - loss: 4.8629 - acc: 0.01 - ETA: 50s - loss: 4.8634 - acc: 0.01 - ETA: 50s - loss: 4.8640 - acc: 0.01 - ETA: 50s - loss: 4.8636 - acc: 0.01 - ETA: 50s - loss: 4.8631 - acc: 0.01 - ETA: 50s - loss: 4.8637 - acc: 0.01 - ETA: 50s - loss: 4.8628 - acc: 0.01 - ETA: 50s - loss: 4.8629 - acc: 0.01 - ETA: 50s - loss: 4.8625 - acc: 0.01 - ETA: 50s - loss: 4.8632 - acc: 0.01 - ETA: 50s - loss: 4.8636 - acc: 0.01 - ETA: 50s - loss: 4.8632 - acc: 0.01 - ETA: 50s - loss: 4.8637 - acc: 0.01 - ETA: 51s - loss: 4.8635 - acc: 0.01 - ETA: 51s - loss: 4.8643 - acc: 0.01 - ETA: 51s - loss: 4.8649 - acc: 0.01 - ETA: 51s - loss: 4.8654 - acc: 0.01 - ETA: 50s - loss: 4.8649 - acc: 0.01 - ETA: 50s - loss: 4.8656 - acc: 0.01 - ETA: 50s - loss: 4.8639 - acc: 0.01 - ETA: 50s - loss: 4.8639 - acc: 0.01 - ETA: 51s - loss: 4.8645 - acc: 0.01 - ETA: 51s - loss: 4.8639 - acc: 0.01 - ETA: 50s - loss: 4.8643 - acc: 0.01 - ETA: 50s - loss: 4.8641 - acc: 0.01 - ETA: 50s - loss: 4.8637 - acc: 0.01 - ETA: 50s - loss: 4.8643 - acc: 0.01 - ETA: 50s - loss: 4.8639 - acc: 0.01 - ETA: 50s - loss: 4.8635 - acc: 0.01 - ETA: 50s - loss: 4.8633 - acc: 0.01 - ETA: 50s - loss: 4.8629 - acc: 0.01 - ETA: 50s - loss: 4.8627 - acc: 0.01 - ETA: 49s - loss: 4.8628 - acc: 0.01 - ETA: 49s - loss: 4.8623 - acc: 0.01 - ETA: 49s - loss: 4.8622 - acc: 0.01 - ETA: 49s - loss: 4.8622 - acc: 0.01 - ETA: 49s - loss: 4.8632 - acc: 0.01 - ETA: 49s - loss: 4.8634 - acc: 0.01 - ETA: 48s - loss: 4.8635 - acc: 0.01 - ETA: 48s - loss: 4.8637 - acc: 0.01 - ETA: 49s - loss: 4.8639 - acc: 0.01 - ETA: 48s - loss: 4.8638 - acc: 0.01 - ETA: 48s - loss: 4.8642 - acc: 0.01 - ETA: 48s - loss: 4.8647 - acc: 0.01 - ETA: 48s - loss: 4.8645 - acc: 0.01 - ETA: 48s - loss: 4.8645 - acc: 0.01 - ETA: 48s - loss: 4.8639 - acc: 0.01 - ETA: 48s - loss: 4.8641 - acc: 0.01 - ETA: 48s - loss: 4.8646 - acc: 0.01 - ETA: 48s - loss: 4.8649 - acc: 0.01 - ETA: 48s - loss: 4.8646 - acc: 0.01 - ETA: 48s - loss: 4.8648 - acc: 0.01 - ETA: 48s - loss: 4.8647 - acc: 0.01 - ETA: 48s - loss: 4.8653 - acc: 0.01 - ETA: 48s - loss: 4.8655 - acc: 0.01 - ETA: 47s - loss: 4.8660 - acc: 0.01 - ETA: 48s - loss: 4.8665 - acc: 0.01 - ETA: 48s - loss: 4.8664 - acc: 0.01 - ETA: 47s - loss: 4.8668 - acc: 0.01 - ETA: 47s - loss: 4.8664 - acc: 0.01 - ETA: 47s - loss: 4.8664 - acc: 0.01 - ETA: 47s - loss: 4.8662 - acc: 0.01 - ETA: 46s - loss: 4.8669 - acc: 0.01 - ETA: 46s - loss: 4.8670 - acc: 0.01 - ETA: 46s - loss: 4.8670 - acc: 0.01 - ETA: 46s - loss: 4.8668 - acc: 0.01 - ETA: 46s - loss: 4.8668 - acc: 0.01 - ETA: 45s - loss: 4.8670 - acc: 0.01 - ETA: 45s - loss: 4.8671 - acc: 0.01 - ETA: 45s - loss: 4.8674 - acc: 0.01 - ETA: 45s - loss: 4.8673 - acc: 0.01 - ETA: 45s - loss: 4.8669 - acc: 0.01 - ETA: 45s - loss: 4.8669 - acc: 0.01 - ETA: 44s - loss: 4.8673 - acc: 0.01 - ETA: 44s - loss: 4.8674 - acc: 0.01 - ETA: 44s - loss: 4.8677 - acc: 0.01 - ETA: 44s - loss: 4.8670 - acc: 0.01 - ETA: 43s - loss: 4.8673 - acc: 0.01 - ETA: 43s - loss: 4.8672 - acc: 0.01 - ETA: 43s - loss: 4.8673 - acc: 0.01 - ETA: 43s - loss: 4.8673 - acc: 0.01 - ETA: 43s - loss: 4.8675 - acc: 0.01 - ETA: 43s - loss: 4.8677 - acc: 0.01 - ETA: 43s - loss: 4.8674 - acc: 0.01 - ETA: 43s - loss: 4.8669 - acc: 0.01 - ETA: 43s - loss: 4.8670 - acc: 0.01 - ETA: 42s - loss: 4.8665 - acc: 0.01 - ETA: 42s - loss: 4.8663 - acc: 0.01 - ETA: 42s - loss: 4.8664 - acc: 0.01 - ETA: 42s - loss: 4.8662 - acc: 0.01 - ETA: 42s - loss: 4.8662 - acc: 0.01 - ETA: 42s - loss: 4.8659 - acc: 0.01 - ETA: 42s - loss: 4.8659 - acc: 0.01 - ETA: 42s - loss: 4.8657 - acc: 0.01 - ETA: 42s - loss: 4.8656 - acc: 0.01 - ETA: 42s - loss: 4.8654 - acc: 0.01 - ETA: 42s - loss: 4.8651 - acc: 0.01 - ETA: 41s - loss: 4.8646 - acc: 0.01 - ETA: 41s - loss: 4.8643 - acc: 0.01 - ETA: 41s - loss: 4.8645 - acc: 0.01 - ETA: 41s - loss: 4.8649 - acc: 0.01 - ETA: 41s - loss: 4.8651 - acc: 0.01 - ETA: 40s - loss: 4.8648 - acc: 0.01 - ETA: 40s - loss: 4.8649 - acc: 0.01 - ETA: 40s - loss: 4.8652 - acc: 0.01 - ETA: 40s - loss: 4.8653 - acc: 0.01 - ETA: 40s - loss: 4.8650 - acc: 0.01 - ETA: 40s - loss: 4.8651 - acc: 0.01 - ETA: 39s - loss: 4.8652 - acc: 0.01 - ETA: 39s - loss: 4.8660 - acc: 0.01 - ETA: 39s - loss: 4.8660 - acc: 0.01 - ETA: 39s - loss: 4.8656 - acc: 0.01 - ETA: 39s - loss: 4.8652 - acc: 0.01 - ETA: 39s - loss: 4.8653 - acc: 0.01 - ETA: 39s - loss: 4.8656 - acc: 0.01 - ETA: 39s - loss: 4.8658 - acc: 0.01 - ETA: 38s - loss: 4.8659 - acc: 0.01 - ETA: 38s - loss: 4.8657 - acc: 0.01 - ETA: 38s - loss: 4.8654 - acc: 0.01 - ETA: 38s - loss: 4.8653 - acc: 0.01 - ETA: 38s - loss: 4.8653 - acc: 0.01 - ETA: 38s - loss: 4.8653 - acc: 0.01 - ETA: 38s - loss: 4.8654 - acc: 0.01 - ETA: 37s - loss: 4.8661 - acc: 0.01 - ETA: 37s - loss: 4.8660 - acc: 0.01 - ETA: 37s - loss: 4.8661 - acc: 0.01 - ETA: 37s - loss: 4.8665 - acc: 0.01 - ETA: 37s - loss: 4.8666 - acc: 0.01 - ETA: 37s - loss: 4.8666 - acc: 0.01 - ETA: 36s - loss: 4.8666 - acc: 0.01 - ETA: 36s - loss: 4.8668 - acc: 0.01 - ETA: 36s - loss: 4.8667 - acc: 0.01 - ETA: 36s - loss: 4.8665 - acc: 0.01 - ETA: 36s - loss: 4.8665 - acc: 0.01 - ETA: 36s - loss: 4.8663 - acc: 0.01 - ETA: 35s - loss: 4.8662 - acc: 0.01 - ETA: 35s - loss: 4.8661 - acc: 0.01 - ETA: 35s - loss: 4.8662 - acc: 0.01 - ETA: 35s - loss: 4.8662 - acc: 0.01 - ETA: 35s - loss: 4.8662 - acc: 0.01 - ETA: 35s - loss: 4.8658 - acc: 0.01 - ETA: 34s - loss: 4.8661 - acc: 0.01 - ETA: 34s - loss: 4.8662 - acc: 0.01 - ETA: 34s - loss: 4.8662 - acc: 0.01 - ETA: 34s - loss: 4.8661 - acc: 0.01 - ETA: 34s - loss: 4.8661 - acc: 0.01 - ETA: 34s - loss: 4.8664 - acc: 0.01 - ETA: 33s - loss: 4.8664 - acc: 0.01 - ETA: 33s - loss: 4.8667 - acc: 0.01 - ETA: 33s - loss: 4.8667 - acc: 0.01 - ETA: 33s - loss: 4.8669 - acc: 0.01 - ETA: 33s - loss: 4.8670 - acc: 0.01 - ETA: 33s - loss: 4.8670 - acc: 0.01 - ETA: 33s - loss: 4.8666 - acc: 0.01 - ETA: 33s - loss: 4.8667 - acc: 0.01 - ETA: 32s - loss: 4.8669 - acc: 0.01 - ETA: 32s - loss: 4.8669 - acc: 0.01 - ETA: 32s - loss: 4.8670 - acc: 0.01 - ETA: 32s - loss: 4.8669 - acc: 0.01 - ETA: 32s - loss: 4.8671 - acc: 0.01 - ETA: 32s - loss: 4.8671 - acc: 0.01 - ETA: 32s - loss: 4.8674 - acc: 0.01 - ETA: 31s - loss: 4.8677 - acc: 0.01 - ETA: 31s - loss: 4.8674 - acc: 0.01 - ETA: 31s - loss: 4.8674 - acc: 0.01 - ETA: 31s - loss: 4.8674 - acc: 0.01 - ETA: 31s - loss: 4.8676 - acc: 0.01 - ETA: 31s - loss: 4.8680 - acc: 0.0132"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8679 - acc: 0.01 - ETA: 30s - loss: 4.8677 - acc: 0.01 - ETA: 30s - loss: 4.8678 - acc: 0.01 - ETA: 30s - loss: 4.8678 - acc: 0.01 - ETA: 30s - loss: 4.8676 - acc: 0.01 - ETA: 30s - loss: 4.8672 - acc: 0.01 - ETA: 29s - loss: 4.8673 - acc: 0.01 - ETA: 29s - loss: 4.8671 - acc: 0.01 - ETA: 29s - loss: 4.8670 - acc: 0.01 - ETA: 29s - loss: 4.8669 - acc: 0.01 - ETA: 29s - loss: 4.8667 - acc: 0.01 - ETA: 29s - loss: 4.8666 - acc: 0.01 - ETA: 29s - loss: 4.8669 - acc: 0.01 - ETA: 28s - loss: 4.8668 - acc: 0.01 - ETA: 28s - loss: 4.8668 - acc: 0.01 - ETA: 28s - loss: 4.8668 - acc: 0.01 - ETA: 28s - loss: 4.8670 - acc: 0.01 - ETA: 28s - loss: 4.8670 - acc: 0.01 - ETA: 28s - loss: 4.8670 - acc: 0.01 - ETA: 27s - loss: 4.8668 - acc: 0.01 - ETA: 27s - loss: 4.8669 - acc: 0.01 - ETA: 27s - loss: 4.8669 - acc: 0.01 - ETA: 27s - loss: 4.8671 - acc: 0.01 - ETA: 27s - loss: 4.8672 - acc: 0.01 - ETA: 27s - loss: 4.8670 - acc: 0.01 - ETA: 26s - loss: 4.8671 - acc: 0.01 - ETA: 26s - loss: 4.8673 - acc: 0.01 - ETA: 26s - loss: 4.8672 - acc: 0.01 - ETA: 26s - loss: 4.8674 - acc: 0.01 - ETA: 26s - loss: 4.8674 - acc: 0.01 - ETA: 26s - loss: 4.8676 - acc: 0.01 - ETA: 25s - loss: 4.8673 - acc: 0.01 - ETA: 25s - loss: 4.8671 - acc: 0.01 - ETA: 25s - loss: 4.8672 - acc: 0.01 - ETA: 25s - loss: 4.8670 - acc: 0.01 - ETA: 25s - loss: 4.8671 - acc: 0.01 - ETA: 25s - loss: 4.8671 - acc: 0.01 - ETA: 25s - loss: 4.8674 - acc: 0.01 - ETA: 24s - loss: 4.8672 - acc: 0.01 - ETA: 24s - loss: 4.8672 - acc: 0.01 - ETA: 24s - loss: 4.8673 - acc: 0.01 - ETA: 24s - loss: 4.8673 - acc: 0.01 - ETA: 24s - loss: 4.8672 - acc: 0.01 - ETA: 24s - loss: 4.8672 - acc: 0.01 - ETA: 23s - loss: 4.8672 - acc: 0.01 - ETA: 23s - loss: 4.8674 - acc: 0.01 - ETA: 23s - loss: 4.8673 - acc: 0.01 - ETA: 23s - loss: 4.8673 - acc: 0.01 - ETA: 23s - loss: 4.8672 - acc: 0.01 - ETA: 23s - loss: 4.8672 - acc: 0.01 - ETA: 22s - loss: 4.8671 - acc: 0.01 - ETA: 22s - loss: 4.8669 - acc: 0.01 - ETA: 22s - loss: 4.8667 - acc: 0.01 - ETA: 22s - loss: 4.8667 - acc: 0.01 - ETA: 22s - loss: 4.8669 - acc: 0.01 - ETA: 22s - loss: 4.8668 - acc: 0.01 - ETA: 22s - loss: 4.8665 - acc: 0.01 - ETA: 21s - loss: 4.8664 - acc: 0.01 - ETA: 21s - loss: 4.8664 - acc: 0.01 - ETA: 21s - loss: 4.8667 - acc: 0.01 - ETA: 21s - loss: 4.8667 - acc: 0.01 - ETA: 21s - loss: 4.8669 - acc: 0.01 - ETA: 21s - loss: 4.8669 - acc: 0.01 - ETA: 20s - loss: 4.8670 - acc: 0.01 - ETA: 20s - loss: 4.8670 - acc: 0.01 - ETA: 20s - loss: 4.8670 - acc: 0.01 - ETA: 20s - loss: 4.8668 - acc: 0.01 - ETA: 20s - loss: 4.8668 - acc: 0.01 - ETA: 20s - loss: 4.8665 - acc: 0.01 - ETA: 19s - loss: 4.8667 - acc: 0.01 - ETA: 19s - loss: 4.8669 - acc: 0.01 - ETA: 19s - loss: 4.8670 - acc: 0.01 - ETA: 19s - loss: 4.8672 - acc: 0.01 - ETA: 19s - loss: 4.8673 - acc: 0.01 - ETA: 19s - loss: 4.8672 - acc: 0.01 - ETA: 18s - loss: 4.8674 - acc: 0.01 - ETA: 18s - loss: 4.8677 - acc: 0.01 - ETA: 18s - loss: 4.8677 - acc: 0.01 - ETA: 18s - loss: 4.8677 - acc: 0.01 - ETA: 18s - loss: 4.8677 - acc: 0.01 - ETA: 18s - loss: 4.8677 - acc: 0.01 - ETA: 17s - loss: 4.8677 - acc: 0.01 - ETA: 17s - loss: 4.8676 - acc: 0.01 - ETA: 17s - loss: 4.8677 - acc: 0.01 - ETA: 17s - loss: 4.8676 - acc: 0.01 - ETA: 17s - loss: 4.8676 - acc: 0.01 - ETA: 17s - loss: 4.8676 - acc: 0.01 - ETA: 17s - loss: 4.8675 - acc: 0.01 - ETA: 16s - loss: 4.8674 - acc: 0.01 - ETA: 16s - loss: 4.8675 - acc: 0.01 - ETA: 16s - loss: 4.8674 - acc: 0.01 - ETA: 16s - loss: 4.8675 - acc: 0.01 - ETA: 16s - loss: 4.8676 - acc: 0.01 - ETA: 16s - loss: 4.8676 - acc: 0.01 - ETA: 15s - loss: 4.8677 - acc: 0.01 - ETA: 15s - loss: 4.8677 - acc: 0.01 - ETA: 15s - loss: 4.8677 - acc: 0.01 - ETA: 15s - loss: 4.8675 - acc: 0.01 - ETA: 15s - loss: 4.8674 - acc: 0.01 - ETA: 15s - loss: 4.8677 - acc: 0.01 - ETA: 15s - loss: 4.8678 - acc: 0.01 - ETA: 14s - loss: 4.8678 - acc: 0.01 - ETA: 14s - loss: 4.8677 - acc: 0.01 - ETA: 14s - loss: 4.8678 - acc: 0.01 - ETA: 14s - loss: 4.8677 - acc: 0.01 - ETA: 14s - loss: 4.8678 - acc: 0.01 - ETA: 14s - loss: 4.8677 - acc: 0.01 - ETA: 13s - loss: 4.8677 - acc: 0.01 - ETA: 13s - loss: 4.8677 - acc: 0.01 - ETA: 13s - loss: 4.8677 - acc: 0.01 - ETA: 13s - loss: 4.8677 - acc: 0.01 - ETA: 13s - loss: 4.8674 - acc: 0.01 - ETA: 13s - loss: 4.8675 - acc: 0.01 - ETA: 12s - loss: 4.8675 - acc: 0.01 - ETA: 12s - loss: 4.8675 - acc: 0.01 - ETA: 12s - loss: 4.8675 - acc: 0.01 - ETA: 12s - loss: 4.8675 - acc: 0.01 - ETA: 12s - loss: 4.8673 - acc: 0.01 - ETA: 12s - loss: 4.8672 - acc: 0.01 - ETA: 11s - loss: 4.8671 - acc: 0.01 - ETA: 11s - loss: 4.8668 - acc: 0.01 - ETA: 11s - loss: 4.8667 - acc: 0.01 - ETA: 11s - loss: 4.8667 - acc: 0.01 - ETA: 11s - loss: 4.8665 - acc: 0.01 - ETA: 11s - loss: 4.8665 - acc: 0.01 - ETA: 10s - loss: 4.8667 - acc: 0.01 - ETA: 10s - loss: 4.8665 - acc: 0.01 - ETA: 10s - loss: 4.8664 - acc: 0.01 - ETA: 10s - loss: 4.8664 - acc: 0.01 - ETA: 10s - loss: 4.8667 - acc: 0.01 - ETA: 10s - loss: 4.8666 - acc: 0.01 - ETA: 10s - loss: 4.8666 - acc: 0.01 - ETA: 9s - loss: 4.8666 - acc: 0.0133 - ETA: 9s - loss: 4.8664 - acc: 0.013 - ETA: 9s - loss: 4.8666 - acc: 0.013 - ETA: 9s - loss: 4.8667 - acc: 0.013 - ETA: 9s - loss: 4.8664 - acc: 0.013 - ETA: 9s - loss: 4.8662 - acc: 0.013 - ETA: 8s - loss: 4.8660 - acc: 0.013 - ETA: 8s - loss: 4.8660 - acc: 0.013 - ETA: 8s - loss: 4.8661 - acc: 0.013 - ETA: 8s - loss: 4.8660 - acc: 0.013 - ETA: 8s - loss: 4.8660 - acc: 0.013 - ETA: 8s - loss: 4.8659 - acc: 0.013 - ETA: 7s - loss: 4.8658 - acc: 0.013 - ETA: 7s - loss: 4.8658 - acc: 0.013 - ETA: 7s - loss: 4.8658 - acc: 0.013 - ETA: 7s - loss: 4.8660 - acc: 0.013 - ETA: 7s - loss: 4.8659 - acc: 0.013 - ETA: 7s - loss: 4.8660 - acc: 0.013 - ETA: 6s - loss: 4.8661 - acc: 0.013 - ETA: 6s - loss: 4.8660 - acc: 0.013 - ETA: 6s - loss: 4.8660 - acc: 0.013 - ETA: 6s - loss: 4.8659 - acc: 0.013 - ETA: 6s - loss: 4.8658 - acc: 0.013 - ETA: 6s - loss: 4.8658 - acc: 0.013 - ETA: 5s - loss: 4.8659 - acc: 0.013 - ETA: 5s - loss: 4.8657 - acc: 0.013 - ETA: 5s - loss: 4.8659 - acc: 0.013 - ETA: 5s - loss: 4.8657 - acc: 0.013 - ETA: 5s - loss: 4.8656 - acc: 0.013 - ETA: 5s - loss: 4.8656 - acc: 0.013 - ETA: 5s - loss: 4.8656 - acc: 0.013 - ETA: 4s - loss: 4.8656 - acc: 0.013 - ETA: 4s - loss: 4.8654 - acc: 0.013 - ETA: 4s - loss: 4.8653 - acc: 0.013 - ETA: 4s - loss: 4.8653 - acc: 0.013 - ETA: 4s - loss: 4.8654 - acc: 0.013 - ETA: 4s - loss: 4.8654 - acc: 0.013 - ETA: 3s - loss: 4.8653 - acc: 0.013 - ETA: 3s - loss: 4.8653 - acc: 0.013 - ETA: 3s - loss: 4.8653 - acc: 0.013 - ETA: 3s - loss: 4.8652 - acc: 0.013 - ETA: 3s - loss: 4.8652 - acc: 0.013 - ETA: 3s - loss: 4.8653 - acc: 0.013 - ETA: 2s - loss: 4.8653 - acc: 0.013 - ETA: 2s - loss: 4.8652 - acc: 0.013 - ETA: 2s - loss: 4.8652 - acc: 0.013 - ETA: 2s - loss: 4.8654 - acc: 0.013 - ETA: 2s - loss: 4.8654 - acc: 0.013 - ETA: 2s - loss: 4.8656 - acc: 0.013 - ETA: 1s - loss: 4.8657 - acc: 0.013 - ETA: 1s - loss: 4.8656 - acc: 0.013 - ETA: 1s - loss: 4.8656 - acc: 0.013 - ETA: 1s - loss: 4.8656 - acc: 0.013 - ETA: 1s - loss: 4.8658 - acc: 0.013 - ETA: 1s - loss: 4.8658 - acc: 0.013 - ETA: 0s - loss: 4.8659 - acc: 0.013 - ETA: 0s - loss: 4.8659 - acc: 0.013 - ETA: 0s - loss: 4.8657 - acc: 0.013 - ETA: 0s - loss: 4.8656 - acc: 0.013 - ETA: 0s - loss: 4.8657 - acc: 0.013 - ETA: 0s - loss: 4.8658 - acc: 0.013 - 72s 172ms/step - loss: 4.8659 - acc: 0.0132 - val_loss: 4.8530 - val_acc: 0.0183\n",
      "\n",
      "Epoch 00020: val_loss improved from 4.86173 to 4.85298, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/417 [==============>...............] - ETA: 6s - loss: 4.8450 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8535 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8615 - acc: 0.0089    - ETA: 6s - loss: 4.8652 - acc: 0.005 - ETA: 9s - loss: 4.8662 - acc: 0.005 - ETA: 16s - loss: 4.8673 - acc: 0.00 - ETA: 21s - loss: 4.8722 - acc: 0.00 - ETA: 23s - loss: 4.8703 - acc: 0.00 - ETA: 25s - loss: 4.8682 - acc: 0.00 - ETA: 29s - loss: 4.8661 - acc: 0.00 - ETA: 31s - loss: 4.8679 - acc: 0.00 - ETA: 33s - loss: 4.8717 - acc: 0.00 - ETA: 34s - loss: 4.8705 - acc: 0.00 - ETA: 35s - loss: 4.8719 - acc: 0.00 - ETA: 36s - loss: 4.8729 - acc: 0.00 - ETA: 36s - loss: 4.8739 - acc: 0.01 - ETA: 36s - loss: 4.8744 - acc: 0.01 - ETA: 37s - loss: 4.8750 - acc: 0.01 - ETA: 38s - loss: 4.8764 - acc: 0.01 - ETA: 39s - loss: 4.8755 - acc: 0.01 - ETA: 41s - loss: 4.8770 - acc: 0.01 - ETA: 41s - loss: 4.8770 - acc: 0.01 - ETA: 41s - loss: 4.8768 - acc: 0.01 - ETA: 41s - loss: 4.8782 - acc: 0.01 - ETA: 42s - loss: 4.8811 - acc: 0.01 - ETA: 42s - loss: 4.8807 - acc: 0.01 - ETA: 43s - loss: 4.8800 - acc: 0.01 - ETA: 43s - loss: 4.8791 - acc: 0.01 - ETA: 43s - loss: 4.8768 - acc: 0.01 - ETA: 43s - loss: 4.8779 - acc: 0.01 - ETA: 45s - loss: 4.8776 - acc: 0.01 - ETA: 45s - loss: 4.8790 - acc: 0.01 - ETA: 45s - loss: 4.8782 - acc: 0.01 - ETA: 45s - loss: 4.8780 - acc: 0.01 - ETA: 45s - loss: 4.8781 - acc: 0.01 - ETA: 45s - loss: 4.8785 - acc: 0.01 - ETA: 45s - loss: 4.8795 - acc: 0.01 - ETA: 45s - loss: 4.8795 - acc: 0.01 - ETA: 45s - loss: 4.8797 - acc: 0.01 - ETA: 45s - loss: 4.8788 - acc: 0.01 - ETA: 46s - loss: 4.8800 - acc: 0.01 - ETA: 46s - loss: 4.8781 - acc: 0.01 - ETA: 46s - loss: 4.8782 - acc: 0.01 - ETA: 46s - loss: 4.8771 - acc: 0.01 - ETA: 47s - loss: 4.8769 - acc: 0.01 - ETA: 47s - loss: 4.8765 - acc: 0.01 - ETA: 47s - loss: 4.8765 - acc: 0.01 - ETA: 47s - loss: 4.8757 - acc: 0.01 - ETA: 49s - loss: 4.8751 - acc: 0.01 - ETA: 48s - loss: 4.8743 - acc: 0.01 - ETA: 49s - loss: 4.8736 - acc: 0.01 - ETA: 49s - loss: 4.8735 - acc: 0.01 - ETA: 49s - loss: 4.8732 - acc: 0.01 - ETA: 48s - loss: 4.8715 - acc: 0.01 - ETA: 48s - loss: 4.8711 - acc: 0.01 - ETA: 48s - loss: 4.8709 - acc: 0.01 - ETA: 48s - loss: 4.8712 - acc: 0.01 - ETA: 48s - loss: 4.8714 - acc: 0.01 - ETA: 49s - loss: 4.8716 - acc: 0.01 - ETA: 49s - loss: 4.8711 - acc: 0.01 - ETA: 49s - loss: 4.8699 - acc: 0.01 - ETA: 49s - loss: 4.8705 - acc: 0.01 - ETA: 49s - loss: 4.8695 - acc: 0.01 - ETA: 49s - loss: 4.8689 - acc: 0.01 - ETA: 48s - loss: 4.8700 - acc: 0.01 - ETA: 48s - loss: 4.8692 - acc: 0.01 - ETA: 48s - loss: 4.8686 - acc: 0.01 - ETA: 48s - loss: 4.8681 - acc: 0.01 - ETA: 48s - loss: 4.8678 - acc: 0.01 - ETA: 49s - loss: 4.8678 - acc: 0.01 - ETA: 49s - loss: 4.8674 - acc: 0.01 - ETA: 49s - loss: 4.8674 - acc: 0.01 - ETA: 49s - loss: 4.8666 - acc: 0.01 - ETA: 49s - loss: 4.8660 - acc: 0.01 - ETA: 49s - loss: 4.8660 - acc: 0.01 - ETA: 49s - loss: 4.8657 - acc: 0.01 - ETA: 49s - loss: 4.8657 - acc: 0.01 - ETA: 50s - loss: 4.8654 - acc: 0.01 - ETA: 50s - loss: 4.8646 - acc: 0.01 - ETA: 49s - loss: 4.8644 - acc: 0.01 - ETA: 49s - loss: 4.8635 - acc: 0.01 - ETA: 49s - loss: 4.8631 - acc: 0.01 - ETA: 49s - loss: 4.8637 - acc: 0.01 - ETA: 49s - loss: 4.8634 - acc: 0.01 - ETA: 49s - loss: 4.8630 - acc: 0.01 - ETA: 49s - loss: 4.8633 - acc: 0.01 - ETA: 49s - loss: 4.8635 - acc: 0.01 - ETA: 48s - loss: 4.8625 - acc: 0.01 - ETA: 49s - loss: 4.8636 - acc: 0.01 - ETA: 48s - loss: 4.8633 - acc: 0.01 - ETA: 48s - loss: 4.8632 - acc: 0.01 - ETA: 48s - loss: 4.8625 - acc: 0.01 - ETA: 48s - loss: 4.8625 - acc: 0.01 - ETA: 48s - loss: 4.8634 - acc: 0.01 - ETA: 48s - loss: 4.8635 - acc: 0.01 - ETA: 47s - loss: 4.8631 - acc: 0.01 - ETA: 47s - loss: 4.8629 - acc: 0.01 - ETA: 47s - loss: 4.8629 - acc: 0.01 - ETA: 47s - loss: 4.8631 - acc: 0.01 - ETA: 47s - loss: 4.8634 - acc: 0.01 - ETA: 47s - loss: 4.8640 - acc: 0.01 - ETA: 47s - loss: 4.8646 - acc: 0.01 - ETA: 47s - loss: 4.8645 - acc: 0.01 - ETA: 48s - loss: 4.8647 - acc: 0.01 - ETA: 47s - loss: 4.8650 - acc: 0.01 - ETA: 47s - loss: 4.8645 - acc: 0.01 - ETA: 47s - loss: 4.8647 - acc: 0.01 - ETA: 47s - loss: 4.8657 - acc: 0.01 - ETA: 47s - loss: 4.8659 - acc: 0.01 - ETA: 47s - loss: 4.8656 - acc: 0.01 - ETA: 47s - loss: 4.8658 - acc: 0.01 - ETA: 47s - loss: 4.8655 - acc: 0.01 - ETA: 46s - loss: 4.8657 - acc: 0.01 - ETA: 47s - loss: 4.8658 - acc: 0.01 - ETA: 46s - loss: 4.8661 - acc: 0.01 - ETA: 46s - loss: 4.8661 - acc: 0.01 - ETA: 46s - loss: 4.8662 - acc: 0.01 - ETA: 46s - loss: 4.8656 - acc: 0.01 - ETA: 46s - loss: 4.8660 - acc: 0.01 - ETA: 46s - loss: 4.8660 - acc: 0.01 - ETA: 46s - loss: 4.8665 - acc: 0.01 - ETA: 46s - loss: 4.8675 - acc: 0.01 - ETA: 46s - loss: 4.8674 - acc: 0.01 - ETA: 45s - loss: 4.8673 - acc: 0.01 - ETA: 45s - loss: 4.8678 - acc: 0.01 - ETA: 45s - loss: 4.8678 - acc: 0.01 - ETA: 45s - loss: 4.8680 - acc: 0.01 - ETA: 44s - loss: 4.8682 - acc: 0.01 - ETA: 44s - loss: 4.8679 - acc: 0.01 - ETA: 44s - loss: 4.8683 - acc: 0.01 - ETA: 44s - loss: 4.8681 - acc: 0.01 - ETA: 44s - loss: 4.8681 - acc: 0.01 - ETA: 44s - loss: 4.8679 - acc: 0.01 - ETA: 44s - loss: 4.8683 - acc: 0.01 - ETA: 43s - loss: 4.8679 - acc: 0.01 - ETA: 43s - loss: 4.8682 - acc: 0.01 - ETA: 43s - loss: 4.8685 - acc: 0.01 - ETA: 43s - loss: 4.8687 - acc: 0.01 - ETA: 43s - loss: 4.8681 - acc: 0.01 - ETA: 43s - loss: 4.8676 - acc: 0.01 - ETA: 42s - loss: 4.8677 - acc: 0.01 - ETA: 42s - loss: 4.8679 - acc: 0.01 - ETA: 42s - loss: 4.8678 - acc: 0.01 - ETA: 42s - loss: 4.8677 - acc: 0.01 - ETA: 42s - loss: 4.8680 - acc: 0.01 - ETA: 42s - loss: 4.8681 - acc: 0.01 - ETA: 42s - loss: 4.8682 - acc: 0.01 - ETA: 41s - loss: 4.8680 - acc: 0.01 - ETA: 41s - loss: 4.8672 - acc: 0.01 - ETA: 41s - loss: 4.8671 - acc: 0.01 - ETA: 41s - loss: 4.8671 - acc: 0.01 - ETA: 41s - loss: 4.8667 - acc: 0.01 - ETA: 41s - loss: 4.8668 - acc: 0.01 - ETA: 41s - loss: 4.8670 - acc: 0.01 - ETA: 40s - loss: 4.8670 - acc: 0.01 - ETA: 40s - loss: 4.8670 - acc: 0.01 - ETA: 40s - loss: 4.8671 - acc: 0.01 - ETA: 40s - loss: 4.8675 - acc: 0.01 - ETA: 40s - loss: 4.8681 - acc: 0.01 - ETA: 40s - loss: 4.8682 - acc: 0.01 - ETA: 40s - loss: 4.8681 - acc: 0.01 - ETA: 39s - loss: 4.8684 - acc: 0.01 - ETA: 39s - loss: 4.8681 - acc: 0.01 - ETA: 39s - loss: 4.8676 - acc: 0.01 - ETA: 39s - loss: 4.8676 - acc: 0.01 - ETA: 39s - loss: 4.8674 - acc: 0.01 - ETA: 38s - loss: 4.8677 - acc: 0.01 - ETA: 39s - loss: 4.8677 - acc: 0.01 - ETA: 38s - loss: 4.8681 - acc: 0.01 - ETA: 38s - loss: 4.8680 - acc: 0.01 - ETA: 38s - loss: 4.8679 - acc: 0.01 - ETA: 38s - loss: 4.8675 - acc: 0.01 - ETA: 38s - loss: 4.8675 - acc: 0.01 - ETA: 38s - loss: 4.8676 - acc: 0.01 - ETA: 37s - loss: 4.8677 - acc: 0.01 - ETA: 37s - loss: 4.8678 - acc: 0.01 - ETA: 37s - loss: 4.8678 - acc: 0.01 - ETA: 37s - loss: 4.8677 - acc: 0.01 - ETA: 37s - loss: 4.8675 - acc: 0.01 - ETA: 37s - loss: 4.8672 - acc: 0.01 - ETA: 36s - loss: 4.8673 - acc: 0.01 - ETA: 36s - loss: 4.8674 - acc: 0.01 - ETA: 36s - loss: 4.8675 - acc: 0.01 - ETA: 36s - loss: 4.8676 - acc: 0.01 - ETA: 36s - loss: 4.8676 - acc: 0.01 - ETA: 36s - loss: 4.8670 - acc: 0.01 - ETA: 36s - loss: 4.8672 - acc: 0.01 - ETA: 35s - loss: 4.8670 - acc: 0.01 - ETA: 35s - loss: 4.8668 - acc: 0.01 - ETA: 35s - loss: 4.8671 - acc: 0.01 - ETA: 35s - loss: 4.8670 - acc: 0.01 - ETA: 35s - loss: 4.8668 - acc: 0.01 - ETA: 34s - loss: 4.8663 - acc: 0.01 - ETA: 34s - loss: 4.8662 - acc: 0.01 - ETA: 34s - loss: 4.8663 - acc: 0.01 - ETA: 34s - loss: 4.8665 - acc: 0.01 - ETA: 34s - loss: 4.8662 - acc: 0.01 - ETA: 34s - loss: 4.8661 - acc: 0.01 - ETA: 33s - loss: 4.8660 - acc: 0.01 - ETA: 33s - loss: 4.8661 - acc: 0.01 - ETA: 33s - loss: 4.8663 - acc: 0.01 - ETA: 33s - loss: 4.8664 - acc: 0.01 - ETA: 33s - loss: 4.8668 - acc: 0.01 - ETA: 33s - loss: 4.8669 - acc: 0.01 - ETA: 32s - loss: 4.8672 - acc: 0.01 - ETA: 32s - loss: 4.8668 - acc: 0.01 - ETA: 32s - loss: 4.8669 - acc: 0.01 - ETA: 32s - loss: 4.8667 - acc: 0.01 - ETA: 32s - loss: 4.8666 - acc: 0.01 - ETA: 32s - loss: 4.8670 - acc: 0.01 - ETA: 32s - loss: 4.8671 - acc: 0.01 - ETA: 31s - loss: 4.8671 - acc: 0.01 - ETA: 31s - loss: 4.8670 - acc: 0.01 - ETA: 31s - loss: 4.8673 - acc: 0.01 - ETA: 31s - loss: 4.8672 - acc: 0.0155"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 31s - loss: 4.8668 - acc: 0.01 - ETA: 31s - loss: 4.8666 - acc: 0.01 - ETA: 30s - loss: 4.8668 - acc: 0.01 - ETA: 30s - loss: 4.8669 - acc: 0.01 - ETA: 30s - loss: 4.8671 - acc: 0.01 - ETA: 30s - loss: 4.8671 - acc: 0.01 - ETA: 30s - loss: 4.8671 - acc: 0.01 - ETA: 30s - loss: 4.8669 - acc: 0.01 - ETA: 30s - loss: 4.8671 - acc: 0.01 - ETA: 29s - loss: 4.8667 - acc: 0.01 - ETA: 29s - loss: 4.8671 - acc: 0.01 - ETA: 29s - loss: 4.8670 - acc: 0.01 - ETA: 29s - loss: 4.8672 - acc: 0.01 - ETA: 29s - loss: 4.8675 - acc: 0.01 - ETA: 29s - loss: 4.8678 - acc: 0.01 - ETA: 28s - loss: 4.8675 - acc: 0.01 - ETA: 28s - loss: 4.8676 - acc: 0.01 - ETA: 28s - loss: 4.8676 - acc: 0.01 - ETA: 28s - loss: 4.8678 - acc: 0.01 - ETA: 28s - loss: 4.8681 - acc: 0.01 - ETA: 28s - loss: 4.8678 - acc: 0.01 - ETA: 28s - loss: 4.8675 - acc: 0.01 - ETA: 27s - loss: 4.8673 - acc: 0.01 - ETA: 27s - loss: 4.8674 - acc: 0.01 - ETA: 27s - loss: 4.8676 - acc: 0.01 - ETA: 27s - loss: 4.8676 - acc: 0.01 - ETA: 27s - loss: 4.8674 - acc: 0.01 - ETA: 27s - loss: 4.8676 - acc: 0.01 - ETA: 26s - loss: 4.8676 - acc: 0.01 - ETA: 26s - loss: 4.8673 - acc: 0.01 - ETA: 26s - loss: 4.8672 - acc: 0.01 - ETA: 26s - loss: 4.8674 - acc: 0.01 - ETA: 26s - loss: 4.8671 - acc: 0.01 - ETA: 26s - loss: 4.8671 - acc: 0.01 - ETA: 25s - loss: 4.8671 - acc: 0.01 - ETA: 25s - loss: 4.8670 - acc: 0.01 - ETA: 25s - loss: 4.8669 - acc: 0.01 - ETA: 25s - loss: 4.8672 - acc: 0.01 - ETA: 25s - loss: 4.8668 - acc: 0.01 - ETA: 25s - loss: 4.8668 - acc: 0.01 - ETA: 24s - loss: 4.8669 - acc: 0.01 - ETA: 24s - loss: 4.8668 - acc: 0.01 - ETA: 24s - loss: 4.8664 - acc: 0.01 - ETA: 24s - loss: 4.8664 - acc: 0.01 - ETA: 24s - loss: 4.8664 - acc: 0.01 - ETA: 24s - loss: 4.8665 - acc: 0.01 - ETA: 24s - loss: 4.8666 - acc: 0.01 - ETA: 23s - loss: 4.8670 - acc: 0.01 - ETA: 23s - loss: 4.8670 - acc: 0.01 - ETA: 23s - loss: 4.8668 - acc: 0.01 - ETA: 23s - loss: 4.8668 - acc: 0.01 - ETA: 23s - loss: 4.8665 - acc: 0.01 - ETA: 23s - loss: 4.8664 - acc: 0.01 - ETA: 22s - loss: 4.8663 - acc: 0.01 - ETA: 22s - loss: 4.8665 - acc: 0.01 - ETA: 22s - loss: 4.8666 - acc: 0.01 - ETA: 22s - loss: 4.8667 - acc: 0.01 - ETA: 22s - loss: 4.8664 - acc: 0.01 - ETA: 22s - loss: 4.8662 - acc: 0.01 - ETA: 21s - loss: 4.8661 - acc: 0.01 - ETA: 21s - loss: 4.8659 - acc: 0.01 - ETA: 21s - loss: 4.8658 - acc: 0.01 - ETA: 21s - loss: 4.8658 - acc: 0.01 - ETA: 21s - loss: 4.8654 - acc: 0.01 - ETA: 21s - loss: 4.8655 - acc: 0.01 - ETA: 20s - loss: 4.8655 - acc: 0.01 - ETA: 20s - loss: 4.8657 - acc: 0.01 - ETA: 20s - loss: 4.8657 - acc: 0.01 - ETA: 20s - loss: 4.8656 - acc: 0.01 - ETA: 20s - loss: 4.8660 - acc: 0.01 - ETA: 19s - loss: 4.8662 - acc: 0.01 - ETA: 19s - loss: 4.8664 - acc: 0.01 - ETA: 19s - loss: 4.8666 - acc: 0.01 - ETA: 19s - loss: 4.8669 - acc: 0.01 - ETA: 19s - loss: 4.8668 - acc: 0.01 - ETA: 19s - loss: 4.8667 - acc: 0.01 - ETA: 18s - loss: 4.8668 - acc: 0.01 - ETA: 18s - loss: 4.8662 - acc: 0.01 - ETA: 18s - loss: 4.8662 - acc: 0.01 - ETA: 18s - loss: 4.8663 - acc: 0.01 - ETA: 18s - loss: 4.8662 - acc: 0.01 - ETA: 18s - loss: 4.8660 - acc: 0.01 - ETA: 18s - loss: 4.8661 - acc: 0.01 - ETA: 17s - loss: 4.8661 - acc: 0.01 - ETA: 17s - loss: 4.8660 - acc: 0.01 - ETA: 17s - loss: 4.8663 - acc: 0.01 - ETA: 17s - loss: 4.8661 - acc: 0.01 - ETA: 17s - loss: 4.8664 - acc: 0.01 - ETA: 17s - loss: 4.8663 - acc: 0.01 - ETA: 16s - loss: 4.8664 - acc: 0.01 - ETA: 16s - loss: 4.8661 - acc: 0.01 - ETA: 16s - loss: 4.8661 - acc: 0.01 - ETA: 16s - loss: 4.8659 - acc: 0.01 - ETA: 16s - loss: 4.8659 - acc: 0.01 - ETA: 16s - loss: 4.8658 - acc: 0.01 - ETA: 15s - loss: 4.8659 - acc: 0.01 - ETA: 15s - loss: 4.8659 - acc: 0.01 - ETA: 15s - loss: 4.8659 - acc: 0.01 - ETA: 15s - loss: 4.8659 - acc: 0.01 - ETA: 15s - loss: 4.8657 - acc: 0.01 - ETA: 15s - loss: 4.8656 - acc: 0.01 - ETA: 14s - loss: 4.8656 - acc: 0.01 - ETA: 14s - loss: 4.8655 - acc: 0.01 - ETA: 14s - loss: 4.8658 - acc: 0.01 - ETA: 14s - loss: 4.8661 - acc: 0.01 - ETA: 14s - loss: 4.8661 - acc: 0.01 - ETA: 14s - loss: 4.8660 - acc: 0.01 - ETA: 14s - loss: 4.8659 - acc: 0.01 - ETA: 13s - loss: 4.8662 - acc: 0.01 - ETA: 13s - loss: 4.8663 - acc: 0.01 - ETA: 13s - loss: 4.8667 - acc: 0.01 - ETA: 13s - loss: 4.8666 - acc: 0.01 - ETA: 13s - loss: 4.8665 - acc: 0.01 - ETA: 13s - loss: 4.8664 - acc: 0.01 - ETA: 12s - loss: 4.8664 - acc: 0.01 - ETA: 12s - loss: 4.8665 - acc: 0.01 - ETA: 12s - loss: 4.8666 - acc: 0.01 - ETA: 12s - loss: 4.8665 - acc: 0.01 - ETA: 12s - loss: 4.8666 - acc: 0.01 - ETA: 11s - loss: 4.8665 - acc: 0.01 - ETA: 11s - loss: 4.8667 - acc: 0.01 - ETA: 11s - loss: 4.8666 - acc: 0.01 - ETA: 11s - loss: 4.8665 - acc: 0.01 - ETA: 11s - loss: 4.8662 - acc: 0.01 - ETA: 11s - loss: 4.8662 - acc: 0.01 - ETA: 10s - loss: 4.8662 - acc: 0.01 - ETA: 10s - loss: 4.8662 - acc: 0.01 - ETA: 10s - loss: 4.8664 - acc: 0.01 - ETA: 10s - loss: 4.8665 - acc: 0.01 - ETA: 10s - loss: 4.8666 - acc: 0.01 - ETA: 10s - loss: 4.8667 - acc: 0.01 - ETA: 9s - loss: 4.8666 - acc: 0.0148 - ETA: 9s - loss: 4.8666 - acc: 0.014 - ETA: 9s - loss: 4.8665 - acc: 0.014 - ETA: 9s - loss: 4.8665 - acc: 0.014 - ETA: 9s - loss: 4.8666 - acc: 0.014 - ETA: 9s - loss: 4.8666 - acc: 0.014 - ETA: 9s - loss: 4.8668 - acc: 0.014 - ETA: 8s - loss: 4.8668 - acc: 0.014 - ETA: 8s - loss: 4.8667 - acc: 0.014 - ETA: 8s - loss: 4.8665 - acc: 0.014 - ETA: 8s - loss: 4.8665 - acc: 0.014 - ETA: 8s - loss: 4.8667 - acc: 0.014 - ETA: 8s - loss: 4.8667 - acc: 0.014 - ETA: 7s - loss: 4.8668 - acc: 0.014 - ETA: 7s - loss: 4.8666 - acc: 0.014 - ETA: 7s - loss: 4.8667 - acc: 0.014 - ETA: 7s - loss: 4.8665 - acc: 0.014 - ETA: 7s - loss: 4.8665 - acc: 0.014 - ETA: 7s - loss: 4.8664 - acc: 0.014 - ETA: 6s - loss: 4.8664 - acc: 0.014 - ETA: 6s - loss: 4.8662 - acc: 0.014 - ETA: 6s - loss: 4.8664 - acc: 0.014 - ETA: 6s - loss: 4.8663 - acc: 0.014 - ETA: 6s - loss: 4.8662 - acc: 0.014 - ETA: 6s - loss: 4.8662 - acc: 0.014 - ETA: 5s - loss: 4.8661 - acc: 0.015 - ETA: 5s - loss: 4.8661 - acc: 0.014 - ETA: 5s - loss: 4.8662 - acc: 0.014 - ETA: 5s - loss: 4.8663 - acc: 0.014 - ETA: 5s - loss: 4.8663 - acc: 0.015 - ETA: 5s - loss: 4.8662 - acc: 0.014 - ETA: 5s - loss: 4.8664 - acc: 0.014 - ETA: 4s - loss: 4.8663 - acc: 0.014 - ETA: 4s - loss: 4.8663 - acc: 0.014 - ETA: 4s - loss: 4.8661 - acc: 0.014 - ETA: 4s - loss: 4.8662 - acc: 0.014 - ETA: 4s - loss: 4.8663 - acc: 0.014 - ETA: 4s - loss: 4.8664 - acc: 0.014 - ETA: 3s - loss: 4.8664 - acc: 0.014 - ETA: 3s - loss: 4.8665 - acc: 0.014 - ETA: 3s - loss: 4.8665 - acc: 0.014 - ETA: 3s - loss: 4.8667 - acc: 0.014 - ETA: 3s - loss: 4.8665 - acc: 0.014 - ETA: 3s - loss: 4.8665 - acc: 0.014 - ETA: 2s - loss: 4.8664 - acc: 0.014 - ETA: 2s - loss: 4.8663 - acc: 0.014 - ETA: 2s - loss: 4.8664 - acc: 0.014 - ETA: 2s - loss: 4.8665 - acc: 0.014 - ETA: 2s - loss: 4.8667 - acc: 0.014 - ETA: 2s - loss: 4.8668 - acc: 0.014 - ETA: 1s - loss: 4.8668 - acc: 0.014 - ETA: 1s - loss: 4.8668 - acc: 0.014 - ETA: 1s - loss: 4.8668 - acc: 0.014 - ETA: 1s - loss: 4.8669 - acc: 0.014 - ETA: 1s - loss: 4.8669 - acc: 0.014 - ETA: 1s - loss: 4.8671 - acc: 0.014 - ETA: 0s - loss: 4.8673 - acc: 0.014 - ETA: 0s - loss: 4.8671 - acc: 0.014 - ETA: 0s - loss: 4.8673 - acc: 0.014 - ETA: 0s - loss: 4.8673 - acc: 0.014 - ETA: 0s - loss: 4.8672 - acc: 0.014 - ETA: 0s - loss: 4.8673 - acc: 0.014 - 72s 172ms/step - loss: 4.8674 - acc: 0.0148 - val_loss: 4.8588 - val_acc: 0.0195\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 4.85298\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222/417 [==============>...............] - ETA: 6s - loss: 4.8288 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8584 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8478 - acc: 0.0089    - ETA: 6s - loss: 4.8553 - acc: 0.017 - ETA: 11s - loss: 4.8544 - acc: 0.01 - ETA: 16s - loss: 4.8569 - acc: 0.01 - ETA: 18s - loss: 4.8592 - acc: 0.01 - ETA: 21s - loss: 4.8581 - acc: 0.01 - ETA: 25s - loss: 4.8573 - acc: 0.01 - ETA: 27s - loss: 4.8592 - acc: 0.01 - ETA: 28s - loss: 4.8566 - acc: 0.02 - ETA: 30s - loss: 4.8547 - acc: 0.01 - ETA: 35s - loss: 4.8548 - acc: 0.02 - ETA: 36s - loss: 4.8553 - acc: 0.02 - ETA: 38s - loss: 4.8547 - acc: 0.01 - ETA: 39s - loss: 4.8526 - acc: 0.01 - ETA: 41s - loss: 4.8592 - acc: 0.01 - ETA: 41s - loss: 4.8582 - acc: 0.01 - ETA: 42s - loss: 4.8570 - acc: 0.02 - ETA: 42s - loss: 4.8603 - acc: 0.02 - ETA: 43s - loss: 4.8593 - acc: 0.02 - ETA: 43s - loss: 4.8633 - acc: 0.02 - ETA: 44s - loss: 4.8638 - acc: 0.02 - ETA: 44s - loss: 4.8663 - acc: 0.02 - ETA: 47s - loss: 4.8659 - acc: 0.01 - ETA: 47s - loss: 4.8651 - acc: 0.01 - ETA: 48s - loss: 4.8645 - acc: 0.01 - ETA: 49s - loss: 4.8622 - acc: 0.01 - ETA: 49s - loss: 4.8639 - acc: 0.01 - ETA: 49s - loss: 4.8625 - acc: 0.01 - ETA: 49s - loss: 4.8646 - acc: 0.01 - ETA: 50s - loss: 4.8637 - acc: 0.01 - ETA: 50s - loss: 4.8644 - acc: 0.02 - ETA: 51s - loss: 4.8637 - acc: 0.01 - ETA: 51s - loss: 4.8625 - acc: 0.01 - ETA: 51s - loss: 4.8619 - acc: 0.01 - ETA: 52s - loss: 4.8629 - acc: 0.01 - ETA: 52s - loss: 4.8619 - acc: 0.01 - ETA: 52s - loss: 4.8625 - acc: 0.01 - ETA: 52s - loss: 4.8623 - acc: 0.01 - ETA: 52s - loss: 4.8634 - acc: 0.01 - ETA: 52s - loss: 4.8620 - acc: 0.01 - ETA: 52s - loss: 4.8637 - acc: 0.01 - ETA: 51s - loss: 4.8638 - acc: 0.01 - ETA: 51s - loss: 4.8639 - acc: 0.01 - ETA: 51s - loss: 4.8656 - acc: 0.01 - ETA: 51s - loss: 4.8654 - acc: 0.01 - ETA: 51s - loss: 4.8649 - acc: 0.01 - ETA: 52s - loss: 4.8643 - acc: 0.01 - ETA: 51s - loss: 4.8644 - acc: 0.01 - ETA: 51s - loss: 4.8655 - acc: 0.01 - ETA: 51s - loss: 4.8659 - acc: 0.01 - ETA: 52s - loss: 4.8649 - acc: 0.01 - ETA: 52s - loss: 4.8651 - acc: 0.01 - ETA: 52s - loss: 4.8649 - acc: 0.01 - ETA: 52s - loss: 4.8661 - acc: 0.01 - ETA: 52s - loss: 4.8657 - acc: 0.01 - ETA: 52s - loss: 4.8661 - acc: 0.01 - ETA: 52s - loss: 4.8662 - acc: 0.01 - ETA: 52s - loss: 4.8650 - acc: 0.01 - ETA: 52s - loss: 4.8652 - acc: 0.01 - ETA: 51s - loss: 4.8651 - acc: 0.01 - ETA: 51s - loss: 4.8646 - acc: 0.01 - ETA: 51s - loss: 4.8650 - acc: 0.01 - ETA: 51s - loss: 4.8649 - acc: 0.01 - ETA: 51s - loss: 4.8630 - acc: 0.01 - ETA: 51s - loss: 4.8632 - acc: 0.01 - ETA: 51s - loss: 4.8637 - acc: 0.01 - ETA: 51s - loss: 4.8639 - acc: 0.01 - ETA: 50s - loss: 4.8638 - acc: 0.01 - ETA: 50s - loss: 4.8639 - acc: 0.01 - ETA: 50s - loss: 4.8632 - acc: 0.01 - ETA: 50s - loss: 4.8623 - acc: 0.01 - ETA: 51s - loss: 4.8620 - acc: 0.01 - ETA: 51s - loss: 4.8609 - acc: 0.01 - ETA: 51s - loss: 4.8616 - acc: 0.01 - ETA: 50s - loss: 4.8612 - acc: 0.01 - ETA: 50s - loss: 4.8619 - acc: 0.01 - ETA: 50s - loss: 4.8625 - acc: 0.01 - ETA: 50s - loss: 4.8620 - acc: 0.01 - ETA: 50s - loss: 4.8615 - acc: 0.01 - ETA: 49s - loss: 4.8617 - acc: 0.01 - ETA: 49s - loss: 4.8629 - acc: 0.01 - ETA: 49s - loss: 4.8620 - acc: 0.01 - ETA: 49s - loss: 4.8615 - acc: 0.01 - ETA: 49s - loss: 4.8618 - acc: 0.01 - ETA: 49s - loss: 4.8612 - acc: 0.01 - ETA: 49s - loss: 4.8611 - acc: 0.01 - ETA: 48s - loss: 4.8605 - acc: 0.01 - ETA: 48s - loss: 4.8600 - acc: 0.01 - ETA: 49s - loss: 4.8594 - acc: 0.01 - ETA: 49s - loss: 4.8591 - acc: 0.01 - ETA: 49s - loss: 4.8590 - acc: 0.01 - ETA: 49s - loss: 4.8597 - acc: 0.01 - ETA: 48s - loss: 4.8601 - acc: 0.01 - ETA: 48s - loss: 4.8602 - acc: 0.01 - ETA: 48s - loss: 4.8597 - acc: 0.01 - ETA: 48s - loss: 4.8606 - acc: 0.01 - ETA: 48s - loss: 4.8607 - acc: 0.01 - ETA: 47s - loss: 4.8606 - acc: 0.01 - ETA: 47s - loss: 4.8617 - acc: 0.01 - ETA: 48s - loss: 4.8623 - acc: 0.01 - ETA: 48s - loss: 4.8624 - acc: 0.01 - ETA: 48s - loss: 4.8618 - acc: 0.01 - ETA: 47s - loss: 4.8616 - acc: 0.01 - ETA: 47s - loss: 4.8614 - acc: 0.01 - ETA: 47s - loss: 4.8617 - acc: 0.01 - ETA: 47s - loss: 4.8620 - acc: 0.01 - ETA: 47s - loss: 4.8610 - acc: 0.01 - ETA: 47s - loss: 4.8620 - acc: 0.01 - ETA: 47s - loss: 4.8628 - acc: 0.01 - ETA: 46s - loss: 4.8631 - acc: 0.01 - ETA: 46s - loss: 4.8640 - acc: 0.01 - ETA: 46s - loss: 4.8638 - acc: 0.01 - ETA: 46s - loss: 4.8638 - acc: 0.01 - ETA: 46s - loss: 4.8635 - acc: 0.01 - ETA: 46s - loss: 4.8632 - acc: 0.01 - ETA: 46s - loss: 4.8640 - acc: 0.01 - ETA: 46s - loss: 4.8640 - acc: 0.01 - ETA: 46s - loss: 4.8637 - acc: 0.01 - ETA: 45s - loss: 4.8633 - acc: 0.01 - ETA: 45s - loss: 4.8642 - acc: 0.01 - ETA: 45s - loss: 4.8635 - acc: 0.01 - ETA: 45s - loss: 4.8634 - acc: 0.01 - ETA: 45s - loss: 4.8638 - acc: 0.01 - ETA: 45s - loss: 4.8636 - acc: 0.01 - ETA: 45s - loss: 4.8636 - acc: 0.01 - ETA: 44s - loss: 4.8634 - acc: 0.01 - ETA: 44s - loss: 4.8636 - acc: 0.01 - ETA: 44s - loss: 4.8634 - acc: 0.01 - ETA: 44s - loss: 4.8635 - acc: 0.01 - ETA: 44s - loss: 4.8629 - acc: 0.01 - ETA: 43s - loss: 4.8628 - acc: 0.01 - ETA: 43s - loss: 4.8629 - acc: 0.01 - ETA: 43s - loss: 4.8633 - acc: 0.01 - ETA: 43s - loss: 4.8634 - acc: 0.01 - ETA: 43s - loss: 4.8640 - acc: 0.01 - ETA: 43s - loss: 4.8642 - acc: 0.01 - ETA: 43s - loss: 4.8639 - acc: 0.01 - ETA: 43s - loss: 4.8641 - acc: 0.01 - ETA: 42s - loss: 4.8641 - acc: 0.01 - ETA: 42s - loss: 4.8638 - acc: 0.01 - ETA: 42s - loss: 4.8637 - acc: 0.01 - ETA: 42s - loss: 4.8637 - acc: 0.01 - ETA: 42s - loss: 4.8641 - acc: 0.01 - ETA: 42s - loss: 4.8637 - acc: 0.01 - ETA: 42s - loss: 4.8639 - acc: 0.01 - ETA: 42s - loss: 4.8641 - acc: 0.01 - ETA: 42s - loss: 4.8639 - acc: 0.01 - ETA: 41s - loss: 4.8638 - acc: 0.01 - ETA: 41s - loss: 4.8635 - acc: 0.01 - ETA: 41s - loss: 4.8634 - acc: 0.01 - ETA: 41s - loss: 4.8636 - acc: 0.01 - ETA: 41s - loss: 4.8638 - acc: 0.01 - ETA: 41s - loss: 4.8640 - acc: 0.01 - ETA: 40s - loss: 4.8636 - acc: 0.01 - ETA: 40s - loss: 4.8640 - acc: 0.01 - ETA: 40s - loss: 4.8643 - acc: 0.01 - ETA: 40s - loss: 4.8642 - acc: 0.01 - ETA: 40s - loss: 4.8643 - acc: 0.01 - ETA: 40s - loss: 4.8643 - acc: 0.01 - ETA: 39s - loss: 4.8646 - acc: 0.01 - ETA: 39s - loss: 4.8641 - acc: 0.01 - ETA: 39s - loss: 4.8641 - acc: 0.01 - ETA: 39s - loss: 4.8638 - acc: 0.01 - ETA: 39s - loss: 4.8638 - acc: 0.01 - ETA: 39s - loss: 4.8640 - acc: 0.01 - ETA: 39s - loss: 4.8633 - acc: 0.01 - ETA: 39s - loss: 4.8633 - acc: 0.01 - ETA: 38s - loss: 4.8634 - acc: 0.01 - ETA: 38s - loss: 4.8639 - acc: 0.01 - ETA: 38s - loss: 4.8638 - acc: 0.01 - ETA: 38s - loss: 4.8641 - acc: 0.01 - ETA: 38s - loss: 4.8643 - acc: 0.01 - ETA: 38s - loss: 4.8643 - acc: 0.01 - ETA: 37s - loss: 4.8645 - acc: 0.01 - ETA: 37s - loss: 4.8644 - acc: 0.01 - ETA: 37s - loss: 4.8647 - acc: 0.01 - ETA: 37s - loss: 4.8649 - acc: 0.01 - ETA: 37s - loss: 4.8649 - acc: 0.01 - ETA: 37s - loss: 4.8647 - acc: 0.01 - ETA: 37s - loss: 4.8643 - acc: 0.01 - ETA: 36s - loss: 4.8646 - acc: 0.01 - ETA: 36s - loss: 4.8642 - acc: 0.01 - ETA: 36s - loss: 4.8642 - acc: 0.01 - ETA: 36s - loss: 4.8640 - acc: 0.01 - ETA: 36s - loss: 4.8642 - acc: 0.01 - ETA: 36s - loss: 4.8644 - acc: 0.01 - ETA: 36s - loss: 4.8643 - acc: 0.01 - ETA: 35s - loss: 4.8643 - acc: 0.01 - ETA: 35s - loss: 4.8643 - acc: 0.01 - ETA: 35s - loss: 4.8646 - acc: 0.01 - ETA: 35s - loss: 4.8642 - acc: 0.01 - ETA: 35s - loss: 4.8639 - acc: 0.01 - ETA: 34s - loss: 4.8640 - acc: 0.01 - ETA: 34s - loss: 4.8637 - acc: 0.01 - ETA: 34s - loss: 4.8637 - acc: 0.01 - ETA: 34s - loss: 4.8635 - acc: 0.01 - ETA: 34s - loss: 4.8632 - acc: 0.01 - ETA: 33s - loss: 4.8632 - acc: 0.01 - ETA: 33s - loss: 4.8631 - acc: 0.01 - ETA: 33s - loss: 4.8630 - acc: 0.01 - ETA: 33s - loss: 4.8632 - acc: 0.01 - ETA: 33s - loss: 4.8630 - acc: 0.01 - ETA: 33s - loss: 4.8627 - acc: 0.01 - ETA: 33s - loss: 4.8629 - acc: 0.01 - ETA: 32s - loss: 4.8633 - acc: 0.01 - ETA: 32s - loss: 4.8632 - acc: 0.01 - ETA: 32s - loss: 4.8636 - acc: 0.01 - ETA: 32s - loss: 4.8639 - acc: 0.01 - ETA: 32s - loss: 4.8638 - acc: 0.01 - ETA: 32s - loss: 4.8638 - acc: 0.01 - ETA: 32s - loss: 4.8636 - acc: 0.01 - ETA: 31s - loss: 4.8637 - acc: 0.01 - ETA: 31s - loss: 4.8635 - acc: 0.0146"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 31s - loss: 4.8635 - acc: 0.01 - ETA: 31s - loss: 4.8635 - acc: 0.01 - ETA: 31s - loss: 4.8632 - acc: 0.01 - ETA: 31s - loss: 4.8630 - acc: 0.01 - ETA: 30s - loss: 4.8631 - acc: 0.01 - ETA: 30s - loss: 4.8632 - acc: 0.01 - ETA: 30s - loss: 4.8628 - acc: 0.01 - ETA: 30s - loss: 4.8626 - acc: 0.01 - ETA: 30s - loss: 4.8627 - acc: 0.01 - ETA: 30s - loss: 4.8628 - acc: 0.01 - ETA: 29s - loss: 4.8625 - acc: 0.01 - ETA: 29s - loss: 4.8622 - acc: 0.01 - ETA: 29s - loss: 4.8621 - acc: 0.01 - ETA: 29s - loss: 4.8625 - acc: 0.01 - ETA: 29s - loss: 4.8627 - acc: 0.01 - ETA: 28s - loss: 4.8628 - acc: 0.01 - ETA: 28s - loss: 4.8627 - acc: 0.01 - ETA: 28s - loss: 4.8628 - acc: 0.01 - ETA: 28s - loss: 4.8628 - acc: 0.01 - ETA: 28s - loss: 4.8631 - acc: 0.01 - ETA: 28s - loss: 4.8632 - acc: 0.01 - ETA: 27s - loss: 4.8633 - acc: 0.01 - ETA: 27s - loss: 4.8632 - acc: 0.01 - ETA: 27s - loss: 4.8632 - acc: 0.01 - ETA: 27s - loss: 4.8634 - acc: 0.01 - ETA: 27s - loss: 4.8634 - acc: 0.01 - ETA: 27s - loss: 4.8632 - acc: 0.01 - ETA: 26s - loss: 4.8631 - acc: 0.01 - ETA: 26s - loss: 4.8630 - acc: 0.01 - ETA: 26s - loss: 4.8631 - acc: 0.01 - ETA: 26s - loss: 4.8629 - acc: 0.01 - ETA: 26s - loss: 4.8628 - acc: 0.01 - ETA: 26s - loss: 4.8628 - acc: 0.01 - ETA: 25s - loss: 4.8631 - acc: 0.01 - ETA: 25s - loss: 4.8631 - acc: 0.01 - ETA: 25s - loss: 4.8629 - acc: 0.01 - ETA: 25s - loss: 4.8632 - acc: 0.01 - ETA: 25s - loss: 4.8632 - acc: 0.01 - ETA: 25s - loss: 4.8631 - acc: 0.01 - ETA: 24s - loss: 4.8633 - acc: 0.01 - ETA: 24s - loss: 4.8633 - acc: 0.01 - ETA: 24s - loss: 4.8633 - acc: 0.01 - ETA: 24s - loss: 4.8633 - acc: 0.01 - ETA: 24s - loss: 4.8630 - acc: 0.01 - ETA: 24s - loss: 4.8630 - acc: 0.01 - ETA: 23s - loss: 4.8630 - acc: 0.01 - ETA: 23s - loss: 4.8627 - acc: 0.01 - ETA: 23s - loss: 4.8628 - acc: 0.01 - ETA: 23s - loss: 4.8628 - acc: 0.01 - ETA: 23s - loss: 4.8629 - acc: 0.01 - ETA: 23s - loss: 4.8628 - acc: 0.01 - ETA: 23s - loss: 4.8624 - acc: 0.01 - ETA: 22s - loss: 4.8623 - acc: 0.01 - ETA: 22s - loss: 4.8622 - acc: 0.01 - ETA: 22s - loss: 4.8622 - acc: 0.01 - ETA: 22s - loss: 4.8623 - acc: 0.01 - ETA: 22s - loss: 4.8623 - acc: 0.01 - ETA: 22s - loss: 4.8624 - acc: 0.01 - ETA: 21s - loss: 4.8625 - acc: 0.01 - ETA: 21s - loss: 4.8625 - acc: 0.01 - ETA: 21s - loss: 4.8624 - acc: 0.01 - ETA: 21s - loss: 4.8623 - acc: 0.01 - ETA: 21s - loss: 4.8623 - acc: 0.01 - ETA: 21s - loss: 4.8621 - acc: 0.01 - ETA: 20s - loss: 4.8622 - acc: 0.01 - ETA: 20s - loss: 4.8623 - acc: 0.01 - ETA: 20s - loss: 4.8621 - acc: 0.01 - ETA: 20s - loss: 4.8620 - acc: 0.01 - ETA: 20s - loss: 4.8620 - acc: 0.01 - ETA: 20s - loss: 4.8620 - acc: 0.01 - ETA: 19s - loss: 4.8623 - acc: 0.01 - ETA: 19s - loss: 4.8623 - acc: 0.01 - ETA: 19s - loss: 4.8623 - acc: 0.01 - ETA: 19s - loss: 4.8622 - acc: 0.01 - ETA: 19s - loss: 4.8623 - acc: 0.01 - ETA: 19s - loss: 4.8625 - acc: 0.01 - ETA: 18s - loss: 4.8624 - acc: 0.01 - ETA: 18s - loss: 4.8622 - acc: 0.01 - ETA: 18s - loss: 4.8620 - acc: 0.01 - ETA: 18s - loss: 4.8621 - acc: 0.01 - ETA: 18s - loss: 4.8621 - acc: 0.01 - ETA: 18s - loss: 4.8622 - acc: 0.01 - ETA: 18s - loss: 4.8621 - acc: 0.01 - ETA: 17s - loss: 4.8620 - acc: 0.01 - ETA: 17s - loss: 4.8619 - acc: 0.01 - ETA: 17s - loss: 4.8618 - acc: 0.01 - ETA: 17s - loss: 4.8616 - acc: 0.01 - ETA: 17s - loss: 4.8617 - acc: 0.01 - ETA: 17s - loss: 4.8615 - acc: 0.01 - ETA: 16s - loss: 4.8617 - acc: 0.01 - ETA: 16s - loss: 4.8614 - acc: 0.01 - ETA: 16s - loss: 4.8615 - acc: 0.01 - ETA: 16s - loss: 4.8617 - acc: 0.01 - ETA: 16s - loss: 4.8617 - acc: 0.01 - ETA: 16s - loss: 4.8616 - acc: 0.01 - ETA: 15s - loss: 4.8616 - acc: 0.01 - ETA: 15s - loss: 4.8616 - acc: 0.01 - ETA: 15s - loss: 4.8615 - acc: 0.01 - ETA: 15s - loss: 4.8615 - acc: 0.01 - ETA: 15s - loss: 4.8616 - acc: 0.01 - ETA: 15s - loss: 4.8614 - acc: 0.01 - ETA: 14s - loss: 4.8612 - acc: 0.01 - ETA: 14s - loss: 4.8611 - acc: 0.01 - ETA: 14s - loss: 4.8611 - acc: 0.01 - ETA: 14s - loss: 4.8612 - acc: 0.01 - ETA: 14s - loss: 4.8612 - acc: 0.01 - ETA: 14s - loss: 4.8608 - acc: 0.01 - ETA: 14s - loss: 4.8611 - acc: 0.01 - ETA: 13s - loss: 4.8611 - acc: 0.01 - ETA: 13s - loss: 4.8610 - acc: 0.01 - ETA: 13s - loss: 4.8609 - acc: 0.01 - ETA: 13s - loss: 4.8610 - acc: 0.01 - ETA: 13s - loss: 4.8610 - acc: 0.01 - ETA: 13s - loss: 4.8612 - acc: 0.01 - ETA: 12s - loss: 4.8612 - acc: 0.01 - ETA: 12s - loss: 4.8611 - acc: 0.01 - ETA: 12s - loss: 4.8610 - acc: 0.01 - ETA: 12s - loss: 4.8609 - acc: 0.01 - ETA: 12s - loss: 4.8612 - acc: 0.01 - ETA: 12s - loss: 4.8611 - acc: 0.01 - ETA: 11s - loss: 4.8610 - acc: 0.01 - ETA: 11s - loss: 4.8610 - acc: 0.01 - ETA: 11s - loss: 4.8612 - acc: 0.01 - ETA: 11s - loss: 4.8613 - acc: 0.01 - ETA: 11s - loss: 4.8613 - acc: 0.01 - ETA: 11s - loss: 4.8615 - acc: 0.01 - ETA: 10s - loss: 4.8616 - acc: 0.01 - ETA: 10s - loss: 4.8619 - acc: 0.01 - ETA: 10s - loss: 4.8617 - acc: 0.01 - ETA: 10s - loss: 4.8614 - acc: 0.01 - ETA: 10s - loss: 4.8614 - acc: 0.01 - ETA: 10s - loss: 4.8612 - acc: 0.01 - ETA: 9s - loss: 4.8613 - acc: 0.0148 - ETA: 9s - loss: 4.8613 - acc: 0.014 - ETA: 9s - loss: 4.8612 - acc: 0.014 - ETA: 9s - loss: 4.8613 - acc: 0.014 - ETA: 9s - loss: 4.8612 - acc: 0.014 - ETA: 9s - loss: 4.8614 - acc: 0.014 - ETA: 9s - loss: 4.8612 - acc: 0.014 - ETA: 8s - loss: 4.8612 - acc: 0.014 - ETA: 8s - loss: 4.8611 - acc: 0.014 - ETA: 8s - loss: 4.8614 - acc: 0.014 - ETA: 8s - loss: 4.8614 - acc: 0.014 - ETA: 8s - loss: 4.8613 - acc: 0.014 - ETA: 8s - loss: 4.8612 - acc: 0.014 - ETA: 7s - loss: 4.8613 - acc: 0.014 - ETA: 7s - loss: 4.8612 - acc: 0.014 - ETA: 7s - loss: 4.8612 - acc: 0.014 - ETA: 7s - loss: 4.8613 - acc: 0.014 - ETA: 7s - loss: 4.8614 - acc: 0.014 - ETA: 7s - loss: 4.8615 - acc: 0.014 - ETA: 6s - loss: 4.8614 - acc: 0.014 - ETA: 6s - loss: 4.8615 - acc: 0.014 - ETA: 6s - loss: 4.8615 - acc: 0.014 - ETA: 6s - loss: 4.8614 - acc: 0.014 - ETA: 6s - loss: 4.8616 - acc: 0.014 - ETA: 6s - loss: 4.8616 - acc: 0.014 - ETA: 5s - loss: 4.8618 - acc: 0.014 - ETA: 5s - loss: 4.8618 - acc: 0.014 - ETA: 5s - loss: 4.8618 - acc: 0.014 - ETA: 5s - loss: 4.8616 - acc: 0.015 - ETA: 5s - loss: 4.8616 - acc: 0.015 - ETA: 5s - loss: 4.8615 - acc: 0.015 - ETA: 4s - loss: 4.8617 - acc: 0.015 - ETA: 4s - loss: 4.8616 - acc: 0.015 - ETA: 4s - loss: 4.8616 - acc: 0.015 - ETA: 4s - loss: 4.8618 - acc: 0.015 - ETA: 4s - loss: 4.8621 - acc: 0.015 - ETA: 4s - loss: 4.8622 - acc: 0.015 - ETA: 4s - loss: 4.8623 - acc: 0.015 - ETA: 3s - loss: 4.8624 - acc: 0.014 - ETA: 3s - loss: 4.8624 - acc: 0.014 - ETA: 3s - loss: 4.8624 - acc: 0.015 - ETA: 3s - loss: 4.8624 - acc: 0.015 - ETA: 3s - loss: 4.8624 - acc: 0.015 - ETA: 3s - loss: 4.8623 - acc: 0.014 - ETA: 2s - loss: 4.8624 - acc: 0.014 - ETA: 2s - loss: 4.8624 - acc: 0.015 - ETA: 2s - loss: 4.8624 - acc: 0.015 - ETA: 2s - loss: 4.8625 - acc: 0.014 - ETA: 2s - loss: 4.8624 - acc: 0.015 - ETA: 2s - loss: 4.8622 - acc: 0.015 - ETA: 1s - loss: 4.8622 - acc: 0.015 - ETA: 1s - loss: 4.8621 - acc: 0.014 - ETA: 1s - loss: 4.8621 - acc: 0.014 - ETA: 1s - loss: 4.8620 - acc: 0.014 - ETA: 1s - loss: 4.8621 - acc: 0.014 - ETA: 1s - loss: 4.8621 - acc: 0.014 - ETA: 0s - loss: 4.8622 - acc: 0.014 - ETA: 0s - loss: 4.8621 - acc: 0.015 - ETA: 0s - loss: 4.8621 - acc: 0.015 - ETA: 0s - loss: 4.8624 - acc: 0.014 - ETA: 0s - loss: 4.8624 - acc: 0.014 - ETA: 0s - loss: 4.8622 - acc: 0.014 - 71s 171ms/step - loss: 4.8620 - acc: 0.0150 - val_loss: 4.8565 - val_acc: 0.0195\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 4.85298\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/417 [===============>..............] - ETA: 7s - loss: 4.7662 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8254 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8509 - acc: 0.0000e+0 - ETA: 9s - loss: 4.8490 - acc: 0.0104    - ETA: 13s - loss: 4.8447 - acc: 0.00 - ETA: 17s - loss: 4.8458 - acc: 0.00 - ETA: 20s - loss: 4.8461 - acc: 0.00 - ETA: 23s - loss: 4.8471 - acc: 0.01 - ETA: 25s - loss: 4.8505 - acc: 0.01 - ETA: 27s - loss: 4.8523 - acc: 0.01 - ETA: 27s - loss: 4.8517 - acc: 0.00 - ETA: 31s - loss: 4.8535 - acc: 0.00 - ETA: 31s - loss: 4.8510 - acc: 0.00 - ETA: 32s - loss: 4.8547 - acc: 0.00 - ETA: 34s - loss: 4.8539 - acc: 0.00 - ETA: 35s - loss: 4.8553 - acc: 0.00 - ETA: 34s - loss: 4.8543 - acc: 0.00 - ETA: 35s - loss: 4.8541 - acc: 0.00 - ETA: 36s - loss: 4.8527 - acc: 0.00 - ETA: 37s - loss: 4.8530 - acc: 0.00 - ETA: 38s - loss: 4.8545 - acc: 0.00 - ETA: 38s - loss: 4.8522 - acc: 0.00 - ETA: 39s - loss: 4.8517 - acc: 0.00 - ETA: 40s - loss: 4.8516 - acc: 0.00 - ETA: 40s - loss: 4.8528 - acc: 0.00 - ETA: 40s - loss: 4.8546 - acc: 0.00 - ETA: 40s - loss: 4.8542 - acc: 0.01 - ETA: 41s - loss: 4.8526 - acc: 0.01 - ETA: 41s - loss: 4.8542 - acc: 0.01 - ETA: 41s - loss: 4.8543 - acc: 0.01 - ETA: 41s - loss: 4.8566 - acc: 0.01 - ETA: 41s - loss: 4.8594 - acc: 0.01 - ETA: 42s - loss: 4.8576 - acc: 0.01 - ETA: 42s - loss: 4.8573 - acc: 0.01 - ETA: 42s - loss: 4.8575 - acc: 0.01 - ETA: 43s - loss: 4.8581 - acc: 0.01 - ETA: 43s - loss: 4.8586 - acc: 0.01 - ETA: 43s - loss: 4.8581 - acc: 0.01 - ETA: 44s - loss: 4.8574 - acc: 0.01 - ETA: 44s - loss: 4.8584 - acc: 0.01 - ETA: 44s - loss: 4.8575 - acc: 0.01 - ETA: 44s - loss: 4.8582 - acc: 0.01 - ETA: 44s - loss: 4.8586 - acc: 0.01 - ETA: 44s - loss: 4.8600 - acc: 0.01 - ETA: 44s - loss: 4.8611 - acc: 0.01 - ETA: 44s - loss: 4.8630 - acc: 0.01 - ETA: 44s - loss: 4.8640 - acc: 0.01 - ETA: 44s - loss: 4.8625 - acc: 0.01 - ETA: 44s - loss: 4.8630 - acc: 0.00 - ETA: 44s - loss: 4.8616 - acc: 0.01 - ETA: 44s - loss: 4.8608 - acc: 0.01 - ETA: 45s - loss: 4.8610 - acc: 0.01 - ETA: 45s - loss: 4.8601 - acc: 0.01 - ETA: 45s - loss: 4.8598 - acc: 0.01 - ETA: 45s - loss: 4.8598 - acc: 0.01 - ETA: 45s - loss: 4.8589 - acc: 0.01 - ETA: 45s - loss: 4.8595 - acc: 0.01 - ETA: 46s - loss: 4.8600 - acc: 0.01 - ETA: 45s - loss: 4.8604 - acc: 0.01 - ETA: 45s - loss: 4.8608 - acc: 0.01 - ETA: 45s - loss: 4.8595 - acc: 0.01 - ETA: 45s - loss: 4.8602 - acc: 0.00 - ETA: 45s - loss: 4.8600 - acc: 0.00 - ETA: 46s - loss: 4.8598 - acc: 0.00 - ETA: 46s - loss: 4.8600 - acc: 0.00 - ETA: 46s - loss: 4.8598 - acc: 0.00 - ETA: 46s - loss: 4.8594 - acc: 0.00 - ETA: 46s - loss: 4.8596 - acc: 0.00 - ETA: 46s - loss: 4.8598 - acc: 0.00 - ETA: 47s - loss: 4.8599 - acc: 0.00 - ETA: 46s - loss: 4.8599 - acc: 0.00 - ETA: 46s - loss: 4.8597 - acc: 0.00 - ETA: 47s - loss: 4.8593 - acc: 0.00 - ETA: 46s - loss: 4.8601 - acc: 0.00 - ETA: 46s - loss: 4.8608 - acc: 0.00 - ETA: 46s - loss: 4.8610 - acc: 0.00 - ETA: 46s - loss: 4.8612 - acc: 0.00 - ETA: 46s - loss: 4.8608 - acc: 0.00 - ETA: 46s - loss: 4.8604 - acc: 0.00 - ETA: 46s - loss: 4.8606 - acc: 0.00 - ETA: 46s - loss: 4.8605 - acc: 0.00 - ETA: 46s - loss: 4.8610 - acc: 0.00 - ETA: 45s - loss: 4.8605 - acc: 0.00 - ETA: 45s - loss: 4.8611 - acc: 0.00 - ETA: 45s - loss: 4.8613 - acc: 0.00 - ETA: 45s - loss: 4.8615 - acc: 0.00 - ETA: 45s - loss: 4.8608 - acc: 0.00 - ETA: 45s - loss: 4.8611 - acc: 0.00 - ETA: 44s - loss: 4.8618 - acc: 0.00 - ETA: 44s - loss: 4.8616 - acc: 0.00 - ETA: 44s - loss: 4.8619 - acc: 0.00 - ETA: 44s - loss: 4.8616 - acc: 0.00 - ETA: 44s - loss: 4.8613 - acc: 0.00 - ETA: 44s - loss: 4.8614 - acc: 0.00 - ETA: 44s - loss: 4.8614 - acc: 0.00 - ETA: 44s - loss: 4.8614 - acc: 0.00 - ETA: 44s - loss: 4.8608 - acc: 0.00 - ETA: 44s - loss: 4.8609 - acc: 0.00 - ETA: 43s - loss: 4.8610 - acc: 0.00 - ETA: 43s - loss: 4.8609 - acc: 0.00 - ETA: 43s - loss: 4.8613 - acc: 0.01 - ETA: 43s - loss: 4.8617 - acc: 0.01 - ETA: 43s - loss: 4.8618 - acc: 0.01 - ETA: 43s - loss: 4.8617 - acc: 0.01 - ETA: 44s - loss: 4.8621 - acc: 0.00 - ETA: 43s - loss: 4.8621 - acc: 0.01 - ETA: 43s - loss: 4.8620 - acc: 0.01 - ETA: 43s - loss: 4.8623 - acc: 0.01 - ETA: 42s - loss: 4.8620 - acc: 0.01 - ETA: 42s - loss: 4.8623 - acc: 0.01 - ETA: 42s - loss: 4.8617 - acc: 0.01 - ETA: 42s - loss: 4.8616 - acc: 0.01 - ETA: 42s - loss: 4.8615 - acc: 0.01 - ETA: 42s - loss: 4.8614 - acc: 0.01 - ETA: 42s - loss: 4.8616 - acc: 0.01 - ETA: 42s - loss: 4.8619 - acc: 0.01 - ETA: 42s - loss: 4.8621 - acc: 0.01 - ETA: 41s - loss: 4.8619 - acc: 0.01 - ETA: 41s - loss: 4.8621 - acc: 0.01 - ETA: 41s - loss: 4.8624 - acc: 0.01 - ETA: 41s - loss: 4.8624 - acc: 0.01 - ETA: 41s - loss: 4.8626 - acc: 0.00 - ETA: 41s - loss: 4.8622 - acc: 0.00 - ETA: 41s - loss: 4.8628 - acc: 0.00 - ETA: 41s - loss: 4.8627 - acc: 0.00 - ETA: 40s - loss: 4.8627 - acc: 0.01 - ETA: 40s - loss: 4.8631 - acc: 0.01 - ETA: 40s - loss: 4.8630 - acc: 0.01 - ETA: 40s - loss: 4.8632 - acc: 0.00 - ETA: 40s - loss: 4.8631 - acc: 0.00 - ETA: 40s - loss: 4.8631 - acc: 0.00 - ETA: 39s - loss: 4.8631 - acc: 0.00 - ETA: 39s - loss: 4.8630 - acc: 0.00 - ETA: 39s - loss: 4.8630 - acc: 0.00 - ETA: 39s - loss: 4.8628 - acc: 0.00 - ETA: 39s - loss: 4.8629 - acc: 0.00 - ETA: 39s - loss: 4.8630 - acc: 0.00 - ETA: 39s - loss: 4.8628 - acc: 0.00 - ETA: 39s - loss: 4.8633 - acc: 0.00 - ETA: 39s - loss: 4.8634 - acc: 0.00 - ETA: 39s - loss: 4.8631 - acc: 0.00 - ETA: 39s - loss: 4.8632 - acc: 0.00 - ETA: 39s - loss: 4.8636 - acc: 0.00 - ETA: 38s - loss: 4.8635 - acc: 0.00 - ETA: 38s - loss: 4.8634 - acc: 0.00 - ETA: 38s - loss: 4.8638 - acc: 0.00 - ETA: 38s - loss: 4.8642 - acc: 0.00 - ETA: 38s - loss: 4.8642 - acc: 0.00 - ETA: 38s - loss: 4.8640 - acc: 0.00 - ETA: 37s - loss: 4.8641 - acc: 0.01 - ETA: 37s - loss: 4.8640 - acc: 0.01 - ETA: 37s - loss: 4.8638 - acc: 0.01 - ETA: 37s - loss: 4.8631 - acc: 0.01 - ETA: 37s - loss: 4.8626 - acc: 0.01 - ETA: 37s - loss: 4.8623 - acc: 0.01 - ETA: 37s - loss: 4.8621 - acc: 0.01 - ETA: 36s - loss: 4.8620 - acc: 0.01 - ETA: 36s - loss: 4.8618 - acc: 0.01 - ETA: 36s - loss: 4.8618 - acc: 0.01 - ETA: 36s - loss: 4.8620 - acc: 0.01 - ETA: 36s - loss: 4.8619 - acc: 0.01 - ETA: 36s - loss: 4.8622 - acc: 0.01 - ETA: 36s - loss: 4.8625 - acc: 0.01 - ETA: 36s - loss: 4.8621 - acc: 0.01 - ETA: 35s - loss: 4.8619 - acc: 0.01 - ETA: 35s - loss: 4.8615 - acc: 0.01 - ETA: 35s - loss: 4.8618 - acc: 0.01 - ETA: 35s - loss: 4.8621 - acc: 0.01 - ETA: 35s - loss: 4.8624 - acc: 0.01 - ETA: 35s - loss: 4.8624 - acc: 0.01 - ETA: 35s - loss: 4.8618 - acc: 0.01 - ETA: 35s - loss: 4.8619 - acc: 0.01 - ETA: 34s - loss: 4.8618 - acc: 0.01 - ETA: 34s - loss: 4.8621 - acc: 0.01 - ETA: 34s - loss: 4.8619 - acc: 0.01 - ETA: 34s - loss: 4.8623 - acc: 0.01 - ETA: 34s - loss: 4.8623 - acc: 0.01 - ETA: 34s - loss: 4.8623 - acc: 0.01 - ETA: 34s - loss: 4.8624 - acc: 0.01 - ETA: 33s - loss: 4.8624 - acc: 0.01 - ETA: 33s - loss: 4.8621 - acc: 0.01 - ETA: 33s - loss: 4.8620 - acc: 0.01 - ETA: 33s - loss: 4.8622 - acc: 0.01 - ETA: 33s - loss: 4.8620 - acc: 0.01 - ETA: 33s - loss: 4.8618 - acc: 0.01 - ETA: 32s - loss: 4.8617 - acc: 0.01 - ETA: 32s - loss: 4.8616 - acc: 0.01 - ETA: 32s - loss: 4.8614 - acc: 0.01 - ETA: 32s - loss: 4.8612 - acc: 0.01 - ETA: 32s - loss: 4.8612 - acc: 0.01 - ETA: 32s - loss: 4.8611 - acc: 0.01 - ETA: 32s - loss: 4.8611 - acc: 0.01 - ETA: 32s - loss: 4.8613 - acc: 0.01 - ETA: 31s - loss: 4.8609 - acc: 0.01 - ETA: 31s - loss: 4.8608 - acc: 0.01 - ETA: 31s - loss: 4.8612 - acc: 0.01 - ETA: 31s - loss: 4.8611 - acc: 0.01 - ETA: 31s - loss: 4.8610 - acc: 0.01 - ETA: 31s - loss: 4.8609 - acc: 0.01 - ETA: 31s - loss: 4.8608 - acc: 0.01 - ETA: 30s - loss: 4.8610 - acc: 0.01 - ETA: 30s - loss: 4.8612 - acc: 0.01 - ETA: 30s - loss: 4.8616 - acc: 0.01 - ETA: 30s - loss: 4.8616 - acc: 0.01 - ETA: 30s - loss: 4.8615 - acc: 0.01 - ETA: 30s - loss: 4.8612 - acc: 0.01 - ETA: 30s - loss: 4.8616 - acc: 0.01 - ETA: 30s - loss: 4.8614 - acc: 0.01 - ETA: 29s - loss: 4.8611 - acc: 0.01 - ETA: 29s - loss: 4.8611 - acc: 0.01 - ETA: 29s - loss: 4.8611 - acc: 0.01 - ETA: 29s - loss: 4.8613 - acc: 0.01 - ETA: 29s - loss: 4.8612 - acc: 0.01 - ETA: 29s - loss: 4.8613 - acc: 0.01 - ETA: 28s - loss: 4.8615 - acc: 0.0131"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8612 - acc: 0.01 - ETA: 28s - loss: 4.8613 - acc: 0.01 - ETA: 28s - loss: 4.8611 - acc: 0.01 - ETA: 28s - loss: 4.8610 - acc: 0.01 - ETA: 28s - loss: 4.8609 - acc: 0.01 - ETA: 28s - loss: 4.8609 - acc: 0.01 - ETA: 27s - loss: 4.8610 - acc: 0.01 - ETA: 27s - loss: 4.8608 - acc: 0.01 - ETA: 27s - loss: 4.8608 - acc: 0.01 - ETA: 27s - loss: 4.8608 - acc: 0.01 - ETA: 27s - loss: 4.8603 - acc: 0.01 - ETA: 27s - loss: 4.8601 - acc: 0.01 - ETA: 27s - loss: 4.8597 - acc: 0.01 - ETA: 26s - loss: 4.8599 - acc: 0.01 - ETA: 26s - loss: 4.8599 - acc: 0.01 - ETA: 26s - loss: 4.8602 - acc: 0.01 - ETA: 26s - loss: 4.8604 - acc: 0.01 - ETA: 26s - loss: 4.8604 - acc: 0.01 - ETA: 26s - loss: 4.8602 - acc: 0.01 - ETA: 26s - loss: 4.8602 - acc: 0.01 - ETA: 25s - loss: 4.8603 - acc: 0.01 - ETA: 25s - loss: 4.8602 - acc: 0.01 - ETA: 25s - loss: 4.8605 - acc: 0.01 - ETA: 25s - loss: 4.8605 - acc: 0.01 - ETA: 25s - loss: 4.8605 - acc: 0.01 - ETA: 25s - loss: 4.8604 - acc: 0.01 - ETA: 25s - loss: 4.8604 - acc: 0.01 - ETA: 24s - loss: 4.8604 - acc: 0.01 - ETA: 24s - loss: 4.8600 - acc: 0.01 - ETA: 24s - loss: 4.8597 - acc: 0.01 - ETA: 24s - loss: 4.8597 - acc: 0.01 - ETA: 24s - loss: 4.8597 - acc: 0.01 - ETA: 24s - loss: 4.8598 - acc: 0.01 - ETA: 24s - loss: 4.8602 - acc: 0.01 - ETA: 23s - loss: 4.8603 - acc: 0.01 - ETA: 23s - loss: 4.8597 - acc: 0.01 - ETA: 23s - loss: 4.8599 - acc: 0.01 - ETA: 23s - loss: 4.8600 - acc: 0.01 - ETA: 23s - loss: 4.8601 - acc: 0.01 - ETA: 23s - loss: 4.8598 - acc: 0.01 - ETA: 23s - loss: 4.8598 - acc: 0.01 - ETA: 22s - loss: 4.8598 - acc: 0.01 - ETA: 22s - loss: 4.8600 - acc: 0.01 - ETA: 22s - loss: 4.8601 - acc: 0.01 - ETA: 22s - loss: 4.8602 - acc: 0.01 - ETA: 22s - loss: 4.8602 - acc: 0.01 - ETA: 22s - loss: 4.8604 - acc: 0.01 - ETA: 21s - loss: 4.8606 - acc: 0.01 - ETA: 21s - loss: 4.8604 - acc: 0.01 - ETA: 21s - loss: 4.8606 - acc: 0.01 - ETA: 21s - loss: 4.8607 - acc: 0.01 - ETA: 21s - loss: 4.8606 - acc: 0.01 - ETA: 21s - loss: 4.8610 - acc: 0.01 - ETA: 21s - loss: 4.8606 - acc: 0.01 - ETA: 21s - loss: 4.8610 - acc: 0.01 - ETA: 20s - loss: 4.8610 - acc: 0.01 - ETA: 20s - loss: 4.8612 - acc: 0.01 - ETA: 20s - loss: 4.8613 - acc: 0.01 - ETA: 20s - loss: 4.8611 - acc: 0.01 - ETA: 20s - loss: 4.8612 - acc: 0.01 - ETA: 20s - loss: 4.8614 - acc: 0.01 - ETA: 19s - loss: 4.8613 - acc: 0.01 - ETA: 19s - loss: 4.8612 - acc: 0.01 - ETA: 19s - loss: 4.8610 - acc: 0.01 - ETA: 19s - loss: 4.8609 - acc: 0.01 - ETA: 19s - loss: 4.8610 - acc: 0.01 - ETA: 19s - loss: 4.8611 - acc: 0.01 - ETA: 19s - loss: 4.8611 - acc: 0.01 - ETA: 18s - loss: 4.8609 - acc: 0.01 - ETA: 18s - loss: 4.8610 - acc: 0.01 - ETA: 18s - loss: 4.8610 - acc: 0.01 - ETA: 18s - loss: 4.8608 - acc: 0.01 - ETA: 18s - loss: 4.8609 - acc: 0.01 - ETA: 18s - loss: 4.8609 - acc: 0.01 - ETA: 17s - loss: 4.8606 - acc: 0.01 - ETA: 17s - loss: 4.8605 - acc: 0.01 - ETA: 17s - loss: 4.8606 - acc: 0.01 - ETA: 17s - loss: 4.8608 - acc: 0.01 - ETA: 17s - loss: 4.8605 - acc: 0.01 - ETA: 17s - loss: 4.8604 - acc: 0.01 - ETA: 16s - loss: 4.8602 - acc: 0.01 - ETA: 16s - loss: 4.8601 - acc: 0.01 - ETA: 16s - loss: 4.8602 - acc: 0.01 - ETA: 16s - loss: 4.8604 - acc: 0.01 - ETA: 16s - loss: 4.8603 - acc: 0.01 - ETA: 16s - loss: 4.8603 - acc: 0.01 - ETA: 16s - loss: 4.8604 - acc: 0.01 - ETA: 15s - loss: 4.8603 - acc: 0.01 - ETA: 15s - loss: 4.8603 - acc: 0.01 - ETA: 15s - loss: 4.8602 - acc: 0.01 - ETA: 15s - loss: 4.8600 - acc: 0.01 - ETA: 15s - loss: 4.8601 - acc: 0.01 - ETA: 15s - loss: 4.8602 - acc: 0.01 - ETA: 15s - loss: 4.8601 - acc: 0.01 - ETA: 14s - loss: 4.8601 - acc: 0.01 - ETA: 14s - loss: 4.8601 - acc: 0.01 - ETA: 14s - loss: 4.8599 - acc: 0.01 - ETA: 14s - loss: 4.8598 - acc: 0.01 - ETA: 14s - loss: 4.8599 - acc: 0.01 - ETA: 14s - loss: 4.8599 - acc: 0.01 - ETA: 13s - loss: 4.8599 - acc: 0.01 - ETA: 13s - loss: 4.8601 - acc: 0.01 - ETA: 13s - loss: 4.8603 - acc: 0.01 - ETA: 13s - loss: 4.8607 - acc: 0.01 - ETA: 13s - loss: 4.8607 - acc: 0.01 - ETA: 13s - loss: 4.8608 - acc: 0.01 - ETA: 13s - loss: 4.8608 - acc: 0.01 - ETA: 12s - loss: 4.8608 - acc: 0.01 - ETA: 12s - loss: 4.8604 - acc: 0.01 - ETA: 12s - loss: 4.8606 - acc: 0.01 - ETA: 12s - loss: 4.8608 - acc: 0.01 - ETA: 12s - loss: 4.8608 - acc: 0.01 - ETA: 12s - loss: 4.8606 - acc: 0.01 - ETA: 11s - loss: 4.8605 - acc: 0.01 - ETA: 11s - loss: 4.8604 - acc: 0.01 - ETA: 11s - loss: 4.8606 - acc: 0.01 - ETA: 11s - loss: 4.8604 - acc: 0.01 - ETA: 11s - loss: 4.8605 - acc: 0.01 - ETA: 11s - loss: 4.8606 - acc: 0.01 - ETA: 11s - loss: 4.8605 - acc: 0.01 - ETA: 10s - loss: 4.8605 - acc: 0.01 - ETA: 10s - loss: 4.8606 - acc: 0.01 - ETA: 10s - loss: 4.8606 - acc: 0.01 - ETA: 10s - loss: 4.8607 - acc: 0.01 - ETA: 10s - loss: 4.8607 - acc: 0.01 - ETA: 10s - loss: 4.8608 - acc: 0.01 - ETA: 9s - loss: 4.8606 - acc: 0.0130 - ETA: 9s - loss: 4.8606 - acc: 0.012 - ETA: 9s - loss: 4.8605 - acc: 0.012 - ETA: 9s - loss: 4.8606 - acc: 0.013 - ETA: 9s - loss: 4.8607 - acc: 0.013 - ETA: 9s - loss: 4.8607 - acc: 0.013 - ETA: 9s - loss: 4.8607 - acc: 0.012 - ETA: 8s - loss: 4.8607 - acc: 0.012 - ETA: 8s - loss: 4.8606 - acc: 0.012 - ETA: 8s - loss: 4.8607 - acc: 0.012 - ETA: 8s - loss: 4.8606 - acc: 0.012 - ETA: 8s - loss: 4.8607 - acc: 0.012 - ETA: 8s - loss: 4.8608 - acc: 0.012 - ETA: 7s - loss: 4.8608 - acc: 0.012 - ETA: 7s - loss: 4.8606 - acc: 0.012 - ETA: 7s - loss: 4.8608 - acc: 0.012 - ETA: 7s - loss: 4.8606 - acc: 0.012 - ETA: 7s - loss: 4.8607 - acc: 0.012 - ETA: 7s - loss: 4.8606 - acc: 0.012 - ETA: 7s - loss: 4.8606 - acc: 0.013 - ETA: 6s - loss: 4.8607 - acc: 0.012 - ETA: 6s - loss: 4.8606 - acc: 0.012 - ETA: 6s - loss: 4.8606 - acc: 0.013 - ETA: 6s - loss: 4.8604 - acc: 0.013 - ETA: 6s - loss: 4.8603 - acc: 0.013 - ETA: 6s - loss: 4.8602 - acc: 0.012 - ETA: 6s - loss: 4.8604 - acc: 0.012 - ETA: 5s - loss: 4.8604 - acc: 0.012 - ETA: 5s - loss: 4.8605 - acc: 0.012 - ETA: 5s - loss: 4.8606 - acc: 0.012 - ETA: 5s - loss: 4.8605 - acc: 0.012 - ETA: 5s - loss: 4.8605 - acc: 0.012 - ETA: 5s - loss: 4.8605 - acc: 0.012 - ETA: 4s - loss: 4.8605 - acc: 0.012 - ETA: 4s - loss: 4.8605 - acc: 0.012 - ETA: 4s - loss: 4.8606 - acc: 0.012 - ETA: 4s - loss: 4.8606 - acc: 0.012 - ETA: 4s - loss: 4.8607 - acc: 0.012 - ETA: 4s - loss: 4.8609 - acc: 0.012 - ETA: 4s - loss: 4.8609 - acc: 0.012 - ETA: 3s - loss: 4.8609 - acc: 0.012 - ETA: 3s - loss: 4.8609 - acc: 0.012 - ETA: 3s - loss: 4.8610 - acc: 0.012 - ETA: 3s - loss: 4.8609 - acc: 0.012 - ETA: 3s - loss: 4.8609 - acc: 0.012 - ETA: 3s - loss: 4.8607 - acc: 0.012 - ETA: 2s - loss: 4.8607 - acc: 0.012 - ETA: 2s - loss: 4.8605 - acc: 0.012 - ETA: 2s - loss: 4.8607 - acc: 0.012 - ETA: 2s - loss: 4.8606 - acc: 0.012 - ETA: 2s - loss: 4.8607 - acc: 0.012 - ETA: 2s - loss: 4.8605 - acc: 0.012 - ETA: 2s - loss: 4.8606 - acc: 0.012 - ETA: 1s - loss: 4.8606 - acc: 0.013 - ETA: 1s - loss: 4.8606 - acc: 0.012 - ETA: 1s - loss: 4.8605 - acc: 0.012 - ETA: 1s - loss: 4.8604 - acc: 0.013 - ETA: 1s - loss: 4.8604 - acc: 0.013 - ETA: 1s - loss: 4.8602 - acc: 0.013 - ETA: 0s - loss: 4.8601 - acc: 0.012 - ETA: 0s - loss: 4.8600 - acc: 0.013 - ETA: 0s - loss: 4.8600 - acc: 0.013 - ETA: 0s - loss: 4.8599 - acc: 0.013 - ETA: 0s - loss: 4.8598 - acc: 0.013 - ETA: 0s - loss: 4.8598 - acc: 0.013 - 68s 164ms/step - loss: 4.8597 - acc: 0.0133 - val_loss: 4.8446 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00023: val_loss improved from 4.85298 to 4.84459, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 6s - loss: 4.8958 - acc: 0.0000e+0 - ETA: 6s - loss: 4.9021 - acc: 0.0312    - ETA: 6s - loss: 4.8611 - acc: 0.023 - ETA: 6s - loss: 4.8607 - acc: 0.020 - ETA: 9s - loss: 4.8555 - acc: 0.024 - ETA: 14s - loss: 4.8536 - acc: 0.02 - ETA: 16s - loss: 4.8526 - acc: 0.02 - ETA: 20s - loss: 4.8518 - acc: 0.02 - ETA: 22s - loss: 4.8516 - acc: 0.02 - ETA: 24s - loss: 4.8505 - acc: 0.02 - ETA: 26s - loss: 4.8458 - acc: 0.02 - ETA: 27s - loss: 4.8464 - acc: 0.02 - ETA: 28s - loss: 4.8472 - acc: 0.02 - ETA: 30s - loss: 4.8459 - acc: 0.02 - ETA: 33s - loss: 4.8428 - acc: 0.02 - ETA: 35s - loss: 4.8425 - acc: 0.02 - ETA: 36s - loss: 4.8452 - acc: 0.02 - ETA: 36s - loss: 4.8423 - acc: 0.02 - ETA: 38s - loss: 4.8417 - acc: 0.02 - ETA: 39s - loss: 4.8419 - acc: 0.02 - ETA: 41s - loss: 4.8408 - acc: 0.02 - ETA: 42s - loss: 4.8444 - acc: 0.02 - ETA: 44s - loss: 4.8447 - acc: 0.02 - ETA: 44s - loss: 4.8473 - acc: 0.01 - ETA: 45s - loss: 4.8488 - acc: 0.01 - ETA: 45s - loss: 4.8485 - acc: 0.01 - ETA: 45s - loss: 4.8500 - acc: 0.01 - ETA: 47s - loss: 4.8488 - acc: 0.01 - ETA: 47s - loss: 4.8497 - acc: 0.01 - ETA: 47s - loss: 4.8459 - acc: 0.01 - ETA: 48s - loss: 4.8472 - acc: 0.01 - ETA: 48s - loss: 4.8499 - acc: 0.01 - ETA: 47s - loss: 4.8527 - acc: 0.01 - ETA: 47s - loss: 4.8539 - acc: 0.01 - ETA: 47s - loss: 4.8541 - acc: 0.01 - ETA: 47s - loss: 4.8522 - acc: 0.01 - ETA: 47s - loss: 4.8541 - acc: 0.01 - ETA: 47s - loss: 4.8541 - acc: 0.01 - ETA: 47s - loss: 4.8544 - acc: 0.01 - ETA: 47s - loss: 4.8536 - acc: 0.01 - ETA: 47s - loss: 4.8533 - acc: 0.01 - ETA: 47s - loss: 4.8538 - acc: 0.01 - ETA: 46s - loss: 4.8549 - acc: 0.01 - ETA: 46s - loss: 4.8543 - acc: 0.01 - ETA: 47s - loss: 4.8558 - acc: 0.01 - ETA: 47s - loss: 4.8556 - acc: 0.01 - ETA: 47s - loss: 4.8571 - acc: 0.01 - ETA: 47s - loss: 4.8592 - acc: 0.01 - ETA: 47s - loss: 4.8574 - acc: 0.01 - ETA: 48s - loss: 4.8574 - acc: 0.01 - ETA: 48s - loss: 4.8583 - acc: 0.01 - ETA: 48s - loss: 4.8572 - acc: 0.01 - ETA: 47s - loss: 4.8580 - acc: 0.01 - ETA: 47s - loss: 4.8579 - acc: 0.01 - ETA: 48s - loss: 4.8586 - acc: 0.01 - ETA: 47s - loss: 4.8576 - acc: 0.01 - ETA: 48s - loss: 4.8580 - acc: 0.01 - ETA: 48s - loss: 4.8583 - acc: 0.01 - ETA: 47s - loss: 4.8596 - acc: 0.01 - ETA: 48s - loss: 4.8588 - acc: 0.01 - ETA: 48s - loss: 4.8586 - acc: 0.01 - ETA: 47s - loss: 4.8570 - acc: 0.01 - ETA: 47s - loss: 4.8574 - acc: 0.01 - ETA: 47s - loss: 4.8577 - acc: 0.01 - ETA: 47s - loss: 4.8584 - acc: 0.01 - ETA: 47s - loss: 4.8587 - acc: 0.01 - ETA: 47s - loss: 4.8606 - acc: 0.01 - ETA: 47s - loss: 4.8605 - acc: 0.01 - ETA: 47s - loss: 4.8606 - acc: 0.01 - ETA: 47s - loss: 4.8603 - acc: 0.01 - ETA: 47s - loss: 4.8592 - acc: 0.01 - ETA: 46s - loss: 4.8586 - acc: 0.01 - ETA: 47s - loss: 4.8584 - acc: 0.01 - ETA: 46s - loss: 4.8587 - acc: 0.01 - ETA: 46s - loss: 4.8596 - acc: 0.01 - ETA: 47s - loss: 4.8604 - acc: 0.01 - ETA: 47s - loss: 4.8601 - acc: 0.01 - ETA: 47s - loss: 4.8593 - acc: 0.01 - ETA: 47s - loss: 4.8593 - acc: 0.01 - ETA: 47s - loss: 4.8584 - acc: 0.01 - ETA: 47s - loss: 4.8586 - acc: 0.01 - ETA: 47s - loss: 4.8593 - acc: 0.01 - ETA: 47s - loss: 4.8594 - acc: 0.01 - ETA: 47s - loss: 4.8594 - acc: 0.01 - ETA: 47s - loss: 4.8593 - acc: 0.01 - ETA: 47s - loss: 4.8595 - acc: 0.01 - ETA: 46s - loss: 4.8592 - acc: 0.01 - ETA: 46s - loss: 4.8597 - acc: 0.01 - ETA: 46s - loss: 4.8595 - acc: 0.01 - ETA: 46s - loss: 4.8595 - acc: 0.01 - ETA: 46s - loss: 4.8596 - acc: 0.01 - ETA: 46s - loss: 4.8602 - acc: 0.01 - ETA: 46s - loss: 4.8602 - acc: 0.01 - ETA: 46s - loss: 4.8602 - acc: 0.01 - ETA: 46s - loss: 4.8601 - acc: 0.01 - ETA: 45s - loss: 4.8603 - acc: 0.01 - ETA: 45s - loss: 4.8596 - acc: 0.01 - ETA: 45s - loss: 4.8600 - acc: 0.01 - ETA: 45s - loss: 4.8608 - acc: 0.01 - ETA: 45s - loss: 4.8608 - acc: 0.01 - ETA: 45s - loss: 4.8601 - acc: 0.01 - ETA: 45s - loss: 4.8594 - acc: 0.01 - ETA: 45s - loss: 4.8599 - acc: 0.01 - ETA: 44s - loss: 4.8601 - acc: 0.01 - ETA: 44s - loss: 4.8598 - acc: 0.01 - ETA: 44s - loss: 4.8599 - acc: 0.01 - ETA: 44s - loss: 4.8596 - acc: 0.01 - ETA: 44s - loss: 4.8592 - acc: 0.01 - ETA: 44s - loss: 4.8596 - acc: 0.01 - ETA: 44s - loss: 4.8596 - acc: 0.01 - ETA: 44s - loss: 4.8599 - acc: 0.01 - ETA: 44s - loss: 4.8594 - acc: 0.01 - ETA: 44s - loss: 4.8596 - acc: 0.01 - ETA: 44s - loss: 4.8597 - acc: 0.01 - ETA: 43s - loss: 4.8603 - acc: 0.01 - ETA: 43s - loss: 4.8601 - acc: 0.01 - ETA: 43s - loss: 4.8608 - acc: 0.01 - ETA: 43s - loss: 4.8611 - acc: 0.01 - ETA: 43s - loss: 4.8609 - acc: 0.01 - ETA: 43s - loss: 4.8612 - acc: 0.01 - ETA: 42s - loss: 4.8611 - acc: 0.01 - ETA: 42s - loss: 4.8609 - acc: 0.01 - ETA: 42s - loss: 4.8608 - acc: 0.01 - ETA: 42s - loss: 4.8609 - acc: 0.01 - ETA: 42s - loss: 4.8609 - acc: 0.01 - ETA: 42s - loss: 4.8606 - acc: 0.01 - ETA: 41s - loss: 4.8610 - acc: 0.01 - ETA: 41s - loss: 4.8610 - acc: 0.01 - ETA: 41s - loss: 4.8610 - acc: 0.01 - ETA: 41s - loss: 4.8616 - acc: 0.01 - ETA: 41s - loss: 4.8614 - acc: 0.01 - ETA: 41s - loss: 4.8614 - acc: 0.01 - ETA: 40s - loss: 4.8616 - acc: 0.01 - ETA: 40s - loss: 4.8614 - acc: 0.01 - ETA: 40s - loss: 4.8614 - acc: 0.01 - ETA: 40s - loss: 4.8612 - acc: 0.01 - ETA: 40s - loss: 4.8615 - acc: 0.01 - ETA: 40s - loss: 4.8610 - acc: 0.01 - ETA: 40s - loss: 4.8613 - acc: 0.01 - ETA: 40s - loss: 4.8616 - acc: 0.01 - ETA: 40s - loss: 4.8615 - acc: 0.01 - ETA: 40s - loss: 4.8611 - acc: 0.01 - ETA: 39s - loss: 4.8605 - acc: 0.01 - ETA: 39s - loss: 4.8601 - acc: 0.01 - ETA: 39s - loss: 4.8604 - acc: 0.01 - ETA: 39s - loss: 4.8602 - acc: 0.01 - ETA: 39s - loss: 4.8602 - acc: 0.01 - ETA: 39s - loss: 4.8603 - acc: 0.01 - ETA: 39s - loss: 4.8603 - acc: 0.01 - ETA: 39s - loss: 4.8607 - acc: 0.01 - ETA: 38s - loss: 4.8605 - acc: 0.01 - ETA: 38s - loss: 4.8606 - acc: 0.01 - ETA: 38s - loss: 4.8613 - acc: 0.01 - ETA: 38s - loss: 4.8609 - acc: 0.01 - ETA: 38s - loss: 4.8612 - acc: 0.01 - ETA: 38s - loss: 4.8614 - acc: 0.01 - ETA: 38s - loss: 4.8614 - acc: 0.01 - ETA: 38s - loss: 4.8612 - acc: 0.01 - ETA: 38s - loss: 4.8616 - acc: 0.01 - ETA: 37s - loss: 4.8616 - acc: 0.01 - ETA: 37s - loss: 4.8617 - acc: 0.01 - ETA: 37s - loss: 4.8616 - acc: 0.01 - ETA: 37s - loss: 4.8617 - acc: 0.01 - ETA: 37s - loss: 4.8612 - acc: 0.01 - ETA: 37s - loss: 4.8612 - acc: 0.01 - ETA: 36s - loss: 4.8612 - acc: 0.01 - ETA: 36s - loss: 4.8612 - acc: 0.01 - ETA: 36s - loss: 4.8611 - acc: 0.01 - ETA: 36s - loss: 4.8612 - acc: 0.01 - ETA: 36s - loss: 4.8607 - acc: 0.01 - ETA: 36s - loss: 4.8605 - acc: 0.01 - ETA: 36s - loss: 4.8607 - acc: 0.01 - ETA: 35s - loss: 4.8607 - acc: 0.01 - ETA: 35s - loss: 4.8607 - acc: 0.01 - ETA: 35s - loss: 4.8608 - acc: 0.01 - ETA: 35s - loss: 4.8609 - acc: 0.01 - ETA: 35s - loss: 4.8610 - acc: 0.01 - ETA: 35s - loss: 4.8611 - acc: 0.01 - ETA: 35s - loss: 4.8610 - acc: 0.01 - ETA: 34s - loss: 4.8608 - acc: 0.01 - ETA: 34s - loss: 4.8609 - acc: 0.01 - ETA: 34s - loss: 4.8611 - acc: 0.01 - ETA: 34s - loss: 4.8604 - acc: 0.01 - ETA: 34s - loss: 4.8607 - acc: 0.01 - ETA: 33s - loss: 4.8607 - acc: 0.01 - ETA: 33s - loss: 4.8610 - acc: 0.01 - ETA: 33s - loss: 4.8609 - acc: 0.01 - ETA: 33s - loss: 4.8608 - acc: 0.01 - ETA: 33s - loss: 4.8607 - acc: 0.01 - ETA: 33s - loss: 4.8605 - acc: 0.01 - ETA: 33s - loss: 4.8611 - acc: 0.01 - ETA: 32s - loss: 4.8609 - acc: 0.01 - ETA: 32s - loss: 4.8614 - acc: 0.01 - ETA: 32s - loss: 4.8610 - acc: 0.01 - ETA: 32s - loss: 4.8611 - acc: 0.01 - ETA: 32s - loss: 4.8613 - acc: 0.01 - ETA: 32s - loss: 4.8615 - acc: 0.01 - ETA: 31s - loss: 4.8614 - acc: 0.01 - ETA: 31s - loss: 4.8610 - acc: 0.01 - ETA: 31s - loss: 4.8610 - acc: 0.01 - ETA: 31s - loss: 4.8610 - acc: 0.01 - ETA: 31s - loss: 4.8607 - acc: 0.01 - ETA: 31s - loss: 4.8607 - acc: 0.01 - ETA: 31s - loss: 4.8608 - acc: 0.01 - ETA: 30s - loss: 4.8610 - acc: 0.01 - ETA: 30s - loss: 4.8611 - acc: 0.01 - ETA: 30s - loss: 4.8612 - acc: 0.01 - ETA: 30s - loss: 4.8613 - acc: 0.01 - ETA: 30s - loss: 4.8610 - acc: 0.01 - ETA: 30s - loss: 4.8607 - acc: 0.01 - ETA: 30s - loss: 4.8607 - acc: 0.01 - ETA: 30s - loss: 4.8605 - acc: 0.01 - ETA: 29s - loss: 4.8603 - acc: 0.01 - ETA: 29s - loss: 4.8606 - acc: 0.01 - ETA: 29s - loss: 4.8610 - acc: 0.0151"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 29s - loss: 4.8610 - acc: 0.01 - ETA: 29s - loss: 4.8610 - acc: 0.01 - ETA: 29s - loss: 4.8610 - acc: 0.01 - ETA: 28s - loss: 4.8608 - acc: 0.01 - ETA: 28s - loss: 4.8605 - acc: 0.01 - ETA: 28s - loss: 4.8606 - acc: 0.01 - ETA: 28s - loss: 4.8605 - acc: 0.01 - ETA: 28s - loss: 4.8605 - acc: 0.01 - ETA: 28s - loss: 4.8606 - acc: 0.01 - ETA: 28s - loss: 4.8604 - acc: 0.01 - ETA: 27s - loss: 4.8605 - acc: 0.01 - ETA: 27s - loss: 4.8605 - acc: 0.01 - ETA: 27s - loss: 4.8605 - acc: 0.01 - ETA: 27s - loss: 4.8607 - acc: 0.01 - ETA: 27s - loss: 4.8608 - acc: 0.01 - ETA: 27s - loss: 4.8607 - acc: 0.01 - ETA: 27s - loss: 4.8608 - acc: 0.01 - ETA: 26s - loss: 4.8611 - acc: 0.01 - ETA: 26s - loss: 4.8614 - acc: 0.01 - ETA: 26s - loss: 4.8614 - acc: 0.01 - ETA: 26s - loss: 4.8613 - acc: 0.01 - ETA: 26s - loss: 4.8610 - acc: 0.01 - ETA: 26s - loss: 4.8610 - acc: 0.01 - ETA: 25s - loss: 4.8608 - acc: 0.01 - ETA: 25s - loss: 4.8604 - acc: 0.01 - ETA: 25s - loss: 4.8600 - acc: 0.01 - ETA: 25s - loss: 4.8599 - acc: 0.01 - ETA: 25s - loss: 4.8598 - acc: 0.01 - ETA: 25s - loss: 4.8600 - acc: 0.01 - ETA: 25s - loss: 4.8601 - acc: 0.01 - ETA: 24s - loss: 4.8600 - acc: 0.01 - ETA: 24s - loss: 4.8600 - acc: 0.01 - ETA: 24s - loss: 4.8599 - acc: 0.01 - ETA: 24s - loss: 4.8599 - acc: 0.01 - ETA: 24s - loss: 4.8599 - acc: 0.01 - ETA: 24s - loss: 4.8596 - acc: 0.01 - ETA: 23s - loss: 4.8593 - acc: 0.01 - ETA: 23s - loss: 4.8591 - acc: 0.01 - ETA: 23s - loss: 4.8587 - acc: 0.01 - ETA: 23s - loss: 4.8586 - acc: 0.01 - ETA: 23s - loss: 4.8587 - acc: 0.01 - ETA: 23s - loss: 4.8586 - acc: 0.01 - ETA: 23s - loss: 4.8586 - acc: 0.01 - ETA: 22s - loss: 4.8585 - acc: 0.01 - ETA: 22s - loss: 4.8587 - acc: 0.01 - ETA: 22s - loss: 4.8585 - acc: 0.01 - ETA: 22s - loss: 4.8587 - acc: 0.01 - ETA: 22s - loss: 4.8585 - acc: 0.01 - ETA: 22s - loss: 4.8585 - acc: 0.01 - ETA: 21s - loss: 4.8584 - acc: 0.01 - ETA: 21s - loss: 4.8586 - acc: 0.01 - ETA: 21s - loss: 4.8587 - acc: 0.01 - ETA: 21s - loss: 4.8589 - acc: 0.01 - ETA: 21s - loss: 4.8589 - acc: 0.01 - ETA: 21s - loss: 4.8590 - acc: 0.01 - ETA: 20s - loss: 4.8593 - acc: 0.01 - ETA: 20s - loss: 4.8594 - acc: 0.01 - ETA: 20s - loss: 4.8594 - acc: 0.01 - ETA: 20s - loss: 4.8593 - acc: 0.01 - ETA: 20s - loss: 4.8594 - acc: 0.01 - ETA: 20s - loss: 4.8594 - acc: 0.01 - ETA: 20s - loss: 4.8595 - acc: 0.01 - ETA: 19s - loss: 4.8593 - acc: 0.01 - ETA: 19s - loss: 4.8595 - acc: 0.01 - ETA: 19s - loss: 4.8594 - acc: 0.01 - ETA: 19s - loss: 4.8595 - acc: 0.01 - ETA: 19s - loss: 4.8595 - acc: 0.01 - ETA: 19s - loss: 4.8600 - acc: 0.01 - ETA: 19s - loss: 4.8600 - acc: 0.01 - ETA: 18s - loss: 4.8604 - acc: 0.01 - ETA: 18s - loss: 4.8603 - acc: 0.01 - ETA: 18s - loss: 4.8606 - acc: 0.01 - ETA: 18s - loss: 4.8606 - acc: 0.01 - ETA: 18s - loss: 4.8604 - acc: 0.01 - ETA: 18s - loss: 4.8604 - acc: 0.01 - ETA: 18s - loss: 4.8605 - acc: 0.01 - ETA: 17s - loss: 4.8605 - acc: 0.01 - ETA: 17s - loss: 4.8605 - acc: 0.01 - ETA: 17s - loss: 4.8607 - acc: 0.01 - ETA: 17s - loss: 4.8607 - acc: 0.01 - ETA: 17s - loss: 4.8607 - acc: 0.01 - ETA: 17s - loss: 4.8608 - acc: 0.01 - ETA: 16s - loss: 4.8608 - acc: 0.01 - ETA: 16s - loss: 4.8609 - acc: 0.01 - ETA: 16s - loss: 4.8612 - acc: 0.01 - ETA: 16s - loss: 4.8615 - acc: 0.01 - ETA: 16s - loss: 4.8616 - acc: 0.01 - ETA: 16s - loss: 4.8615 - acc: 0.01 - ETA: 16s - loss: 4.8613 - acc: 0.01 - ETA: 15s - loss: 4.8613 - acc: 0.01 - ETA: 15s - loss: 4.8612 - acc: 0.01 - ETA: 15s - loss: 4.8611 - acc: 0.01 - ETA: 15s - loss: 4.8610 - acc: 0.01 - ETA: 15s - loss: 4.8611 - acc: 0.01 - ETA: 15s - loss: 4.8612 - acc: 0.01 - ETA: 14s - loss: 4.8610 - acc: 0.01 - ETA: 14s - loss: 4.8610 - acc: 0.01 - ETA: 14s - loss: 4.8609 - acc: 0.01 - ETA: 14s - loss: 4.8610 - acc: 0.01 - ETA: 14s - loss: 4.8609 - acc: 0.01 - ETA: 14s - loss: 4.8608 - acc: 0.01 - ETA: 14s - loss: 4.8607 - acc: 0.01 - ETA: 13s - loss: 4.8607 - acc: 0.01 - ETA: 13s - loss: 4.8606 - acc: 0.01 - ETA: 13s - loss: 4.8604 - acc: 0.01 - ETA: 13s - loss: 4.8602 - acc: 0.01 - ETA: 13s - loss: 4.8600 - acc: 0.01 - ETA: 13s - loss: 4.8602 - acc: 0.01 - ETA: 13s - loss: 4.8602 - acc: 0.01 - ETA: 12s - loss: 4.8601 - acc: 0.01 - ETA: 12s - loss: 4.8600 - acc: 0.01 - ETA: 12s - loss: 4.8599 - acc: 0.01 - ETA: 12s - loss: 4.8599 - acc: 0.01 - ETA: 12s - loss: 4.8597 - acc: 0.01 - ETA: 12s - loss: 4.8597 - acc: 0.01 - ETA: 11s - loss: 4.8598 - acc: 0.01 - ETA: 11s - loss: 4.8597 - acc: 0.01 - ETA: 11s - loss: 4.8598 - acc: 0.01 - ETA: 11s - loss: 4.8598 - acc: 0.01 - ETA: 11s - loss: 4.8597 - acc: 0.01 - ETA: 11s - loss: 4.8597 - acc: 0.01 - ETA: 11s - loss: 4.8598 - acc: 0.01 - ETA: 10s - loss: 4.8598 - acc: 0.01 - ETA: 10s - loss: 4.8598 - acc: 0.01 - ETA: 10s - loss: 4.8597 - acc: 0.01 - ETA: 10s - loss: 4.8597 - acc: 0.01 - ETA: 10s - loss: 4.8597 - acc: 0.01 - ETA: 10s - loss: 4.8594 - acc: 0.01 - ETA: 9s - loss: 4.8595 - acc: 0.0158 - ETA: 9s - loss: 4.8594 - acc: 0.015 - ETA: 9s - loss: 4.8593 - acc: 0.015 - ETA: 9s - loss: 4.8596 - acc: 0.015 - ETA: 9s - loss: 4.8596 - acc: 0.015 - ETA: 9s - loss: 4.8594 - acc: 0.016 - ETA: 9s - loss: 4.8592 - acc: 0.016 - ETA: 8s - loss: 4.8593 - acc: 0.016 - ETA: 8s - loss: 4.8592 - acc: 0.016 - ETA: 8s - loss: 4.8594 - acc: 0.016 - ETA: 8s - loss: 4.8595 - acc: 0.016 - ETA: 8s - loss: 4.8595 - acc: 0.016 - ETA: 8s - loss: 4.8592 - acc: 0.016 - ETA: 7s - loss: 4.8591 - acc: 0.016 - ETA: 7s - loss: 4.8590 - acc: 0.016 - ETA: 7s - loss: 4.8590 - acc: 0.016 - ETA: 7s - loss: 4.8588 - acc: 0.016 - ETA: 7s - loss: 4.8588 - acc: 0.016 - ETA: 7s - loss: 4.8590 - acc: 0.016 - ETA: 7s - loss: 4.8589 - acc: 0.016 - ETA: 6s - loss: 4.8589 - acc: 0.016 - ETA: 6s - loss: 4.8587 - acc: 0.016 - ETA: 6s - loss: 4.8587 - acc: 0.016 - ETA: 6s - loss: 4.8590 - acc: 0.016 - ETA: 6s - loss: 4.8591 - acc: 0.016 - ETA: 6s - loss: 4.8589 - acc: 0.015 - ETA: 5s - loss: 4.8589 - acc: 0.016 - ETA: 5s - loss: 4.8589 - acc: 0.016 - ETA: 5s - loss: 4.8587 - acc: 0.016 - ETA: 5s - loss: 4.8588 - acc: 0.016 - ETA: 5s - loss: 4.8589 - acc: 0.016 - ETA: 5s - loss: 4.8590 - acc: 0.016 - ETA: 5s - loss: 4.8591 - acc: 0.016 - ETA: 4s - loss: 4.8591 - acc: 0.016 - ETA: 4s - loss: 4.8590 - acc: 0.016 - ETA: 4s - loss: 4.8592 - acc: 0.016 - ETA: 4s - loss: 4.8590 - acc: 0.016 - ETA: 4s - loss: 4.8591 - acc: 0.016 - ETA: 4s - loss: 4.8590 - acc: 0.016 - ETA: 3s - loss: 4.8592 - acc: 0.016 - ETA: 3s - loss: 4.8591 - acc: 0.016 - ETA: 3s - loss: 4.8592 - acc: 0.016 - ETA: 3s - loss: 4.8594 - acc: 0.016 - ETA: 3s - loss: 4.8595 - acc: 0.016 - ETA: 3s - loss: 4.8595 - acc: 0.016 - ETA: 3s - loss: 4.8593 - acc: 0.016 - ETA: 2s - loss: 4.8594 - acc: 0.016 - ETA: 2s - loss: 4.8593 - acc: 0.016 - ETA: 2s - loss: 4.8593 - acc: 0.015 - ETA: 2s - loss: 4.8592 - acc: 0.015 - ETA: 2s - loss: 4.8591 - acc: 0.016 - ETA: 2s - loss: 4.8591 - acc: 0.016 - ETA: 1s - loss: 4.8592 - acc: 0.016 - ETA: 1s - loss: 4.8590 - acc: 0.016 - ETA: 1s - loss: 4.8590 - acc: 0.016 - ETA: 1s - loss: 4.8590 - acc: 0.016 - ETA: 1s - loss: 4.8592 - acc: 0.016 - ETA: 1s - loss: 4.8591 - acc: 0.016 - ETA: 1s - loss: 4.8592 - acc: 0.016 - ETA: 0s - loss: 4.8593 - acc: 0.016 - ETA: 0s - loss: 4.8593 - acc: 0.015 - ETA: 0s - loss: 4.8593 - acc: 0.016 - ETA: 0s - loss: 4.8593 - acc: 0.016 - ETA: 0s - loss: 4.8594 - acc: 0.016 - ETA: 0s - loss: 4.8594 - acc: 0.016 - 68s 162ms/step - loss: 4.8593 - acc: 0.0160 - val_loss: 4.8487 - val_acc: 0.0195\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 4.84459\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 6s - loss: 4.8534 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8328 - acc: 0.0125    - ETA: 6s - loss: 4.8469 - acc: 0.013 - ETA: 15s - loss: 4.8717 - acc: 0.01 - ETA: 18s - loss: 4.8735 - acc: 0.01 - ETA: 20s - loss: 4.8727 - acc: 0.01 - ETA: 22s - loss: 4.8714 - acc: 0.01 - ETA: 24s - loss: 4.8704 - acc: 0.01 - ETA: 25s - loss: 4.8706 - acc: 0.01 - ETA: 27s - loss: 4.8700 - acc: 0.01 - ETA: 28s - loss: 4.8737 - acc: 0.01 - ETA: 30s - loss: 4.8749 - acc: 0.01 - ETA: 31s - loss: 4.8740 - acc: 0.01 - ETA: 31s - loss: 4.8772 - acc: 0.01 - ETA: 33s - loss: 4.8743 - acc: 0.01 - ETA: 33s - loss: 4.8745 - acc: 0.01 - ETA: 34s - loss: 4.8754 - acc: 0.01 - ETA: 35s - loss: 4.8710 - acc: 0.01 - ETA: 36s - loss: 4.8713 - acc: 0.01 - ETA: 37s - loss: 4.8709 - acc: 0.01 - ETA: 38s - loss: 4.8699 - acc: 0.01 - ETA: 38s - loss: 4.8701 - acc: 0.01 - ETA: 38s - loss: 4.8670 - acc: 0.01 - ETA: 39s - loss: 4.8675 - acc: 0.01 - ETA: 39s - loss: 4.8640 - acc: 0.01 - ETA: 40s - loss: 4.8636 - acc: 0.01 - ETA: 43s - loss: 4.8630 - acc: 0.01 - ETA: 43s - loss: 4.8607 - acc: 0.01 - ETA: 43s - loss: 4.8574 - acc: 0.02 - ETA: 43s - loss: 4.8555 - acc: 0.02 - ETA: 43s - loss: 4.8552 - acc: 0.02 - ETA: 43s - loss: 4.8539 - acc: 0.02 - ETA: 43s - loss: 4.8538 - acc: 0.02 - ETA: 43s - loss: 4.8526 - acc: 0.02 - ETA: 43s - loss: 4.8532 - acc: 0.02 - ETA: 43s - loss: 4.8532 - acc: 0.02 - ETA: 43s - loss: 4.8549 - acc: 0.02 - ETA: 43s - loss: 4.8521 - acc: 0.01 - ETA: 43s - loss: 4.8511 - acc: 0.01 - ETA: 44s - loss: 4.8531 - acc: 0.01 - ETA: 44s - loss: 4.8542 - acc: 0.01 - ETA: 44s - loss: 4.8540 - acc: 0.01 - ETA: 44s - loss: 4.8542 - acc: 0.01 - ETA: 44s - loss: 4.8551 - acc: 0.01 - ETA: 45s - loss: 4.8545 - acc: 0.01 - ETA: 45s - loss: 4.8535 - acc: 0.01 - ETA: 46s - loss: 4.8536 - acc: 0.01 - ETA: 46s - loss: 4.8550 - acc: 0.01 - ETA: 47s - loss: 4.8537 - acc: 0.01 - ETA: 47s - loss: 4.8544 - acc: 0.01 - ETA: 47s - loss: 4.8549 - acc: 0.02 - ETA: 46s - loss: 4.8562 - acc: 0.02 - ETA: 46s - loss: 4.8558 - acc: 0.02 - ETA: 46s - loss: 4.8566 - acc: 0.01 - ETA: 46s - loss: 4.8555 - acc: 0.02 - ETA: 46s - loss: 4.8561 - acc: 0.02 - ETA: 46s - loss: 4.8567 - acc: 0.01 - ETA: 46s - loss: 4.8579 - acc: 0.01 - ETA: 46s - loss: 4.8582 - acc: 0.01 - ETA: 46s - loss: 4.8573 - acc: 0.01 - ETA: 46s - loss: 4.8557 - acc: 0.01 - ETA: 46s - loss: 4.8560 - acc: 0.01 - ETA: 46s - loss: 4.8563 - acc: 0.01 - ETA: 46s - loss: 4.8567 - acc: 0.01 - ETA: 45s - loss: 4.8566 - acc: 0.01 - ETA: 45s - loss: 4.8557 - acc: 0.01 - ETA: 46s - loss: 4.8553 - acc: 0.01 - ETA: 45s - loss: 4.8553 - acc: 0.01 - ETA: 45s - loss: 4.8542 - acc: 0.01 - ETA: 45s - loss: 4.8533 - acc: 0.01 - ETA: 45s - loss: 4.8529 - acc: 0.01 - ETA: 46s - loss: 4.8512 - acc: 0.01 - ETA: 45s - loss: 4.8517 - acc: 0.01 - ETA: 45s - loss: 4.8511 - acc: 0.01 - ETA: 46s - loss: 4.8515 - acc: 0.01 - ETA: 45s - loss: 4.8507 - acc: 0.01 - ETA: 45s - loss: 4.8508 - acc: 0.01 - ETA: 45s - loss: 4.8507 - acc: 0.01 - ETA: 45s - loss: 4.8521 - acc: 0.01 - ETA: 45s - loss: 4.8523 - acc: 0.01 - ETA: 45s - loss: 4.8534 - acc: 0.01 - ETA: 45s - loss: 4.8538 - acc: 0.01 - ETA: 45s - loss: 4.8539 - acc: 0.01 - ETA: 45s - loss: 4.8545 - acc: 0.01 - ETA: 45s - loss: 4.8540 - acc: 0.01 - ETA: 44s - loss: 4.8541 - acc: 0.01 - ETA: 44s - loss: 4.8543 - acc: 0.01 - ETA: 45s - loss: 4.8541 - acc: 0.01 - ETA: 44s - loss: 4.8532 - acc: 0.01 - ETA: 44s - loss: 4.8524 - acc: 0.01 - ETA: 44s - loss: 4.8526 - acc: 0.01 - ETA: 44s - loss: 4.8532 - acc: 0.01 - ETA: 44s - loss: 4.8527 - acc: 0.01 - ETA: 44s - loss: 4.8527 - acc: 0.01 - ETA: 44s - loss: 4.8534 - acc: 0.01 - ETA: 44s - loss: 4.8544 - acc: 0.01 - ETA: 44s - loss: 4.8543 - acc: 0.01 - ETA: 44s - loss: 4.8542 - acc: 0.01 - ETA: 43s - loss: 4.8547 - acc: 0.01 - ETA: 43s - loss: 4.8552 - acc: 0.01 - ETA: 43s - loss: 4.8559 - acc: 0.01 - ETA: 43s - loss: 4.8555 - acc: 0.01 - ETA: 43s - loss: 4.8555 - acc: 0.01 - ETA: 43s - loss: 4.8559 - acc: 0.01 - ETA: 43s - loss: 4.8553 - acc: 0.01 - ETA: 43s - loss: 4.8549 - acc: 0.01 - ETA: 43s - loss: 4.8550 - acc: 0.01 - ETA: 42s - loss: 4.8545 - acc: 0.01 - ETA: 42s - loss: 4.8549 - acc: 0.01 - ETA: 42s - loss: 4.8550 - acc: 0.01 - ETA: 42s - loss: 4.8552 - acc: 0.01 - ETA: 42s - loss: 4.8552 - acc: 0.01 - ETA: 42s - loss: 4.8554 - acc: 0.01 - ETA: 42s - loss: 4.8555 - acc: 0.01 - ETA: 42s - loss: 4.8554 - acc: 0.01 - ETA: 42s - loss: 4.8556 - acc: 0.01 - ETA: 42s - loss: 4.8560 - acc: 0.01 - ETA: 42s - loss: 4.8556 - acc: 0.01 - ETA: 42s - loss: 4.8558 - acc: 0.01 - ETA: 41s - loss: 4.8553 - acc: 0.01 - ETA: 41s - loss: 4.8553 - acc: 0.01 - ETA: 41s - loss: 4.8554 - acc: 0.01 - ETA: 41s - loss: 4.8560 - acc: 0.01 - ETA: 41s - loss: 4.8565 - acc: 0.01 - ETA: 41s - loss: 4.8563 - acc: 0.01 - ETA: 41s - loss: 4.8568 - acc: 0.01 - ETA: 40s - loss: 4.8571 - acc: 0.01 - ETA: 40s - loss: 4.8577 - acc: 0.01 - ETA: 40s - loss: 4.8575 - acc: 0.01 - ETA: 40s - loss: 4.8574 - acc: 0.01 - ETA: 40s - loss: 4.8572 - acc: 0.01 - ETA: 40s - loss: 4.8572 - acc: 0.01 - ETA: 40s - loss: 4.8578 - acc: 0.01 - ETA: 39s - loss: 4.8579 - acc: 0.01 - ETA: 39s - loss: 4.8576 - acc: 0.01 - ETA: 39s - loss: 4.8581 - acc: 0.01 - ETA: 39s - loss: 4.8581 - acc: 0.01 - ETA: 39s - loss: 4.8582 - acc: 0.01 - ETA: 39s - loss: 4.8587 - acc: 0.01 - ETA: 39s - loss: 4.8596 - acc: 0.01 - ETA: 38s - loss: 4.8597 - acc: 0.01 - ETA: 38s - loss: 4.8593 - acc: 0.01 - ETA: 38s - loss: 4.8596 - acc: 0.01 - ETA: 38s - loss: 4.8601 - acc: 0.01 - ETA: 38s - loss: 4.8596 - acc: 0.01 - ETA: 38s - loss: 4.8595 - acc: 0.01 - ETA: 38s - loss: 4.8595 - acc: 0.01 - ETA: 37s - loss: 4.8595 - acc: 0.01 - ETA: 37s - loss: 4.8591 - acc: 0.01 - ETA: 37s - loss: 4.8591 - acc: 0.01 - ETA: 37s - loss: 4.8588 - acc: 0.01 - ETA: 37s - loss: 4.8580 - acc: 0.01 - ETA: 37s - loss: 4.8578 - acc: 0.01 - ETA: 37s - loss: 4.8575 - acc: 0.01 - ETA: 37s - loss: 4.8574 - acc: 0.01 - ETA: 37s - loss: 4.8574 - acc: 0.01 - ETA: 37s - loss: 4.8581 - acc: 0.01 - ETA: 36s - loss: 4.8578 - acc: 0.01 - ETA: 36s - loss: 4.8578 - acc: 0.01 - ETA: 36s - loss: 4.8576 - acc: 0.01 - ETA: 36s - loss: 4.8578 - acc: 0.01 - ETA: 36s - loss: 4.8580 - acc: 0.01 - ETA: 36s - loss: 4.8580 - acc: 0.01 - ETA: 35s - loss: 4.8585 - acc: 0.01 - ETA: 35s - loss: 4.8585 - acc: 0.01 - ETA: 35s - loss: 4.8583 - acc: 0.01 - ETA: 35s - loss: 4.8580 - acc: 0.01 - ETA: 35s - loss: 4.8580 - acc: 0.01 - ETA: 35s - loss: 4.8581 - acc: 0.01 - ETA: 35s - loss: 4.8583 - acc: 0.01 - ETA: 34s - loss: 4.8582 - acc: 0.01 - ETA: 34s - loss: 4.8585 - acc: 0.01 - ETA: 34s - loss: 4.8590 - acc: 0.01 - ETA: 34s - loss: 4.8590 - acc: 0.01 - ETA: 34s - loss: 4.8592 - acc: 0.01 - ETA: 34s - loss: 4.8590 - acc: 0.01 - ETA: 33s - loss: 4.8588 - acc: 0.01 - ETA: 33s - loss: 4.8595 - acc: 0.01 - ETA: 33s - loss: 4.8595 - acc: 0.01 - ETA: 33s - loss: 4.8594 - acc: 0.01 - ETA: 33s - loss: 4.8590 - acc: 0.01 - ETA: 33s - loss: 4.8589 - acc: 0.01 - ETA: 32s - loss: 4.8590 - acc: 0.01 - ETA: 33s - loss: 4.8590 - acc: 0.01 - ETA: 32s - loss: 4.8585 - acc: 0.01 - ETA: 32s - loss: 4.8586 - acc: 0.01 - ETA: 32s - loss: 4.8588 - acc: 0.01 - ETA: 32s - loss: 4.8590 - acc: 0.01 - ETA: 32s - loss: 4.8589 - acc: 0.01 - ETA: 32s - loss: 4.8585 - acc: 0.01 - ETA: 32s - loss: 4.8586 - acc: 0.01 - ETA: 31s - loss: 4.8584 - acc: 0.01 - ETA: 31s - loss: 4.8586 - acc: 0.01 - ETA: 31s - loss: 4.8581 - acc: 0.01 - ETA: 31s - loss: 4.8579 - acc: 0.01 - ETA: 31s - loss: 4.8578 - acc: 0.01 - ETA: 31s - loss: 4.8581 - acc: 0.01 - ETA: 31s - loss: 4.8580 - acc: 0.01 - ETA: 31s - loss: 4.8580 - acc: 0.01 - ETA: 31s - loss: 4.8578 - acc: 0.01 - ETA: 30s - loss: 4.8584 - acc: 0.01 - ETA: 30s - loss: 4.8585 - acc: 0.01 - ETA: 30s - loss: 4.8585 - acc: 0.01 - ETA: 30s - loss: 4.8582 - acc: 0.01 - ETA: 30s - loss: 4.8585 - acc: 0.01 - ETA: 30s - loss: 4.8584 - acc: 0.01 - ETA: 29s - loss: 4.8585 - acc: 0.01 - ETA: 29s - loss: 4.8584 - acc: 0.01 - ETA: 29s - loss: 4.8582 - acc: 0.01 - ETA: 29s - loss: 4.8580 - acc: 0.01 - ETA: 29s - loss: 4.8581 - acc: 0.01 - ETA: 29s - loss: 4.8580 - acc: 0.01 - ETA: 29s - loss: 4.8574 - acc: 0.01 - ETA: 28s - loss: 4.8571 - acc: 0.01 - ETA: 28s - loss: 4.8573 - acc: 0.0159"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8579 - acc: 0.01 - ETA: 28s - loss: 4.8581 - acc: 0.01 - ETA: 28s - loss: 4.8586 - acc: 0.01 - ETA: 28s - loss: 4.8587 - acc: 0.01 - ETA: 28s - loss: 4.8587 - acc: 0.01 - ETA: 27s - loss: 4.8586 - acc: 0.01 - ETA: 27s - loss: 4.8587 - acc: 0.01 - ETA: 27s - loss: 4.8587 - acc: 0.01 - ETA: 27s - loss: 4.8590 - acc: 0.01 - ETA: 27s - loss: 4.8591 - acc: 0.01 - ETA: 27s - loss: 4.8589 - acc: 0.01 - ETA: 27s - loss: 4.8589 - acc: 0.01 - ETA: 26s - loss: 4.8588 - acc: 0.01 - ETA: 26s - loss: 4.8588 - acc: 0.01 - ETA: 26s - loss: 4.8584 - acc: 0.01 - ETA: 26s - loss: 4.8586 - acc: 0.01 - ETA: 26s - loss: 4.8581 - acc: 0.01 - ETA: 26s - loss: 4.8577 - acc: 0.01 - ETA: 25s - loss: 4.8576 - acc: 0.01 - ETA: 25s - loss: 4.8574 - acc: 0.01 - ETA: 25s - loss: 4.8573 - acc: 0.01 - ETA: 25s - loss: 4.8571 - acc: 0.01 - ETA: 25s - loss: 4.8571 - acc: 0.01 - ETA: 25s - loss: 4.8573 - acc: 0.01 - ETA: 25s - loss: 4.8571 - acc: 0.01 - ETA: 24s - loss: 4.8570 - acc: 0.01 - ETA: 24s - loss: 4.8566 - acc: 0.01 - ETA: 24s - loss: 4.8567 - acc: 0.01 - ETA: 24s - loss: 4.8567 - acc: 0.01 - ETA: 24s - loss: 4.8569 - acc: 0.01 - ETA: 24s - loss: 4.8566 - acc: 0.01 - ETA: 24s - loss: 4.8567 - acc: 0.01 - ETA: 23s - loss: 4.8571 - acc: 0.01 - ETA: 23s - loss: 4.8568 - acc: 0.01 - ETA: 23s - loss: 4.8568 - acc: 0.01 - ETA: 23s - loss: 4.8569 - acc: 0.01 - ETA: 23s - loss: 4.8572 - acc: 0.01 - ETA: 23s - loss: 4.8572 - acc: 0.01 - ETA: 22s - loss: 4.8575 - acc: 0.01 - ETA: 22s - loss: 4.8572 - acc: 0.01 - ETA: 22s - loss: 4.8571 - acc: 0.01 - ETA: 22s - loss: 4.8570 - acc: 0.01 - ETA: 22s - loss: 4.8569 - acc: 0.01 - ETA: 22s - loss: 4.8569 - acc: 0.01 - ETA: 22s - loss: 4.8572 - acc: 0.01 - ETA: 21s - loss: 4.8571 - acc: 0.01 - ETA: 21s - loss: 4.8574 - acc: 0.01 - ETA: 21s - loss: 4.8574 - acc: 0.01 - ETA: 21s - loss: 4.8575 - acc: 0.01 - ETA: 21s - loss: 4.8577 - acc: 0.01 - ETA: 21s - loss: 4.8578 - acc: 0.01 - ETA: 21s - loss: 4.8579 - acc: 0.01 - ETA: 20s - loss: 4.8580 - acc: 0.01 - ETA: 20s - loss: 4.8579 - acc: 0.01 - ETA: 20s - loss: 4.8581 - acc: 0.01 - ETA: 20s - loss: 4.8581 - acc: 0.01 - ETA: 20s - loss: 4.8581 - acc: 0.01 - ETA: 20s - loss: 4.8577 - acc: 0.01 - ETA: 20s - loss: 4.8579 - acc: 0.01 - ETA: 19s - loss: 4.8579 - acc: 0.01 - ETA: 19s - loss: 4.8580 - acc: 0.01 - ETA: 19s - loss: 4.8579 - acc: 0.01 - ETA: 19s - loss: 4.8578 - acc: 0.01 - ETA: 19s - loss: 4.8578 - acc: 0.01 - ETA: 19s - loss: 4.8575 - acc: 0.01 - ETA: 19s - loss: 4.8575 - acc: 0.01 - ETA: 19s - loss: 4.8571 - acc: 0.01 - ETA: 18s - loss: 4.8571 - acc: 0.01 - ETA: 18s - loss: 4.8569 - acc: 0.01 - ETA: 18s - loss: 4.8565 - acc: 0.01 - ETA: 18s - loss: 4.8567 - acc: 0.01 - ETA: 18s - loss: 4.8563 - acc: 0.01 - ETA: 18s - loss: 4.8564 - acc: 0.01 - ETA: 17s - loss: 4.8563 - acc: 0.01 - ETA: 17s - loss: 4.8563 - acc: 0.01 - ETA: 17s - loss: 4.8562 - acc: 0.01 - ETA: 17s - loss: 4.8560 - acc: 0.01 - ETA: 17s - loss: 4.8563 - acc: 0.01 - ETA: 17s - loss: 4.8564 - acc: 0.01 - ETA: 17s - loss: 4.8564 - acc: 0.01 - ETA: 16s - loss: 4.8561 - acc: 0.01 - ETA: 16s - loss: 4.8561 - acc: 0.01 - ETA: 16s - loss: 4.8559 - acc: 0.01 - ETA: 16s - loss: 4.8559 - acc: 0.01 - ETA: 16s - loss: 4.8557 - acc: 0.01 - ETA: 16s - loss: 4.8554 - acc: 0.01 - ETA: 16s - loss: 4.8555 - acc: 0.01 - ETA: 15s - loss: 4.8558 - acc: 0.01 - ETA: 15s - loss: 4.8557 - acc: 0.01 - ETA: 15s - loss: 4.8554 - acc: 0.01 - ETA: 15s - loss: 4.8554 - acc: 0.01 - ETA: 15s - loss: 4.8553 - acc: 0.01 - ETA: 15s - loss: 4.8551 - acc: 0.01 - ETA: 14s - loss: 4.8554 - acc: 0.01 - ETA: 14s - loss: 4.8553 - acc: 0.01 - ETA: 14s - loss: 4.8555 - acc: 0.01 - ETA: 14s - loss: 4.8556 - acc: 0.01 - ETA: 14s - loss: 4.8558 - acc: 0.01 - ETA: 14s - loss: 4.8561 - acc: 0.01 - ETA: 14s - loss: 4.8560 - acc: 0.01 - ETA: 13s - loss: 4.8555 - acc: 0.01 - ETA: 13s - loss: 4.8554 - acc: 0.01 - ETA: 13s - loss: 4.8552 - acc: 0.01 - ETA: 13s - loss: 4.8553 - acc: 0.01 - ETA: 13s - loss: 4.8554 - acc: 0.01 - ETA: 13s - loss: 4.8555 - acc: 0.01 - ETA: 12s - loss: 4.8558 - acc: 0.01 - ETA: 12s - loss: 4.8559 - acc: 0.01 - ETA: 12s - loss: 4.8556 - acc: 0.01 - ETA: 12s - loss: 4.8557 - acc: 0.01 - ETA: 12s - loss: 4.8556 - acc: 0.01 - ETA: 12s - loss: 4.8558 - acc: 0.01 - ETA: 12s - loss: 4.8555 - acc: 0.01 - ETA: 11s - loss: 4.8556 - acc: 0.01 - ETA: 11s - loss: 4.8556 - acc: 0.01 - ETA: 11s - loss: 4.8556 - acc: 0.01 - ETA: 11s - loss: 4.8559 - acc: 0.01 - ETA: 11s - loss: 4.8561 - acc: 0.01 - ETA: 11s - loss: 4.8562 - acc: 0.01 - ETA: 11s - loss: 4.8560 - acc: 0.01 - ETA: 10s - loss: 4.8560 - acc: 0.01 - ETA: 10s - loss: 4.8559 - acc: 0.01 - ETA: 10s - loss: 4.8557 - acc: 0.01 - ETA: 10s - loss: 4.8559 - acc: 0.01 - ETA: 10s - loss: 4.8559 - acc: 0.01 - ETA: 10s - loss: 4.8558 - acc: 0.01 - ETA: 9s - loss: 4.8560 - acc: 0.0153 - ETA: 9s - loss: 4.8560 - acc: 0.015 - ETA: 9s - loss: 4.8562 - acc: 0.015 - ETA: 9s - loss: 4.8562 - acc: 0.015 - ETA: 9s - loss: 4.8561 - acc: 0.015 - ETA: 9s - loss: 4.8561 - acc: 0.015 - ETA: 9s - loss: 4.8562 - acc: 0.015 - ETA: 8s - loss: 4.8562 - acc: 0.015 - ETA: 8s - loss: 4.8562 - acc: 0.015 - ETA: 8s - loss: 4.8567 - acc: 0.015 - ETA: 8s - loss: 4.8567 - acc: 0.015 - ETA: 8s - loss: 4.8566 - acc: 0.015 - ETA: 8s - loss: 4.8566 - acc: 0.015 - ETA: 7s - loss: 4.8565 - acc: 0.014 - ETA: 7s - loss: 4.8566 - acc: 0.014 - ETA: 7s - loss: 4.8567 - acc: 0.014 - ETA: 7s - loss: 4.8565 - acc: 0.015 - ETA: 7s - loss: 4.8563 - acc: 0.015 - ETA: 7s - loss: 4.8566 - acc: 0.015 - ETA: 7s - loss: 4.8568 - acc: 0.015 - ETA: 6s - loss: 4.8568 - acc: 0.015 - ETA: 6s - loss: 4.8568 - acc: 0.015 - ETA: 6s - loss: 4.8569 - acc: 0.015 - ETA: 6s - loss: 4.8571 - acc: 0.015 - ETA: 6s - loss: 4.8573 - acc: 0.015 - ETA: 6s - loss: 4.8574 - acc: 0.015 - ETA: 6s - loss: 4.8574 - acc: 0.015 - ETA: 5s - loss: 4.8573 - acc: 0.015 - ETA: 5s - loss: 4.8577 - acc: 0.015 - ETA: 5s - loss: 4.8578 - acc: 0.015 - ETA: 5s - loss: 4.8578 - acc: 0.014 - ETA: 5s - loss: 4.8577 - acc: 0.014 - ETA: 5s - loss: 4.8576 - acc: 0.014 - ETA: 5s - loss: 4.8578 - acc: 0.014 - ETA: 4s - loss: 4.8578 - acc: 0.014 - ETA: 4s - loss: 4.8576 - acc: 0.015 - ETA: 4s - loss: 4.8574 - acc: 0.015 - ETA: 4s - loss: 4.8574 - acc: 0.015 - ETA: 4s - loss: 4.8573 - acc: 0.015 - ETA: 4s - loss: 4.8574 - acc: 0.015 - ETA: 3s - loss: 4.8576 - acc: 0.015 - ETA: 3s - loss: 4.8578 - acc: 0.015 - ETA: 3s - loss: 4.8577 - acc: 0.015 - ETA: 3s - loss: 4.8578 - acc: 0.015 - ETA: 3s - loss: 4.8579 - acc: 0.015 - ETA: 3s - loss: 4.8581 - acc: 0.015 - ETA: 3s - loss: 4.8581 - acc: 0.015 - ETA: 2s - loss: 4.8581 - acc: 0.015 - ETA: 2s - loss: 4.8580 - acc: 0.015 - ETA: 2s - loss: 4.8581 - acc: 0.015 - ETA: 2s - loss: 4.8582 - acc: 0.015 - ETA: 2s - loss: 4.8580 - acc: 0.015 - ETA: 2s - loss: 4.8579 - acc: 0.015 - ETA: 1s - loss: 4.8580 - acc: 0.015 - ETA: 1s - loss: 4.8579 - acc: 0.015 - ETA: 1s - loss: 4.8579 - acc: 0.015 - ETA: 1s - loss: 4.8580 - acc: 0.015 - ETA: 1s - loss: 4.8577 - acc: 0.015 - ETA: 1s - loss: 4.8577 - acc: 0.015 - ETA: 1s - loss: 4.8574 - acc: 0.015 - ETA: 0s - loss: 4.8573 - acc: 0.015 - ETA: 0s - loss: 4.8574 - acc: 0.015 - ETA: 0s - loss: 4.8573 - acc: 0.015 - ETA: 0s - loss: 4.8576 - acc: 0.015 - ETA: 0s - loss: 4.8576 - acc: 0.015 - ETA: 0s - loss: 4.8577 - acc: 0.015 - 67s 161ms/step - loss: 4.8575 - acc: 0.0154 - val_loss: 4.8507 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 4.84459\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 6s - loss: 4.8794 - acc: 0.062 - ETA: 6s - loss: 4.8597 - acc: 0.037 - ETA: 6s - loss: 4.8516 - acc: 0.020 - ETA: 9s - loss: 4.8476 - acc: 0.024 - ETA: 15s - loss: 4.8445 - acc: 0.02 - ETA: 18s - loss: 4.8495 - acc: 0.02 - ETA: 20s - loss: 4.8451 - acc: 0.01 - ETA: 23s - loss: 4.8454 - acc: 0.02 - ETA: 25s - loss: 4.8469 - acc: 0.02 - ETA: 27s - loss: 4.8504 - acc: 0.01 - ETA: 27s - loss: 4.8527 - acc: 0.01 - ETA: 29s - loss: 4.8519 - acc: 0.01 - ETA: 30s - loss: 4.8464 - acc: 0.01 - ETA: 31s - loss: 4.8454 - acc: 0.01 - ETA: 32s - loss: 4.8450 - acc: 0.02 - ETA: 32s - loss: 4.8470 - acc: 0.02 - ETA: 33s - loss: 4.8483 - acc: 0.01 - ETA: 35s - loss: 4.8468 - acc: 0.02 - ETA: 35s - loss: 4.8469 - acc: 0.02 - ETA: 35s - loss: 4.8458 - acc: 0.02 - ETA: 35s - loss: 4.8449 - acc: 0.02 - ETA: 36s - loss: 4.8422 - acc: 0.02 - ETA: 36s - loss: 4.8387 - acc: 0.01 - ETA: 37s - loss: 4.8407 - acc: 0.01 - ETA: 37s - loss: 4.8426 - acc: 0.01 - ETA: 38s - loss: 4.8409 - acc: 0.01 - ETA: 38s - loss: 4.8435 - acc: 0.01 - ETA: 40s - loss: 4.8421 - acc: 0.01 - ETA: 40s - loss: 4.8414 - acc: 0.01 - ETA: 41s - loss: 4.8413 - acc: 0.01 - ETA: 42s - loss: 4.8420 - acc: 0.01 - ETA: 42s - loss: 4.8391 - acc: 0.01 - ETA: 43s - loss: 4.8407 - acc: 0.01 - ETA: 43s - loss: 4.8412 - acc: 0.01 - ETA: 43s - loss: 4.8428 - acc: 0.01 - ETA: 43s - loss: 4.8430 - acc: 0.01 - ETA: 43s - loss: 4.8441 - acc: 0.01 - ETA: 43s - loss: 4.8458 - acc: 0.01 - ETA: 43s - loss: 4.8470 - acc: 0.01 - ETA: 43s - loss: 4.8469 - acc: 0.01 - ETA: 43s - loss: 4.8467 - acc: 0.02 - ETA: 44s - loss: 4.8471 - acc: 0.02 - ETA: 44s - loss: 4.8497 - acc: 0.02 - ETA: 45s - loss: 4.8487 - acc: 0.02 - ETA: 45s - loss: 4.8510 - acc: 0.02 - ETA: 45s - loss: 4.8513 - acc: 0.02 - ETA: 45s - loss: 4.8512 - acc: 0.02 - ETA: 45s - loss: 4.8497 - acc: 0.02 - ETA: 45s - loss: 4.8498 - acc: 0.02 - ETA: 45s - loss: 4.8502 - acc: 0.02 - ETA: 45s - loss: 4.8503 - acc: 0.02 - ETA: 45s - loss: 4.8500 - acc: 0.02 - ETA: 44s - loss: 4.8491 - acc: 0.02 - ETA: 44s - loss: 4.8496 - acc: 0.02 - ETA: 44s - loss: 4.8502 - acc: 0.02 - ETA: 44s - loss: 4.8501 - acc: 0.02 - ETA: 44s - loss: 4.8513 - acc: 0.02 - ETA: 44s - loss: 4.8503 - acc: 0.02 - ETA: 44s - loss: 4.8512 - acc: 0.02 - ETA: 44s - loss: 4.8528 - acc: 0.02 - ETA: 44s - loss: 4.8533 - acc: 0.02 - ETA: 44s - loss: 4.8539 - acc: 0.02 - ETA: 44s - loss: 4.8553 - acc: 0.02 - ETA: 44s - loss: 4.8560 - acc: 0.02 - ETA: 44s - loss: 4.8565 - acc: 0.02 - ETA: 44s - loss: 4.8564 - acc: 0.02 - ETA: 44s - loss: 4.8570 - acc: 0.01 - ETA: 44s - loss: 4.8570 - acc: 0.02 - ETA: 44s - loss: 4.8581 - acc: 0.02 - ETA: 44s - loss: 4.8577 - acc: 0.01 - ETA: 44s - loss: 4.8569 - acc: 0.02 - ETA: 44s - loss: 4.8558 - acc: 0.02 - ETA: 44s - loss: 4.8560 - acc: 0.02 - ETA: 44s - loss: 4.8569 - acc: 0.02 - ETA: 43s - loss: 4.8568 - acc: 0.02 - ETA: 43s - loss: 4.8581 - acc: 0.02 - ETA: 43s - loss: 4.8582 - acc: 0.02 - ETA: 43s - loss: 4.8583 - acc: 0.02 - ETA: 43s - loss: 4.8581 - acc: 0.02 - ETA: 43s - loss: 4.8589 - acc: 0.02 - ETA: 43s - loss: 4.8585 - acc: 0.02 - ETA: 43s - loss: 4.8586 - acc: 0.02 - ETA: 43s - loss: 4.8582 - acc: 0.02 - ETA: 43s - loss: 4.8574 - acc: 0.02 - ETA: 43s - loss: 4.8568 - acc: 0.02 - ETA: 43s - loss: 4.8565 - acc: 0.02 - ETA: 43s - loss: 4.8560 - acc: 0.02 - ETA: 43s - loss: 4.8561 - acc: 0.02 - ETA: 44s - loss: 4.8556 - acc: 0.01 - ETA: 43s - loss: 4.8563 - acc: 0.01 - ETA: 43s - loss: 4.8566 - acc: 0.01 - ETA: 43s - loss: 4.8566 - acc: 0.01 - ETA: 44s - loss: 4.8557 - acc: 0.01 - ETA: 43s - loss: 4.8559 - acc: 0.01 - ETA: 43s - loss: 4.8561 - acc: 0.01 - ETA: 43s - loss: 4.8554 - acc: 0.01 - ETA: 43s - loss: 4.8548 - acc: 0.01 - ETA: 43s - loss: 4.8551 - acc: 0.01 - ETA: 43s - loss: 4.8542 - acc: 0.01 - ETA: 43s - loss: 4.8533 - acc: 0.02 - ETA: 43s - loss: 4.8526 - acc: 0.02 - ETA: 43s - loss: 4.8526 - acc: 0.02 - ETA: 43s - loss: 4.8520 - acc: 0.02 - ETA: 43s - loss: 4.8533 - acc: 0.02 - ETA: 43s - loss: 4.8533 - acc: 0.02 - ETA: 43s - loss: 4.8540 - acc: 0.02 - ETA: 43s - loss: 4.8537 - acc: 0.02 - ETA: 42s - loss: 4.8533 - acc: 0.02 - ETA: 42s - loss: 4.8526 - acc: 0.02 - ETA: 42s - loss: 4.8525 - acc: 0.02 - ETA: 42s - loss: 4.8516 - acc: 0.02 - ETA: 42s - loss: 4.8522 - acc: 0.02 - ETA: 42s - loss: 4.8532 - acc: 0.02 - ETA: 42s - loss: 4.8539 - acc: 0.02 - ETA: 42s - loss: 4.8544 - acc: 0.02 - ETA: 42s - loss: 4.8544 - acc: 0.02 - ETA: 42s - loss: 4.8543 - acc: 0.02 - ETA: 42s - loss: 4.8548 - acc: 0.02 - ETA: 42s - loss: 4.8556 - acc: 0.02 - ETA: 41s - loss: 4.8551 - acc: 0.01 - ETA: 41s - loss: 4.8549 - acc: 0.01 - ETA: 41s - loss: 4.8554 - acc: 0.01 - ETA: 41s - loss: 4.8556 - acc: 0.01 - ETA: 41s - loss: 4.8558 - acc: 0.01 - ETA: 41s - loss: 4.8559 - acc: 0.01 - ETA: 41s - loss: 4.8553 - acc: 0.01 - ETA: 40s - loss: 4.8554 - acc: 0.01 - ETA: 40s - loss: 4.8551 - acc: 0.01 - ETA: 40s - loss: 4.8546 - acc: 0.01 - ETA: 40s - loss: 4.8547 - acc: 0.01 - ETA: 40s - loss: 4.8549 - acc: 0.01 - ETA: 40s - loss: 4.8549 - acc: 0.01 - ETA: 40s - loss: 4.8551 - acc: 0.01 - ETA: 39s - loss: 4.8546 - acc: 0.01 - ETA: 39s - loss: 4.8549 - acc: 0.01 - ETA: 39s - loss: 4.8555 - acc: 0.01 - ETA: 39s - loss: 4.8558 - acc: 0.01 - ETA: 39s - loss: 4.8554 - acc: 0.01 - ETA: 39s - loss: 4.8555 - acc: 0.01 - ETA: 39s - loss: 4.8551 - acc: 0.01 - ETA: 39s - loss: 4.8562 - acc: 0.01 - ETA: 39s - loss: 4.8563 - acc: 0.01 - ETA: 38s - loss: 4.8563 - acc: 0.01 - ETA: 38s - loss: 4.8563 - acc: 0.01 - ETA: 38s - loss: 4.8569 - acc: 0.01 - ETA: 38s - loss: 4.8566 - acc: 0.01 - ETA: 38s - loss: 4.8565 - acc: 0.01 - ETA: 38s - loss: 4.8567 - acc: 0.01 - ETA: 37s - loss: 4.8570 - acc: 0.01 - ETA: 37s - loss: 4.8571 - acc: 0.01 - ETA: 37s - loss: 4.8565 - acc: 0.01 - ETA: 37s - loss: 4.8569 - acc: 0.01 - ETA: 37s - loss: 4.8568 - acc: 0.01 - ETA: 37s - loss: 4.8574 - acc: 0.01 - ETA: 37s - loss: 4.8572 - acc: 0.01 - ETA: 37s - loss: 4.8571 - acc: 0.01 - ETA: 37s - loss: 4.8567 - acc: 0.01 - ETA: 37s - loss: 4.8567 - acc: 0.01 - ETA: 37s - loss: 4.8566 - acc: 0.01 - ETA: 36s - loss: 4.8568 - acc: 0.01 - ETA: 36s - loss: 4.8573 - acc: 0.01 - ETA: 36s - loss: 4.8572 - acc: 0.01 - ETA: 36s - loss: 4.8578 - acc: 0.01 - ETA: 36s - loss: 4.8582 - acc: 0.01 - ETA: 36s - loss: 4.8583 - acc: 0.01 - ETA: 35s - loss: 4.8581 - acc: 0.01 - ETA: 35s - loss: 4.8581 - acc: 0.01 - ETA: 35s - loss: 4.8586 - acc: 0.01 - ETA: 35s - loss: 4.8586 - acc: 0.01 - ETA: 35s - loss: 4.8585 - acc: 0.01 - ETA: 35s - loss: 4.8586 - acc: 0.01 - ETA: 34s - loss: 4.8591 - acc: 0.01 - ETA: 34s - loss: 4.8587 - acc: 0.01 - ETA: 34s - loss: 4.8585 - acc: 0.01 - ETA: 34s - loss: 4.8584 - acc: 0.01 - ETA: 34s - loss: 4.8582 - acc: 0.01 - ETA: 34s - loss: 4.8581 - acc: 0.01 - ETA: 34s - loss: 4.8580 - acc: 0.01 - ETA: 33s - loss: 4.8584 - acc: 0.01 - ETA: 33s - loss: 4.8585 - acc: 0.01 - ETA: 33s - loss: 4.8588 - acc: 0.01 - ETA: 33s - loss: 4.8586 - acc: 0.01 - ETA: 33s - loss: 4.8586 - acc: 0.01 - ETA: 33s - loss: 4.8583 - acc: 0.01 - ETA: 33s - loss: 4.8583 - acc: 0.01 - ETA: 33s - loss: 4.8582 - acc: 0.01 - ETA: 33s - loss: 4.8582 - acc: 0.01 - ETA: 33s - loss: 4.8586 - acc: 0.01 - ETA: 33s - loss: 4.8587 - acc: 0.01 - ETA: 33s - loss: 4.8588 - acc: 0.01 - ETA: 32s - loss: 4.8591 - acc: 0.01 - ETA: 32s - loss: 4.8593 - acc: 0.01 - ETA: 32s - loss: 4.8597 - acc: 0.01 - ETA: 32s - loss: 4.8589 - acc: 0.01 - ETA: 32s - loss: 4.8590 - acc: 0.01 - ETA: 32s - loss: 4.8591 - acc: 0.01 - ETA: 31s - loss: 4.8590 - acc: 0.01 - ETA: 31s - loss: 4.8593 - acc: 0.01 - ETA: 31s - loss: 4.8592 - acc: 0.01 - ETA: 31s - loss: 4.8594 - acc: 0.01 - ETA: 31s - loss: 4.8592 - acc: 0.01 - ETA: 31s - loss: 4.8594 - acc: 0.01 - ETA: 31s - loss: 4.8598 - acc: 0.01 - ETA: 30s - loss: 4.8598 - acc: 0.01 - ETA: 30s - loss: 4.8597 - acc: 0.01 - ETA: 30s - loss: 4.8598 - acc: 0.01 - ETA: 30s - loss: 4.8596 - acc: 0.01 - ETA: 30s - loss: 4.8597 - acc: 0.01 - ETA: 30s - loss: 4.8595 - acc: 0.01 - ETA: 30s - loss: 4.8598 - acc: 0.01 - ETA: 29s - loss: 4.8596 - acc: 0.01 - ETA: 29s - loss: 4.8597 - acc: 0.01 - ETA: 29s - loss: 4.8594 - acc: 0.01 - ETA: 29s - loss: 4.8590 - acc: 0.01 - ETA: 29s - loss: 4.8588 - acc: 0.0151"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 29s - loss: 4.8586 - acc: 0.01 - ETA: 29s - loss: 4.8583 - acc: 0.01 - ETA: 28s - loss: 4.8583 - acc: 0.01 - ETA: 28s - loss: 4.8579 - acc: 0.01 - ETA: 28s - loss: 4.8579 - acc: 0.01 - ETA: 28s - loss: 4.8579 - acc: 0.01 - ETA: 28s - loss: 4.8578 - acc: 0.01 - ETA: 28s - loss: 4.8577 - acc: 0.01 - ETA: 28s - loss: 4.8575 - acc: 0.01 - ETA: 28s - loss: 4.8575 - acc: 0.01 - ETA: 27s - loss: 4.8580 - acc: 0.01 - ETA: 27s - loss: 4.8580 - acc: 0.01 - ETA: 27s - loss: 4.8582 - acc: 0.01 - ETA: 27s - loss: 4.8580 - acc: 0.01 - ETA: 27s - loss: 4.8581 - acc: 0.01 - ETA: 27s - loss: 4.8582 - acc: 0.01 - ETA: 27s - loss: 4.8582 - acc: 0.01 - ETA: 26s - loss: 4.8581 - acc: 0.01 - ETA: 26s - loss: 4.8583 - acc: 0.01 - ETA: 26s - loss: 4.8582 - acc: 0.01 - ETA: 26s - loss: 4.8585 - acc: 0.01 - ETA: 26s - loss: 4.8584 - acc: 0.01 - ETA: 26s - loss: 4.8584 - acc: 0.01 - ETA: 25s - loss: 4.8582 - acc: 0.01 - ETA: 25s - loss: 4.8582 - acc: 0.01 - ETA: 25s - loss: 4.8584 - acc: 0.01 - ETA: 25s - loss: 4.8583 - acc: 0.01 - ETA: 25s - loss: 4.8584 - acc: 0.01 - ETA: 24s - loss: 4.8586 - acc: 0.01 - ETA: 24s - loss: 4.8587 - acc: 0.01 - ETA: 24s - loss: 4.8590 - acc: 0.01 - ETA: 24s - loss: 4.8588 - acc: 0.01 - ETA: 24s - loss: 4.8591 - acc: 0.01 - ETA: 24s - loss: 4.8589 - acc: 0.01 - ETA: 24s - loss: 4.8590 - acc: 0.01 - ETA: 23s - loss: 4.8590 - acc: 0.01 - ETA: 23s - loss: 4.8590 - acc: 0.01 - ETA: 23s - loss: 4.8588 - acc: 0.01 - ETA: 23s - loss: 4.8588 - acc: 0.01 - ETA: 23s - loss: 4.8590 - acc: 0.01 - ETA: 23s - loss: 4.8591 - acc: 0.01 - ETA: 23s - loss: 4.8591 - acc: 0.01 - ETA: 22s - loss: 4.8589 - acc: 0.01 - ETA: 22s - loss: 4.8591 - acc: 0.01 - ETA: 22s - loss: 4.8587 - acc: 0.01 - ETA: 22s - loss: 4.8587 - acc: 0.01 - ETA: 22s - loss: 4.8588 - acc: 0.01 - ETA: 22s - loss: 4.8587 - acc: 0.01 - ETA: 22s - loss: 4.8590 - acc: 0.01 - ETA: 21s - loss: 4.8590 - acc: 0.01 - ETA: 21s - loss: 4.8590 - acc: 0.01 - ETA: 21s - loss: 4.8590 - acc: 0.01 - ETA: 21s - loss: 4.8593 - acc: 0.01 - ETA: 21s - loss: 4.8589 - acc: 0.01 - ETA: 21s - loss: 4.8592 - acc: 0.01 - ETA: 21s - loss: 4.8595 - acc: 0.01 - ETA: 21s - loss: 4.8595 - acc: 0.01 - ETA: 20s - loss: 4.8594 - acc: 0.01 - ETA: 20s - loss: 4.8591 - acc: 0.01 - ETA: 20s - loss: 4.8587 - acc: 0.01 - ETA: 20s - loss: 4.8590 - acc: 0.01 - ETA: 20s - loss: 4.8590 - acc: 0.01 - ETA: 20s - loss: 4.8590 - acc: 0.01 - ETA: 19s - loss: 4.8590 - acc: 0.01 - ETA: 19s - loss: 4.8589 - acc: 0.01 - ETA: 19s - loss: 4.8587 - acc: 0.01 - ETA: 19s - loss: 4.8586 - acc: 0.01 - ETA: 19s - loss: 4.8582 - acc: 0.01 - ETA: 19s - loss: 4.8581 - acc: 0.01 - ETA: 18s - loss: 4.8577 - acc: 0.01 - ETA: 18s - loss: 4.8577 - acc: 0.01 - ETA: 18s - loss: 4.8577 - acc: 0.01 - ETA: 18s - loss: 4.8573 - acc: 0.01 - ETA: 18s - loss: 4.8573 - acc: 0.01 - ETA: 18s - loss: 4.8572 - acc: 0.01 - ETA: 17s - loss: 4.8572 - acc: 0.01 - ETA: 17s - loss: 4.8572 - acc: 0.01 - ETA: 17s - loss: 4.8572 - acc: 0.01 - ETA: 17s - loss: 4.8570 - acc: 0.01 - ETA: 17s - loss: 4.8571 - acc: 0.01 - ETA: 17s - loss: 4.8571 - acc: 0.01 - ETA: 17s - loss: 4.8569 - acc: 0.01 - ETA: 16s - loss: 4.8569 - acc: 0.01 - ETA: 16s - loss: 4.8569 - acc: 0.01 - ETA: 16s - loss: 4.8567 - acc: 0.01 - ETA: 16s - loss: 4.8569 - acc: 0.01 - ETA: 16s - loss: 4.8568 - acc: 0.01 - ETA: 16s - loss: 4.8566 - acc: 0.01 - ETA: 15s - loss: 4.8565 - acc: 0.01 - ETA: 15s - loss: 4.8563 - acc: 0.01 - ETA: 15s - loss: 4.8561 - acc: 0.01 - ETA: 15s - loss: 4.8562 - acc: 0.01 - ETA: 15s - loss: 4.8561 - acc: 0.01 - ETA: 15s - loss: 4.8562 - acc: 0.01 - ETA: 15s - loss: 4.8561 - acc: 0.01 - ETA: 14s - loss: 4.8561 - acc: 0.01 - ETA: 14s - loss: 4.8561 - acc: 0.01 - ETA: 14s - loss: 4.8563 - acc: 0.01 - ETA: 14s - loss: 4.8564 - acc: 0.01 - ETA: 14s - loss: 4.8562 - acc: 0.01 - ETA: 14s - loss: 4.8564 - acc: 0.01 - ETA: 13s - loss: 4.8563 - acc: 0.01 - ETA: 13s - loss: 4.8563 - acc: 0.01 - ETA: 13s - loss: 4.8563 - acc: 0.01 - ETA: 13s - loss: 4.8564 - acc: 0.01 - ETA: 13s - loss: 4.8566 - acc: 0.01 - ETA: 13s - loss: 4.8570 - acc: 0.01 - ETA: 13s - loss: 4.8573 - acc: 0.01 - ETA: 12s - loss: 4.8573 - acc: 0.01 - ETA: 12s - loss: 4.8571 - acc: 0.01 - ETA: 12s - loss: 4.8577 - acc: 0.01 - ETA: 12s - loss: 4.8576 - acc: 0.01 - ETA: 12s - loss: 4.8575 - acc: 0.01 - ETA: 12s - loss: 4.8576 - acc: 0.01 - ETA: 11s - loss: 4.8577 - acc: 0.01 - ETA: 11s - loss: 4.8574 - acc: 0.01 - ETA: 11s - loss: 4.8573 - acc: 0.01 - ETA: 11s - loss: 4.8574 - acc: 0.01 - ETA: 11s - loss: 4.8574 - acc: 0.01 - ETA: 11s - loss: 4.8572 - acc: 0.01 - ETA: 10s - loss: 4.8571 - acc: 0.01 - ETA: 10s - loss: 4.8572 - acc: 0.01 - ETA: 10s - loss: 4.8572 - acc: 0.01 - ETA: 10s - loss: 4.8570 - acc: 0.01 - ETA: 10s - loss: 4.8570 - acc: 0.01 - ETA: 10s - loss: 4.8570 - acc: 0.01 - ETA: 10s - loss: 4.8568 - acc: 0.01 - ETA: 9s - loss: 4.8566 - acc: 0.0139 - ETA: 9s - loss: 4.8568 - acc: 0.013 - ETA: 9s - loss: 4.8569 - acc: 0.013 - ETA: 9s - loss: 4.8568 - acc: 0.013 - ETA: 9s - loss: 4.8567 - acc: 0.013 - ETA: 9s - loss: 4.8567 - acc: 0.013 - ETA: 8s - loss: 4.8566 - acc: 0.013 - ETA: 8s - loss: 4.8565 - acc: 0.013 - ETA: 8s - loss: 4.8565 - acc: 0.013 - ETA: 8s - loss: 4.8567 - acc: 0.013 - ETA: 8s - loss: 4.8564 - acc: 0.013 - ETA: 8s - loss: 4.8564 - acc: 0.013 - ETA: 8s - loss: 4.8564 - acc: 0.013 - ETA: 7s - loss: 4.8564 - acc: 0.014 - ETA: 7s - loss: 4.8564 - acc: 0.013 - ETA: 7s - loss: 4.8563 - acc: 0.013 - ETA: 7s - loss: 4.8565 - acc: 0.013 - ETA: 7s - loss: 4.8564 - acc: 0.013 - ETA: 7s - loss: 4.8563 - acc: 0.013 - ETA: 6s - loss: 4.8562 - acc: 0.014 - ETA: 6s - loss: 4.8563 - acc: 0.014 - ETA: 6s - loss: 4.8563 - acc: 0.014 - ETA: 6s - loss: 4.8562 - acc: 0.014 - ETA: 6s - loss: 4.8567 - acc: 0.013 - ETA: 6s - loss: 4.8565 - acc: 0.013 - ETA: 6s - loss: 4.8567 - acc: 0.013 - ETA: 5s - loss: 4.8566 - acc: 0.013 - ETA: 5s - loss: 4.8564 - acc: 0.013 - ETA: 5s - loss: 4.8562 - acc: 0.013 - ETA: 5s - loss: 4.8560 - acc: 0.013 - ETA: 5s - loss: 4.8560 - acc: 0.014 - ETA: 5s - loss: 4.8560 - acc: 0.014 - ETA: 4s - loss: 4.8558 - acc: 0.013 - ETA: 4s - loss: 4.8558 - acc: 0.013 - ETA: 4s - loss: 4.8559 - acc: 0.013 - ETA: 4s - loss: 4.8559 - acc: 0.013 - ETA: 4s - loss: 4.8561 - acc: 0.013 - ETA: 4s - loss: 4.8564 - acc: 0.013 - ETA: 3s - loss: 4.8566 - acc: 0.013 - ETA: 3s - loss: 4.8569 - acc: 0.013 - ETA: 3s - loss: 4.8568 - acc: 0.013 - ETA: 3s - loss: 4.8569 - acc: 0.013 - ETA: 3s - loss: 4.8567 - acc: 0.013 - ETA: 3s - loss: 4.8568 - acc: 0.013 - ETA: 3s - loss: 4.8570 - acc: 0.013 - ETA: 2s - loss: 4.8572 - acc: 0.013 - ETA: 2s - loss: 4.8571 - acc: 0.013 - ETA: 2s - loss: 4.8571 - acc: 0.013 - ETA: 2s - loss: 4.8571 - acc: 0.013 - ETA: 2s - loss: 4.8572 - acc: 0.013 - ETA: 2s - loss: 4.8570 - acc: 0.013 - ETA: 1s - loss: 4.8572 - acc: 0.013 - ETA: 1s - loss: 4.8572 - acc: 0.013 - ETA: 1s - loss: 4.8572 - acc: 0.013 - ETA: 1s - loss: 4.8571 - acc: 0.013 - ETA: 1s - loss: 4.8571 - acc: 0.013 - ETA: 1s - loss: 4.8572 - acc: 0.013 - ETA: 0s - loss: 4.8568 - acc: 0.013 - ETA: 0s - loss: 4.8568 - acc: 0.013 - ETA: 0s - loss: 4.8569 - acc: 0.013 - ETA: 0s - loss: 4.8569 - acc: 0.013 - ETA: 0s - loss: 4.8569 - acc: 0.013 - ETA: 0s - loss: 4.8567 - acc: 0.013 - 70s 169ms/step - loss: 4.8567 - acc: 0.0136 - val_loss: 4.8432 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00026: val_loss improved from 4.84459 to 4.84323, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 6s - loss: 4.7442 - acc: 0.0000e+0 - ETA: 7s - loss: 4.8222 - acc: 0.0312    - ETA: 7s - loss: 4.8367 - acc: 0.017 - ETA: 6s - loss: 4.8253 - acc: 0.028 - ETA: 9s - loss: 4.8399 - acc: 0.024 - ETA: 13s - loss: 4.8402 - acc: 0.02 - ETA: 18s - loss: 4.8423 - acc: 0.02 - ETA: 21s - loss: 4.8471 - acc: 0.01 - ETA: 25s - loss: 4.8421 - acc: 0.02 - ETA: 27s - loss: 4.8423 - acc: 0.02 - ETA: 30s - loss: 4.8450 - acc: 0.01 - ETA: 30s - loss: 4.8459 - acc: 0.01 - ETA: 32s - loss: 4.8493 - acc: 0.01 - ETA: 33s - loss: 4.8528 - acc: 0.01 - ETA: 34s - loss: 4.8542 - acc: 0.01 - ETA: 35s - loss: 4.8555 - acc: 0.01 - ETA: 36s - loss: 4.8549 - acc: 0.01 - ETA: 38s - loss: 4.8573 - acc: 0.01 - ETA: 39s - loss: 4.8575 - acc: 0.01 - ETA: 40s - loss: 4.8583 - acc: 0.01 - ETA: 40s - loss: 4.8592 - acc: 0.01 - ETA: 40s - loss: 4.8593 - acc: 0.01 - ETA: 41s - loss: 4.8580 - acc: 0.01 - ETA: 42s - loss: 4.8571 - acc: 0.01 - ETA: 42s - loss: 4.8565 - acc: 0.01 - ETA: 43s - loss: 4.8572 - acc: 0.01 - ETA: 43s - loss: 4.8548 - acc: 0.01 - ETA: 43s - loss: 4.8562 - acc: 0.01 - ETA: 44s - loss: 4.8578 - acc: 0.01 - ETA: 47s - loss: 4.8567 - acc: 0.01 - ETA: 47s - loss: 4.8572 - acc: 0.01 - ETA: 48s - loss: 4.8588 - acc: 0.01 - ETA: 48s - loss: 4.8582 - acc: 0.01 - ETA: 48s - loss: 4.8587 - acc: 0.01 - ETA: 48s - loss: 4.8597 - acc: 0.01 - ETA: 48s - loss: 4.8592 - acc: 0.01 - ETA: 48s - loss: 4.8576 - acc: 0.01 - ETA: 49s - loss: 4.8577 - acc: 0.01 - ETA: 48s - loss: 4.8577 - acc: 0.01 - ETA: 48s - loss: 4.8550 - acc: 0.01 - ETA: 48s - loss: 4.8536 - acc: 0.01 - ETA: 48s - loss: 4.8546 - acc: 0.01 - ETA: 49s - loss: 4.8549 - acc: 0.01 - ETA: 49s - loss: 4.8544 - acc: 0.01 - ETA: 49s - loss: 4.8549 - acc: 0.01 - ETA: 49s - loss: 4.8535 - acc: 0.01 - ETA: 49s - loss: 4.8534 - acc: 0.01 - ETA: 49s - loss: 4.8524 - acc: 0.01 - ETA: 49s - loss: 4.8536 - acc: 0.01 - ETA: 49s - loss: 4.8538 - acc: 0.01 - ETA: 49s - loss: 4.8535 - acc: 0.01 - ETA: 49s - loss: 4.8533 - acc: 0.01 - ETA: 49s - loss: 4.8527 - acc: 0.01 - ETA: 49s - loss: 4.8520 - acc: 0.01 - ETA: 49s - loss: 4.8530 - acc: 0.01 - ETA: 49s - loss: 4.8522 - acc: 0.01 - ETA: 49s - loss: 4.8530 - acc: 0.01 - ETA: 50s - loss: 4.8532 - acc: 0.01 - ETA: 49s - loss: 4.8526 - acc: 0.01 - ETA: 49s - loss: 4.8521 - acc: 0.01 - ETA: 49s - loss: 4.8520 - acc: 0.01 - ETA: 49s - loss: 4.8520 - acc: 0.01 - ETA: 49s - loss: 4.8514 - acc: 0.01 - ETA: 49s - loss: 4.8517 - acc: 0.01 - ETA: 50s - loss: 4.8519 - acc: 0.01 - ETA: 49s - loss: 4.8521 - acc: 0.01 - ETA: 49s - loss: 4.8527 - acc: 0.01 - ETA: 49s - loss: 4.8524 - acc: 0.01 - ETA: 49s - loss: 4.8518 - acc: 0.01 - ETA: 49s - loss: 4.8514 - acc: 0.01 - ETA: 50s - loss: 4.8516 - acc: 0.01 - ETA: 50s - loss: 4.8516 - acc: 0.01 - ETA: 50s - loss: 4.8521 - acc: 0.01 - ETA: 49s - loss: 4.8519 - acc: 0.01 - ETA: 49s - loss: 4.8519 - acc: 0.01 - ETA: 49s - loss: 4.8523 - acc: 0.01 - ETA: 49s - loss: 4.8525 - acc: 0.01 - ETA: 49s - loss: 4.8525 - acc: 0.01 - ETA: 49s - loss: 4.8519 - acc: 0.01 - ETA: 49s - loss: 4.8510 - acc: 0.01 - ETA: 49s - loss: 4.8524 - acc: 0.01 - ETA: 48s - loss: 4.8534 - acc: 0.01 - ETA: 49s - loss: 4.8538 - acc: 0.01 - ETA: 48s - loss: 4.8523 - acc: 0.01 - ETA: 48s - loss: 4.8527 - acc: 0.01 - ETA: 48s - loss: 4.8529 - acc: 0.01 - ETA: 48s - loss: 4.8528 - acc: 0.01 - ETA: 48s - loss: 4.8528 - acc: 0.01 - ETA: 47s - loss: 4.8524 - acc: 0.01 - ETA: 47s - loss: 4.8519 - acc: 0.01 - ETA: 48s - loss: 4.8520 - acc: 0.01 - ETA: 47s - loss: 4.8532 - acc: 0.01 - ETA: 47s - loss: 4.8545 - acc: 0.01 - ETA: 47s - loss: 4.8539 - acc: 0.01 - ETA: 47s - loss: 4.8540 - acc: 0.01 - ETA: 47s - loss: 4.8545 - acc: 0.01 - ETA: 47s - loss: 4.8545 - acc: 0.01 - ETA: 46s - loss: 4.8555 - acc: 0.01 - ETA: 46s - loss: 4.8555 - acc: 0.01 - ETA: 46s - loss: 4.8562 - acc: 0.01 - ETA: 46s - loss: 4.8565 - acc: 0.01 - ETA: 46s - loss: 4.8561 - acc: 0.01 - ETA: 46s - loss: 4.8565 - acc: 0.01 - ETA: 46s - loss: 4.8566 - acc: 0.01 - ETA: 46s - loss: 4.8575 - acc: 0.01 - ETA: 46s - loss: 4.8579 - acc: 0.01 - ETA: 46s - loss: 4.8582 - acc: 0.01 - ETA: 46s - loss: 4.8582 - acc: 0.01 - ETA: 46s - loss: 4.8573 - acc: 0.01 - ETA: 45s - loss: 4.8574 - acc: 0.01 - ETA: 45s - loss: 4.8564 - acc: 0.01 - ETA: 45s - loss: 4.8561 - acc: 0.01 - ETA: 45s - loss: 4.8566 - acc: 0.01 - ETA: 45s - loss: 4.8560 - acc: 0.01 - ETA: 45s - loss: 4.8565 - acc: 0.01 - ETA: 44s - loss: 4.8566 - acc: 0.01 - ETA: 44s - loss: 4.8561 - acc: 0.01 - ETA: 44s - loss: 4.8551 - acc: 0.01 - ETA: 44s - loss: 4.8550 - acc: 0.01 - ETA: 44s - loss: 4.8552 - acc: 0.01 - ETA: 43s - loss: 4.8550 - acc: 0.01 - ETA: 43s - loss: 4.8549 - acc: 0.01 - ETA: 43s - loss: 4.8538 - acc: 0.01 - ETA: 43s - loss: 4.8535 - acc: 0.01 - ETA: 43s - loss: 4.8537 - acc: 0.01 - ETA: 43s - loss: 4.8534 - acc: 0.01 - ETA: 43s - loss: 4.8529 - acc: 0.01 - ETA: 43s - loss: 4.8527 - acc: 0.01 - ETA: 43s - loss: 4.8530 - acc: 0.01 - ETA: 42s - loss: 4.8524 - acc: 0.01 - ETA: 42s - loss: 4.8517 - acc: 0.01 - ETA: 42s - loss: 4.8521 - acc: 0.01 - ETA: 42s - loss: 4.8524 - acc: 0.01 - ETA: 42s - loss: 4.8533 - acc: 0.01 - ETA: 41s - loss: 4.8527 - acc: 0.01 - ETA: 41s - loss: 4.8526 - acc: 0.01 - ETA: 41s - loss: 4.8531 - acc: 0.01 - ETA: 41s - loss: 4.8533 - acc: 0.01 - ETA: 41s - loss: 4.8535 - acc: 0.01 - ETA: 41s - loss: 4.8539 - acc: 0.01 - ETA: 41s - loss: 4.8535 - acc: 0.01 - ETA: 41s - loss: 4.8539 - acc: 0.01 - ETA: 40s - loss: 4.8536 - acc: 0.01 - ETA: 40s - loss: 4.8539 - acc: 0.01 - ETA: 40s - loss: 4.8540 - acc: 0.01 - ETA: 40s - loss: 4.8535 - acc: 0.01 - ETA: 40s - loss: 4.8534 - acc: 0.01 - ETA: 40s - loss: 4.8533 - acc: 0.01 - ETA: 40s - loss: 4.8538 - acc: 0.01 - ETA: 40s - loss: 4.8537 - acc: 0.01 - ETA: 39s - loss: 4.8531 - acc: 0.01 - ETA: 39s - loss: 4.8528 - acc: 0.01 - ETA: 39s - loss: 4.8528 - acc: 0.01 - ETA: 39s - loss: 4.8532 - acc: 0.01 - ETA: 39s - loss: 4.8531 - acc: 0.01 - ETA: 39s - loss: 4.8533 - acc: 0.01 - ETA: 38s - loss: 4.8532 - acc: 0.01 - ETA: 38s - loss: 4.8540 - acc: 0.01 - ETA: 38s - loss: 4.8534 - acc: 0.01 - ETA: 38s - loss: 4.8537 - acc: 0.01 - ETA: 38s - loss: 4.8537 - acc: 0.01 - ETA: 38s - loss: 4.8537 - acc: 0.01 - ETA: 37s - loss: 4.8533 - acc: 0.01 - ETA: 37s - loss: 4.8529 - acc: 0.01 - ETA: 37s - loss: 4.8524 - acc: 0.01 - ETA: 37s - loss: 4.8524 - acc: 0.01 - ETA: 37s - loss: 4.8522 - acc: 0.01 - ETA: 37s - loss: 4.8525 - acc: 0.01 - ETA: 37s - loss: 4.8524 - acc: 0.01 - ETA: 37s - loss: 4.8527 - acc: 0.01 - ETA: 36s - loss: 4.8526 - acc: 0.01 - ETA: 36s - loss: 4.8529 - acc: 0.01 - ETA: 36s - loss: 4.8533 - acc: 0.01 - ETA: 36s - loss: 4.8534 - acc: 0.01 - ETA: 36s - loss: 4.8536 - acc: 0.01 - ETA: 36s - loss: 4.8538 - acc: 0.01 - ETA: 36s - loss: 4.8537 - acc: 0.01 - ETA: 36s - loss: 4.8537 - acc: 0.01 - ETA: 35s - loss: 4.8535 - acc: 0.01 - ETA: 35s - loss: 4.8537 - acc: 0.01 - ETA: 35s - loss: 4.8539 - acc: 0.01 - ETA: 35s - loss: 4.8536 - acc: 0.01 - ETA: 35s - loss: 4.8539 - acc: 0.01 - ETA: 35s - loss: 4.8538 - acc: 0.01 - ETA: 35s - loss: 4.8536 - acc: 0.01 - ETA: 35s - loss: 4.8539 - acc: 0.01 - ETA: 35s - loss: 4.8541 - acc: 0.01 - ETA: 34s - loss: 4.8536 - acc: 0.01 - ETA: 34s - loss: 4.8535 - acc: 0.01 - ETA: 34s - loss: 4.8536 - acc: 0.01 - ETA: 34s - loss: 4.8539 - acc: 0.01 - ETA: 34s - loss: 4.8538 - acc: 0.01 - ETA: 34s - loss: 4.8537 - acc: 0.01 - ETA: 33s - loss: 4.8535 - acc: 0.01 - ETA: 33s - loss: 4.8535 - acc: 0.01 - ETA: 33s - loss: 4.8532 - acc: 0.01 - ETA: 33s - loss: 4.8535 - acc: 0.01 - ETA: 33s - loss: 4.8536 - acc: 0.01 - ETA: 33s - loss: 4.8535 - acc: 0.01 - ETA: 32s - loss: 4.8538 - acc: 0.01 - ETA: 32s - loss: 4.8534 - acc: 0.01 - ETA: 32s - loss: 4.8533 - acc: 0.01 - ETA: 32s - loss: 4.8535 - acc: 0.01 - ETA: 32s - loss: 4.8543 - acc: 0.01 - ETA: 32s - loss: 4.8547 - acc: 0.01 - ETA: 32s - loss: 4.8547 - acc: 0.01 - ETA: 31s - loss: 4.8547 - acc: 0.01 - ETA: 31s - loss: 4.8549 - acc: 0.01 - ETA: 31s - loss: 4.8551 - acc: 0.01 - ETA: 31s - loss: 4.8552 - acc: 0.01 - ETA: 31s - loss: 4.8550 - acc: 0.01 - ETA: 31s - loss: 4.8552 - acc: 0.01 - ETA: 30s - loss: 4.8548 - acc: 0.01 - ETA: 30s - loss: 4.8552 - acc: 0.01 - ETA: 30s - loss: 4.8548 - acc: 0.0165"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8548 - acc: 0.01 - ETA: 30s - loss: 4.8546 - acc: 0.01 - ETA: 30s - loss: 4.8546 - acc: 0.01 - ETA: 29s - loss: 4.8544 - acc: 0.01 - ETA: 29s - loss: 4.8544 - acc: 0.01 - ETA: 29s - loss: 4.8545 - acc: 0.01 - ETA: 29s - loss: 4.8552 - acc: 0.01 - ETA: 29s - loss: 4.8553 - acc: 0.01 - ETA: 29s - loss: 4.8553 - acc: 0.01 - ETA: 29s - loss: 4.8554 - acc: 0.01 - ETA: 28s - loss: 4.8553 - acc: 0.01 - ETA: 28s - loss: 4.8559 - acc: 0.01 - ETA: 28s - loss: 4.8556 - acc: 0.01 - ETA: 28s - loss: 4.8560 - acc: 0.01 - ETA: 28s - loss: 4.8559 - acc: 0.01 - ETA: 28s - loss: 4.8559 - acc: 0.01 - ETA: 27s - loss: 4.8559 - acc: 0.01 - ETA: 27s - loss: 4.8563 - acc: 0.01 - ETA: 27s - loss: 4.8563 - acc: 0.01 - ETA: 27s - loss: 4.8558 - acc: 0.01 - ETA: 27s - loss: 4.8554 - acc: 0.01 - ETA: 27s - loss: 4.8552 - acc: 0.01 - ETA: 27s - loss: 4.8554 - acc: 0.01 - ETA: 26s - loss: 4.8556 - acc: 0.01 - ETA: 26s - loss: 4.8553 - acc: 0.01 - ETA: 26s - loss: 4.8552 - acc: 0.01 - ETA: 26s - loss: 4.8554 - acc: 0.01 - ETA: 26s - loss: 4.8554 - acc: 0.01 - ETA: 26s - loss: 4.8553 - acc: 0.01 - ETA: 25s - loss: 4.8552 - acc: 0.01 - ETA: 25s - loss: 4.8553 - acc: 0.01 - ETA: 25s - loss: 4.8554 - acc: 0.01 - ETA: 25s - loss: 4.8556 - acc: 0.01 - ETA: 25s - loss: 4.8554 - acc: 0.01 - ETA: 25s - loss: 4.8552 - acc: 0.01 - ETA: 24s - loss: 4.8552 - acc: 0.01 - ETA: 24s - loss: 4.8554 - acc: 0.01 - ETA: 24s - loss: 4.8554 - acc: 0.01 - ETA: 24s - loss: 4.8558 - acc: 0.01 - ETA: 24s - loss: 4.8557 - acc: 0.01 - ETA: 24s - loss: 4.8557 - acc: 0.01 - ETA: 24s - loss: 4.8557 - acc: 0.01 - ETA: 24s - loss: 4.8559 - acc: 0.01 - ETA: 23s - loss: 4.8560 - acc: 0.01 - ETA: 23s - loss: 4.8557 - acc: 0.01 - ETA: 23s - loss: 4.8556 - acc: 0.01 - ETA: 23s - loss: 4.8557 - acc: 0.01 - ETA: 23s - loss: 4.8557 - acc: 0.01 - ETA: 22s - loss: 4.8557 - acc: 0.01 - ETA: 22s - loss: 4.8554 - acc: 0.01 - ETA: 22s - loss: 4.8552 - acc: 0.01 - ETA: 22s - loss: 4.8551 - acc: 0.01 - ETA: 22s - loss: 4.8552 - acc: 0.01 - ETA: 22s - loss: 4.8551 - acc: 0.01 - ETA: 22s - loss: 4.8552 - acc: 0.01 - ETA: 21s - loss: 4.8555 - acc: 0.01 - ETA: 21s - loss: 4.8555 - acc: 0.01 - ETA: 21s - loss: 4.8558 - acc: 0.01 - ETA: 21s - loss: 4.8559 - acc: 0.01 - ETA: 21s - loss: 4.8561 - acc: 0.01 - ETA: 21s - loss: 4.8559 - acc: 0.01 - ETA: 20s - loss: 4.8559 - acc: 0.01 - ETA: 20s - loss: 4.8561 - acc: 0.01 - ETA: 20s - loss: 4.8563 - acc: 0.01 - ETA: 20s - loss: 4.8565 - acc: 0.01 - ETA: 20s - loss: 4.8569 - acc: 0.01 - ETA: 20s - loss: 4.8570 - acc: 0.01 - ETA: 20s - loss: 4.8571 - acc: 0.01 - ETA: 19s - loss: 4.8573 - acc: 0.01 - ETA: 19s - loss: 4.8573 - acc: 0.01 - ETA: 19s - loss: 4.8571 - acc: 0.01 - ETA: 19s - loss: 4.8566 - acc: 0.01 - ETA: 19s - loss: 4.8567 - acc: 0.01 - ETA: 18s - loss: 4.8568 - acc: 0.01 - ETA: 18s - loss: 4.8567 - acc: 0.01 - ETA: 18s - loss: 4.8567 - acc: 0.01 - ETA: 18s - loss: 4.8569 - acc: 0.01 - ETA: 18s - loss: 4.8565 - acc: 0.01 - ETA: 18s - loss: 4.8565 - acc: 0.01 - ETA: 18s - loss: 4.8565 - acc: 0.01 - ETA: 17s - loss: 4.8565 - acc: 0.01 - ETA: 17s - loss: 4.8570 - acc: 0.01 - ETA: 17s - loss: 4.8569 - acc: 0.01 - ETA: 17s - loss: 4.8570 - acc: 0.01 - ETA: 17s - loss: 4.8568 - acc: 0.01 - ETA: 17s - loss: 4.8567 - acc: 0.01 - ETA: 16s - loss: 4.8565 - acc: 0.01 - ETA: 16s - loss: 4.8567 - acc: 0.01 - ETA: 16s - loss: 4.8570 - acc: 0.01 - ETA: 16s - loss: 4.8567 - acc: 0.01 - ETA: 16s - loss: 4.8570 - acc: 0.01 - ETA: 16s - loss: 4.8570 - acc: 0.01 - ETA: 15s - loss: 4.8569 - acc: 0.01 - ETA: 15s - loss: 4.8569 - acc: 0.01 - ETA: 15s - loss: 4.8571 - acc: 0.01 - ETA: 15s - loss: 4.8570 - acc: 0.01 - ETA: 15s - loss: 4.8568 - acc: 0.01 - ETA: 15s - loss: 4.8569 - acc: 0.01 - ETA: 15s - loss: 4.8566 - acc: 0.01 - ETA: 14s - loss: 4.8565 - acc: 0.01 - ETA: 14s - loss: 4.8563 - acc: 0.01 - ETA: 14s - loss: 4.8563 - acc: 0.01 - ETA: 14s - loss: 4.8563 - acc: 0.01 - ETA: 14s - loss: 4.8563 - acc: 0.01 - ETA: 14s - loss: 4.8564 - acc: 0.01 - ETA: 13s - loss: 4.8563 - acc: 0.01 - ETA: 13s - loss: 4.8564 - acc: 0.01 - ETA: 13s - loss: 4.8564 - acc: 0.01 - ETA: 13s - loss: 4.8564 - acc: 0.01 - ETA: 13s - loss: 4.8562 - acc: 0.01 - ETA: 13s - loss: 4.8562 - acc: 0.01 - ETA: 13s - loss: 4.8560 - acc: 0.01 - ETA: 12s - loss: 4.8561 - acc: 0.01 - ETA: 12s - loss: 4.8561 - acc: 0.01 - ETA: 12s - loss: 4.8560 - acc: 0.01 - ETA: 12s - loss: 4.8559 - acc: 0.01 - ETA: 12s - loss: 4.8557 - acc: 0.01 - ETA: 12s - loss: 4.8558 - acc: 0.01 - ETA: 11s - loss: 4.8559 - acc: 0.01 - ETA: 11s - loss: 4.8560 - acc: 0.01 - ETA: 11s - loss: 4.8558 - acc: 0.01 - ETA: 11s - loss: 4.8558 - acc: 0.01 - ETA: 11s - loss: 4.8559 - acc: 0.01 - ETA: 11s - loss: 4.8558 - acc: 0.01 - ETA: 10s - loss: 4.8557 - acc: 0.01 - ETA: 10s - loss: 4.8554 - acc: 0.01 - ETA: 10s - loss: 4.8554 - acc: 0.01 - ETA: 10s - loss: 4.8555 - acc: 0.01 - ETA: 10s - loss: 4.8553 - acc: 0.01 - ETA: 10s - loss: 4.8553 - acc: 0.01 - ETA: 9s - loss: 4.8554 - acc: 0.0167 - ETA: 9s - loss: 4.8554 - acc: 0.016 - ETA: 9s - loss: 4.8556 - acc: 0.016 - ETA: 9s - loss: 4.8557 - acc: 0.016 - ETA: 9s - loss: 4.8552 - acc: 0.017 - ETA: 9s - loss: 4.8550 - acc: 0.017 - ETA: 9s - loss: 4.8550 - acc: 0.017 - ETA: 8s - loss: 4.8547 - acc: 0.017 - ETA: 8s - loss: 4.8548 - acc: 0.017 - ETA: 8s - loss: 4.8548 - acc: 0.017 - ETA: 8s - loss: 4.8551 - acc: 0.017 - ETA: 8s - loss: 4.8551 - acc: 0.017 - ETA: 8s - loss: 4.8549 - acc: 0.017 - ETA: 7s - loss: 4.8550 - acc: 0.017 - ETA: 7s - loss: 4.8549 - acc: 0.017 - ETA: 7s - loss: 4.8552 - acc: 0.017 - ETA: 7s - loss: 4.8551 - acc: 0.017 - ETA: 7s - loss: 4.8546 - acc: 0.017 - ETA: 7s - loss: 4.8546 - acc: 0.017 - ETA: 6s - loss: 4.8544 - acc: 0.017 - ETA: 6s - loss: 4.8544 - acc: 0.017 - ETA: 6s - loss: 4.8545 - acc: 0.017 - ETA: 6s - loss: 4.8546 - acc: 0.017 - ETA: 6s - loss: 4.8546 - acc: 0.017 - ETA: 6s - loss: 4.8548 - acc: 0.017 - ETA: 6s - loss: 4.8547 - acc: 0.017 - ETA: 5s - loss: 4.8547 - acc: 0.017 - ETA: 5s - loss: 4.8546 - acc: 0.017 - ETA: 5s - loss: 4.8548 - acc: 0.017 - ETA: 5s - loss: 4.8549 - acc: 0.017 - ETA: 5s - loss: 4.8549 - acc: 0.017 - ETA: 5s - loss: 4.8548 - acc: 0.017 - ETA: 4s - loss: 4.8548 - acc: 0.017 - ETA: 4s - loss: 4.8550 - acc: 0.016 - ETA: 4s - loss: 4.8551 - acc: 0.016 - ETA: 4s - loss: 4.8550 - acc: 0.016 - ETA: 4s - loss: 4.8548 - acc: 0.016 - ETA: 4s - loss: 4.8547 - acc: 0.016 - ETA: 3s - loss: 4.8545 - acc: 0.017 - ETA: 3s - loss: 4.8546 - acc: 0.017 - ETA: 3s - loss: 4.8545 - acc: 0.017 - ETA: 3s - loss: 4.8546 - acc: 0.017 - ETA: 3s - loss: 4.8546 - acc: 0.017 - ETA: 3s - loss: 4.8548 - acc: 0.017 - ETA: 2s - loss: 4.8549 - acc: 0.017 - ETA: 2s - loss: 4.8548 - acc: 0.017 - ETA: 2s - loss: 4.8549 - acc: 0.017 - ETA: 2s - loss: 4.8548 - acc: 0.017 - ETA: 2s - loss: 4.8545 - acc: 0.017 - ETA: 2s - loss: 4.8544 - acc: 0.017 - ETA: 1s - loss: 4.8545 - acc: 0.017 - ETA: 1s - loss: 4.8545 - acc: 0.017 - ETA: 1s - loss: 4.8544 - acc: 0.017 - ETA: 1s - loss: 4.8544 - acc: 0.017 - ETA: 1s - loss: 4.8544 - acc: 0.017 - ETA: 1s - loss: 4.8544 - acc: 0.017 - ETA: 0s - loss: 4.8542 - acc: 0.017 - ETA: 0s - loss: 4.8542 - acc: 0.017 - ETA: 0s - loss: 4.8544 - acc: 0.016 - ETA: 0s - loss: 4.8546 - acc: 0.016 - ETA: 0s - loss: 4.8547 - acc: 0.016 - ETA: 0s - loss: 4.8547 - acc: 0.016 - 71s 170ms/step - loss: 4.8547 - acc: 0.0168 - val_loss: 4.8394 - val_acc: 0.0232\n",
      "\n",
      "Epoch 00027: val_loss improved from 4.84323 to 4.83939, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 6s - loss: 4.9657 - acc: 0.0000e+0 - ETA: 7s - loss: 4.9071 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8870 - acc: 0.0234    - ETA: 6s - loss: 4.8796 - acc: 0.017 - ETA: 10s - loss: 4.8660 - acc: 0.01 - ETA: 13s - loss: 4.8632 - acc: 0.01 - ETA: 17s - loss: 4.8651 - acc: 0.01 - ETA: 22s - loss: 4.8604 - acc: 0.01 - ETA: 25s - loss: 4.8656 - acc: 0.01 - ETA: 26s - loss: 4.8605 - acc: 0.01 - ETA: 28s - loss: 4.8591 - acc: 0.01 - ETA: 32s - loss: 4.8580 - acc: 0.01 - ETA: 33s - loss: 4.8562 - acc: 0.01 - ETA: 34s - loss: 4.8535 - acc: 0.01 - ETA: 35s - loss: 4.8530 - acc: 0.01 - ETA: 35s - loss: 4.8509 - acc: 0.01 - ETA: 36s - loss: 4.8523 - acc: 0.01 - ETA: 37s - loss: 4.8511 - acc: 0.01 - ETA: 38s - loss: 4.8501 - acc: 0.01 - ETA: 38s - loss: 4.8519 - acc: 0.01 - ETA: 38s - loss: 4.8541 - acc: 0.01 - ETA: 38s - loss: 4.8537 - acc: 0.01 - ETA: 38s - loss: 4.8491 - acc: 0.01 - ETA: 39s - loss: 4.8510 - acc: 0.01 - ETA: 39s - loss: 4.8516 - acc: 0.01 - ETA: 39s - loss: 4.8519 - acc: 0.01 - ETA: 39s - loss: 4.8501 - acc: 0.01 - ETA: 40s - loss: 4.8498 - acc: 0.01 - ETA: 40s - loss: 4.8487 - acc: 0.01 - ETA: 41s - loss: 4.8489 - acc: 0.01 - ETA: 41s - loss: 4.8522 - acc: 0.01 - ETA: 42s - loss: 4.8506 - acc: 0.01 - ETA: 43s - loss: 4.8511 - acc: 0.01 - ETA: 44s - loss: 4.8525 - acc: 0.01 - ETA: 44s - loss: 4.8519 - acc: 0.01 - ETA: 44s - loss: 4.8507 - acc: 0.01 - ETA: 44s - loss: 4.8523 - acc: 0.01 - ETA: 44s - loss: 4.8511 - acc: 0.01 - ETA: 44s - loss: 4.8523 - acc: 0.01 - ETA: 46s - loss: 4.8497 - acc: 0.01 - ETA: 46s - loss: 4.8509 - acc: 0.01 - ETA: 46s - loss: 4.8522 - acc: 0.01 - ETA: 46s - loss: 4.8544 - acc: 0.01 - ETA: 47s - loss: 4.8550 - acc: 0.01 - ETA: 47s - loss: 4.8565 - acc: 0.01 - ETA: 47s - loss: 4.8565 - acc: 0.01 - ETA: 47s - loss: 4.8539 - acc: 0.01 - ETA: 48s - loss: 4.8543 - acc: 0.01 - ETA: 48s - loss: 4.8554 - acc: 0.01 - ETA: 48s - loss: 4.8550 - acc: 0.01 - ETA: 48s - loss: 4.8542 - acc: 0.01 - ETA: 48s - loss: 4.8552 - acc: 0.01 - ETA: 48s - loss: 4.8552 - acc: 0.01 - ETA: 48s - loss: 4.8541 - acc: 0.01 - ETA: 49s - loss: 4.8541 - acc: 0.01 - ETA: 49s - loss: 4.8548 - acc: 0.01 - ETA: 49s - loss: 4.8550 - acc: 0.01 - ETA: 49s - loss: 4.8551 - acc: 0.01 - ETA: 49s - loss: 4.8540 - acc: 0.01 - ETA: 48s - loss: 4.8532 - acc: 0.01 - ETA: 48s - loss: 4.8527 - acc: 0.01 - ETA: 48s - loss: 4.8536 - acc: 0.01 - ETA: 48s - loss: 4.8537 - acc: 0.01 - ETA: 48s - loss: 4.8534 - acc: 0.01 - ETA: 48s - loss: 4.8515 - acc: 0.01 - ETA: 48s - loss: 4.8511 - acc: 0.01 - ETA: 48s - loss: 4.8505 - acc: 0.01 - ETA: 48s - loss: 4.8510 - acc: 0.01 - ETA: 48s - loss: 4.8516 - acc: 0.01 - ETA: 48s - loss: 4.8516 - acc: 0.01 - ETA: 48s - loss: 4.8534 - acc: 0.01 - ETA: 48s - loss: 4.8534 - acc: 0.01 - ETA: 48s - loss: 4.8552 - acc: 0.01 - ETA: 48s - loss: 4.8553 - acc: 0.01 - ETA: 48s - loss: 4.8550 - acc: 0.01 - ETA: 48s - loss: 4.8556 - acc: 0.01 - ETA: 48s - loss: 4.8556 - acc: 0.01 - ETA: 48s - loss: 4.8549 - acc: 0.01 - ETA: 48s - loss: 4.8555 - acc: 0.01 - ETA: 48s - loss: 4.8554 - acc: 0.01 - ETA: 48s - loss: 4.8556 - acc: 0.01 - ETA: 48s - loss: 4.8554 - acc: 0.01 - ETA: 47s - loss: 4.8552 - acc: 0.01 - ETA: 47s - loss: 4.8551 - acc: 0.01 - ETA: 48s - loss: 4.8551 - acc: 0.01 - ETA: 47s - loss: 4.8554 - acc: 0.01 - ETA: 47s - loss: 4.8553 - acc: 0.01 - ETA: 47s - loss: 4.8553 - acc: 0.01 - ETA: 47s - loss: 4.8548 - acc: 0.01 - ETA: 47s - loss: 4.8540 - acc: 0.01 - ETA: 46s - loss: 4.8538 - acc: 0.01 - ETA: 46s - loss: 4.8549 - acc: 0.01 - ETA: 46s - loss: 4.8559 - acc: 0.01 - ETA: 46s - loss: 4.8565 - acc: 0.01 - ETA: 46s - loss: 4.8568 - acc: 0.01 - ETA: 46s - loss: 4.8569 - acc: 0.01 - ETA: 46s - loss: 4.8570 - acc: 0.01 - ETA: 46s - loss: 4.8564 - acc: 0.01 - ETA: 45s - loss: 4.8557 - acc: 0.01 - ETA: 45s - loss: 4.8554 - acc: 0.01 - ETA: 45s - loss: 4.8551 - acc: 0.01 - ETA: 45s - loss: 4.8559 - acc: 0.01 - ETA: 45s - loss: 4.8561 - acc: 0.01 - ETA: 45s - loss: 4.8562 - acc: 0.01 - ETA: 45s - loss: 4.8560 - acc: 0.01 - ETA: 45s - loss: 4.8561 - acc: 0.01 - ETA: 45s - loss: 4.8566 - acc: 0.01 - ETA: 45s - loss: 4.8566 - acc: 0.01 - ETA: 45s - loss: 4.8560 - acc: 0.01 - ETA: 44s - loss: 4.8570 - acc: 0.01 - ETA: 44s - loss: 4.8569 - acc: 0.01 - ETA: 44s - loss: 4.8566 - acc: 0.01 - ETA: 44s - loss: 4.8572 - acc: 0.01 - ETA: 44s - loss: 4.8564 - acc: 0.01 - ETA: 44s - loss: 4.8563 - acc: 0.01 - ETA: 44s - loss: 4.8561 - acc: 0.01 - ETA: 44s - loss: 4.8562 - acc: 0.01 - ETA: 44s - loss: 4.8569 - acc: 0.01 - ETA: 44s - loss: 4.8566 - acc: 0.01 - ETA: 43s - loss: 4.8571 - acc: 0.01 - ETA: 43s - loss: 4.8568 - acc: 0.01 - ETA: 43s - loss: 4.8567 - acc: 0.01 - ETA: 43s - loss: 4.8571 - acc: 0.01 - ETA: 43s - loss: 4.8569 - acc: 0.01 - ETA: 43s - loss: 4.8567 - acc: 0.01 - ETA: 43s - loss: 4.8568 - acc: 0.01 - ETA: 43s - loss: 4.8569 - acc: 0.01 - ETA: 43s - loss: 4.8566 - acc: 0.01 - ETA: 43s - loss: 4.8561 - acc: 0.01 - ETA: 43s - loss: 4.8564 - acc: 0.01 - ETA: 43s - loss: 4.8567 - acc: 0.01 - ETA: 42s - loss: 4.8565 - acc: 0.01 - ETA: 42s - loss: 4.8558 - acc: 0.01 - ETA: 42s - loss: 4.8559 - acc: 0.01 - ETA: 42s - loss: 4.8560 - acc: 0.01 - ETA: 42s - loss: 4.8555 - acc: 0.01 - ETA: 42s - loss: 4.8556 - acc: 0.01 - ETA: 42s - loss: 4.8557 - acc: 0.01 - ETA: 41s - loss: 4.8558 - acc: 0.01 - ETA: 41s - loss: 4.8560 - acc: 0.01 - ETA: 41s - loss: 4.8565 - acc: 0.01 - ETA: 41s - loss: 4.8571 - acc: 0.01 - ETA: 41s - loss: 4.8573 - acc: 0.01 - ETA: 41s - loss: 4.8571 - acc: 0.01 - ETA: 40s - loss: 4.8571 - acc: 0.01 - ETA: 40s - loss: 4.8566 - acc: 0.01 - ETA: 40s - loss: 4.8567 - acc: 0.01 - ETA: 40s - loss: 4.8572 - acc: 0.01 - ETA: 40s - loss: 4.8569 - acc: 0.01 - ETA: 40s - loss: 4.8570 - acc: 0.01 - ETA: 40s - loss: 4.8570 - acc: 0.01 - ETA: 40s - loss: 4.8577 - acc: 0.01 - ETA: 40s - loss: 4.8576 - acc: 0.01 - ETA: 39s - loss: 4.8577 - acc: 0.01 - ETA: 39s - loss: 4.8578 - acc: 0.01 - ETA: 39s - loss: 4.8575 - acc: 0.01 - ETA: 39s - loss: 4.8578 - acc: 0.01 - ETA: 39s - loss: 4.8575 - acc: 0.01 - ETA: 39s - loss: 4.8575 - acc: 0.01 - ETA: 38s - loss: 4.8577 - acc: 0.01 - ETA: 38s - loss: 4.8576 - acc: 0.01 - ETA: 38s - loss: 4.8575 - acc: 0.01 - ETA: 38s - loss: 4.8571 - acc: 0.01 - ETA: 38s - loss: 4.8570 - acc: 0.01 - ETA: 38s - loss: 4.8568 - acc: 0.01 - ETA: 37s - loss: 4.8561 - acc: 0.01 - ETA: 37s - loss: 4.8561 - acc: 0.01 - ETA: 37s - loss: 4.8555 - acc: 0.01 - ETA: 37s - loss: 4.8555 - acc: 0.01 - ETA: 37s - loss: 4.8556 - acc: 0.01 - ETA: 36s - loss: 4.8556 - acc: 0.01 - ETA: 36s - loss: 4.8552 - acc: 0.01 - ETA: 36s - loss: 4.8548 - acc: 0.01 - ETA: 36s - loss: 4.8547 - acc: 0.01 - ETA: 36s - loss: 4.8545 - acc: 0.01 - ETA: 36s - loss: 4.8543 - acc: 0.01 - ETA: 36s - loss: 4.8537 - acc: 0.01 - ETA: 35s - loss: 4.8537 - acc: 0.01 - ETA: 35s - loss: 4.8540 - acc: 0.01 - ETA: 35s - loss: 4.8546 - acc: 0.01 - ETA: 35s - loss: 4.8546 - acc: 0.01 - ETA: 35s - loss: 4.8549 - acc: 0.01 - ETA: 35s - loss: 4.8540 - acc: 0.01 - ETA: 34s - loss: 4.8539 - acc: 0.01 - ETA: 34s - loss: 4.8537 - acc: 0.01 - ETA: 34s - loss: 4.8531 - acc: 0.01 - ETA: 34s - loss: 4.8531 - acc: 0.01 - ETA: 34s - loss: 4.8535 - acc: 0.01 - ETA: 34s - loss: 4.8535 - acc: 0.01 - ETA: 34s - loss: 4.8539 - acc: 0.01 - ETA: 33s - loss: 4.8535 - acc: 0.01 - ETA: 33s - loss: 4.8537 - acc: 0.01 - ETA: 33s - loss: 4.8538 - acc: 0.01 - ETA: 33s - loss: 4.8530 - acc: 0.01 - ETA: 33s - loss: 4.8531 - acc: 0.01 - ETA: 33s - loss: 4.8526 - acc: 0.01 - ETA: 33s - loss: 4.8530 - acc: 0.01 - ETA: 33s - loss: 4.8530 - acc: 0.01 - ETA: 33s - loss: 4.8528 - acc: 0.01 - ETA: 32s - loss: 4.8531 - acc: 0.01 - ETA: 32s - loss: 4.8532 - acc: 0.01 - ETA: 32s - loss: 4.8537 - acc: 0.01 - ETA: 32s - loss: 4.8533 - acc: 0.01 - ETA: 32s - loss: 4.8535 - acc: 0.01 - ETA: 32s - loss: 4.8534 - acc: 0.01 - ETA: 32s - loss: 4.8535 - acc: 0.01 - ETA: 32s - loss: 4.8533 - acc: 0.01 - ETA: 31s - loss: 4.8534 - acc: 0.01 - ETA: 31s - loss: 4.8537 - acc: 0.01 - ETA: 31s - loss: 4.8535 - acc: 0.01 - ETA: 31s - loss: 4.8534 - acc: 0.01 - ETA: 31s - loss: 4.8538 - acc: 0.01 - ETA: 30s - loss: 4.8538 - acc: 0.01 - ETA: 30s - loss: 4.8541 - acc: 0.01 - ETA: 30s - loss: 4.8540 - acc: 0.0177"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8541 - acc: 0.01 - ETA: 30s - loss: 4.8539 - acc: 0.01 - ETA: 30s - loss: 4.8538 - acc: 0.01 - ETA: 30s - loss: 4.8538 - acc: 0.01 - ETA: 29s - loss: 4.8542 - acc: 0.01 - ETA: 29s - loss: 4.8547 - acc: 0.01 - ETA: 29s - loss: 4.8545 - acc: 0.01 - ETA: 29s - loss: 4.8546 - acc: 0.01 - ETA: 29s - loss: 4.8548 - acc: 0.01 - ETA: 29s - loss: 4.8547 - acc: 0.01 - ETA: 28s - loss: 4.8552 - acc: 0.01 - ETA: 28s - loss: 4.8550 - acc: 0.01 - ETA: 28s - loss: 4.8550 - acc: 0.01 - ETA: 28s - loss: 4.8550 - acc: 0.01 - ETA: 28s - loss: 4.8557 - acc: 0.01 - ETA: 28s - loss: 4.8559 - acc: 0.01 - ETA: 27s - loss: 4.8555 - acc: 0.01 - ETA: 27s - loss: 4.8553 - acc: 0.01 - ETA: 27s - loss: 4.8553 - acc: 0.01 - ETA: 27s - loss: 4.8549 - acc: 0.01 - ETA: 27s - loss: 4.8545 - acc: 0.01 - ETA: 27s - loss: 4.8545 - acc: 0.01 - ETA: 27s - loss: 4.8543 - acc: 0.01 - ETA: 26s - loss: 4.8543 - acc: 0.01 - ETA: 26s - loss: 4.8548 - acc: 0.01 - ETA: 26s - loss: 4.8547 - acc: 0.01 - ETA: 26s - loss: 4.8550 - acc: 0.01 - ETA: 26s - loss: 4.8553 - acc: 0.01 - ETA: 26s - loss: 4.8555 - acc: 0.01 - ETA: 25s - loss: 4.8551 - acc: 0.01 - ETA: 25s - loss: 4.8549 - acc: 0.01 - ETA: 25s - loss: 4.8552 - acc: 0.01 - ETA: 25s - loss: 4.8552 - acc: 0.01 - ETA: 25s - loss: 4.8553 - acc: 0.01 - ETA: 25s - loss: 4.8553 - acc: 0.01 - ETA: 24s - loss: 4.8553 - acc: 0.01 - ETA: 24s - loss: 4.8554 - acc: 0.01 - ETA: 24s - loss: 4.8552 - acc: 0.01 - ETA: 24s - loss: 4.8553 - acc: 0.01 - ETA: 24s - loss: 4.8552 - acc: 0.01 - ETA: 24s - loss: 4.8552 - acc: 0.01 - ETA: 23s - loss: 4.8553 - acc: 0.01 - ETA: 23s - loss: 4.8553 - acc: 0.01 - ETA: 23s - loss: 4.8555 - acc: 0.01 - ETA: 23s - loss: 4.8552 - acc: 0.01 - ETA: 23s - loss: 4.8550 - acc: 0.01 - ETA: 23s - loss: 4.8549 - acc: 0.01 - ETA: 22s - loss: 4.8548 - acc: 0.01 - ETA: 22s - loss: 4.8546 - acc: 0.01 - ETA: 22s - loss: 4.8544 - acc: 0.01 - ETA: 22s - loss: 4.8546 - acc: 0.01 - ETA: 22s - loss: 4.8543 - acc: 0.01 - ETA: 22s - loss: 4.8542 - acc: 0.01 - ETA: 21s - loss: 4.8544 - acc: 0.01 - ETA: 21s - loss: 4.8545 - acc: 0.01 - ETA: 21s - loss: 4.8541 - acc: 0.01 - ETA: 21s - loss: 4.8539 - acc: 0.01 - ETA: 21s - loss: 4.8537 - acc: 0.01 - ETA: 21s - loss: 4.8538 - acc: 0.01 - ETA: 20s - loss: 4.8535 - acc: 0.01 - ETA: 20s - loss: 4.8534 - acc: 0.01 - ETA: 20s - loss: 4.8536 - acc: 0.01 - ETA: 20s - loss: 4.8542 - acc: 0.01 - ETA: 20s - loss: 4.8543 - acc: 0.01 - ETA: 20s - loss: 4.8544 - acc: 0.01 - ETA: 19s - loss: 4.8544 - acc: 0.01 - ETA: 19s - loss: 4.8544 - acc: 0.01 - ETA: 19s - loss: 4.8545 - acc: 0.01 - ETA: 19s - loss: 4.8546 - acc: 0.01 - ETA: 19s - loss: 4.8544 - acc: 0.01 - ETA: 19s - loss: 4.8545 - acc: 0.01 - ETA: 19s - loss: 4.8543 - acc: 0.01 - ETA: 18s - loss: 4.8542 - acc: 0.01 - ETA: 18s - loss: 4.8546 - acc: 0.01 - ETA: 18s - loss: 4.8546 - acc: 0.01 - ETA: 18s - loss: 4.8545 - acc: 0.01 - ETA: 18s - loss: 4.8542 - acc: 0.01 - ETA: 18s - loss: 4.8542 - acc: 0.01 - ETA: 18s - loss: 4.8542 - acc: 0.01 - ETA: 17s - loss: 4.8541 - acc: 0.01 - ETA: 17s - loss: 4.8541 - acc: 0.01 - ETA: 17s - loss: 4.8538 - acc: 0.01 - ETA: 17s - loss: 4.8535 - acc: 0.01 - ETA: 17s - loss: 4.8538 - acc: 0.01 - ETA: 17s - loss: 4.8539 - acc: 0.01 - ETA: 16s - loss: 4.8538 - acc: 0.01 - ETA: 16s - loss: 4.8539 - acc: 0.01 - ETA: 16s - loss: 4.8539 - acc: 0.01 - ETA: 16s - loss: 4.8540 - acc: 0.01 - ETA: 16s - loss: 4.8543 - acc: 0.01 - ETA: 16s - loss: 4.8544 - acc: 0.01 - ETA: 15s - loss: 4.8544 - acc: 0.01 - ETA: 15s - loss: 4.8544 - acc: 0.01 - ETA: 15s - loss: 4.8542 - acc: 0.01 - ETA: 15s - loss: 4.8542 - acc: 0.01 - ETA: 15s - loss: 4.8543 - acc: 0.01 - ETA: 15s - loss: 4.8542 - acc: 0.01 - ETA: 15s - loss: 4.8541 - acc: 0.01 - ETA: 14s - loss: 4.8540 - acc: 0.01 - ETA: 14s - loss: 4.8539 - acc: 0.01 - ETA: 14s - loss: 4.8539 - acc: 0.01 - ETA: 14s - loss: 4.8540 - acc: 0.01 - ETA: 14s - loss: 4.8540 - acc: 0.01 - ETA: 14s - loss: 4.8538 - acc: 0.01 - ETA: 13s - loss: 4.8538 - acc: 0.01 - ETA: 13s - loss: 4.8537 - acc: 0.01 - ETA: 13s - loss: 4.8538 - acc: 0.01 - ETA: 13s - loss: 4.8535 - acc: 0.01 - ETA: 13s - loss: 4.8534 - acc: 0.01 - ETA: 13s - loss: 4.8535 - acc: 0.01 - ETA: 13s - loss: 4.8537 - acc: 0.01 - ETA: 12s - loss: 4.8540 - acc: 0.01 - ETA: 12s - loss: 4.8539 - acc: 0.01 - ETA: 12s - loss: 4.8539 - acc: 0.01 - ETA: 12s - loss: 4.8537 - acc: 0.01 - ETA: 12s - loss: 4.8538 - acc: 0.01 - ETA: 12s - loss: 4.8538 - acc: 0.01 - ETA: 11s - loss: 4.8539 - acc: 0.01 - ETA: 11s - loss: 4.8538 - acc: 0.01 - ETA: 11s - loss: 4.8540 - acc: 0.01 - ETA: 11s - loss: 4.8539 - acc: 0.01 - ETA: 11s - loss: 4.8539 - acc: 0.01 - ETA: 11s - loss: 4.8539 - acc: 0.01 - ETA: 11s - loss: 4.8541 - acc: 0.01 - ETA: 10s - loss: 4.8539 - acc: 0.01 - ETA: 10s - loss: 4.8538 - acc: 0.01 - ETA: 10s - loss: 4.8537 - acc: 0.01 - ETA: 10s - loss: 4.8535 - acc: 0.01 - ETA: 10s - loss: 4.8539 - acc: 0.01 - ETA: 10s - loss: 4.8538 - acc: 0.01 - ETA: 9s - loss: 4.8540 - acc: 0.0177 - ETA: 9s - loss: 4.8539 - acc: 0.017 - ETA: 9s - loss: 4.8538 - acc: 0.017 - ETA: 9s - loss: 4.8538 - acc: 0.017 - ETA: 9s - loss: 4.8535 - acc: 0.017 - ETA: 9s - loss: 4.8536 - acc: 0.017 - ETA: 8s - loss: 4.8537 - acc: 0.017 - ETA: 8s - loss: 4.8540 - acc: 0.017 - ETA: 8s - loss: 4.8538 - acc: 0.017 - ETA: 8s - loss: 4.8539 - acc: 0.017 - ETA: 8s - loss: 4.8542 - acc: 0.017 - ETA: 8s - loss: 4.8541 - acc: 0.017 - ETA: 8s - loss: 4.8541 - acc: 0.017 - ETA: 7s - loss: 4.8540 - acc: 0.017 - ETA: 7s - loss: 4.8539 - acc: 0.017 - ETA: 7s - loss: 4.8539 - acc: 0.017 - ETA: 7s - loss: 4.8537 - acc: 0.017 - ETA: 7s - loss: 4.8538 - acc: 0.017 - ETA: 7s - loss: 4.8540 - acc: 0.017 - ETA: 6s - loss: 4.8540 - acc: 0.017 - ETA: 6s - loss: 4.8544 - acc: 0.017 - ETA: 6s - loss: 4.8545 - acc: 0.017 - ETA: 6s - loss: 4.8548 - acc: 0.017 - ETA: 6s - loss: 4.8547 - acc: 0.017 - ETA: 6s - loss: 4.8547 - acc: 0.017 - ETA: 6s - loss: 4.8544 - acc: 0.017 - ETA: 5s - loss: 4.8545 - acc: 0.017 - ETA: 5s - loss: 4.8546 - acc: 0.017 - ETA: 5s - loss: 4.8545 - acc: 0.017 - ETA: 5s - loss: 4.8543 - acc: 0.017 - ETA: 5s - loss: 4.8542 - acc: 0.017 - ETA: 5s - loss: 4.8542 - acc: 0.017 - ETA: 4s - loss: 4.8543 - acc: 0.017 - ETA: 4s - loss: 4.8542 - acc: 0.017 - ETA: 4s - loss: 4.8541 - acc: 0.016 - ETA: 4s - loss: 4.8539 - acc: 0.016 - ETA: 4s - loss: 4.8538 - acc: 0.016 - ETA: 4s - loss: 4.8535 - acc: 0.016 - ETA: 3s - loss: 4.8536 - acc: 0.016 - ETA: 3s - loss: 4.8537 - acc: 0.016 - ETA: 3s - loss: 4.8537 - acc: 0.016 - ETA: 3s - loss: 4.8536 - acc: 0.016 - ETA: 3s - loss: 4.8536 - acc: 0.016 - ETA: 3s - loss: 4.8536 - acc: 0.016 - ETA: 3s - loss: 4.8539 - acc: 0.016 - ETA: 2s - loss: 4.8542 - acc: 0.016 - ETA: 2s - loss: 4.8541 - acc: 0.016 - ETA: 2s - loss: 4.8540 - acc: 0.016 - ETA: 2s - loss: 4.8539 - acc: 0.016 - ETA: 2s - loss: 4.8537 - acc: 0.016 - ETA: 2s - loss: 4.8536 - acc: 0.016 - ETA: 1s - loss: 4.8536 - acc: 0.016 - ETA: 1s - loss: 4.8535 - acc: 0.016 - ETA: 1s - loss: 4.8537 - acc: 0.016 - ETA: 1s - loss: 4.8536 - acc: 0.016 - ETA: 1s - loss: 4.8536 - acc: 0.016 - ETA: 1s - loss: 4.8538 - acc: 0.016 - ETA: 0s - loss: 4.8537 - acc: 0.016 - ETA: 0s - loss: 4.8540 - acc: 0.016 - ETA: 0s - loss: 4.8538 - acc: 0.016 - ETA: 0s - loss: 4.8538 - acc: 0.016 - ETA: 0s - loss: 4.8538 - acc: 0.016 - ETA: 0s - loss: 4.8539 - acc: 0.016 - 71s 169ms/step - loss: 4.8540 - acc: 0.0168 - val_loss: 4.8402 - val_acc: 0.0171\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 4.83939\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 6s - loss: 4.8943 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8412 - acc: 0.0125    - ETA: 6s - loss: 4.8399 - acc: 0.007 - ETA: 7s - loss: 4.8475 - acc: 0.010 - ETA: 11s - loss: 4.8405 - acc: 0.00 - ETA: 19s - loss: 4.8359 - acc: 0.01 - ETA: 22s - loss: 4.8413 - acc: 0.01 - ETA: 24s - loss: 4.8479 - acc: 0.01 - ETA: 26s - loss: 4.8472 - acc: 0.01 - ETA: 27s - loss: 4.8520 - acc: 0.01 - ETA: 28s - loss: 4.8488 - acc: 0.01 - ETA: 30s - loss: 4.8526 - acc: 0.01 - ETA: 32s - loss: 4.8588 - acc: 0.01 - ETA: 33s - loss: 4.8603 - acc: 0.01 - ETA: 36s - loss: 4.8563 - acc: 0.01 - ETA: 36s - loss: 4.8547 - acc: 0.01 - ETA: 37s - loss: 4.8552 - acc: 0.01 - ETA: 38s - loss: 4.8517 - acc: 0.01 - ETA: 38s - loss: 4.8504 - acc: 0.01 - ETA: 38s - loss: 4.8466 - acc: 0.01 - ETA: 40s - loss: 4.8473 - acc: 0.01 - ETA: 40s - loss: 4.8461 - acc: 0.01 - ETA: 40s - loss: 4.8494 - acc: 0.01 - ETA: 40s - loss: 4.8505 - acc: 0.01 - ETA: 40s - loss: 4.8489 - acc: 0.01 - ETA: 41s - loss: 4.8492 - acc: 0.01 - ETA: 41s - loss: 4.8479 - acc: 0.01 - ETA: 42s - loss: 4.8485 - acc: 0.01 - ETA: 42s - loss: 4.8508 - acc: 0.01 - ETA: 43s - loss: 4.8519 - acc: 0.01 - ETA: 43s - loss: 4.8523 - acc: 0.01 - ETA: 43s - loss: 4.8529 - acc: 0.01 - ETA: 44s - loss: 4.8519 - acc: 0.01 - ETA: 44s - loss: 4.8510 - acc: 0.01 - ETA: 45s - loss: 4.8507 - acc: 0.01 - ETA: 45s - loss: 4.8517 - acc: 0.01 - ETA: 45s - loss: 4.8501 - acc: 0.01 - ETA: 45s - loss: 4.8512 - acc: 0.01 - ETA: 45s - loss: 4.8528 - acc: 0.01 - ETA: 45s - loss: 4.8513 - acc: 0.01 - ETA: 45s - loss: 4.8505 - acc: 0.01 - ETA: 45s - loss: 4.8498 - acc: 0.01 - ETA: 45s - loss: 4.8500 - acc: 0.01 - ETA: 46s - loss: 4.8501 - acc: 0.01 - ETA: 46s - loss: 4.8494 - acc: 0.01 - ETA: 46s - loss: 4.8512 - acc: 0.01 - ETA: 46s - loss: 4.8517 - acc: 0.01 - ETA: 46s - loss: 4.8507 - acc: 0.01 - ETA: 46s - loss: 4.8503 - acc: 0.01 - ETA: 46s - loss: 4.8507 - acc: 0.01 - ETA: 46s - loss: 4.8507 - acc: 0.01 - ETA: 46s - loss: 4.8517 - acc: 0.01 - ETA: 46s - loss: 4.8522 - acc: 0.01 - ETA: 46s - loss: 4.8539 - acc: 0.01 - ETA: 46s - loss: 4.8548 - acc: 0.01 - ETA: 45s - loss: 4.8553 - acc: 0.01 - ETA: 46s - loss: 4.8556 - acc: 0.01 - ETA: 46s - loss: 4.8556 - acc: 0.01 - ETA: 46s - loss: 4.8570 - acc: 0.01 - ETA: 46s - loss: 4.8573 - acc: 0.01 - ETA: 46s - loss: 4.8582 - acc: 0.01 - ETA: 46s - loss: 4.8579 - acc: 0.01 - ETA: 46s - loss: 4.8580 - acc: 0.01 - ETA: 46s - loss: 4.8581 - acc: 0.01 - ETA: 46s - loss: 4.8582 - acc: 0.01 - ETA: 46s - loss: 4.8590 - acc: 0.01 - ETA: 46s - loss: 4.8588 - acc: 0.01 - ETA: 46s - loss: 4.8574 - acc: 0.01 - ETA: 46s - loss: 4.8578 - acc: 0.01 - ETA: 46s - loss: 4.8574 - acc: 0.01 - ETA: 46s - loss: 4.8591 - acc: 0.01 - ETA: 46s - loss: 4.8582 - acc: 0.01 - ETA: 47s - loss: 4.8580 - acc: 0.01 - ETA: 47s - loss: 4.8570 - acc: 0.01 - ETA: 47s - loss: 4.8570 - acc: 0.01 - ETA: 47s - loss: 4.8574 - acc: 0.01 - ETA: 47s - loss: 4.8559 - acc: 0.01 - ETA: 46s - loss: 4.8552 - acc: 0.01 - ETA: 46s - loss: 4.8548 - acc: 0.01 - ETA: 46s - loss: 4.8548 - acc: 0.01 - ETA: 46s - loss: 4.8553 - acc: 0.01 - ETA: 46s - loss: 4.8547 - acc: 0.01 - ETA: 46s - loss: 4.8551 - acc: 0.01 - ETA: 46s - loss: 4.8544 - acc: 0.01 - ETA: 46s - loss: 4.8541 - acc: 0.01 - ETA: 46s - loss: 4.8546 - acc: 0.01 - ETA: 45s - loss: 4.8544 - acc: 0.01 - ETA: 46s - loss: 4.8555 - acc: 0.01 - ETA: 46s - loss: 4.8552 - acc: 0.01 - ETA: 46s - loss: 4.8554 - acc: 0.01 - ETA: 46s - loss: 4.8545 - acc: 0.01 - ETA: 45s - loss: 4.8544 - acc: 0.01 - ETA: 45s - loss: 4.8541 - acc: 0.01 - ETA: 45s - loss: 4.8537 - acc: 0.01 - ETA: 45s - loss: 4.8538 - acc: 0.01 - ETA: 45s - loss: 4.8530 - acc: 0.01 - ETA: 44s - loss: 4.8527 - acc: 0.01 - ETA: 44s - loss: 4.8532 - acc: 0.01 - ETA: 44s - loss: 4.8539 - acc: 0.01 - ETA: 44s - loss: 4.8553 - acc: 0.01 - ETA: 44s - loss: 4.8544 - acc: 0.01 - ETA: 44s - loss: 4.8548 - acc: 0.01 - ETA: 43s - loss: 4.8550 - acc: 0.01 - ETA: 43s - loss: 4.8544 - acc: 0.01 - ETA: 43s - loss: 4.8544 - acc: 0.01 - ETA: 43s - loss: 4.8540 - acc: 0.01 - ETA: 43s - loss: 4.8550 - acc: 0.01 - ETA: 43s - loss: 4.8550 - acc: 0.01 - ETA: 43s - loss: 4.8541 - acc: 0.01 - ETA: 43s - loss: 4.8543 - acc: 0.01 - ETA: 43s - loss: 4.8545 - acc: 0.01 - ETA: 43s - loss: 4.8544 - acc: 0.01 - ETA: 43s - loss: 4.8547 - acc: 0.01 - ETA: 43s - loss: 4.8553 - acc: 0.01 - ETA: 42s - loss: 4.8550 - acc: 0.01 - ETA: 42s - loss: 4.8548 - acc: 0.01 - ETA: 43s - loss: 4.8544 - acc: 0.01 - ETA: 43s - loss: 4.8546 - acc: 0.01 - ETA: 43s - loss: 4.8552 - acc: 0.01 - ETA: 42s - loss: 4.8551 - acc: 0.01 - ETA: 42s - loss: 4.8549 - acc: 0.01 - ETA: 42s - loss: 4.8551 - acc: 0.01 - ETA: 42s - loss: 4.8551 - acc: 0.01 - ETA: 42s - loss: 4.8549 - acc: 0.01 - ETA: 42s - loss: 4.8549 - acc: 0.01 - ETA: 42s - loss: 4.8544 - acc: 0.01 - ETA: 42s - loss: 4.8547 - acc: 0.01 - ETA: 42s - loss: 4.8546 - acc: 0.01 - ETA: 42s - loss: 4.8542 - acc: 0.01 - ETA: 42s - loss: 4.8523 - acc: 0.01 - ETA: 42s - loss: 4.8527 - acc: 0.01 - ETA: 41s - loss: 4.8531 - acc: 0.01 - ETA: 41s - loss: 4.8534 - acc: 0.01 - ETA: 41s - loss: 4.8537 - acc: 0.01 - ETA: 41s - loss: 4.8540 - acc: 0.01 - ETA: 41s - loss: 4.8544 - acc: 0.01 - ETA: 41s - loss: 4.8547 - acc: 0.01 - ETA: 41s - loss: 4.8550 - acc: 0.01 - ETA: 40s - loss: 4.8550 - acc: 0.01 - ETA: 40s - loss: 4.8552 - acc: 0.01 - ETA: 40s - loss: 4.8548 - acc: 0.01 - ETA: 40s - loss: 4.8546 - acc: 0.01 - ETA: 40s - loss: 4.8540 - acc: 0.01 - ETA: 40s - loss: 4.8540 - acc: 0.01 - ETA: 39s - loss: 4.8541 - acc: 0.01 - ETA: 39s - loss: 4.8545 - acc: 0.01 - ETA: 39s - loss: 4.8546 - acc: 0.01 - ETA: 39s - loss: 4.8542 - acc: 0.01 - ETA: 39s - loss: 4.8542 - acc: 0.01 - ETA: 39s - loss: 4.8540 - acc: 0.01 - ETA: 39s - loss: 4.8538 - acc: 0.01 - ETA: 38s - loss: 4.8538 - acc: 0.01 - ETA: 38s - loss: 4.8536 - acc: 0.01 - ETA: 38s - loss: 4.8537 - acc: 0.01 - ETA: 38s - loss: 4.8537 - acc: 0.01 - ETA: 38s - loss: 4.8534 - acc: 0.01 - ETA: 38s - loss: 4.8528 - acc: 0.01 - ETA: 38s - loss: 4.8529 - acc: 0.01 - ETA: 38s - loss: 4.8532 - acc: 0.01 - ETA: 37s - loss: 4.8531 - acc: 0.01 - ETA: 37s - loss: 4.8530 - acc: 0.01 - ETA: 37s - loss: 4.8532 - acc: 0.01 - ETA: 37s - loss: 4.8528 - acc: 0.01 - ETA: 37s - loss: 4.8529 - acc: 0.01 - ETA: 37s - loss: 4.8532 - acc: 0.01 - ETA: 37s - loss: 4.8535 - acc: 0.01 - ETA: 37s - loss: 4.8533 - acc: 0.01 - ETA: 36s - loss: 4.8534 - acc: 0.01 - ETA: 36s - loss: 4.8537 - acc: 0.01 - ETA: 36s - loss: 4.8542 - acc: 0.01 - ETA: 36s - loss: 4.8544 - acc: 0.01 - ETA: 36s - loss: 4.8541 - acc: 0.01 - ETA: 36s - loss: 4.8535 - acc: 0.01 - ETA: 36s - loss: 4.8533 - acc: 0.01 - ETA: 36s - loss: 4.8531 - acc: 0.01 - ETA: 36s - loss: 4.8539 - acc: 0.01 - ETA: 35s - loss: 4.8541 - acc: 0.01 - ETA: 35s - loss: 4.8542 - acc: 0.01 - ETA: 35s - loss: 4.8543 - acc: 0.01 - ETA: 35s - loss: 4.8542 - acc: 0.01 - ETA: 35s - loss: 4.8547 - acc: 0.01 - ETA: 35s - loss: 4.8553 - acc: 0.01 - ETA: 34s - loss: 4.8551 - acc: 0.01 - ETA: 34s - loss: 4.8550 - acc: 0.01 - ETA: 34s - loss: 4.8548 - acc: 0.01 - ETA: 34s - loss: 4.8551 - acc: 0.01 - ETA: 34s - loss: 4.8551 - acc: 0.01 - ETA: 34s - loss: 4.8553 - acc: 0.01 - ETA: 34s - loss: 4.8554 - acc: 0.01 - ETA: 34s - loss: 4.8557 - acc: 0.01 - ETA: 33s - loss: 4.8557 - acc: 0.01 - ETA: 33s - loss: 4.8556 - acc: 0.01 - ETA: 33s - loss: 4.8557 - acc: 0.01 - ETA: 33s - loss: 4.8556 - acc: 0.01 - ETA: 33s - loss: 4.8554 - acc: 0.01 - ETA: 33s - loss: 4.8551 - acc: 0.01 - ETA: 33s - loss: 4.8552 - acc: 0.01 - ETA: 32s - loss: 4.8549 - acc: 0.01 - ETA: 32s - loss: 4.8548 - acc: 0.01 - ETA: 32s - loss: 4.8542 - acc: 0.01 - ETA: 32s - loss: 4.8544 - acc: 0.01 - ETA: 32s - loss: 4.8539 - acc: 0.01 - ETA: 32s - loss: 4.8540 - acc: 0.01 - ETA: 31s - loss: 4.8542 - acc: 0.01 - ETA: 31s - loss: 4.8538 - acc: 0.01 - ETA: 31s - loss: 4.8535 - acc: 0.01 - ETA: 31s - loss: 4.8539 - acc: 0.01 - ETA: 31s - loss: 4.8537 - acc: 0.01 - ETA: 31s - loss: 4.8537 - acc: 0.01 - ETA: 31s - loss: 4.8539 - acc: 0.01 - ETA: 30s - loss: 4.8545 - acc: 0.01 - ETA: 30s - loss: 4.8542 - acc: 0.01 - ETA: 30s - loss: 4.8544 - acc: 0.01 - ETA: 30s - loss: 4.8545 - acc: 0.01 - ETA: 30s - loss: 4.8549 - acc: 0.0123"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 30s - loss: 4.8546 - acc: 0.01 - ETA: 29s - loss: 4.8545 - acc: 0.01 - ETA: 29s - loss: 4.8543 - acc: 0.01 - ETA: 29s - loss: 4.8540 - acc: 0.01 - ETA: 29s - loss: 4.8539 - acc: 0.01 - ETA: 29s - loss: 4.8541 - acc: 0.01 - ETA: 29s - loss: 4.8539 - acc: 0.01 - ETA: 29s - loss: 4.8537 - acc: 0.01 - ETA: 28s - loss: 4.8539 - acc: 0.01 - ETA: 28s - loss: 4.8543 - acc: 0.01 - ETA: 28s - loss: 4.8543 - acc: 0.01 - ETA: 28s - loss: 4.8540 - acc: 0.01 - ETA: 28s - loss: 4.8542 - acc: 0.01 - ETA: 28s - loss: 4.8540 - acc: 0.01 - ETA: 28s - loss: 4.8544 - acc: 0.01 - ETA: 27s - loss: 4.8543 - acc: 0.01 - ETA: 27s - loss: 4.8547 - acc: 0.01 - ETA: 27s - loss: 4.8546 - acc: 0.01 - ETA: 27s - loss: 4.8547 - acc: 0.01 - ETA: 27s - loss: 4.8547 - acc: 0.01 - ETA: 27s - loss: 4.8548 - acc: 0.01 - ETA: 27s - loss: 4.8546 - acc: 0.01 - ETA: 26s - loss: 4.8545 - acc: 0.01 - ETA: 26s - loss: 4.8539 - acc: 0.01 - ETA: 26s - loss: 4.8538 - acc: 0.01 - ETA: 26s - loss: 4.8540 - acc: 0.01 - ETA: 26s - loss: 4.8540 - acc: 0.01 - ETA: 26s - loss: 4.8538 - acc: 0.01 - ETA: 26s - loss: 4.8539 - acc: 0.01 - ETA: 25s - loss: 4.8542 - acc: 0.01 - ETA: 25s - loss: 4.8544 - acc: 0.01 - ETA: 25s - loss: 4.8540 - acc: 0.01 - ETA: 25s - loss: 4.8543 - acc: 0.01 - ETA: 25s - loss: 4.8541 - acc: 0.01 - ETA: 25s - loss: 4.8542 - acc: 0.01 - ETA: 24s - loss: 4.8546 - acc: 0.01 - ETA: 24s - loss: 4.8546 - acc: 0.01 - ETA: 24s - loss: 4.8547 - acc: 0.01 - ETA: 24s - loss: 4.8546 - acc: 0.01 - ETA: 24s - loss: 4.8549 - acc: 0.01 - ETA: 24s - loss: 4.8550 - acc: 0.01 - ETA: 23s - loss: 4.8551 - acc: 0.01 - ETA: 23s - loss: 4.8549 - acc: 0.01 - ETA: 23s - loss: 4.8548 - acc: 0.01 - ETA: 23s - loss: 4.8549 - acc: 0.01 - ETA: 23s - loss: 4.8548 - acc: 0.01 - ETA: 23s - loss: 4.8549 - acc: 0.01 - ETA: 23s - loss: 4.8544 - acc: 0.01 - ETA: 22s - loss: 4.8544 - acc: 0.01 - ETA: 22s - loss: 4.8546 - acc: 0.01 - ETA: 22s - loss: 4.8546 - acc: 0.01 - ETA: 22s - loss: 4.8545 - acc: 0.01 - ETA: 22s - loss: 4.8546 - acc: 0.01 - ETA: 22s - loss: 4.8544 - acc: 0.01 - ETA: 21s - loss: 4.8546 - acc: 0.01 - ETA: 21s - loss: 4.8548 - acc: 0.01 - ETA: 21s - loss: 4.8547 - acc: 0.01 - ETA: 21s - loss: 4.8552 - acc: 0.01 - ETA: 21s - loss: 4.8555 - acc: 0.01 - ETA: 21s - loss: 4.8553 - acc: 0.01 - ETA: 20s - loss: 4.8550 - acc: 0.01 - ETA: 20s - loss: 4.8546 - acc: 0.01 - ETA: 20s - loss: 4.8547 - acc: 0.01 - ETA: 20s - loss: 4.8549 - acc: 0.01 - ETA: 20s - loss: 4.8548 - acc: 0.01 - ETA: 20s - loss: 4.8550 - acc: 0.01 - ETA: 20s - loss: 4.8548 - acc: 0.01 - ETA: 19s - loss: 4.8551 - acc: 0.01 - ETA: 19s - loss: 4.8549 - acc: 0.01 - ETA: 19s - loss: 4.8552 - acc: 0.01 - ETA: 19s - loss: 4.8548 - acc: 0.01 - ETA: 19s - loss: 4.8547 - acc: 0.01 - ETA: 19s - loss: 4.8544 - acc: 0.01 - ETA: 19s - loss: 4.8543 - acc: 0.01 - ETA: 18s - loss: 4.8544 - acc: 0.01 - ETA: 18s - loss: 4.8544 - acc: 0.01 - ETA: 18s - loss: 4.8545 - acc: 0.01 - ETA: 18s - loss: 4.8548 - acc: 0.01 - ETA: 18s - loss: 4.8547 - acc: 0.01 - ETA: 18s - loss: 4.8543 - acc: 0.01 - ETA: 17s - loss: 4.8542 - acc: 0.01 - ETA: 17s - loss: 4.8542 - acc: 0.01 - ETA: 17s - loss: 4.8539 - acc: 0.01 - ETA: 17s - loss: 4.8540 - acc: 0.01 - ETA: 17s - loss: 4.8537 - acc: 0.01 - ETA: 17s - loss: 4.8537 - acc: 0.01 - ETA: 17s - loss: 4.8534 - acc: 0.01 - ETA: 16s - loss: 4.8536 - acc: 0.01 - ETA: 16s - loss: 4.8538 - acc: 0.01 - ETA: 16s - loss: 4.8537 - acc: 0.01 - ETA: 16s - loss: 4.8535 - acc: 0.01 - ETA: 16s - loss: 4.8538 - acc: 0.01 - ETA: 16s - loss: 4.8536 - acc: 0.01 - ETA: 15s - loss: 4.8536 - acc: 0.01 - ETA: 15s - loss: 4.8535 - acc: 0.01 - ETA: 15s - loss: 4.8537 - acc: 0.01 - ETA: 15s - loss: 4.8536 - acc: 0.01 - ETA: 15s - loss: 4.8537 - acc: 0.01 - ETA: 15s - loss: 4.8539 - acc: 0.01 - ETA: 15s - loss: 4.8543 - acc: 0.01 - ETA: 14s - loss: 4.8542 - acc: 0.01 - ETA: 14s - loss: 4.8539 - acc: 0.01 - ETA: 14s - loss: 4.8539 - acc: 0.01 - ETA: 14s - loss: 4.8540 - acc: 0.01 - ETA: 14s - loss: 4.8539 - acc: 0.01 - ETA: 14s - loss: 4.8540 - acc: 0.01 - ETA: 13s - loss: 4.8539 - acc: 0.01 - ETA: 13s - loss: 4.8537 - acc: 0.01 - ETA: 13s - loss: 4.8536 - acc: 0.01 - ETA: 13s - loss: 4.8534 - acc: 0.01 - ETA: 13s - loss: 4.8534 - acc: 0.01 - ETA: 13s - loss: 4.8532 - acc: 0.01 - ETA: 12s - loss: 4.8530 - acc: 0.01 - ETA: 12s - loss: 4.8532 - acc: 0.01 - ETA: 12s - loss: 4.8533 - acc: 0.01 - ETA: 12s - loss: 4.8531 - acc: 0.01 - ETA: 12s - loss: 4.8529 - acc: 0.01 - ETA: 12s - loss: 4.8526 - acc: 0.01 - ETA: 12s - loss: 4.8525 - acc: 0.01 - ETA: 11s - loss: 4.8524 - acc: 0.01 - ETA: 11s - loss: 4.8525 - acc: 0.01 - ETA: 11s - loss: 4.8528 - acc: 0.01 - ETA: 11s - loss: 4.8527 - acc: 0.01 - ETA: 11s - loss: 4.8524 - acc: 0.01 - ETA: 11s - loss: 4.8523 - acc: 0.01 - ETA: 10s - loss: 4.8523 - acc: 0.01 - ETA: 10s - loss: 4.8522 - acc: 0.01 - ETA: 10s - loss: 4.8522 - acc: 0.01 - ETA: 10s - loss: 4.8521 - acc: 0.01 - ETA: 10s - loss: 4.8524 - acc: 0.01 - ETA: 10s - loss: 4.8524 - acc: 0.01 - ETA: 9s - loss: 4.8522 - acc: 0.0146 - ETA: 9s - loss: 4.8520 - acc: 0.014 - ETA: 9s - loss: 4.8519 - acc: 0.014 - ETA: 9s - loss: 4.8518 - acc: 0.014 - ETA: 9s - loss: 4.8518 - acc: 0.014 - ETA: 9s - loss: 4.8519 - acc: 0.014 - ETA: 8s - loss: 4.8520 - acc: 0.014 - ETA: 8s - loss: 4.8520 - acc: 0.014 - ETA: 8s - loss: 4.8518 - acc: 0.014 - ETA: 8s - loss: 4.8517 - acc: 0.014 - ETA: 8s - loss: 4.8516 - acc: 0.014 - ETA: 8s - loss: 4.8514 - acc: 0.014 - ETA: 7s - loss: 4.8513 - acc: 0.014 - ETA: 7s - loss: 4.8516 - acc: 0.014 - ETA: 7s - loss: 4.8513 - acc: 0.014 - ETA: 7s - loss: 4.8516 - acc: 0.014 - ETA: 7s - loss: 4.8517 - acc: 0.014 - ETA: 7s - loss: 4.8521 - acc: 0.014 - ETA: 6s - loss: 4.8521 - acc: 0.014 - ETA: 6s - loss: 4.8520 - acc: 0.014 - ETA: 6s - loss: 4.8518 - acc: 0.014 - ETA: 6s - loss: 4.8520 - acc: 0.014 - ETA: 6s - loss: 4.8519 - acc: 0.014 - ETA: 5s - loss: 4.8518 - acc: 0.014 - ETA: 5s - loss: 4.8519 - acc: 0.014 - ETA: 5s - loss: 4.8519 - acc: 0.014 - ETA: 5s - loss: 4.8522 - acc: 0.014 - ETA: 5s - loss: 4.8523 - acc: 0.014 - ETA: 5s - loss: 4.8526 - acc: 0.014 - ETA: 4s - loss: 4.8526 - acc: 0.014 - ETA: 4s - loss: 4.8525 - acc: 0.014 - ETA: 4s - loss: 4.8527 - acc: 0.014 - ETA: 4s - loss: 4.8527 - acc: 0.014 - ETA: 4s - loss: 4.8526 - acc: 0.014 - ETA: 4s - loss: 4.8525 - acc: 0.014 - ETA: 3s - loss: 4.8523 - acc: 0.014 - ETA: 3s - loss: 4.8524 - acc: 0.014 - ETA: 3s - loss: 4.8527 - acc: 0.014 - ETA: 3s - loss: 4.8526 - acc: 0.014 - ETA: 3s - loss: 4.8528 - acc: 0.014 - ETA: 3s - loss: 4.8529 - acc: 0.014 - ETA: 3s - loss: 4.8531 - acc: 0.014 - ETA: 2s - loss: 4.8530 - acc: 0.014 - ETA: 2s - loss: 4.8527 - acc: 0.014 - ETA: 2s - loss: 4.8527 - acc: 0.015 - ETA: 2s - loss: 4.8528 - acc: 0.014 - ETA: 2s - loss: 4.8525 - acc: 0.014 - ETA: 1s - loss: 4.8522 - acc: 0.014 - ETA: 1s - loss: 4.8523 - acc: 0.014 - ETA: 1s - loss: 4.8520 - acc: 0.014 - ETA: 1s - loss: 4.8518 - acc: 0.014 - ETA: 1s - loss: 4.8516 - acc: 0.014 - ETA: 0s - loss: 4.8516 - acc: 0.014 - ETA: 0s - loss: 4.8514 - acc: 0.014 - ETA: 0s - loss: 4.8512 - acc: 0.014 - ETA: 0s - loss: 4.8510 - acc: 0.014 - ETA: 0s - loss: 4.8513 - acc: 0.014 - ETA: 0s - loss: 4.8511 - acc: 0.014 - 70s 168ms/step - loss: 4.8511 - acc: 0.0148 - val_loss: 4.8382 - val_acc: 0.0208\n",
      "\n",
      "Epoch 00029: val_loss improved from 4.83939 to 4.83817, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 7s - loss: 4.8618 - acc: 0.0000e+0 - ETA: 6s - loss: 4.9023 - acc: 0.0125    - ETA: 6s - loss: 4.8726 - acc: 0.020 - ETA: 7s - loss: 4.8718 - acc: 0.026 - ETA: 10s - loss: 4.8652 - acc: 0.02 - ETA: 15s - loss: 4.8597 - acc: 0.03 - ETA: 18s - loss: 4.8622 - acc: 0.02 - ETA: 20s - loss: 4.8603 - acc: 0.03 - ETA: 22s - loss: 4.8604 - acc: 0.02 - ETA: 24s - loss: 4.8573 - acc: 0.02 - ETA: 29s - loss: 4.8584 - acc: 0.02 - ETA: 30s - loss: 4.8542 - acc: 0.02 - ETA: 32s - loss: 4.8536 - acc: 0.02 - ETA: 34s - loss: 4.8544 - acc: 0.02 - ETA: 36s - loss: 4.8572 - acc: 0.02 - ETA: 37s - loss: 4.8584 - acc: 0.02 - ETA: 38s - loss: 4.8499 - acc: 0.02 - ETA: 38s - loss: 4.8510 - acc: 0.02 - ETA: 39s - loss: 4.8522 - acc: 0.02 - ETA: 39s - loss: 4.8523 - acc: 0.02 - ETA: 40s - loss: 4.8532 - acc: 0.02 - ETA: 40s - loss: 4.8540 - acc: 0.02 - ETA: 40s - loss: 4.8530 - acc: 0.02 - ETA: 40s - loss: 4.8591 - acc: 0.02 - ETA: 41s - loss: 4.8598 - acc: 0.02 - ETA: 41s - loss: 4.8570 - acc: 0.02 - ETA: 42s - loss: 4.8549 - acc: 0.02 - ETA: 43s - loss: 4.8550 - acc: 0.02 - ETA: 43s - loss: 4.8541 - acc: 0.02 - ETA: 43s - loss: 4.8558 - acc: 0.02 - ETA: 44s - loss: 4.8560 - acc: 0.02 - ETA: 44s - loss: 4.8563 - acc: 0.02 - ETA: 43s - loss: 4.8558 - acc: 0.02 - ETA: 43s - loss: 4.8541 - acc: 0.02 - ETA: 43s - loss: 4.8531 - acc: 0.02 - ETA: 44s - loss: 4.8521 - acc: 0.02 - ETA: 44s - loss: 4.8542 - acc: 0.02 - ETA: 44s - loss: 4.8545 - acc: 0.02 - ETA: 45s - loss: 4.8541 - acc: 0.02 - ETA: 45s - loss: 4.8549 - acc: 0.02 - ETA: 47s - loss: 4.8544 - acc: 0.02 - ETA: 48s - loss: 4.8564 - acc: 0.02 - ETA: 48s - loss: 4.8559 - acc: 0.02 - ETA: 48s - loss: 4.8565 - acc: 0.02 - ETA: 48s - loss: 4.8581 - acc: 0.02 - ETA: 47s - loss: 4.8586 - acc: 0.02 - ETA: 48s - loss: 4.8582 - acc: 0.02 - ETA: 48s - loss: 4.8566 - acc: 0.02 - ETA: 47s - loss: 4.8566 - acc: 0.02 - ETA: 47s - loss: 4.8560 - acc: 0.02 - ETA: 47s - loss: 4.8553 - acc: 0.02 - ETA: 47s - loss: 4.8572 - acc: 0.02 - ETA: 47s - loss: 4.8563 - acc: 0.02 - ETA: 47s - loss: 4.8549 - acc: 0.02 - ETA: 47s - loss: 4.8531 - acc: 0.02 - ETA: 47s - loss: 4.8539 - acc: 0.02 - ETA: 47s - loss: 4.8533 - acc: 0.02 - ETA: 47s - loss: 4.8537 - acc: 0.02 - ETA: 47s - loss: 4.8534 - acc: 0.02 - ETA: 47s - loss: 4.8524 - acc: 0.02 - ETA: 47s - loss: 4.8506 - acc: 0.02 - ETA: 47s - loss: 4.8500 - acc: 0.02 - ETA: 46s - loss: 4.8484 - acc: 0.02 - ETA: 46s - loss: 4.8480 - acc: 0.02 - ETA: 46s - loss: 4.8486 - acc: 0.02 - ETA: 46s - loss: 4.8482 - acc: 0.02 - ETA: 46s - loss: 4.8485 - acc: 0.02 - ETA: 46s - loss: 4.8490 - acc: 0.02 - ETA: 46s - loss: 4.8500 - acc: 0.02 - ETA: 46s - loss: 4.8491 - acc: 0.02 - ETA: 46s - loss: 4.8480 - acc: 0.02 - ETA: 46s - loss: 4.8466 - acc: 0.02 - ETA: 46s - loss: 4.8457 - acc: 0.02 - ETA: 45s - loss: 4.8457 - acc: 0.02 - ETA: 46s - loss: 4.8472 - acc: 0.02 - ETA: 46s - loss: 4.8466 - acc: 0.02 - ETA: 46s - loss: 4.8458 - acc: 0.02 - ETA: 46s - loss: 4.8469 - acc: 0.02 - ETA: 45s - loss: 4.8454 - acc: 0.02 - ETA: 45s - loss: 4.8448 - acc: 0.02 - ETA: 45s - loss: 4.8451 - acc: 0.02 - ETA: 45s - loss: 4.8455 - acc: 0.02 - ETA: 45s - loss: 4.8458 - acc: 0.02 - ETA: 45s - loss: 4.8465 - acc: 0.02 - ETA: 45s - loss: 4.8467 - acc: 0.02 - ETA: 45s - loss: 4.8457 - acc: 0.02 - ETA: 45s - loss: 4.8466 - acc: 0.02 - ETA: 45s - loss: 4.8460 - acc: 0.02 - ETA: 46s - loss: 4.8469 - acc: 0.02 - ETA: 46s - loss: 4.8472 - acc: 0.02 - ETA: 46s - loss: 4.8467 - acc: 0.02 - ETA: 46s - loss: 4.8458 - acc: 0.02 - ETA: 45s - loss: 4.8448 - acc: 0.02 - ETA: 45s - loss: 4.8449 - acc: 0.02 - ETA: 45s - loss: 4.8458 - acc: 0.02 - ETA: 45s - loss: 4.8460 - acc: 0.02 - ETA: 45s - loss: 4.8467 - acc: 0.02 - ETA: 45s - loss: 4.8478 - acc: 0.02 - ETA: 44s - loss: 4.8478 - acc: 0.02 - ETA: 44s - loss: 4.8473 - acc: 0.02 - ETA: 44s - loss: 4.8472 - acc: 0.02 - ETA: 44s - loss: 4.8475 - acc: 0.02 - ETA: 44s - loss: 4.8477 - acc: 0.02 - ETA: 44s - loss: 4.8469 - acc: 0.02 - ETA: 43s - loss: 4.8462 - acc: 0.02 - ETA: 43s - loss: 4.8459 - acc: 0.02 - ETA: 43s - loss: 4.8466 - acc: 0.02 - ETA: 43s - loss: 4.8479 - acc: 0.02 - ETA: 43s - loss: 4.8484 - acc: 0.02 - ETA: 43s - loss: 4.8484 - acc: 0.02 - ETA: 42s - loss: 4.8486 - acc: 0.02 - ETA: 42s - loss: 4.8484 - acc: 0.02 - ETA: 42s - loss: 4.8478 - acc: 0.02 - ETA: 42s - loss: 4.8488 - acc: 0.02 - ETA: 42s - loss: 4.8488 - acc: 0.02 - ETA: 42s - loss: 4.8490 - acc: 0.02 - ETA: 42s - loss: 4.8482 - acc: 0.02 - ETA: 41s - loss: 4.8486 - acc: 0.02 - ETA: 41s - loss: 4.8490 - acc: 0.02 - ETA: 41s - loss: 4.8485 - acc: 0.02 - ETA: 41s - loss: 4.8483 - acc: 0.02 - ETA: 41s - loss: 4.8477 - acc: 0.02 - ETA: 41s - loss: 4.8479 - acc: 0.02 - ETA: 41s - loss: 4.8490 - acc: 0.02 - ETA: 41s - loss: 4.8490 - acc: 0.02 - ETA: 40s - loss: 4.8490 - acc: 0.02 - ETA: 40s - loss: 4.8492 - acc: 0.02 - ETA: 40s - loss: 4.8500 - acc: 0.02 - ETA: 40s - loss: 4.8498 - acc: 0.02 - ETA: 40s - loss: 4.8504 - acc: 0.01 - ETA: 40s - loss: 4.8508 - acc: 0.01 - ETA: 39s - loss: 4.8506 - acc: 0.01 - ETA: 39s - loss: 4.8506 - acc: 0.01 - ETA: 39s - loss: 4.8507 - acc: 0.01 - ETA: 39s - loss: 4.8512 - acc: 0.01 - ETA: 39s - loss: 4.8508 - acc: 0.02 - ETA: 38s - loss: 4.8504 - acc: 0.02 - ETA: 38s - loss: 4.8504 - acc: 0.02 - ETA: 38s - loss: 4.8508 - acc: 0.02 - ETA: 38s - loss: 4.8499 - acc: 0.02 - ETA: 38s - loss: 4.8491 - acc: 0.02 - ETA: 38s - loss: 4.8487 - acc: 0.02 - ETA: 38s - loss: 4.8488 - acc: 0.02 - ETA: 38s - loss: 4.8483 - acc: 0.02 - ETA: 38s - loss: 4.8484 - acc: 0.02 - ETA: 37s - loss: 4.8478 - acc: 0.02 - ETA: 37s - loss: 4.8483 - acc: 0.02 - ETA: 37s - loss: 4.8480 - acc: 0.02 - ETA: 37s - loss: 4.8479 - acc: 0.02 - ETA: 37s - loss: 4.8475 - acc: 0.02 - ETA: 37s - loss: 4.8471 - acc: 0.02 - ETA: 37s - loss: 4.8464 - acc: 0.02 - ETA: 36s - loss: 4.8468 - acc: 0.02 - ETA: 36s - loss: 4.8460 - acc: 0.02 - ETA: 36s - loss: 4.8453 - acc: 0.02 - ETA: 36s - loss: 4.8453 - acc: 0.02 - ETA: 36s - loss: 4.8458 - acc: 0.02 - ETA: 36s - loss: 4.8459 - acc: 0.02 - ETA: 36s - loss: 4.8459 - acc: 0.02 - ETA: 35s - loss: 4.8465 - acc: 0.02 - ETA: 35s - loss: 4.8465 - acc: 0.02 - ETA: 35s - loss: 4.8460 - acc: 0.01 - ETA: 35s - loss: 4.8456 - acc: 0.01 - ETA: 35s - loss: 4.8455 - acc: 0.02 - ETA: 35s - loss: 4.8455 - acc: 0.02 - ETA: 35s - loss: 4.8460 - acc: 0.02 - ETA: 35s - loss: 4.8459 - acc: 0.02 - ETA: 34s - loss: 4.8448 - acc: 0.02 - ETA: 34s - loss: 4.8447 - acc: 0.02 - ETA: 34s - loss: 4.8448 - acc: 0.02 - ETA: 34s - loss: 4.8448 - acc: 0.02 - ETA: 34s - loss: 4.8451 - acc: 0.02 - ETA: 34s - loss: 4.8446 - acc: 0.02 - ETA: 34s - loss: 4.8453 - acc: 0.02 - ETA: 33s - loss: 4.8456 - acc: 0.02 - ETA: 33s - loss: 4.8455 - acc: 0.02 - ETA: 33s - loss: 4.8454 - acc: 0.02 - ETA: 33s - loss: 4.8460 - acc: 0.02 - ETA: 33s - loss: 4.8467 - acc: 0.02 - ETA: 33s - loss: 4.8470 - acc: 0.02 - ETA: 33s - loss: 4.8475 - acc: 0.02 - ETA: 33s - loss: 4.8478 - acc: 0.02 - ETA: 32s - loss: 4.8483 - acc: 0.02 - ETA: 32s - loss: 4.8486 - acc: 0.02 - ETA: 32s - loss: 4.8485 - acc: 0.02 - ETA: 32s - loss: 4.8489 - acc: 0.02 - ETA: 32s - loss: 4.8487 - acc: 0.02 - ETA: 32s - loss: 4.8484 - acc: 0.02 - ETA: 32s - loss: 4.8487 - acc: 0.02 - ETA: 32s - loss: 4.8487 - acc: 0.02 - ETA: 32s - loss: 4.8486 - acc: 0.02 - ETA: 31s - loss: 4.8482 - acc: 0.02 - ETA: 31s - loss: 4.8486 - acc: 0.02 - ETA: 31s - loss: 4.8492 - acc: 0.02 - ETA: 31s - loss: 4.8498 - acc: 0.02 - ETA: 31s - loss: 4.8501 - acc: 0.01 - ETA: 31s - loss: 4.8507 - acc: 0.01 - ETA: 31s - loss: 4.8505 - acc: 0.02 - ETA: 31s - loss: 4.8505 - acc: 0.01 - ETA: 30s - loss: 4.8506 - acc: 0.01 - ETA: 30s - loss: 4.8508 - acc: 0.01 - ETA: 30s - loss: 4.8507 - acc: 0.01 - ETA: 30s - loss: 4.8508 - acc: 0.02 - ETA: 30s - loss: 4.8511 - acc: 0.02 - ETA: 30s - loss: 4.8510 - acc: 0.02 - ETA: 30s - loss: 4.8507 - acc: 0.01 - ETA: 29s - loss: 4.8508 - acc: 0.01 - ETA: 29s - loss: 4.8507 - acc: 0.02 - ETA: 29s - loss: 4.8507 - acc: 0.02 - ETA: 29s - loss: 4.8513 - acc: 0.02 - ETA: 29s - loss: 4.8516 - acc: 0.02 - ETA: 29s - loss: 4.8517 - acc: 0.01 - ETA: 28s - loss: 4.8517 - acc: 0.01 - ETA: 28s - loss: 4.8513 - acc: 0.01 - ETA: 28s - loss: 4.8507 - acc: 0.0202"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8506 - acc: 0.02 - ETA: 28s - loss: 4.8505 - acc: 0.02 - ETA: 28s - loss: 4.8507 - acc: 0.02 - ETA: 27s - loss: 4.8507 - acc: 0.02 - ETA: 27s - loss: 4.8507 - acc: 0.02 - ETA: 27s - loss: 4.8505 - acc: 0.02 - ETA: 27s - loss: 4.8506 - acc: 0.02 - ETA: 27s - loss: 4.8511 - acc: 0.02 - ETA: 27s - loss: 4.8510 - acc: 0.02 - ETA: 27s - loss: 4.8515 - acc: 0.02 - ETA: 26s - loss: 4.8511 - acc: 0.02 - ETA: 26s - loss: 4.8509 - acc: 0.02 - ETA: 26s - loss: 4.8509 - acc: 0.02 - ETA: 26s - loss: 4.8509 - acc: 0.02 - ETA: 26s - loss: 4.8508 - acc: 0.02 - ETA: 26s - loss: 4.8508 - acc: 0.02 - ETA: 26s - loss: 4.8504 - acc: 0.02 - ETA: 25s - loss: 4.8502 - acc: 0.02 - ETA: 25s - loss: 4.8504 - acc: 0.02 - ETA: 25s - loss: 4.8500 - acc: 0.02 - ETA: 25s - loss: 4.8506 - acc: 0.02 - ETA: 25s - loss: 4.8503 - acc: 0.02 - ETA: 25s - loss: 4.8500 - acc: 0.02 - ETA: 25s - loss: 4.8497 - acc: 0.02 - ETA: 24s - loss: 4.8497 - acc: 0.02 - ETA: 24s - loss: 4.8498 - acc: 0.02 - ETA: 24s - loss: 4.8495 - acc: 0.02 - ETA: 24s - loss: 4.8493 - acc: 0.02 - ETA: 24s - loss: 4.8492 - acc: 0.02 - ETA: 24s - loss: 4.8494 - acc: 0.02 - ETA: 24s - loss: 4.8496 - acc: 0.01 - ETA: 23s - loss: 4.8494 - acc: 0.01 - ETA: 23s - loss: 4.8493 - acc: 0.01 - ETA: 23s - loss: 4.8495 - acc: 0.01 - ETA: 23s - loss: 4.8500 - acc: 0.01 - ETA: 23s - loss: 4.8500 - acc: 0.01 - ETA: 23s - loss: 4.8498 - acc: 0.01 - ETA: 23s - loss: 4.8501 - acc: 0.01 - ETA: 22s - loss: 4.8496 - acc: 0.01 - ETA: 22s - loss: 4.8495 - acc: 0.01 - ETA: 22s - loss: 4.8498 - acc: 0.01 - ETA: 22s - loss: 4.8497 - acc: 0.01 - ETA: 22s - loss: 4.8499 - acc: 0.01 - ETA: 22s - loss: 4.8500 - acc: 0.01 - ETA: 22s - loss: 4.8503 - acc: 0.01 - ETA: 21s - loss: 4.8504 - acc: 0.01 - ETA: 21s - loss: 4.8502 - acc: 0.01 - ETA: 21s - loss: 4.8506 - acc: 0.01 - ETA: 21s - loss: 4.8507 - acc: 0.01 - ETA: 21s - loss: 4.8507 - acc: 0.01 - ETA: 21s - loss: 4.8508 - acc: 0.01 - ETA: 20s - loss: 4.8509 - acc: 0.01 - ETA: 20s - loss: 4.8509 - acc: 0.01 - ETA: 20s - loss: 4.8507 - acc: 0.01 - ETA: 20s - loss: 4.8507 - acc: 0.01 - ETA: 20s - loss: 4.8508 - acc: 0.01 - ETA: 20s - loss: 4.8505 - acc: 0.01 - ETA: 20s - loss: 4.8506 - acc: 0.01 - ETA: 19s - loss: 4.8503 - acc: 0.01 - ETA: 19s - loss: 4.8500 - acc: 0.01 - ETA: 19s - loss: 4.8502 - acc: 0.01 - ETA: 19s - loss: 4.8499 - acc: 0.01 - ETA: 19s - loss: 4.8497 - acc: 0.01 - ETA: 19s - loss: 4.8499 - acc: 0.01 - ETA: 19s - loss: 4.8498 - acc: 0.01 - ETA: 18s - loss: 4.8500 - acc: 0.01 - ETA: 18s - loss: 4.8501 - acc: 0.01 - ETA: 18s - loss: 4.8499 - acc: 0.01 - ETA: 18s - loss: 4.8500 - acc: 0.01 - ETA: 18s - loss: 4.8499 - acc: 0.01 - ETA: 18s - loss: 4.8497 - acc: 0.01 - ETA: 17s - loss: 4.8496 - acc: 0.01 - ETA: 17s - loss: 4.8498 - acc: 0.01 - ETA: 17s - loss: 4.8500 - acc: 0.01 - ETA: 17s - loss: 4.8499 - acc: 0.01 - ETA: 17s - loss: 4.8499 - acc: 0.01 - ETA: 17s - loss: 4.8501 - acc: 0.01 - ETA: 17s - loss: 4.8502 - acc: 0.01 - ETA: 16s - loss: 4.8497 - acc: 0.01 - ETA: 16s - loss: 4.8496 - acc: 0.01 - ETA: 16s - loss: 4.8492 - acc: 0.01 - ETA: 16s - loss: 4.8489 - acc: 0.01 - ETA: 16s - loss: 4.8490 - acc: 0.01 - ETA: 16s - loss: 4.8490 - acc: 0.01 - ETA: 16s - loss: 4.8490 - acc: 0.01 - ETA: 16s - loss: 4.8489 - acc: 0.01 - ETA: 15s - loss: 4.8486 - acc: 0.01 - ETA: 15s - loss: 4.8489 - acc: 0.01 - ETA: 15s - loss: 4.8483 - acc: 0.01 - ETA: 15s - loss: 4.8483 - acc: 0.02 - ETA: 15s - loss: 4.8483 - acc: 0.01 - ETA: 15s - loss: 4.8484 - acc: 0.02 - ETA: 14s - loss: 4.8484 - acc: 0.02 - ETA: 14s - loss: 4.8482 - acc: 0.01 - ETA: 14s - loss: 4.8482 - acc: 0.02 - ETA: 14s - loss: 4.8484 - acc: 0.02 - ETA: 14s - loss: 4.8485 - acc: 0.01 - ETA: 14s - loss: 4.8486 - acc: 0.02 - ETA: 14s - loss: 4.8484 - acc: 0.02 - ETA: 13s - loss: 4.8487 - acc: 0.01 - ETA: 13s - loss: 4.8489 - acc: 0.01 - ETA: 13s - loss: 4.8485 - acc: 0.02 - ETA: 13s - loss: 4.8488 - acc: 0.01 - ETA: 13s - loss: 4.8488 - acc: 0.01 - ETA: 13s - loss: 4.8485 - acc: 0.02 - ETA: 13s - loss: 4.8486 - acc: 0.01 - ETA: 12s - loss: 4.8490 - acc: 0.01 - ETA: 12s - loss: 4.8489 - acc: 0.01 - ETA: 12s - loss: 4.8489 - acc: 0.01 - ETA: 12s - loss: 4.8487 - acc: 0.01 - ETA: 12s - loss: 4.8490 - acc: 0.01 - ETA: 12s - loss: 4.8491 - acc: 0.01 - ETA: 12s - loss: 4.8491 - acc: 0.01 - ETA: 11s - loss: 4.8490 - acc: 0.01 - ETA: 11s - loss: 4.8490 - acc: 0.01 - ETA: 11s - loss: 4.8492 - acc: 0.01 - ETA: 11s - loss: 4.8493 - acc: 0.01 - ETA: 11s - loss: 4.8492 - acc: 0.01 - ETA: 11s - loss: 4.8493 - acc: 0.01 - ETA: 11s - loss: 4.8491 - acc: 0.01 - ETA: 10s - loss: 4.8490 - acc: 0.01 - ETA: 10s - loss: 4.8491 - acc: 0.01 - ETA: 10s - loss: 4.8491 - acc: 0.01 - ETA: 10s - loss: 4.8495 - acc: 0.01 - ETA: 10s - loss: 4.8495 - acc: 0.01 - ETA: 10s - loss: 4.8495 - acc: 0.01 - ETA: 10s - loss: 4.8495 - acc: 0.01 - ETA: 9s - loss: 4.8494 - acc: 0.0196 - ETA: 9s - loss: 4.8495 - acc: 0.019 - ETA: 9s - loss: 4.8493 - acc: 0.019 - ETA: 9s - loss: 4.8495 - acc: 0.019 - ETA: 9s - loss: 4.8498 - acc: 0.019 - ETA: 9s - loss: 4.8498 - acc: 0.019 - ETA: 9s - loss: 4.8497 - acc: 0.019 - ETA: 8s - loss: 4.8496 - acc: 0.019 - ETA: 8s - loss: 4.8498 - acc: 0.019 - ETA: 8s - loss: 4.8500 - acc: 0.019 - ETA: 8s - loss: 4.8500 - acc: 0.019 - ETA: 8s - loss: 4.8500 - acc: 0.019 - ETA: 8s - loss: 4.8500 - acc: 0.018 - ETA: 7s - loss: 4.8499 - acc: 0.018 - ETA: 7s - loss: 4.8497 - acc: 0.018 - ETA: 7s - loss: 4.8498 - acc: 0.018 - ETA: 7s - loss: 4.8495 - acc: 0.018 - ETA: 7s - loss: 4.8493 - acc: 0.018 - ETA: 7s - loss: 4.8494 - acc: 0.018 - ETA: 7s - loss: 4.8495 - acc: 0.018 - ETA: 6s - loss: 4.8496 - acc: 0.018 - ETA: 6s - loss: 4.8496 - acc: 0.018 - ETA: 6s - loss: 4.8496 - acc: 0.018 - ETA: 6s - loss: 4.8496 - acc: 0.018 - ETA: 6s - loss: 4.8497 - acc: 0.018 - ETA: 6s - loss: 4.8497 - acc: 0.018 - ETA: 6s - loss: 4.8496 - acc: 0.018 - ETA: 5s - loss: 4.8497 - acc: 0.018 - ETA: 5s - loss: 4.8496 - acc: 0.018 - ETA: 5s - loss: 4.8496 - acc: 0.018 - ETA: 5s - loss: 4.8494 - acc: 0.018 - ETA: 5s - loss: 4.8494 - acc: 0.018 - ETA: 5s - loss: 4.8496 - acc: 0.018 - ETA: 5s - loss: 4.8497 - acc: 0.018 - ETA: 4s - loss: 4.8495 - acc: 0.018 - ETA: 4s - loss: 4.8497 - acc: 0.018 - ETA: 4s - loss: 4.8497 - acc: 0.018 - ETA: 4s - loss: 4.8498 - acc: 0.018 - ETA: 4s - loss: 4.8495 - acc: 0.018 - ETA: 4s - loss: 4.8497 - acc: 0.018 - ETA: 3s - loss: 4.8497 - acc: 0.018 - ETA: 3s - loss: 4.8501 - acc: 0.018 - ETA: 3s - loss: 4.8499 - acc: 0.018 - ETA: 3s - loss: 4.8499 - acc: 0.018 - ETA: 3s - loss: 4.8502 - acc: 0.018 - ETA: 3s - loss: 4.8502 - acc: 0.018 - ETA: 2s - loss: 4.8504 - acc: 0.018 - ETA: 2s - loss: 4.8506 - acc: 0.018 - ETA: 2s - loss: 4.8504 - acc: 0.018 - ETA: 2s - loss: 4.8500 - acc: 0.018 - ETA: 2s - loss: 4.8500 - acc: 0.018 - ETA: 2s - loss: 4.8501 - acc: 0.018 - ETA: 1s - loss: 4.8501 - acc: 0.018 - ETA: 1s - loss: 4.8499 - acc: 0.018 - ETA: 1s - loss: 4.8499 - acc: 0.018 - ETA: 1s - loss: 4.8498 - acc: 0.018 - ETA: 1s - loss: 4.8500 - acc: 0.017 - ETA: 1s - loss: 4.8500 - acc: 0.018 - ETA: 1s - loss: 4.8502 - acc: 0.018 - ETA: 0s - loss: 4.8502 - acc: 0.018 - ETA: 0s - loss: 4.8499 - acc: 0.018 - ETA: 0s - loss: 4.8498 - acc: 0.018 - ETA: 0s - loss: 4.8499 - acc: 0.018 - ETA: 0s - loss: 4.8500 - acc: 0.018 - ETA: 0s - loss: 4.8498 - acc: 0.018 - 68s 162ms/step - loss: 4.8498 - acc: 0.0181 - val_loss: 4.8298 - val_acc: 0.0403\n",
      "\n",
      "Epoch 00030: val_loss improved from 4.83817 to 4.82983, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 5s - loss: 4.8366 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8062 - acc: 0.0500    - ETA: 6s - loss: 4.8078 - acc: 0.041 - ETA: 10s - loss: 4.8344 - acc: 0.02 - ETA: 13s - loss: 4.8408 - acc: 0.02 - ETA: 15s - loss: 4.8420 - acc: 0.02 - ETA: 17s - loss: 4.8451 - acc: 0.02 - ETA: 19s - loss: 4.8459 - acc: 0.02 - ETA: 21s - loss: 4.8460 - acc: 0.02 - ETA: 23s - loss: 4.8468 - acc: 0.02 - ETA: 24s - loss: 4.8474 - acc: 0.02 - ETA: 25s - loss: 4.8503 - acc: 0.02 - ETA: 25s - loss: 4.8477 - acc: 0.01 - ETA: 27s - loss: 4.8443 - acc: 0.02 - ETA: 27s - loss: 4.8461 - acc: 0.02 - ETA: 28s - loss: 4.8481 - acc: 0.02 - ETA: 29s - loss: 4.8444 - acc: 0.02 - ETA: 30s - loss: 4.8422 - acc: 0.02 - ETA: 30s - loss: 4.8450 - acc: 0.02 - ETA: 33s - loss: 4.8475 - acc: 0.01 - ETA: 33s - loss: 4.8486 - acc: 0.02 - ETA: 33s - loss: 4.8493 - acc: 0.02 - ETA: 34s - loss: 4.8518 - acc: 0.01 - ETA: 34s - loss: 4.8520 - acc: 0.01 - ETA: 34s - loss: 4.8526 - acc: 0.01 - ETA: 35s - loss: 4.8517 - acc: 0.01 - ETA: 35s - loss: 4.8516 - acc: 0.01 - ETA: 36s - loss: 4.8517 - acc: 0.01 - ETA: 37s - loss: 4.8524 - acc: 0.01 - ETA: 37s - loss: 4.8513 - acc: 0.01 - ETA: 38s - loss: 4.8539 - acc: 0.01 - ETA: 38s - loss: 4.8536 - acc: 0.01 - ETA: 38s - loss: 4.8544 - acc: 0.01 - ETA: 39s - loss: 4.8541 - acc: 0.01 - ETA: 39s - loss: 4.8532 - acc: 0.01 - ETA: 40s - loss: 4.8508 - acc: 0.01 - ETA: 41s - loss: 4.8520 - acc: 0.01 - ETA: 41s - loss: 4.8500 - acc: 0.01 - ETA: 42s - loss: 4.8511 - acc: 0.01 - ETA: 42s - loss: 4.8505 - acc: 0.01 - ETA: 42s - loss: 4.8524 - acc: 0.01 - ETA: 42s - loss: 4.8518 - acc: 0.01 - ETA: 42s - loss: 4.8531 - acc: 0.01 - ETA: 42s - loss: 4.8514 - acc: 0.01 - ETA: 42s - loss: 4.8494 - acc: 0.01 - ETA: 42s - loss: 4.8493 - acc: 0.01 - ETA: 42s - loss: 4.8487 - acc: 0.01 - ETA: 42s - loss: 4.8480 - acc: 0.01 - ETA: 42s - loss: 4.8480 - acc: 0.01 - ETA: 43s - loss: 4.8487 - acc: 0.01 - ETA: 43s - loss: 4.8484 - acc: 0.01 - ETA: 43s - loss: 4.8487 - acc: 0.01 - ETA: 43s - loss: 4.8486 - acc: 0.01 - ETA: 43s - loss: 4.8486 - acc: 0.01 - ETA: 44s - loss: 4.8498 - acc: 0.01 - ETA: 44s - loss: 4.8493 - acc: 0.01 - ETA: 44s - loss: 4.8495 - acc: 0.01 - ETA: 44s - loss: 4.8500 - acc: 0.01 - ETA: 44s - loss: 4.8506 - acc: 0.01 - ETA: 44s - loss: 4.8506 - acc: 0.01 - ETA: 44s - loss: 4.8511 - acc: 0.01 - ETA: 44s - loss: 4.8505 - acc: 0.01 - ETA: 44s - loss: 4.8502 - acc: 0.01 - ETA: 44s - loss: 4.8499 - acc: 0.01 - ETA: 44s - loss: 4.8489 - acc: 0.01 - ETA: 44s - loss: 4.8496 - acc: 0.01 - ETA: 44s - loss: 4.8496 - acc: 0.01 - ETA: 44s - loss: 4.8486 - acc: 0.01 - ETA: 44s - loss: 4.8473 - acc: 0.01 - ETA: 44s - loss: 4.8466 - acc: 0.01 - ETA: 44s - loss: 4.8475 - acc: 0.01 - ETA: 44s - loss: 4.8475 - acc: 0.01 - ETA: 44s - loss: 4.8487 - acc: 0.01 - ETA: 44s - loss: 4.8488 - acc: 0.01 - ETA: 44s - loss: 4.8484 - acc: 0.01 - ETA: 44s - loss: 4.8487 - acc: 0.01 - ETA: 44s - loss: 4.8490 - acc: 0.01 - ETA: 44s - loss: 4.8495 - acc: 0.01 - ETA: 44s - loss: 4.8489 - acc: 0.01 - ETA: 44s - loss: 4.8483 - acc: 0.01 - ETA: 45s - loss: 4.8489 - acc: 0.01 - ETA: 45s - loss: 4.8494 - acc: 0.01 - ETA: 45s - loss: 4.8492 - acc: 0.01 - ETA: 44s - loss: 4.8489 - acc: 0.01 - ETA: 45s - loss: 4.8497 - acc: 0.01 - ETA: 45s - loss: 4.8496 - acc: 0.01 - ETA: 45s - loss: 4.8499 - acc: 0.01 - ETA: 45s - loss: 4.8503 - acc: 0.01 - ETA: 45s - loss: 4.8497 - acc: 0.01 - ETA: 44s - loss: 4.8506 - acc: 0.01 - ETA: 44s - loss: 4.8526 - acc: 0.01 - ETA: 44s - loss: 4.8529 - acc: 0.01 - ETA: 44s - loss: 4.8525 - acc: 0.01 - ETA: 44s - loss: 4.8524 - acc: 0.01 - ETA: 44s - loss: 4.8526 - acc: 0.01 - ETA: 44s - loss: 4.8515 - acc: 0.01 - ETA: 44s - loss: 4.8522 - acc: 0.01 - ETA: 43s - loss: 4.8521 - acc: 0.01 - ETA: 43s - loss: 4.8516 - acc: 0.01 - ETA: 43s - loss: 4.8523 - acc: 0.01 - ETA: 43s - loss: 4.8525 - acc: 0.01 - ETA: 43s - loss: 4.8529 - acc: 0.01 - ETA: 43s - loss: 4.8530 - acc: 0.01 - ETA: 43s - loss: 4.8522 - acc: 0.01 - ETA: 43s - loss: 4.8515 - acc: 0.01 - ETA: 42s - loss: 4.8515 - acc: 0.01 - ETA: 42s - loss: 4.8525 - acc: 0.01 - ETA: 42s - loss: 4.8519 - acc: 0.01 - ETA: 42s - loss: 4.8521 - acc: 0.01 - ETA: 42s - loss: 4.8520 - acc: 0.01 - ETA: 42s - loss: 4.8519 - acc: 0.01 - ETA: 42s - loss: 4.8511 - acc: 0.01 - ETA: 42s - loss: 4.8517 - acc: 0.01 - ETA: 42s - loss: 4.8520 - acc: 0.01 - ETA: 42s - loss: 4.8534 - acc: 0.01 - ETA: 42s - loss: 4.8532 - acc: 0.01 - ETA: 42s - loss: 4.8535 - acc: 0.01 - ETA: 42s - loss: 4.8530 - acc: 0.01 - ETA: 42s - loss: 4.8526 - acc: 0.01 - ETA: 42s - loss: 4.8524 - acc: 0.01 - ETA: 42s - loss: 4.8525 - acc: 0.01 - ETA: 42s - loss: 4.8524 - acc: 0.01 - ETA: 42s - loss: 4.8523 - acc: 0.01 - ETA: 42s - loss: 4.8524 - acc: 0.01 - ETA: 42s - loss: 4.8516 - acc: 0.01 - ETA: 42s - loss: 4.8519 - acc: 0.01 - ETA: 41s - loss: 4.8518 - acc: 0.01 - ETA: 42s - loss: 4.8521 - acc: 0.01 - ETA: 41s - loss: 4.8522 - acc: 0.01 - ETA: 41s - loss: 4.8517 - acc: 0.01 - ETA: 41s - loss: 4.8525 - acc: 0.01 - ETA: 41s - loss: 4.8524 - acc: 0.01 - ETA: 41s - loss: 4.8523 - acc: 0.01 - ETA: 41s - loss: 4.8523 - acc: 0.01 - ETA: 41s - loss: 4.8517 - acc: 0.01 - ETA: 40s - loss: 4.8514 - acc: 0.01 - ETA: 41s - loss: 4.8516 - acc: 0.01 - ETA: 40s - loss: 4.8519 - acc: 0.01 - ETA: 40s - loss: 4.8516 - acc: 0.01 - ETA: 40s - loss: 4.8517 - acc: 0.01 - ETA: 40s - loss: 4.8516 - acc: 0.01 - ETA: 40s - loss: 4.8509 - acc: 0.01 - ETA: 40s - loss: 4.8516 - acc: 0.01 - ETA: 40s - loss: 4.8518 - acc: 0.01 - ETA: 40s - loss: 4.8518 - acc: 0.01 - ETA: 39s - loss: 4.8522 - acc: 0.01 - ETA: 39s - loss: 4.8526 - acc: 0.01 - ETA: 39s - loss: 4.8517 - acc: 0.01 - ETA: 39s - loss: 4.8516 - acc: 0.01 - ETA: 39s - loss: 4.8515 - acc: 0.01 - ETA: 39s - loss: 4.8525 - acc: 0.01 - ETA: 39s - loss: 4.8524 - acc: 0.01 - ETA: 38s - loss: 4.8528 - acc: 0.01 - ETA: 38s - loss: 4.8524 - acc: 0.01 - ETA: 38s - loss: 4.8522 - acc: 0.01 - ETA: 38s - loss: 4.8517 - acc: 0.01 - ETA: 38s - loss: 4.8518 - acc: 0.01 - ETA: 38s - loss: 4.8521 - acc: 0.01 - ETA: 38s - loss: 4.8521 - acc: 0.01 - ETA: 37s - loss: 4.8518 - acc: 0.01 - ETA: 37s - loss: 4.8521 - acc: 0.01 - ETA: 37s - loss: 4.8516 - acc: 0.01 - ETA: 37s - loss: 4.8512 - acc: 0.01 - ETA: 37s - loss: 4.8518 - acc: 0.01 - ETA: 37s - loss: 4.8525 - acc: 0.01 - ETA: 37s - loss: 4.8530 - acc: 0.01 - ETA: 37s - loss: 4.8525 - acc: 0.01 - ETA: 36s - loss: 4.8530 - acc: 0.01 - ETA: 36s - loss: 4.8525 - acc: 0.01 - ETA: 36s - loss: 4.8525 - acc: 0.01 - ETA: 36s - loss: 4.8524 - acc: 0.01 - ETA: 36s - loss: 4.8522 - acc: 0.01 - ETA: 36s - loss: 4.8521 - acc: 0.01 - ETA: 36s - loss: 4.8519 - acc: 0.01 - ETA: 36s - loss: 4.8520 - acc: 0.01 - ETA: 35s - loss: 4.8523 - acc: 0.01 - ETA: 35s - loss: 4.8523 - acc: 0.01 - ETA: 35s - loss: 4.8523 - acc: 0.01 - ETA: 35s - loss: 4.8522 - acc: 0.01 - ETA: 35s - loss: 4.8520 - acc: 0.01 - ETA: 35s - loss: 4.8520 - acc: 0.01 - ETA: 35s - loss: 4.8520 - acc: 0.01 - ETA: 34s - loss: 4.8518 - acc: 0.01 - ETA: 34s - loss: 4.8516 - acc: 0.01 - ETA: 34s - loss: 4.8519 - acc: 0.01 - ETA: 34s - loss: 4.8514 - acc: 0.01 - ETA: 34s - loss: 4.8517 - acc: 0.01 - ETA: 34s - loss: 4.8515 - acc: 0.01 - ETA: 34s - loss: 4.8513 - acc: 0.01 - ETA: 33s - loss: 4.8518 - acc: 0.01 - ETA: 33s - loss: 4.8523 - acc: 0.01 - ETA: 33s - loss: 4.8523 - acc: 0.01 - ETA: 33s - loss: 4.8522 - acc: 0.01 - ETA: 33s - loss: 4.8523 - acc: 0.01 - ETA: 33s - loss: 4.8520 - acc: 0.01 - ETA: 32s - loss: 4.8523 - acc: 0.01 - ETA: 32s - loss: 4.8526 - acc: 0.01 - ETA: 32s - loss: 4.8523 - acc: 0.01 - ETA: 32s - loss: 4.8526 - acc: 0.01 - ETA: 32s - loss: 4.8521 - acc: 0.01 - ETA: 32s - loss: 4.8521 - acc: 0.01 - ETA: 32s - loss: 4.8515 - acc: 0.01 - ETA: 31s - loss: 4.8520 - acc: 0.01 - ETA: 31s - loss: 4.8522 - acc: 0.01 - ETA: 31s - loss: 4.8520 - acc: 0.01 - ETA: 31s - loss: 4.8519 - acc: 0.01 - ETA: 31s - loss: 4.8519 - acc: 0.01 - ETA: 31s - loss: 4.8521 - acc: 0.01 - ETA: 31s - loss: 4.8522 - acc: 0.01 - ETA: 30s - loss: 4.8524 - acc: 0.01 - ETA: 30s - loss: 4.8525 - acc: 0.01 - ETA: 30s - loss: 4.8524 - acc: 0.01 - ETA: 30s - loss: 4.8523 - acc: 0.01 - ETA: 30s - loss: 4.8525 - acc: 0.01 - ETA: 30s - loss: 4.8528 - acc: 0.0106"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 29s - loss: 4.8535 - acc: 0.01 - ETA: 29s - loss: 4.8532 - acc: 0.01 - ETA: 29s - loss: 4.8531 - acc: 0.01 - ETA: 29s - loss: 4.8529 - acc: 0.01 - ETA: 29s - loss: 4.8532 - acc: 0.01 - ETA: 29s - loss: 4.8528 - acc: 0.01 - ETA: 28s - loss: 4.8522 - acc: 0.01 - ETA: 28s - loss: 4.8522 - acc: 0.01 - ETA: 28s - loss: 4.8523 - acc: 0.01 - ETA: 28s - loss: 4.8521 - acc: 0.01 - ETA: 28s - loss: 4.8516 - acc: 0.01 - ETA: 28s - loss: 4.8517 - acc: 0.01 - ETA: 27s - loss: 4.8516 - acc: 0.01 - ETA: 27s - loss: 4.8520 - acc: 0.01 - ETA: 27s - loss: 4.8521 - acc: 0.01 - ETA: 27s - loss: 4.8519 - acc: 0.01 - ETA: 27s - loss: 4.8518 - acc: 0.01 - ETA: 27s - loss: 4.8518 - acc: 0.01 - ETA: 27s - loss: 4.8520 - acc: 0.01 - ETA: 26s - loss: 4.8516 - acc: 0.01 - ETA: 26s - loss: 4.8515 - acc: 0.01 - ETA: 26s - loss: 4.8516 - acc: 0.01 - ETA: 26s - loss: 4.8514 - acc: 0.01 - ETA: 26s - loss: 4.8514 - acc: 0.01 - ETA: 26s - loss: 4.8511 - acc: 0.01 - ETA: 26s - loss: 4.8511 - acc: 0.01 - ETA: 25s - loss: 4.8509 - acc: 0.01 - ETA: 25s - loss: 4.8510 - acc: 0.01 - ETA: 25s - loss: 4.8509 - acc: 0.01 - ETA: 25s - loss: 4.8507 - acc: 0.01 - ETA: 25s - loss: 4.8508 - acc: 0.01 - ETA: 25s - loss: 4.8503 - acc: 0.01 - ETA: 24s - loss: 4.8503 - acc: 0.01 - ETA: 24s - loss: 4.8505 - acc: 0.01 - ETA: 24s - loss: 4.8507 - acc: 0.01 - ETA: 24s - loss: 4.8509 - acc: 0.01 - ETA: 24s - loss: 4.8505 - acc: 0.01 - ETA: 24s - loss: 4.8506 - acc: 0.01 - ETA: 24s - loss: 4.8504 - acc: 0.01 - ETA: 23s - loss: 4.8499 - acc: 0.01 - ETA: 23s - loss: 4.8497 - acc: 0.01 - ETA: 23s - loss: 4.8496 - acc: 0.01 - ETA: 23s - loss: 4.8502 - acc: 0.01 - ETA: 23s - loss: 4.8505 - acc: 0.01 - ETA: 23s - loss: 4.8504 - acc: 0.01 - ETA: 22s - loss: 4.8504 - acc: 0.01 - ETA: 22s - loss: 4.8505 - acc: 0.01 - ETA: 22s - loss: 4.8512 - acc: 0.01 - ETA: 22s - loss: 4.8512 - acc: 0.01 - ETA: 22s - loss: 4.8509 - acc: 0.01 - ETA: 22s - loss: 4.8510 - acc: 0.01 - ETA: 21s - loss: 4.8508 - acc: 0.01 - ETA: 21s - loss: 4.8513 - acc: 0.01 - ETA: 21s - loss: 4.8510 - acc: 0.01 - ETA: 21s - loss: 4.8510 - acc: 0.01 - ETA: 21s - loss: 4.8512 - acc: 0.01 - ETA: 21s - loss: 4.8510 - acc: 0.01 - ETA: 21s - loss: 4.8508 - acc: 0.01 - ETA: 20s - loss: 4.8511 - acc: 0.01 - ETA: 20s - loss: 4.8512 - acc: 0.01 - ETA: 20s - loss: 4.8510 - acc: 0.01 - ETA: 20s - loss: 4.8509 - acc: 0.01 - ETA: 20s - loss: 4.8510 - acc: 0.01 - ETA: 20s - loss: 4.8509 - acc: 0.01 - ETA: 19s - loss: 4.8509 - acc: 0.01 - ETA: 19s - loss: 4.8510 - acc: 0.01 - ETA: 19s - loss: 4.8509 - acc: 0.01 - ETA: 19s - loss: 4.8507 - acc: 0.01 - ETA: 19s - loss: 4.8509 - acc: 0.01 - ETA: 19s - loss: 4.8509 - acc: 0.01 - ETA: 18s - loss: 4.8506 - acc: 0.01 - ETA: 18s - loss: 4.8505 - acc: 0.01 - ETA: 18s - loss: 4.8505 - acc: 0.01 - ETA: 18s - loss: 4.8503 - acc: 0.01 - ETA: 18s - loss: 4.8504 - acc: 0.01 - ETA: 18s - loss: 4.8504 - acc: 0.01 - ETA: 18s - loss: 4.8502 - acc: 0.01 - ETA: 17s - loss: 4.8504 - acc: 0.01 - ETA: 17s - loss: 4.8506 - acc: 0.01 - ETA: 17s - loss: 4.8503 - acc: 0.01 - ETA: 17s - loss: 4.8498 - acc: 0.01 - ETA: 17s - loss: 4.8499 - acc: 0.01 - ETA: 17s - loss: 4.8499 - acc: 0.01 - ETA: 17s - loss: 4.8500 - acc: 0.01 - ETA: 16s - loss: 4.8497 - acc: 0.01 - ETA: 16s - loss: 4.8499 - acc: 0.01 - ETA: 16s - loss: 4.8498 - acc: 0.01 - ETA: 16s - loss: 4.8496 - acc: 0.01 - ETA: 16s - loss: 4.8491 - acc: 0.01 - ETA: 16s - loss: 4.8490 - acc: 0.01 - ETA: 15s - loss: 4.8488 - acc: 0.01 - ETA: 15s - loss: 4.8488 - acc: 0.01 - ETA: 15s - loss: 4.8488 - acc: 0.01 - ETA: 15s - loss: 4.8488 - acc: 0.01 - ETA: 15s - loss: 4.8488 - acc: 0.01 - ETA: 15s - loss: 4.8489 - acc: 0.01 - ETA: 14s - loss: 4.8490 - acc: 0.01 - ETA: 14s - loss: 4.8492 - acc: 0.01 - ETA: 14s - loss: 4.8492 - acc: 0.01 - ETA: 14s - loss: 4.8493 - acc: 0.01 - ETA: 14s - loss: 4.8492 - acc: 0.01 - ETA: 14s - loss: 4.8493 - acc: 0.01 - ETA: 13s - loss: 4.8493 - acc: 0.01 - ETA: 13s - loss: 4.8496 - acc: 0.01 - ETA: 13s - loss: 4.8497 - acc: 0.01 - ETA: 13s - loss: 4.8497 - acc: 0.01 - ETA: 13s - loss: 4.8497 - acc: 0.01 - ETA: 13s - loss: 4.8495 - acc: 0.01 - ETA: 13s - loss: 4.8495 - acc: 0.01 - ETA: 12s - loss: 4.8494 - acc: 0.01 - ETA: 12s - loss: 4.8494 - acc: 0.01 - ETA: 12s - loss: 4.8491 - acc: 0.01 - ETA: 12s - loss: 4.8492 - acc: 0.01 - ETA: 12s - loss: 4.8493 - acc: 0.01 - ETA: 12s - loss: 4.8493 - acc: 0.01 - ETA: 11s - loss: 4.8484 - acc: 0.01 - ETA: 11s - loss: 4.8489 - acc: 0.01 - ETA: 11s - loss: 4.8489 - acc: 0.01 - ETA: 11s - loss: 4.8486 - acc: 0.01 - ETA: 11s - loss: 4.8486 - acc: 0.01 - ETA: 10s - loss: 4.8485 - acc: 0.01 - ETA: 10s - loss: 4.8484 - acc: 0.01 - ETA: 10s - loss: 4.8487 - acc: 0.01 - ETA: 10s - loss: 4.8487 - acc: 0.01 - ETA: 10s - loss: 4.8486 - acc: 0.01 - ETA: 10s - loss: 4.8489 - acc: 0.01 - ETA: 9s - loss: 4.8488 - acc: 0.0122 - ETA: 9s - loss: 4.8488 - acc: 0.012 - ETA: 9s - loss: 4.8488 - acc: 0.012 - ETA: 9s - loss: 4.8490 - acc: 0.012 - ETA: 9s - loss: 4.8489 - acc: 0.012 - ETA: 9s - loss: 4.8491 - acc: 0.012 - ETA: 9s - loss: 4.8490 - acc: 0.012 - ETA: 8s - loss: 4.8491 - acc: 0.012 - ETA: 8s - loss: 4.8490 - acc: 0.012 - ETA: 8s - loss: 4.8491 - acc: 0.012 - ETA: 8s - loss: 4.8492 - acc: 0.012 - ETA: 8s - loss: 4.8496 - acc: 0.012 - ETA: 8s - loss: 4.8496 - acc: 0.012 - ETA: 7s - loss: 4.8496 - acc: 0.012 - ETA: 7s - loss: 4.8498 - acc: 0.012 - ETA: 7s - loss: 4.8499 - acc: 0.012 - ETA: 7s - loss: 4.8501 - acc: 0.012 - ETA: 7s - loss: 4.8498 - acc: 0.012 - ETA: 7s - loss: 4.8498 - acc: 0.012 - ETA: 6s - loss: 4.8499 - acc: 0.012 - ETA: 6s - loss: 4.8498 - acc: 0.012 - ETA: 6s - loss: 4.8497 - acc: 0.012 - ETA: 6s - loss: 4.8497 - acc: 0.012 - ETA: 6s - loss: 4.8498 - acc: 0.012 - ETA: 6s - loss: 4.8498 - acc: 0.012 - ETA: 6s - loss: 4.8497 - acc: 0.012 - ETA: 5s - loss: 4.8497 - acc: 0.012 - ETA: 5s - loss: 4.8498 - acc: 0.013 - ETA: 5s - loss: 4.8500 - acc: 0.013 - ETA: 5s - loss: 4.8499 - acc: 0.012 - ETA: 5s - loss: 4.8497 - acc: 0.013 - ETA: 5s - loss: 4.8500 - acc: 0.013 - ETA: 4s - loss: 4.8501 - acc: 0.013 - ETA: 4s - loss: 4.8503 - acc: 0.013 - ETA: 4s - loss: 4.8501 - acc: 0.012 - ETA: 4s - loss: 4.8502 - acc: 0.012 - ETA: 4s - loss: 4.8502 - acc: 0.012 - ETA: 4s - loss: 4.8502 - acc: 0.012 - ETA: 4s - loss: 4.8503 - acc: 0.012 - ETA: 3s - loss: 4.8502 - acc: 0.012 - ETA: 3s - loss: 4.8503 - acc: 0.012 - ETA: 3s - loss: 4.8504 - acc: 0.012 - ETA: 3s - loss: 4.8507 - acc: 0.012 - ETA: 3s - loss: 4.8505 - acc: 0.012 - ETA: 3s - loss: 4.8505 - acc: 0.012 - ETA: 2s - loss: 4.8504 - acc: 0.012 - ETA: 2s - loss: 4.8505 - acc: 0.012 - ETA: 2s - loss: 4.8504 - acc: 0.012 - ETA: 2s - loss: 4.8505 - acc: 0.012 - ETA: 2s - loss: 4.8505 - acc: 0.012 - ETA: 2s - loss: 4.8505 - acc: 0.012 - ETA: 2s - loss: 4.8505 - acc: 0.012 - ETA: 1s - loss: 4.8507 - acc: 0.012 - ETA: 1s - loss: 4.8506 - acc: 0.012 - ETA: 1s - loss: 4.8506 - acc: 0.012 - ETA: 1s - loss: 4.8504 - acc: 0.012 - ETA: 1s - loss: 4.8504 - acc: 0.012 - ETA: 1s - loss: 4.8506 - acc: 0.012 - ETA: 0s - loss: 4.8503 - acc: 0.012 - ETA: 0s - loss: 4.8502 - acc: 0.012 - ETA: 0s - loss: 4.8501 - acc: 0.013 - ETA: 0s - loss: 4.8501 - acc: 0.013 - ETA: 0s - loss: 4.8502 - acc: 0.013 - ETA: 0s - loss: 4.8501 - acc: 0.013 - 68s 163ms/step - loss: 4.8503 - acc: 0.0132 - val_loss: 4.8417 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 4.82983\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 5s - loss: 4.8772 - acc: 0.0000e+0 - ETA: 5s - loss: 4.8340 - acc: 0.0000e+0 - ETA: 5s - loss: 4.8395 - acc: 0.0069    - ETA: 10s - loss: 4.8405 - acc: 0.00 - ETA: 14s - loss: 4.8387 - acc: 0.01 - ETA: 18s - loss: 4.8384 - acc: 0.01 - ETA: 20s - loss: 4.8452 - acc: 0.01 - ETA: 23s - loss: 4.8492 - acc: 0.01 - ETA: 24s - loss: 4.8523 - acc: 0.01 - ETA: 25s - loss: 4.8473 - acc: 0.01 - ETA: 26s - loss: 4.8541 - acc: 0.01 - ETA: 28s - loss: 4.8577 - acc: 0.01 - ETA: 29s - loss: 4.8577 - acc: 0.01 - ETA: 30s - loss: 4.8602 - acc: 0.01 - ETA: 31s - loss: 4.8579 - acc: 0.01 - ETA: 32s - loss: 4.8599 - acc: 0.01 - ETA: 32s - loss: 4.8584 - acc: 0.00 - ETA: 33s - loss: 4.8582 - acc: 0.00 - ETA: 33s - loss: 4.8601 - acc: 0.01 - ETA: 34s - loss: 4.8644 - acc: 0.01 - ETA: 35s - loss: 4.8639 - acc: 0.01 - ETA: 36s - loss: 4.8623 - acc: 0.01 - ETA: 36s - loss: 4.8599 - acc: 0.01 - ETA: 37s - loss: 4.8597 - acc: 0.01 - ETA: 37s - loss: 4.8571 - acc: 0.01 - ETA: 37s - loss: 4.8582 - acc: 0.01 - ETA: 37s - loss: 4.8609 - acc: 0.01 - ETA: 38s - loss: 4.8595 - acc: 0.01 - ETA: 38s - loss: 4.8594 - acc: 0.01 - ETA: 38s - loss: 4.8590 - acc: 0.01 - ETA: 38s - loss: 4.8582 - acc: 0.01 - ETA: 39s - loss: 4.8564 - acc: 0.01 - ETA: 40s - loss: 4.8545 - acc: 0.01 - ETA: 40s - loss: 4.8531 - acc: 0.01 - ETA: 40s - loss: 4.8538 - acc: 0.01 - ETA: 40s - loss: 4.8529 - acc: 0.01 - ETA: 41s - loss: 4.8519 - acc: 0.01 - ETA: 41s - loss: 4.8503 - acc: 0.01 - ETA: 41s - loss: 4.8488 - acc: 0.01 - ETA: 41s - loss: 4.8501 - acc: 0.01 - ETA: 40s - loss: 4.8481 - acc: 0.01 - ETA: 41s - loss: 4.8469 - acc: 0.01 - ETA: 41s - loss: 4.8480 - acc: 0.01 - ETA: 41s - loss: 4.8480 - acc: 0.01 - ETA: 41s - loss: 4.8471 - acc: 0.01 - ETA: 41s - loss: 4.8468 - acc: 0.01 - ETA: 41s - loss: 4.8461 - acc: 0.01 - ETA: 41s - loss: 4.8453 - acc: 0.01 - ETA: 41s - loss: 4.8418 - acc: 0.01 - ETA: 41s - loss: 4.8414 - acc: 0.01 - ETA: 41s - loss: 4.8382 - acc: 0.01 - ETA: 41s - loss: 4.8405 - acc: 0.01 - ETA: 41s - loss: 4.8403 - acc: 0.01 - ETA: 41s - loss: 4.8391 - acc: 0.01 - ETA: 41s - loss: 4.8391 - acc: 0.01 - ETA: 41s - loss: 4.8398 - acc: 0.01 - ETA: 41s - loss: 4.8389 - acc: 0.01 - ETA: 41s - loss: 4.8387 - acc: 0.01 - ETA: 41s - loss: 4.8387 - acc: 0.01 - ETA: 41s - loss: 4.8383 - acc: 0.01 - ETA: 41s - loss: 4.8375 - acc: 0.01 - ETA: 41s - loss: 4.8396 - acc: 0.01 - ETA: 41s - loss: 4.8389 - acc: 0.01 - ETA: 41s - loss: 4.8397 - acc: 0.01 - ETA: 41s - loss: 4.8406 - acc: 0.02 - ETA: 41s - loss: 4.8392 - acc: 0.02 - ETA: 41s - loss: 4.8388 - acc: 0.01 - ETA: 41s - loss: 4.8398 - acc: 0.01 - ETA: 41s - loss: 4.8390 - acc: 0.02 - ETA: 42s - loss: 4.8390 - acc: 0.02 - ETA: 42s - loss: 4.8377 - acc: 0.02 - ETA: 42s - loss: 4.8377 - acc: 0.02 - ETA: 42s - loss: 4.8379 - acc: 0.01 - ETA: 42s - loss: 4.8381 - acc: 0.02 - ETA: 42s - loss: 4.8383 - acc: 0.02 - ETA: 42s - loss: 4.8378 - acc: 0.01 - ETA: 42s - loss: 4.8369 - acc: 0.01 - ETA: 42s - loss: 4.8375 - acc: 0.01 - ETA: 42s - loss: 4.8380 - acc: 0.01 - ETA: 42s - loss: 4.8378 - acc: 0.01 - ETA: 42s - loss: 4.8379 - acc: 0.01 - ETA: 42s - loss: 4.8376 - acc: 0.01 - ETA: 42s - loss: 4.8380 - acc: 0.01 - ETA: 42s - loss: 4.8374 - acc: 0.02 - ETA: 42s - loss: 4.8371 - acc: 0.01 - ETA: 41s - loss: 4.8380 - acc: 0.01 - ETA: 41s - loss: 4.8384 - acc: 0.01 - ETA: 41s - loss: 4.8385 - acc: 0.01 - ETA: 41s - loss: 4.8378 - acc: 0.01 - ETA: 41s - loss: 4.8382 - acc: 0.01 - ETA: 41s - loss: 4.8382 - acc: 0.01 - ETA: 41s - loss: 4.8389 - acc: 0.01 - ETA: 41s - loss: 4.8396 - acc: 0.01 - ETA: 40s - loss: 4.8402 - acc: 0.01 - ETA: 41s - loss: 4.8404 - acc: 0.01 - ETA: 41s - loss: 4.8401 - acc: 0.01 - ETA: 41s - loss: 4.8402 - acc: 0.01 - ETA: 41s - loss: 4.8402 - acc: 0.01 - ETA: 41s - loss: 4.8395 - acc: 0.01 - ETA: 41s - loss: 4.8401 - acc: 0.01 - ETA: 41s - loss: 4.8421 - acc: 0.01 - ETA: 41s - loss: 4.8427 - acc: 0.01 - ETA: 41s - loss: 4.8437 - acc: 0.01 - ETA: 40s - loss: 4.8440 - acc: 0.01 - ETA: 40s - loss: 4.8432 - acc: 0.01 - ETA: 40s - loss: 4.8440 - acc: 0.01 - ETA: 40s - loss: 4.8435 - acc: 0.01 - ETA: 40s - loss: 4.8437 - acc: 0.01 - ETA: 40s - loss: 4.8436 - acc: 0.01 - ETA: 40s - loss: 4.8437 - acc: 0.01 - ETA: 40s - loss: 4.8433 - acc: 0.01 - ETA: 39s - loss: 4.8447 - acc: 0.01 - ETA: 39s - loss: 4.8437 - acc: 0.01 - ETA: 39s - loss: 4.8440 - acc: 0.01 - ETA: 39s - loss: 4.8428 - acc: 0.01 - ETA: 39s - loss: 4.8433 - acc: 0.01 - ETA: 39s - loss: 4.8438 - acc: 0.01 - ETA: 39s - loss: 4.8441 - acc: 0.01 - ETA: 39s - loss: 4.8443 - acc: 0.01 - ETA: 38s - loss: 4.8439 - acc: 0.01 - ETA: 38s - loss: 4.8434 - acc: 0.01 - ETA: 38s - loss: 4.8439 - acc: 0.01 - ETA: 38s - loss: 4.8428 - acc: 0.01 - ETA: 38s - loss: 4.8425 - acc: 0.01 - ETA: 38s - loss: 4.8431 - acc: 0.01 - ETA: 38s - loss: 4.8429 - acc: 0.01 - ETA: 38s - loss: 4.8427 - acc: 0.01 - ETA: 37s - loss: 4.8426 - acc: 0.01 - ETA: 37s - loss: 4.8423 - acc: 0.01 - ETA: 37s - loss: 4.8425 - acc: 0.01 - ETA: 37s - loss: 4.8429 - acc: 0.01 - ETA: 37s - loss: 4.8432 - acc: 0.01 - ETA: 37s - loss: 4.8430 - acc: 0.01 - ETA: 37s - loss: 4.8425 - acc: 0.01 - ETA: 36s - loss: 4.8433 - acc: 0.01 - ETA: 36s - loss: 4.8441 - acc: 0.01 - ETA: 36s - loss: 4.8444 - acc: 0.01 - ETA: 36s - loss: 4.8440 - acc: 0.01 - ETA: 36s - loss: 4.8436 - acc: 0.01 - ETA: 36s - loss: 4.8440 - acc: 0.01 - ETA: 36s - loss: 4.8443 - acc: 0.01 - ETA: 36s - loss: 4.8442 - acc: 0.01 - ETA: 36s - loss: 4.8438 - acc: 0.01 - ETA: 35s - loss: 4.8433 - acc: 0.01 - ETA: 35s - loss: 4.8427 - acc: 0.01 - ETA: 35s - loss: 4.8419 - acc: 0.01 - ETA: 35s - loss: 4.8421 - acc: 0.01 - ETA: 35s - loss: 4.8422 - acc: 0.01 - ETA: 35s - loss: 4.8421 - acc: 0.01 - ETA: 35s - loss: 4.8428 - acc: 0.01 - ETA: 34s - loss: 4.8423 - acc: 0.01 - ETA: 34s - loss: 4.8425 - acc: 0.01 - ETA: 34s - loss: 4.8433 - acc: 0.01 - ETA: 34s - loss: 4.8433 - acc: 0.01 - ETA: 34s - loss: 4.8434 - acc: 0.01 - ETA: 34s - loss: 4.8433 - acc: 0.01 - ETA: 34s - loss: 4.8432 - acc: 0.01 - ETA: 34s - loss: 4.8432 - acc: 0.01 - ETA: 33s - loss: 4.8433 - acc: 0.01 - ETA: 33s - loss: 4.8440 - acc: 0.01 - ETA: 33s - loss: 4.8445 - acc: 0.01 - ETA: 33s - loss: 4.8443 - acc: 0.01 - ETA: 33s - loss: 4.8450 - acc: 0.01 - ETA: 33s - loss: 4.8456 - acc: 0.01 - ETA: 33s - loss: 4.8456 - acc: 0.01 - ETA: 33s - loss: 4.8453 - acc: 0.01 - ETA: 33s - loss: 4.8456 - acc: 0.01 - ETA: 33s - loss: 4.8450 - acc: 0.01 - ETA: 33s - loss: 4.8451 - acc: 0.01 - ETA: 32s - loss: 4.8450 - acc: 0.01 - ETA: 32s - loss: 4.8452 - acc: 0.01 - ETA: 32s - loss: 4.8448 - acc: 0.01 - ETA: 32s - loss: 4.8449 - acc: 0.01 - ETA: 32s - loss: 4.8448 - acc: 0.01 - ETA: 32s - loss: 4.8443 - acc: 0.01 - ETA: 32s - loss: 4.8441 - acc: 0.01 - ETA: 32s - loss: 4.8435 - acc: 0.01 - ETA: 32s - loss: 4.8435 - acc: 0.01 - ETA: 32s - loss: 4.8434 - acc: 0.01 - ETA: 31s - loss: 4.8429 - acc: 0.01 - ETA: 31s - loss: 4.8428 - acc: 0.01 - ETA: 31s - loss: 4.8431 - acc: 0.01 - ETA: 31s - loss: 4.8430 - acc: 0.01 - ETA: 31s - loss: 4.8428 - acc: 0.01 - ETA: 31s - loss: 4.8430 - acc: 0.01 - ETA: 30s - loss: 4.8433 - acc: 0.01 - ETA: 30s - loss: 4.8430 - acc: 0.01 - ETA: 30s - loss: 4.8432 - acc: 0.01 - ETA: 30s - loss: 4.8427 - acc: 0.01 - ETA: 30s - loss: 4.8427 - acc: 0.01 - ETA: 30s - loss: 4.8427 - acc: 0.01 - ETA: 30s - loss: 4.8428 - acc: 0.01 - ETA: 30s - loss: 4.8425 - acc: 0.01 - ETA: 30s - loss: 4.8428 - acc: 0.01 - ETA: 30s - loss: 4.8424 - acc: 0.01 - ETA: 30s - loss: 4.8426 - acc: 0.01 - ETA: 29s - loss: 4.8426 - acc: 0.01 - ETA: 29s - loss: 4.8426 - acc: 0.01 - ETA: 29s - loss: 4.8425 - acc: 0.01 - ETA: 29s - loss: 4.8427 - acc: 0.01 - ETA: 29s - loss: 4.8433 - acc: 0.01 - ETA: 29s - loss: 4.8439 - acc: 0.01 - ETA: 29s - loss: 4.8440 - acc: 0.01 - ETA: 29s - loss: 4.8441 - acc: 0.01 - ETA: 29s - loss: 4.8440 - acc: 0.01 - ETA: 29s - loss: 4.8443 - acc: 0.01 - ETA: 28s - loss: 4.8445 - acc: 0.01 - ETA: 28s - loss: 4.8449 - acc: 0.01 - ETA: 28s - loss: 4.8445 - acc: 0.01 - ETA: 28s - loss: 4.8447 - acc: 0.01 - ETA: 28s - loss: 4.8449 - acc: 0.01 - ETA: 28s - loss: 4.8447 - acc: 0.01 - ETA: 28s - loss: 4.8445 - acc: 0.01 - ETA: 27s - loss: 4.8443 - acc: 0.01 - ETA: 27s - loss: 4.8441 - acc: 0.0170"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 27s - loss: 4.8441 - acc: 0.01 - ETA: 27s - loss: 4.8439 - acc: 0.01 - ETA: 27s - loss: 4.8439 - acc: 0.01 - ETA: 27s - loss: 4.8441 - acc: 0.01 - ETA: 27s - loss: 4.8438 - acc: 0.01 - ETA: 26s - loss: 4.8438 - acc: 0.01 - ETA: 26s - loss: 4.8440 - acc: 0.01 - ETA: 26s - loss: 4.8444 - acc: 0.01 - ETA: 26s - loss: 4.8443 - acc: 0.01 - ETA: 26s - loss: 4.8442 - acc: 0.01 - ETA: 26s - loss: 4.8443 - acc: 0.01 - ETA: 26s - loss: 4.8443 - acc: 0.01 - ETA: 26s - loss: 4.8443 - acc: 0.01 - ETA: 25s - loss: 4.8447 - acc: 0.01 - ETA: 25s - loss: 4.8444 - acc: 0.01 - ETA: 25s - loss: 4.8442 - acc: 0.01 - ETA: 25s - loss: 4.8439 - acc: 0.01 - ETA: 25s - loss: 4.8445 - acc: 0.01 - ETA: 25s - loss: 4.8443 - acc: 0.01 - ETA: 25s - loss: 4.8442 - acc: 0.01 - ETA: 25s - loss: 4.8444 - acc: 0.01 - ETA: 24s - loss: 4.8445 - acc: 0.01 - ETA: 24s - loss: 4.8450 - acc: 0.01 - ETA: 24s - loss: 4.8450 - acc: 0.01 - ETA: 24s - loss: 4.8455 - acc: 0.01 - ETA: 24s - loss: 4.8455 - acc: 0.01 - ETA: 24s - loss: 4.8455 - acc: 0.01 - ETA: 24s - loss: 4.8449 - acc: 0.01 - ETA: 23s - loss: 4.8442 - acc: 0.01 - ETA: 23s - loss: 4.8444 - acc: 0.01 - ETA: 23s - loss: 4.8447 - acc: 0.01 - ETA: 23s - loss: 4.8446 - acc: 0.01 - ETA: 23s - loss: 4.8448 - acc: 0.01 - ETA: 23s - loss: 4.8446 - acc: 0.01 - ETA: 23s - loss: 4.8448 - acc: 0.01 - ETA: 23s - loss: 4.8451 - acc: 0.01 - ETA: 22s - loss: 4.8450 - acc: 0.01 - ETA: 22s - loss: 4.8449 - acc: 0.01 - ETA: 22s - loss: 4.8452 - acc: 0.01 - ETA: 22s - loss: 4.8457 - acc: 0.01 - ETA: 22s - loss: 4.8454 - acc: 0.01 - ETA: 22s - loss: 4.8457 - acc: 0.01 - ETA: 22s - loss: 4.8456 - acc: 0.01 - ETA: 21s - loss: 4.8453 - acc: 0.01 - ETA: 21s - loss: 4.8454 - acc: 0.01 - ETA: 21s - loss: 4.8456 - acc: 0.01 - ETA: 21s - loss: 4.8455 - acc: 0.01 - ETA: 21s - loss: 4.8456 - acc: 0.01 - ETA: 21s - loss: 4.8456 - acc: 0.01 - ETA: 21s - loss: 4.8457 - acc: 0.01 - ETA: 20s - loss: 4.8455 - acc: 0.01 - ETA: 20s - loss: 4.8454 - acc: 0.01 - ETA: 20s - loss: 4.8452 - acc: 0.01 - ETA: 20s - loss: 4.8452 - acc: 0.01 - ETA: 20s - loss: 4.8450 - acc: 0.01 - ETA: 20s - loss: 4.8446 - acc: 0.01 - ETA: 20s - loss: 4.8441 - acc: 0.01 - ETA: 19s - loss: 4.8444 - acc: 0.01 - ETA: 19s - loss: 4.8444 - acc: 0.01 - ETA: 19s - loss: 4.8445 - acc: 0.01 - ETA: 19s - loss: 4.8447 - acc: 0.01 - ETA: 19s - loss: 4.8450 - acc: 0.01 - ETA: 19s - loss: 4.8452 - acc: 0.01 - ETA: 19s - loss: 4.8454 - acc: 0.01 - ETA: 18s - loss: 4.8455 - acc: 0.01 - ETA: 18s - loss: 4.8456 - acc: 0.01 - ETA: 18s - loss: 4.8455 - acc: 0.01 - ETA: 18s - loss: 4.8457 - acc: 0.01 - ETA: 18s - loss: 4.8459 - acc: 0.01 - ETA: 18s - loss: 4.8460 - acc: 0.01 - ETA: 17s - loss: 4.8459 - acc: 0.01 - ETA: 17s - loss: 4.8459 - acc: 0.01 - ETA: 17s - loss: 4.8459 - acc: 0.01 - ETA: 17s - loss: 4.8458 - acc: 0.01 - ETA: 17s - loss: 4.8457 - acc: 0.01 - ETA: 17s - loss: 4.8458 - acc: 0.01 - ETA: 17s - loss: 4.8461 - acc: 0.01 - ETA: 16s - loss: 4.8471 - acc: 0.01 - ETA: 16s - loss: 4.8472 - acc: 0.01 - ETA: 16s - loss: 4.8471 - acc: 0.01 - ETA: 16s - loss: 4.8472 - acc: 0.01 - ETA: 16s - loss: 4.8473 - acc: 0.01 - ETA: 15s - loss: 4.8474 - acc: 0.01 - ETA: 15s - loss: 4.8476 - acc: 0.01 - ETA: 15s - loss: 4.8475 - acc: 0.01 - ETA: 15s - loss: 4.8476 - acc: 0.01 - ETA: 15s - loss: 4.8477 - acc: 0.01 - ETA: 15s - loss: 4.8474 - acc: 0.01 - ETA: 15s - loss: 4.8476 - acc: 0.01 - ETA: 14s - loss: 4.8480 - acc: 0.01 - ETA: 14s - loss: 4.8480 - acc: 0.01 - ETA: 14s - loss: 4.8481 - acc: 0.01 - ETA: 14s - loss: 4.8482 - acc: 0.01 - ETA: 14s - loss: 4.8482 - acc: 0.01 - ETA: 14s - loss: 4.8483 - acc: 0.01 - ETA: 13s - loss: 4.8481 - acc: 0.01 - ETA: 13s - loss: 4.8479 - acc: 0.01 - ETA: 13s - loss: 4.8479 - acc: 0.01 - ETA: 13s - loss: 4.8480 - acc: 0.01 - ETA: 13s - loss: 4.8479 - acc: 0.01 - ETA: 13s - loss: 4.8477 - acc: 0.01 - ETA: 13s - loss: 4.8478 - acc: 0.01 - ETA: 12s - loss: 4.8478 - acc: 0.01 - ETA: 12s - loss: 4.8482 - acc: 0.01 - ETA: 12s - loss: 4.8477 - acc: 0.01 - ETA: 12s - loss: 4.8477 - acc: 0.01 - ETA: 12s - loss: 4.8477 - acc: 0.01 - ETA: 12s - loss: 4.8478 - acc: 0.01 - ETA: 12s - loss: 4.8480 - acc: 0.01 - ETA: 11s - loss: 4.8479 - acc: 0.01 - ETA: 11s - loss: 4.8478 - acc: 0.01 - ETA: 11s - loss: 4.8476 - acc: 0.01 - ETA: 11s - loss: 4.8479 - acc: 0.01 - ETA: 11s - loss: 4.8476 - acc: 0.01 - ETA: 11s - loss: 4.8475 - acc: 0.01 - ETA: 11s - loss: 4.8474 - acc: 0.01 - ETA: 10s - loss: 4.8472 - acc: 0.01 - ETA: 10s - loss: 4.8470 - acc: 0.01 - ETA: 10s - loss: 4.8470 - acc: 0.01 - ETA: 10s - loss: 4.8471 - acc: 0.01 - ETA: 10s - loss: 4.8472 - acc: 0.01 - ETA: 10s - loss: 4.8472 - acc: 0.01 - ETA: 10s - loss: 4.8472 - acc: 0.01 - ETA: 9s - loss: 4.8471 - acc: 0.0158 - ETA: 9s - loss: 4.8473 - acc: 0.015 - ETA: 9s - loss: 4.8472 - acc: 0.015 - ETA: 9s - loss: 4.8473 - acc: 0.015 - ETA: 9s - loss: 4.8475 - acc: 0.015 - ETA: 9s - loss: 4.8474 - acc: 0.016 - ETA: 9s - loss: 4.8476 - acc: 0.015 - ETA: 8s - loss: 4.8480 - acc: 0.015 - ETA: 8s - loss: 4.8481 - acc: 0.015 - ETA: 8s - loss: 4.8479 - acc: 0.015 - ETA: 8s - loss: 4.8481 - acc: 0.015 - ETA: 8s - loss: 4.8479 - acc: 0.015 - ETA: 8s - loss: 4.8481 - acc: 0.015 - ETA: 8s - loss: 4.8480 - acc: 0.015 - ETA: 7s - loss: 4.8481 - acc: 0.015 - ETA: 7s - loss: 4.8479 - acc: 0.015 - ETA: 7s - loss: 4.8479 - acc: 0.015 - ETA: 7s - loss: 4.8479 - acc: 0.015 - ETA: 7s - loss: 4.8474 - acc: 0.015 - ETA: 7s - loss: 4.8474 - acc: 0.015 - ETA: 6s - loss: 4.8476 - acc: 0.015 - ETA: 6s - loss: 4.8471 - acc: 0.016 - ETA: 6s - loss: 4.8473 - acc: 0.016 - ETA: 6s - loss: 4.8473 - acc: 0.016 - ETA: 6s - loss: 4.8473 - acc: 0.016 - ETA: 6s - loss: 4.8472 - acc: 0.016 - ETA: 5s - loss: 4.8472 - acc: 0.016 - ETA: 5s - loss: 4.8473 - acc: 0.016 - ETA: 5s - loss: 4.8473 - acc: 0.016 - ETA: 5s - loss: 4.8472 - acc: 0.016 - ETA: 5s - loss: 4.8471 - acc: 0.016 - ETA: 5s - loss: 4.8470 - acc: 0.016 - ETA: 5s - loss: 4.8469 - acc: 0.016 - ETA: 4s - loss: 4.8470 - acc: 0.016 - ETA: 4s - loss: 4.8471 - acc: 0.016 - ETA: 4s - loss: 4.8473 - acc: 0.016 - ETA: 4s - loss: 4.8475 - acc: 0.016 - ETA: 4s - loss: 4.8474 - acc: 0.016 - ETA: 4s - loss: 4.8473 - acc: 0.016 - ETA: 3s - loss: 4.8472 - acc: 0.016 - ETA: 3s - loss: 4.8469 - acc: 0.016 - ETA: 3s - loss: 4.8468 - acc: 0.016 - ETA: 3s - loss: 4.8469 - acc: 0.016 - ETA: 3s - loss: 4.8467 - acc: 0.016 - ETA: 3s - loss: 4.8466 - acc: 0.015 - ETA: 3s - loss: 4.8465 - acc: 0.016 - ETA: 2s - loss: 4.8466 - acc: 0.016 - ETA: 2s - loss: 4.8465 - acc: 0.016 - ETA: 2s - loss: 4.8468 - acc: 0.016 - ETA: 2s - loss: 4.8465 - acc: 0.016 - ETA: 2s - loss: 4.8466 - acc: 0.016 - ETA: 2s - loss: 4.8467 - acc: 0.016 - ETA: 1s - loss: 4.8467 - acc: 0.016 - ETA: 1s - loss: 4.8466 - acc: 0.016 - ETA: 1s - loss: 4.8466 - acc: 0.016 - ETA: 1s - loss: 4.8466 - acc: 0.016 - ETA: 1s - loss: 4.8467 - acc: 0.016 - ETA: 1s - loss: 4.8469 - acc: 0.016 - ETA: 1s - loss: 4.8470 - acc: 0.016 - ETA: 0s - loss: 4.8467 - acc: 0.016 - ETA: 0s - loss: 4.8467 - acc: 0.016 - ETA: 0s - loss: 4.8465 - acc: 0.016 - ETA: 0s - loss: 4.8466 - acc: 0.016 - ETA: 0s - loss: 4.8469 - acc: 0.016 - ETA: 0s - loss: 4.8466 - acc: 0.016 - 67s 161ms/step - loss: 4.8466 - acc: 0.0165 - val_loss: 4.8345 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 4.82983\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/417 [===============>..............] - ETA: 4s - loss: 4.9241 - acc: 0.0000e+0 - ETA: 5s - loss: 4.8989 - acc: 0.0000e+0 - ETA: 5s - loss: 4.8642 - acc: 0.0208    - ETA: 8s - loss: 4.8656 - acc: 0.024 - ETA: 11s - loss: 4.8680 - acc: 0.02 - ETA: 14s - loss: 4.8758 - acc: 0.02 - ETA: 18s - loss: 4.8719 - acc: 0.01 - ETA: 20s - loss: 4.8733 - acc: 0.01 - ETA: 22s - loss: 4.8679 - acc: 0.01 - ETA: 23s - loss: 4.8695 - acc: 0.01 - ETA: 25s - loss: 4.8743 - acc: 0.01 - ETA: 30s - loss: 4.8684 - acc: 0.02 - ETA: 31s - loss: 4.8673 - acc: 0.01 - ETA: 32s - loss: 4.8687 - acc: 0.01 - ETA: 32s - loss: 4.8712 - acc: 0.01 - ETA: 33s - loss: 4.8736 - acc: 0.02 - ETA: 34s - loss: 4.8750 - acc: 0.01 - ETA: 35s - loss: 4.8724 - acc: 0.01 - ETA: 36s - loss: 4.8669 - acc: 0.02 - ETA: 38s - loss: 4.8662 - acc: 0.01 - ETA: 39s - loss: 4.8669 - acc: 0.01 - ETA: 39s - loss: 4.8652 - acc: 0.01 - ETA: 40s - loss: 4.8632 - acc: 0.02 - ETA: 40s - loss: 4.8638 - acc: 0.02 - ETA: 41s - loss: 4.8617 - acc: 0.02 - ETA: 40s - loss: 4.8626 - acc: 0.01 - ETA: 41s - loss: 4.8610 - acc: 0.02 - ETA: 42s - loss: 4.8605 - acc: 0.02 - ETA: 42s - loss: 4.8614 - acc: 0.01 - ETA: 42s - loss: 4.8571 - acc: 0.02 - ETA: 42s - loss: 4.8594 - acc: 0.02 - ETA: 43s - loss: 4.8622 - acc: 0.01 - ETA: 44s - loss: 4.8624 - acc: 0.01 - ETA: 44s - loss: 4.8608 - acc: 0.01 - ETA: 44s - loss: 4.8597 - acc: 0.01 - ETA: 44s - loss: 4.8602 - acc: 0.02 - ETA: 46s - loss: 4.8609 - acc: 0.02 - ETA: 46s - loss: 4.8571 - acc: 0.02 - ETA: 45s - loss: 4.8573 - acc: 0.02 - ETA: 45s - loss: 4.8571 - acc: 0.02 - ETA: 45s - loss: 4.8561 - acc: 0.02 - ETA: 46s - loss: 4.8562 - acc: 0.02 - ETA: 45s - loss: 4.8560 - acc: 0.02 - ETA: 46s - loss: 4.8568 - acc: 0.02 - ETA: 46s - loss: 4.8567 - acc: 0.02 - ETA: 46s - loss: 4.8584 - acc: 0.02 - ETA: 46s - loss: 4.8563 - acc: 0.02 - ETA: 46s - loss: 4.8540 - acc: 0.02 - ETA: 46s - loss: 4.8545 - acc: 0.02 - ETA: 46s - loss: 4.8537 - acc: 0.02 - ETA: 46s - loss: 4.8527 - acc: 0.02 - ETA: 46s - loss: 4.8539 - acc: 0.02 - ETA: 46s - loss: 4.8537 - acc: 0.02 - ETA: 46s - loss: 4.8547 - acc: 0.02 - ETA: 46s - loss: 4.8549 - acc: 0.02 - ETA: 46s - loss: 4.8560 - acc: 0.02 - ETA: 46s - loss: 4.8551 - acc: 0.02 - ETA: 46s - loss: 4.8534 - acc: 0.02 - ETA: 46s - loss: 4.8539 - acc: 0.02 - ETA: 46s - loss: 4.8547 - acc: 0.02 - ETA: 46s - loss: 4.8558 - acc: 0.02 - ETA: 45s - loss: 4.8554 - acc: 0.02 - ETA: 45s - loss: 4.8562 - acc: 0.02 - ETA: 45s - loss: 4.8552 - acc: 0.02 - ETA: 45s - loss: 4.8552 - acc: 0.02 - ETA: 45s - loss: 4.8542 - acc: 0.02 - ETA: 45s - loss: 4.8555 - acc: 0.02 - ETA: 45s - loss: 4.8552 - acc: 0.02 - ETA: 45s - loss: 4.8568 - acc: 0.02 - ETA: 45s - loss: 4.8561 - acc: 0.02 - ETA: 45s - loss: 4.8564 - acc: 0.02 - ETA: 45s - loss: 4.8569 - acc: 0.02 - ETA: 46s - loss: 4.8559 - acc: 0.02 - ETA: 45s - loss: 4.8539 - acc: 0.02 - ETA: 45s - loss: 4.8534 - acc: 0.02 - ETA: 45s - loss: 4.8533 - acc: 0.02 - ETA: 45s - loss: 4.8538 - acc: 0.02 - ETA: 45s - loss: 4.8519 - acc: 0.01 - ETA: 45s - loss: 4.8505 - acc: 0.02 - ETA: 45s - loss: 4.8501 - acc: 0.02 - ETA: 45s - loss: 4.8507 - acc: 0.01 - ETA: 44s - loss: 4.8504 - acc: 0.02 - ETA: 45s - loss: 4.8511 - acc: 0.01 - ETA: 44s - loss: 4.8513 - acc: 0.01 - ETA: 44s - loss: 4.8511 - acc: 0.02 - ETA: 44s - loss: 4.8516 - acc: 0.02 - ETA: 44s - loss: 4.8518 - acc: 0.02 - ETA: 44s - loss: 4.8515 - acc: 0.02 - ETA: 44s - loss: 4.8516 - acc: 0.02 - ETA: 44s - loss: 4.8515 - acc: 0.02 - ETA: 43s - loss: 4.8509 - acc: 0.02 - ETA: 43s - loss: 4.8512 - acc: 0.02 - ETA: 43s - loss: 4.8511 - acc: 0.01 - ETA: 43s - loss: 4.8496 - acc: 0.02 - ETA: 43s - loss: 4.8496 - acc: 0.02 - ETA: 43s - loss: 4.8489 - acc: 0.02 - ETA: 43s - loss: 4.8481 - acc: 0.02 - ETA: 43s - loss: 4.8488 - acc: 0.02 - ETA: 43s - loss: 4.8490 - acc: 0.02 - ETA: 42s - loss: 4.8499 - acc: 0.02 - ETA: 42s - loss: 4.8509 - acc: 0.02 - ETA: 42s - loss: 4.8515 - acc: 0.01 - ETA: 42s - loss: 4.8516 - acc: 0.01 - ETA: 42s - loss: 4.8506 - acc: 0.02 - ETA: 42s - loss: 4.8508 - acc: 0.01 - ETA: 42s - loss: 4.8503 - acc: 0.01 - ETA: 42s - loss: 4.8505 - acc: 0.01 - ETA: 42s - loss: 4.8512 - acc: 0.01 - ETA: 42s - loss: 4.8514 - acc: 0.01 - ETA: 42s - loss: 4.8512 - acc: 0.01 - ETA: 42s - loss: 4.8518 - acc: 0.01 - ETA: 42s - loss: 4.8515 - acc: 0.01 - ETA: 42s - loss: 4.8507 - acc: 0.01 - ETA: 42s - loss: 4.8504 - acc: 0.01 - ETA: 42s - loss: 4.8501 - acc: 0.01 - ETA: 42s - loss: 4.8495 - acc: 0.02 - ETA: 42s - loss: 4.8492 - acc: 0.02 - ETA: 42s - loss: 4.8494 - acc: 0.02 - ETA: 42s - loss: 4.8496 - acc: 0.02 - ETA: 41s - loss: 4.8496 - acc: 0.02 - ETA: 41s - loss: 4.8495 - acc: 0.01 - ETA: 41s - loss: 4.8499 - acc: 0.01 - ETA: 41s - loss: 4.8500 - acc: 0.01 - ETA: 41s - loss: 4.8502 - acc: 0.01 - ETA: 41s - loss: 4.8501 - acc: 0.01 - ETA: 40s - loss: 4.8505 - acc: 0.01 - ETA: 40s - loss: 4.8506 - acc: 0.01 - ETA: 40s - loss: 4.8494 - acc: 0.01 - ETA: 40s - loss: 4.8497 - acc: 0.01 - ETA: 40s - loss: 4.8498 - acc: 0.01 - ETA: 40s - loss: 4.8494 - acc: 0.01 - ETA: 40s - loss: 4.8483 - acc: 0.01 - ETA: 40s - loss: 4.8478 - acc: 0.01 - ETA: 39s - loss: 4.8476 - acc: 0.01 - ETA: 39s - loss: 4.8475 - acc: 0.01 - ETA: 39s - loss: 4.8472 - acc: 0.01 - ETA: 39s - loss: 4.8467 - acc: 0.01 - ETA: 39s - loss: 4.8475 - acc: 0.01 - ETA: 39s - loss: 4.8465 - acc: 0.02 - ETA: 39s - loss: 4.8460 - acc: 0.02 - ETA: 38s - loss: 4.8468 - acc: 0.02 - ETA: 38s - loss: 4.8459 - acc: 0.02 - ETA: 38s - loss: 4.8466 - acc: 0.02 - ETA: 38s - loss: 4.8465 - acc: 0.02 - ETA: 38s - loss: 4.8458 - acc: 0.02 - ETA: 38s - loss: 4.8456 - acc: 0.02 - ETA: 38s - loss: 4.8458 - acc: 0.02 - ETA: 38s - loss: 4.8466 - acc: 0.02 - ETA: 38s - loss: 4.8466 - acc: 0.02 - ETA: 38s - loss: 4.8463 - acc: 0.02 - ETA: 38s - loss: 4.8460 - acc: 0.02 - ETA: 37s - loss: 4.8451 - acc: 0.02 - ETA: 37s - loss: 4.8448 - acc: 0.02 - ETA: 37s - loss: 4.8457 - acc: 0.02 - ETA: 37s - loss: 4.8455 - acc: 0.02 - ETA: 37s - loss: 4.8451 - acc: 0.02 - ETA: 37s - loss: 4.8455 - acc: 0.02 - ETA: 37s - loss: 4.8453 - acc: 0.02 - ETA: 36s - loss: 4.8454 - acc: 0.02 - ETA: 36s - loss: 4.8453 - acc: 0.02 - ETA: 36s - loss: 4.8455 - acc: 0.02 - ETA: 36s - loss: 4.8461 - acc: 0.02 - ETA: 36s - loss: 4.8457 - acc: 0.02 - ETA: 36s - loss: 4.8461 - acc: 0.02 - ETA: 36s - loss: 4.8466 - acc: 0.02 - ETA: 36s - loss: 4.8465 - acc: 0.02 - ETA: 35s - loss: 4.8462 - acc: 0.01 - ETA: 35s - loss: 4.8461 - acc: 0.01 - ETA: 35s - loss: 4.8457 - acc: 0.01 - ETA: 35s - loss: 4.8451 - acc: 0.01 - ETA: 35s - loss: 4.8451 - acc: 0.01 - ETA: 35s - loss: 4.8450 - acc: 0.01 - ETA: 34s - loss: 4.8451 - acc: 0.01 - ETA: 34s - loss: 4.8447 - acc: 0.01 - ETA: 34s - loss: 4.8444 - acc: 0.01 - ETA: 34s - loss: 4.8445 - acc: 0.01 - ETA: 34s - loss: 4.8447 - acc: 0.01 - ETA: 34s - loss: 4.8448 - acc: 0.01 - ETA: 34s - loss: 4.8451 - acc: 0.01 - ETA: 34s - loss: 4.8450 - acc: 0.01 - ETA: 33s - loss: 4.8451 - acc: 0.01 - ETA: 33s - loss: 4.8447 - acc: 0.01 - ETA: 33s - loss: 4.8449 - acc: 0.01 - ETA: 33s - loss: 4.8452 - acc: 0.01 - ETA: 33s - loss: 4.8451 - acc: 0.01 - ETA: 33s - loss: 4.8448 - acc: 0.01 - ETA: 32s - loss: 4.8446 - acc: 0.01 - ETA: 32s - loss: 4.8449 - acc: 0.01 - ETA: 32s - loss: 4.8445 - acc: 0.01 - ETA: 32s - loss: 4.8444 - acc: 0.01 - ETA: 32s - loss: 4.8445 - acc: 0.01 - ETA: 32s - loss: 4.8448 - acc: 0.01 - ETA: 32s - loss: 4.8444 - acc: 0.01 - ETA: 31s - loss: 4.8450 - acc: 0.01 - ETA: 31s - loss: 4.8451 - acc: 0.01 - ETA: 31s - loss: 4.8457 - acc: 0.01 - ETA: 31s - loss: 4.8458 - acc: 0.01 - ETA: 31s - loss: 4.8454 - acc: 0.01 - ETA: 31s - loss: 4.8453 - acc: 0.02 - ETA: 30s - loss: 4.8457 - acc: 0.02 - ETA: 30s - loss: 4.8454 - acc: 0.02 - ETA: 30s - loss: 4.8458 - acc: 0.02 - ETA: 30s - loss: 4.8455 - acc: 0.02 - ETA: 30s - loss: 4.8455 - acc: 0.02 - ETA: 30s - loss: 4.8460 - acc: 0.01 - ETA: 30s - loss: 4.8455 - acc: 0.02 - ETA: 30s - loss: 4.8454 - acc: 0.02 - ETA: 29s - loss: 4.8457 - acc: 0.01 - ETA: 29s - loss: 4.8456 - acc: 0.02 - ETA: 29s - loss: 4.8459 - acc: 0.02 - ETA: 29s - loss: 4.8453 - acc: 0.02 - ETA: 29s - loss: 4.8454 - acc: 0.02 - ETA: 29s - loss: 4.8457 - acc: 0.02 - ETA: 28s - loss: 4.8461 - acc: 0.01 - ETA: 28s - loss: 4.8459 - acc: 0.0198"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8461 - acc: 0.01 - ETA: 28s - loss: 4.8458 - acc: 0.01 - ETA: 28s - loss: 4.8463 - acc: 0.01 - ETA: 28s - loss: 4.8463 - acc: 0.01 - ETA: 28s - loss: 4.8462 - acc: 0.01 - ETA: 28s - loss: 4.8463 - acc: 0.01 - ETA: 27s - loss: 4.8465 - acc: 0.01 - ETA: 27s - loss: 4.8463 - acc: 0.01 - ETA: 27s - loss: 4.8465 - acc: 0.01 - ETA: 27s - loss: 4.8465 - acc: 0.02 - ETA: 27s - loss: 4.8466 - acc: 0.02 - ETA: 27s - loss: 4.8460 - acc: 0.02 - ETA: 27s - loss: 4.8460 - acc: 0.02 - ETA: 26s - loss: 4.8461 - acc: 0.02 - ETA: 26s - loss: 4.8459 - acc: 0.02 - ETA: 26s - loss: 4.8459 - acc: 0.02 - ETA: 26s - loss: 4.8459 - acc: 0.02 - ETA: 26s - loss: 4.8457 - acc: 0.02 - ETA: 26s - loss: 4.8460 - acc: 0.02 - ETA: 25s - loss: 4.8458 - acc: 0.02 - ETA: 25s - loss: 4.8464 - acc: 0.02 - ETA: 25s - loss: 4.8466 - acc: 0.02 - ETA: 25s - loss: 4.8466 - acc: 0.02 - ETA: 25s - loss: 4.8466 - acc: 0.02 - ETA: 25s - loss: 4.8464 - acc: 0.02 - ETA: 25s - loss: 4.8461 - acc: 0.02 - ETA: 25s - loss: 4.8459 - acc: 0.02 - ETA: 24s - loss: 4.8465 - acc: 0.02 - ETA: 24s - loss: 4.8466 - acc: 0.02 - ETA: 24s - loss: 4.8465 - acc: 0.02 - ETA: 24s - loss: 4.8465 - acc: 0.02 - ETA: 24s - loss: 4.8466 - acc: 0.02 - ETA: 24s - loss: 4.8462 - acc: 0.02 - ETA: 23s - loss: 4.8462 - acc: 0.02 - ETA: 23s - loss: 4.8461 - acc: 0.02 - ETA: 23s - loss: 4.8462 - acc: 0.02 - ETA: 23s - loss: 4.8460 - acc: 0.02 - ETA: 23s - loss: 4.8459 - acc: 0.02 - ETA: 23s - loss: 4.8461 - acc: 0.02 - ETA: 23s - loss: 4.8463 - acc: 0.02 - ETA: 22s - loss: 4.8463 - acc: 0.02 - ETA: 22s - loss: 4.8458 - acc: 0.02 - ETA: 22s - loss: 4.8459 - acc: 0.02 - ETA: 22s - loss: 4.8460 - acc: 0.02 - ETA: 22s - loss: 4.8459 - acc: 0.02 - ETA: 22s - loss: 4.8458 - acc: 0.02 - ETA: 21s - loss: 4.8460 - acc: 0.02 - ETA: 21s - loss: 4.8460 - acc: 0.02 - ETA: 21s - loss: 4.8462 - acc: 0.02 - ETA: 21s - loss: 4.8464 - acc: 0.02 - ETA: 21s - loss: 4.8463 - acc: 0.02 - ETA: 21s - loss: 4.8461 - acc: 0.02 - ETA: 20s - loss: 4.8458 - acc: 0.02 - ETA: 20s - loss: 4.8454 - acc: 0.02 - ETA: 20s - loss: 4.8454 - acc: 0.02 - ETA: 20s - loss: 4.8457 - acc: 0.02 - ETA: 20s - loss: 4.8460 - acc: 0.02 - ETA: 20s - loss: 4.8460 - acc: 0.02 - ETA: 20s - loss: 4.8460 - acc: 0.02 - ETA: 19s - loss: 4.8459 - acc: 0.02 - ETA: 19s - loss: 4.8461 - acc: 0.02 - ETA: 19s - loss: 4.8460 - acc: 0.02 - ETA: 19s - loss: 4.8459 - acc: 0.02 - ETA: 19s - loss: 4.8459 - acc: 0.02 - ETA: 19s - loss: 4.8459 - acc: 0.02 - ETA: 19s - loss: 4.8459 - acc: 0.02 - ETA: 18s - loss: 4.8460 - acc: 0.02 - ETA: 18s - loss: 4.8457 - acc: 0.02 - ETA: 18s - loss: 4.8460 - acc: 0.02 - ETA: 18s - loss: 4.8459 - acc: 0.02 - ETA: 18s - loss: 4.8461 - acc: 0.02 - ETA: 18s - loss: 4.8456 - acc: 0.02 - ETA: 18s - loss: 4.8457 - acc: 0.02 - ETA: 17s - loss: 4.8454 - acc: 0.02 - ETA: 17s - loss: 4.8455 - acc: 0.02 - ETA: 17s - loss: 4.8456 - acc: 0.02 - ETA: 17s - loss: 4.8453 - acc: 0.02 - ETA: 17s - loss: 4.8447 - acc: 0.02 - ETA: 17s - loss: 4.8446 - acc: 0.02 - ETA: 16s - loss: 4.8445 - acc: 0.02 - ETA: 16s - loss: 4.8441 - acc: 0.02 - ETA: 16s - loss: 4.8443 - acc: 0.02 - ETA: 16s - loss: 4.8443 - acc: 0.02 - ETA: 16s - loss: 4.8439 - acc: 0.02 - ETA: 16s - loss: 4.8437 - acc: 0.02 - ETA: 16s - loss: 4.8432 - acc: 0.02 - ETA: 15s - loss: 4.8432 - acc: 0.02 - ETA: 15s - loss: 4.8435 - acc: 0.02 - ETA: 15s - loss: 4.8436 - acc: 0.02 - ETA: 15s - loss: 4.8437 - acc: 0.01 - ETA: 15s - loss: 4.8436 - acc: 0.01 - ETA: 15s - loss: 4.8434 - acc: 0.02 - ETA: 14s - loss: 4.8435 - acc: 0.02 - ETA: 14s - loss: 4.8437 - acc: 0.02 - ETA: 14s - loss: 4.8432 - acc: 0.02 - ETA: 14s - loss: 4.8427 - acc: 0.01 - ETA: 14s - loss: 4.8429 - acc: 0.01 - ETA: 14s - loss: 4.8428 - acc: 0.01 - ETA: 14s - loss: 4.8429 - acc: 0.01 - ETA: 13s - loss: 4.8427 - acc: 0.01 - ETA: 13s - loss: 4.8425 - acc: 0.01 - ETA: 13s - loss: 4.8426 - acc: 0.01 - ETA: 13s - loss: 4.8427 - acc: 0.01 - ETA: 13s - loss: 4.8430 - acc: 0.01 - ETA: 13s - loss: 4.8429 - acc: 0.01 - ETA: 12s - loss: 4.8427 - acc: 0.01 - ETA: 12s - loss: 4.8426 - acc: 0.01 - ETA: 12s - loss: 4.8427 - acc: 0.01 - ETA: 12s - loss: 4.8427 - acc: 0.01 - ETA: 12s - loss: 4.8425 - acc: 0.01 - ETA: 12s - loss: 4.8427 - acc: 0.01 - ETA: 12s - loss: 4.8426 - acc: 0.01 - ETA: 11s - loss: 4.8427 - acc: 0.01 - ETA: 11s - loss: 4.8428 - acc: 0.01 - ETA: 11s - loss: 4.8430 - acc: 0.01 - ETA: 11s - loss: 4.8430 - acc: 0.01 - ETA: 11s - loss: 4.8433 - acc: 0.01 - ETA: 11s - loss: 4.8432 - acc: 0.01 - ETA: 10s - loss: 4.8430 - acc: 0.01 - ETA: 10s - loss: 4.8429 - acc: 0.01 - ETA: 10s - loss: 4.8425 - acc: 0.01 - ETA: 10s - loss: 4.8423 - acc: 0.01 - ETA: 10s - loss: 4.8430 - acc: 0.01 - ETA: 9s - loss: 4.8429 - acc: 0.0188 - ETA: 9s - loss: 4.8431 - acc: 0.018 - ETA: 9s - loss: 4.8431 - acc: 0.018 - ETA: 9s - loss: 4.8432 - acc: 0.018 - ETA: 9s - loss: 4.8428 - acc: 0.018 - ETA: 9s - loss: 4.8430 - acc: 0.018 - ETA: 8s - loss: 4.8426 - acc: 0.019 - ETA: 8s - loss: 4.8428 - acc: 0.018 - ETA: 8s - loss: 4.8427 - acc: 0.018 - ETA: 8s - loss: 4.8429 - acc: 0.018 - ETA: 8s - loss: 4.8427 - acc: 0.018 - ETA: 8s - loss: 4.8426 - acc: 0.019 - ETA: 8s - loss: 4.8426 - acc: 0.019 - ETA: 7s - loss: 4.8425 - acc: 0.019 - ETA: 7s - loss: 4.8426 - acc: 0.019 - ETA: 7s - loss: 4.8425 - acc: 0.019 - ETA: 7s - loss: 4.8423 - acc: 0.019 - ETA: 7s - loss: 4.8426 - acc: 0.019 - ETA: 7s - loss: 4.8425 - acc: 0.019 - ETA: 6s - loss: 4.8425 - acc: 0.019 - ETA: 6s - loss: 4.8423 - acc: 0.019 - ETA: 6s - loss: 4.8424 - acc: 0.019 - ETA: 6s - loss: 4.8426 - acc: 0.019 - ETA: 6s - loss: 4.8424 - acc: 0.019 - ETA: 6s - loss: 4.8424 - acc: 0.019 - ETA: 6s - loss: 4.8425 - acc: 0.019 - ETA: 5s - loss: 4.8420 - acc: 0.019 - ETA: 5s - loss: 4.8417 - acc: 0.019 - ETA: 5s - loss: 4.8416 - acc: 0.019 - ETA: 5s - loss: 4.8417 - acc: 0.019 - ETA: 5s - loss: 4.8415 - acc: 0.019 - ETA: 5s - loss: 4.8417 - acc: 0.019 - ETA: 4s - loss: 4.8419 - acc: 0.019 - ETA: 4s - loss: 4.8417 - acc: 0.019 - ETA: 4s - loss: 4.8416 - acc: 0.019 - ETA: 4s - loss: 4.8411 - acc: 0.019 - ETA: 4s - loss: 4.8413 - acc: 0.019 - ETA: 4s - loss: 4.8412 - acc: 0.019 - ETA: 4s - loss: 4.8416 - acc: 0.019 - ETA: 3s - loss: 4.8414 - acc: 0.019 - ETA: 3s - loss: 4.8414 - acc: 0.019 - ETA: 3s - loss: 4.8414 - acc: 0.019 - ETA: 3s - loss: 4.8414 - acc: 0.019 - ETA: 3s - loss: 4.8415 - acc: 0.019 - ETA: 3s - loss: 4.8416 - acc: 0.019 - ETA: 2s - loss: 4.8414 - acc: 0.019 - ETA: 2s - loss: 4.8415 - acc: 0.019 - ETA: 2s - loss: 4.8413 - acc: 0.019 - ETA: 2s - loss: 4.8413 - acc: 0.019 - ETA: 2s - loss: 4.8415 - acc: 0.019 - ETA: 2s - loss: 4.8415 - acc: 0.019 - ETA: 2s - loss: 4.8414 - acc: 0.019 - ETA: 1s - loss: 4.8414 - acc: 0.019 - ETA: 1s - loss: 4.8414 - acc: 0.019 - ETA: 1s - loss: 4.8412 - acc: 0.019 - ETA: 1s - loss: 4.8415 - acc: 0.019 - ETA: 1s - loss: 4.8414 - acc: 0.019 - ETA: 1s - loss: 4.8415 - acc: 0.020 - ETA: 0s - loss: 4.8415 - acc: 0.020 - ETA: 0s - loss: 4.8414 - acc: 0.020 - ETA: 0s - loss: 4.8417 - acc: 0.020 - ETA: 0s - loss: 4.8415 - acc: 0.020 - ETA: 0s - loss: 4.8415 - acc: 0.020 - ETA: 0s - loss: 4.8414 - acc: 0.020 - 68s 163ms/step - loss: 4.8412 - acc: 0.0201 - val_loss: 4.8213 - val_acc: 0.0269\n",
      "\n",
      "Epoch 00033: val_loss improved from 4.82983 to 4.82132, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/417 [===============>..............] - ETA: 5s - loss: 4.7764 - acc: 0.062 - ETA: 5s - loss: 4.8489 - acc: 0.037 - ETA: 5s - loss: 4.8319 - acc: 0.020 - ETA: 9s - loss: 4.8533 - acc: 0.019 - ETA: 13s - loss: 4.8396 - acc: 0.02 - ETA: 21s - loss: 4.8402 - acc: 0.02 - ETA: 25s - loss: 4.8446 - acc: 0.01 - ETA: 27s - loss: 4.8439 - acc: 0.01 - ETA: 28s - loss: 4.8436 - acc: 0.02 - ETA: 29s - loss: 4.8463 - acc: 0.01 - ETA: 31s - loss: 4.8447 - acc: 0.02 - ETA: 32s - loss: 4.8442 - acc: 0.02 - ETA: 33s - loss: 4.8392 - acc: 0.01 - ETA: 34s - loss: 4.8444 - acc: 0.01 - ETA: 34s - loss: 4.8471 - acc: 0.01 - ETA: 36s - loss: 4.8477 - acc: 0.01 - ETA: 37s - loss: 4.8502 - acc: 0.01 - ETA: 37s - loss: 4.8499 - acc: 0.01 - ETA: 38s - loss: 4.8519 - acc: 0.01 - ETA: 38s - loss: 4.8528 - acc: 0.01 - ETA: 38s - loss: 4.8551 - acc: 0.01 - ETA: 38s - loss: 4.8565 - acc: 0.01 - ETA: 39s - loss: 4.8548 - acc: 0.01 - ETA: 39s - loss: 4.8531 - acc: 0.01 - ETA: 39s - loss: 4.8510 - acc: 0.01 - ETA: 39s - loss: 4.8468 - acc: 0.02 - ETA: 39s - loss: 4.8490 - acc: 0.02 - ETA: 39s - loss: 4.8505 - acc: 0.02 - ETA: 39s - loss: 4.8469 - acc: 0.02 - ETA: 39s - loss: 4.8483 - acc: 0.02 - ETA: 41s - loss: 4.8500 - acc: 0.02 - ETA: 42s - loss: 4.8494 - acc: 0.02 - ETA: 42s - loss: 4.8488 - acc: 0.02 - ETA: 42s - loss: 4.8500 - acc: 0.02 - ETA: 43s - loss: 4.8489 - acc: 0.02 - ETA: 44s - loss: 4.8483 - acc: 0.02 - ETA: 44s - loss: 4.8482 - acc: 0.02 - ETA: 44s - loss: 4.8498 - acc: 0.02 - ETA: 43s - loss: 4.8514 - acc: 0.02 - ETA: 44s - loss: 4.8520 - acc: 0.02 - ETA: 43s - loss: 4.8516 - acc: 0.02 - ETA: 43s - loss: 4.8503 - acc: 0.02 - ETA: 44s - loss: 4.8495 - acc: 0.02 - ETA: 44s - loss: 4.8489 - acc: 0.02 - ETA: 44s - loss: 4.8477 - acc: 0.02 - ETA: 44s - loss: 4.8487 - acc: 0.02 - ETA: 44s - loss: 4.8497 - acc: 0.02 - ETA: 45s - loss: 4.8502 - acc: 0.02 - ETA: 46s - loss: 4.8494 - acc: 0.02 - ETA: 46s - loss: 4.8502 - acc: 0.02 - ETA: 46s - loss: 4.8509 - acc: 0.01 - ETA: 46s - loss: 4.8515 - acc: 0.01 - ETA: 47s - loss: 4.8522 - acc: 0.01 - ETA: 47s - loss: 4.8533 - acc: 0.01 - ETA: 46s - loss: 4.8510 - acc: 0.01 - ETA: 46s - loss: 4.8515 - acc: 0.01 - ETA: 47s - loss: 4.8526 - acc: 0.01 - ETA: 47s - loss: 4.8528 - acc: 0.01 - ETA: 47s - loss: 4.8537 - acc: 0.01 - ETA: 46s - loss: 4.8535 - acc: 0.01 - ETA: 46s - loss: 4.8547 - acc: 0.01 - ETA: 47s - loss: 4.8554 - acc: 0.02 - ETA: 47s - loss: 4.8545 - acc: 0.02 - ETA: 47s - loss: 4.8538 - acc: 0.02 - ETA: 46s - loss: 4.8550 - acc: 0.02 - ETA: 46s - loss: 4.8552 - acc: 0.02 - ETA: 46s - loss: 4.8542 - acc: 0.02 - ETA: 46s - loss: 4.8538 - acc: 0.02 - ETA: 46s - loss: 4.8539 - acc: 0.02 - ETA: 46s - loss: 4.8528 - acc: 0.01 - ETA: 46s - loss: 4.8519 - acc: 0.01 - ETA: 46s - loss: 4.8512 - acc: 0.01 - ETA: 46s - loss: 4.8506 - acc: 0.01 - ETA: 46s - loss: 4.8493 - acc: 0.02 - ETA: 45s - loss: 4.8490 - acc: 0.02 - ETA: 45s - loss: 4.8473 - acc: 0.02 - ETA: 45s - loss: 4.8472 - acc: 0.02 - ETA: 45s - loss: 4.8471 - acc: 0.02 - ETA: 45s - loss: 4.8477 - acc: 0.02 - ETA: 45s - loss: 4.8475 - acc: 0.02 - ETA: 45s - loss: 4.8472 - acc: 0.02 - ETA: 45s - loss: 4.8483 - acc: 0.02 - ETA: 45s - loss: 4.8485 - acc: 0.02 - ETA: 45s - loss: 4.8481 - acc: 0.02 - ETA: 44s - loss: 4.8486 - acc: 0.02 - ETA: 45s - loss: 4.8487 - acc: 0.02 - ETA: 45s - loss: 4.8489 - acc: 0.02 - ETA: 45s - loss: 4.8487 - acc: 0.02 - ETA: 44s - loss: 4.8489 - acc: 0.02 - ETA: 44s - loss: 4.8487 - acc: 0.02 - ETA: 44s - loss: 4.8481 - acc: 0.02 - ETA: 44s - loss: 4.8480 - acc: 0.02 - ETA: 44s - loss: 4.8470 - acc: 0.02 - ETA: 44s - loss: 4.8472 - acc: 0.01 - ETA: 44s - loss: 4.8476 - acc: 0.01 - ETA: 43s - loss: 4.8479 - acc: 0.01 - ETA: 43s - loss: 4.8469 - acc: 0.01 - ETA: 43s - loss: 4.8459 - acc: 0.02 - ETA: 43s - loss: 4.8465 - acc: 0.02 - ETA: 43s - loss: 4.8465 - acc: 0.02 - ETA: 43s - loss: 4.8468 - acc: 0.02 - ETA: 43s - loss: 4.8463 - acc: 0.02 - ETA: 42s - loss: 4.8466 - acc: 0.01 - ETA: 42s - loss: 4.8463 - acc: 0.01 - ETA: 42s - loss: 4.8451 - acc: 0.02 - ETA: 42s - loss: 4.8455 - acc: 0.01 - ETA: 42s - loss: 4.8449 - acc: 0.01 - ETA: 41s - loss: 4.8450 - acc: 0.01 - ETA: 41s - loss: 4.8459 - acc: 0.01 - ETA: 41s - loss: 4.8459 - acc: 0.01 - ETA: 41s - loss: 4.8453 - acc: 0.01 - ETA: 41s - loss: 4.8456 - acc: 0.01 - ETA: 41s - loss: 4.8459 - acc: 0.01 - ETA: 41s - loss: 4.8459 - acc: 0.01 - ETA: 41s - loss: 4.8468 - acc: 0.01 - ETA: 41s - loss: 4.8467 - acc: 0.01 - ETA: 40s - loss: 4.8470 - acc: 0.01 - ETA: 40s - loss: 4.8463 - acc: 0.01 - ETA: 40s - loss: 4.8467 - acc: 0.01 - ETA: 40s - loss: 4.8466 - acc: 0.01 - ETA: 40s - loss: 4.8471 - acc: 0.01 - ETA: 40s - loss: 4.8470 - acc: 0.01 - ETA: 39s - loss: 4.8476 - acc: 0.01 - ETA: 39s - loss: 4.8475 - acc: 0.01 - ETA: 39s - loss: 4.8475 - acc: 0.01 - ETA: 39s - loss: 4.8468 - acc: 0.01 - ETA: 39s - loss: 4.8463 - acc: 0.01 - ETA: 39s - loss: 4.8462 - acc: 0.01 - ETA: 39s - loss: 4.8456 - acc: 0.01 - ETA: 38s - loss: 4.8458 - acc: 0.01 - ETA: 38s - loss: 4.8464 - acc: 0.01 - ETA: 38s - loss: 4.8462 - acc: 0.01 - ETA: 38s - loss: 4.8458 - acc: 0.01 - ETA: 38s - loss: 4.8462 - acc: 0.01 - ETA: 38s - loss: 4.8466 - acc: 0.01 - ETA: 38s - loss: 4.8470 - acc: 0.01 - ETA: 37s - loss: 4.8471 - acc: 0.01 - ETA: 37s - loss: 4.8474 - acc: 0.01 - ETA: 37s - loss: 4.8473 - acc: 0.01 - ETA: 37s - loss: 4.8467 - acc: 0.01 - ETA: 37s - loss: 4.8466 - acc: 0.01 - ETA: 37s - loss: 4.8463 - acc: 0.01 - ETA: 37s - loss: 4.8454 - acc: 0.02 - ETA: 37s - loss: 4.8447 - acc: 0.02 - ETA: 37s - loss: 4.8451 - acc: 0.02 - ETA: 37s - loss: 4.8461 - acc: 0.02 - ETA: 36s - loss: 4.8458 - acc: 0.02 - ETA: 36s - loss: 4.8459 - acc: 0.02 - ETA: 36s - loss: 4.8461 - acc: 0.01 - ETA: 36s - loss: 4.8454 - acc: 0.01 - ETA: 36s - loss: 4.8458 - acc: 0.01 - ETA: 36s - loss: 4.8461 - acc: 0.01 - ETA: 36s - loss: 4.8470 - acc: 0.01 - ETA: 35s - loss: 4.8468 - acc: 0.01 - ETA: 35s - loss: 4.8461 - acc: 0.01 - ETA: 35s - loss: 4.8464 - acc: 0.01 - ETA: 35s - loss: 4.8464 - acc: 0.01 - ETA: 35s - loss: 4.8468 - acc: 0.01 - ETA: 35s - loss: 4.8472 - acc: 0.01 - ETA: 35s - loss: 4.8468 - acc: 0.01 - ETA: 34s - loss: 4.8477 - acc: 0.01 - ETA: 34s - loss: 4.8479 - acc: 0.01 - ETA: 34s - loss: 4.8477 - acc: 0.01 - ETA: 34s - loss: 4.8469 - acc: 0.01 - ETA: 34s - loss: 4.8468 - acc: 0.01 - ETA: 34s - loss: 4.8469 - acc: 0.01 - ETA: 34s - loss: 4.8465 - acc: 0.01 - ETA: 34s - loss: 4.8467 - acc: 0.01 - ETA: 34s - loss: 4.8463 - acc: 0.01 - ETA: 33s - loss: 4.8463 - acc: 0.01 - ETA: 33s - loss: 4.8464 - acc: 0.01 - ETA: 33s - loss: 4.8464 - acc: 0.01 - ETA: 33s - loss: 4.8462 - acc: 0.01 - ETA: 33s - loss: 4.8460 - acc: 0.01 - ETA: 33s - loss: 4.8465 - acc: 0.01 - ETA: 33s - loss: 4.8466 - acc: 0.01 - ETA: 33s - loss: 4.8464 - acc: 0.01 - ETA: 33s - loss: 4.8466 - acc: 0.01 - ETA: 32s - loss: 4.8464 - acc: 0.01 - ETA: 32s - loss: 4.8464 - acc: 0.01 - ETA: 32s - loss: 4.8464 - acc: 0.01 - ETA: 32s - loss: 4.8467 - acc: 0.01 - ETA: 32s - loss: 4.8470 - acc: 0.01 - ETA: 32s - loss: 4.8472 - acc: 0.01 - ETA: 32s - loss: 4.8469 - acc: 0.01 - ETA: 31s - loss: 4.8466 - acc: 0.01 - ETA: 31s - loss: 4.8467 - acc: 0.01 - ETA: 31s - loss: 4.8470 - acc: 0.01 - ETA: 31s - loss: 4.8466 - acc: 0.01 - ETA: 31s - loss: 4.8457 - acc: 0.01 - ETA: 31s - loss: 4.8452 - acc: 0.01 - ETA: 31s - loss: 4.8452 - acc: 0.01 - ETA: 31s - loss: 4.8454 - acc: 0.01 - ETA: 30s - loss: 4.8454 - acc: 0.01 - ETA: 30s - loss: 4.8455 - acc: 0.01 - ETA: 30s - loss: 4.8454 - acc: 0.01 - ETA: 30s - loss: 4.8459 - acc: 0.01 - ETA: 30s - loss: 4.8464 - acc: 0.01 - ETA: 30s - loss: 4.8464 - acc: 0.01 - ETA: 30s - loss: 4.8466 - acc: 0.01 - ETA: 30s - loss: 4.8472 - acc: 0.01 - ETA: 29s - loss: 4.8478 - acc: 0.01 - ETA: 29s - loss: 4.8479 - acc: 0.01 - ETA: 29s - loss: 4.8477 - acc: 0.01 - ETA: 29s - loss: 4.8477 - acc: 0.01 - ETA: 29s - loss: 4.8475 - acc: 0.01 - ETA: 29s - loss: 4.8471 - acc: 0.01 - ETA: 28s - loss: 4.8467 - acc: 0.01 - ETA: 28s - loss: 4.8465 - acc: 0.01 - ETA: 28s - loss: 4.8462 - acc: 0.01 - ETA: 28s - loss: 4.8460 - acc: 0.01 - ETA: 28s - loss: 4.8459 - acc: 0.01 - ETA: 28s - loss: 4.8462 - acc: 0.01 - ETA: 28s - loss: 4.8468 - acc: 0.01 - ETA: 27s - loss: 4.8464 - acc: 0.0176"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 27s - loss: 4.8466 - acc: 0.01 - ETA: 27s - loss: 4.8466 - acc: 0.01 - ETA: 27s - loss: 4.8461 - acc: 0.01 - ETA: 27s - loss: 4.8465 - acc: 0.01 - ETA: 27s - loss: 4.8463 - acc: 0.01 - ETA: 27s - loss: 4.8464 - acc: 0.01 - ETA: 27s - loss: 4.8464 - acc: 0.01 - ETA: 26s - loss: 4.8464 - acc: 0.01 - ETA: 26s - loss: 4.8466 - acc: 0.01 - ETA: 26s - loss: 4.8467 - acc: 0.01 - ETA: 26s - loss: 4.8461 - acc: 0.01 - ETA: 26s - loss: 4.8462 - acc: 0.01 - ETA: 26s - loss: 4.8464 - acc: 0.01 - ETA: 26s - loss: 4.8464 - acc: 0.01 - ETA: 26s - loss: 4.8465 - acc: 0.01 - ETA: 25s - loss: 4.8467 - acc: 0.01 - ETA: 25s - loss: 4.8466 - acc: 0.01 - ETA: 25s - loss: 4.8464 - acc: 0.01 - ETA: 25s - loss: 4.8465 - acc: 0.01 - ETA: 25s - loss: 4.8465 - acc: 0.01 - ETA: 25s - loss: 4.8470 - acc: 0.01 - ETA: 25s - loss: 4.8469 - acc: 0.01 - ETA: 24s - loss: 4.8469 - acc: 0.01 - ETA: 24s - loss: 4.8472 - acc: 0.01 - ETA: 24s - loss: 4.8472 - acc: 0.01 - ETA: 24s - loss: 4.8470 - acc: 0.01 - ETA: 24s - loss: 4.8468 - acc: 0.01 - ETA: 24s - loss: 4.8465 - acc: 0.01 - ETA: 24s - loss: 4.8464 - acc: 0.01 - ETA: 23s - loss: 4.8464 - acc: 0.01 - ETA: 23s - loss: 4.8462 - acc: 0.01 - ETA: 23s - loss: 4.8455 - acc: 0.01 - ETA: 23s - loss: 4.8455 - acc: 0.01 - ETA: 23s - loss: 4.8458 - acc: 0.01 - ETA: 23s - loss: 4.8462 - acc: 0.01 - ETA: 22s - loss: 4.8464 - acc: 0.01 - ETA: 22s - loss: 4.8462 - acc: 0.01 - ETA: 22s - loss: 4.8461 - acc: 0.01 - ETA: 22s - loss: 4.8459 - acc: 0.01 - ETA: 22s - loss: 4.8457 - acc: 0.01 - ETA: 22s - loss: 4.8460 - acc: 0.01 - ETA: 22s - loss: 4.8455 - acc: 0.01 - ETA: 21s - loss: 4.8455 - acc: 0.01 - ETA: 21s - loss: 4.8452 - acc: 0.01 - ETA: 21s - loss: 4.8453 - acc: 0.01 - ETA: 21s - loss: 4.8454 - acc: 0.01 - ETA: 21s - loss: 4.8453 - acc: 0.01 - ETA: 21s - loss: 4.8458 - acc: 0.01 - ETA: 20s - loss: 4.8457 - acc: 0.01 - ETA: 20s - loss: 4.8455 - acc: 0.01 - ETA: 20s - loss: 4.8455 - acc: 0.01 - ETA: 20s - loss: 4.8455 - acc: 0.01 - ETA: 20s - loss: 4.8449 - acc: 0.01 - ETA: 20s - loss: 4.8451 - acc: 0.01 - ETA: 19s - loss: 4.8450 - acc: 0.01 - ETA: 19s - loss: 4.8450 - acc: 0.01 - ETA: 19s - loss: 4.8453 - acc: 0.01 - ETA: 19s - loss: 4.8454 - acc: 0.01 - ETA: 19s - loss: 4.8457 - acc: 0.01 - ETA: 19s - loss: 4.8459 - acc: 0.01 - ETA: 19s - loss: 4.8462 - acc: 0.01 - ETA: 18s - loss: 4.8464 - acc: 0.01 - ETA: 18s - loss: 4.8467 - acc: 0.01 - ETA: 18s - loss: 4.8464 - acc: 0.01 - ETA: 18s - loss: 4.8466 - acc: 0.01 - ETA: 18s - loss: 4.8465 - acc: 0.01 - ETA: 18s - loss: 4.8465 - acc: 0.01 - ETA: 18s - loss: 4.8467 - acc: 0.01 - ETA: 17s - loss: 4.8468 - acc: 0.01 - ETA: 17s - loss: 4.8470 - acc: 0.01 - ETA: 17s - loss: 4.8468 - acc: 0.01 - ETA: 17s - loss: 4.8468 - acc: 0.01 - ETA: 17s - loss: 4.8463 - acc: 0.01 - ETA: 17s - loss: 4.8463 - acc: 0.01 - ETA: 17s - loss: 4.8462 - acc: 0.01 - ETA: 16s - loss: 4.8463 - acc: 0.01 - ETA: 16s - loss: 4.8462 - acc: 0.01 - ETA: 16s - loss: 4.8461 - acc: 0.01 - ETA: 16s - loss: 4.8461 - acc: 0.01 - ETA: 16s - loss: 4.8459 - acc: 0.01 - ETA: 16s - loss: 4.8461 - acc: 0.01 - ETA: 15s - loss: 4.8452 - acc: 0.01 - ETA: 15s - loss: 4.8446 - acc: 0.01 - ETA: 15s - loss: 4.8445 - acc: 0.01 - ETA: 15s - loss: 4.8447 - acc: 0.01 - ETA: 15s - loss: 4.8448 - acc: 0.01 - ETA: 15s - loss: 4.8447 - acc: 0.01 - ETA: 15s - loss: 4.8443 - acc: 0.01 - ETA: 14s - loss: 4.8442 - acc: 0.01 - ETA: 14s - loss: 4.8438 - acc: 0.01 - ETA: 14s - loss: 4.8442 - acc: 0.01 - ETA: 14s - loss: 4.8449 - acc: 0.01 - ETA: 14s - loss: 4.8450 - acc: 0.01 - ETA: 14s - loss: 4.8449 - acc: 0.01 - ETA: 14s - loss: 4.8451 - acc: 0.01 - ETA: 13s - loss: 4.8450 - acc: 0.01 - ETA: 13s - loss: 4.8452 - acc: 0.01 - ETA: 13s - loss: 4.8449 - acc: 0.01 - ETA: 13s - loss: 4.8449 - acc: 0.01 - ETA: 13s - loss: 4.8451 - acc: 0.01 - ETA: 13s - loss: 4.8450 - acc: 0.01 - ETA: 13s - loss: 4.8446 - acc: 0.01 - ETA: 12s - loss: 4.8449 - acc: 0.01 - ETA: 12s - loss: 4.8447 - acc: 0.01 - ETA: 12s - loss: 4.8444 - acc: 0.01 - ETA: 12s - loss: 4.8441 - acc: 0.01 - ETA: 12s - loss: 4.8438 - acc: 0.01 - ETA: 12s - loss: 4.8438 - acc: 0.01 - ETA: 12s - loss: 4.8434 - acc: 0.01 - ETA: 11s - loss: 4.8435 - acc: 0.01 - ETA: 11s - loss: 4.8435 - acc: 0.01 - ETA: 11s - loss: 4.8438 - acc: 0.01 - ETA: 11s - loss: 4.8437 - acc: 0.01 - ETA: 11s - loss: 4.8438 - acc: 0.01 - ETA: 11s - loss: 4.8437 - acc: 0.01 - ETA: 10s - loss: 4.8435 - acc: 0.01 - ETA: 10s - loss: 4.8436 - acc: 0.01 - ETA: 10s - loss: 4.8439 - acc: 0.01 - ETA: 10s - loss: 4.8435 - acc: 0.01 - ETA: 10s - loss: 4.8436 - acc: 0.01 - ETA: 10s - loss: 4.8431 - acc: 0.01 - ETA: 10s - loss: 4.8430 - acc: 0.01 - ETA: 9s - loss: 4.8430 - acc: 0.0179 - ETA: 9s - loss: 4.8428 - acc: 0.017 - ETA: 9s - loss: 4.8429 - acc: 0.017 - ETA: 9s - loss: 4.8429 - acc: 0.017 - ETA: 9s - loss: 4.8426 - acc: 0.017 - ETA: 9s - loss: 4.8431 - acc: 0.017 - ETA: 9s - loss: 4.8431 - acc: 0.017 - ETA: 8s - loss: 4.8432 - acc: 0.017 - ETA: 8s - loss: 4.8429 - acc: 0.017 - ETA: 8s - loss: 4.8429 - acc: 0.017 - ETA: 8s - loss: 4.8422 - acc: 0.017 - ETA: 8s - loss: 4.8423 - acc: 0.017 - ETA: 8s - loss: 4.8421 - acc: 0.017 - ETA: 8s - loss: 4.8420 - acc: 0.017 - ETA: 7s - loss: 4.8419 - acc: 0.017 - ETA: 7s - loss: 4.8420 - acc: 0.017 - ETA: 7s - loss: 4.8418 - acc: 0.017 - ETA: 7s - loss: 4.8419 - acc: 0.017 - ETA: 7s - loss: 4.8420 - acc: 0.017 - ETA: 7s - loss: 4.8422 - acc: 0.017 - ETA: 7s - loss: 4.8420 - acc: 0.017 - ETA: 6s - loss: 4.8422 - acc: 0.017 - ETA: 6s - loss: 4.8422 - acc: 0.017 - ETA: 6s - loss: 4.8422 - acc: 0.017 - ETA: 6s - loss: 4.8423 - acc: 0.017 - ETA: 6s - loss: 4.8423 - acc: 0.017 - ETA: 6s - loss: 4.8419 - acc: 0.017 - ETA: 6s - loss: 4.8415 - acc: 0.017 - ETA: 5s - loss: 4.8417 - acc: 0.017 - ETA: 5s - loss: 4.8420 - acc: 0.017 - ETA: 5s - loss: 4.8423 - acc: 0.017 - ETA: 5s - loss: 4.8423 - acc: 0.017 - ETA: 5s - loss: 4.8421 - acc: 0.017 - ETA: 5s - loss: 4.8421 - acc: 0.017 - ETA: 4s - loss: 4.8419 - acc: 0.017 - ETA: 4s - loss: 4.8421 - acc: 0.017 - ETA: 4s - loss: 4.8425 - acc: 0.017 - ETA: 4s - loss: 4.8426 - acc: 0.017 - ETA: 4s - loss: 4.8426 - acc: 0.017 - ETA: 4s - loss: 4.8423 - acc: 0.017 - ETA: 3s - loss: 4.8423 - acc: 0.017 - ETA: 3s - loss: 4.8422 - acc: 0.017 - ETA: 3s - loss: 4.8421 - acc: 0.017 - ETA: 3s - loss: 4.8423 - acc: 0.017 - ETA: 3s - loss: 4.8424 - acc: 0.017 - ETA: 3s - loss: 4.8424 - acc: 0.017 - ETA: 3s - loss: 4.8426 - acc: 0.017 - ETA: 2s - loss: 4.8427 - acc: 0.017 - ETA: 2s - loss: 4.8428 - acc: 0.017 - ETA: 2s - loss: 4.8426 - acc: 0.017 - ETA: 2s - loss: 4.8422 - acc: 0.017 - ETA: 2s - loss: 4.8423 - acc: 0.017 - ETA: 2s - loss: 4.8421 - acc: 0.017 - ETA: 1s - loss: 4.8422 - acc: 0.017 - ETA: 1s - loss: 4.8419 - acc: 0.017 - ETA: 1s - loss: 4.8421 - acc: 0.017 - ETA: 1s - loss: 4.8421 - acc: 0.017 - ETA: 1s - loss: 4.8423 - acc: 0.017 - ETA: 1s - loss: 4.8422 - acc: 0.017 - ETA: 1s - loss: 4.8422 - acc: 0.017 - ETA: 0s - loss: 4.8423 - acc: 0.017 - ETA: 0s - loss: 4.8427 - acc: 0.017 - ETA: 0s - loss: 4.8428 - acc: 0.017 - ETA: 0s - loss: 4.8429 - acc: 0.017 - ETA: 0s - loss: 4.8432 - acc: 0.017 - ETA: 0s - loss: 4.8432 - acc: 0.017 - 68s 164ms/step - loss: 4.8429 - acc: 0.0171 - val_loss: 4.8253 - val_acc: 0.0293\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 4.82132\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/417 [==============>...............] - ETA: 39s - loss: 4.9833 - acc: 0.0000e+ - ETA: 40s - loss: 4.9402 - acc: 0.0000e+ - ETA: 40s - loss: 4.8722 - acc: 0.0000e+ - ETA: 40s - loss: 4.8658 - acc: 0.0156   - ETA: 40s - loss: 4.8827 - acc: 0.01 - ETA: 40s - loss: 4.8743 - acc: 0.01 - ETA: 40s - loss: 4.8679 - acc: 0.01 - ETA: 40s - loss: 4.8660 - acc: 0.01 - ETA: 40s - loss: 4.8598 - acc: 0.02 - ETA: 40s - loss: 4.8606 - acc: 0.01 - ETA: 40s - loss: 4.8465 - acc: 0.01 - ETA: 40s - loss: 4.8419 - acc: 0.02 - ETA: 40s - loss: 4.8392 - acc: 0.01 - ETA: 40s - loss: 4.8454 - acc: 0.01 - ETA: 39s - loss: 4.8422 - acc: 0.01 - ETA: 39s - loss: 4.8366 - acc: 0.01 - ETA: 39s - loss: 4.8369 - acc: 0.01 - ETA: 39s - loss: 4.8359 - acc: 0.01 - ETA: 39s - loss: 4.8382 - acc: 0.01 - ETA: 39s - loss: 4.8440 - acc: 0.01 - ETA: 39s - loss: 4.8376 - acc: 0.01 - ETA: 38s - loss: 4.8453 - acc: 0.01 - ETA: 39s - loss: 4.8484 - acc: 0.01 - ETA: 41s - loss: 4.8474 - acc: 0.01 - ETA: 42s - loss: 4.8478 - acc: 0.01 - ETA: 43s - loss: 4.8501 - acc: 0.01 - ETA: 44s - loss: 4.8545 - acc: 0.01 - ETA: 45s - loss: 4.8539 - acc: 0.01 - ETA: 45s - loss: 4.8543 - acc: 0.01 - ETA: 45s - loss: 4.8532 - acc: 0.01 - ETA: 45s - loss: 4.8504 - acc: 0.01 - ETA: 45s - loss: 4.8505 - acc: 0.01 - ETA: 46s - loss: 4.8511 - acc: 0.01 - ETA: 47s - loss: 4.8501 - acc: 0.01 - ETA: 47s - loss: 4.8490 - acc: 0.01 - ETA: 47s - loss: 4.8493 - acc: 0.01 - ETA: 47s - loss: 4.8513 - acc: 0.01 - ETA: 47s - loss: 4.8514 - acc: 0.01 - ETA: 47s - loss: 4.8521 - acc: 0.01 - ETA: 48s - loss: 4.8481 - acc: 0.01 - ETA: 48s - loss: 4.8466 - acc: 0.01 - ETA: 48s - loss: 4.8461 - acc: 0.01 - ETA: 48s - loss: 4.8456 - acc: 0.01 - ETA: 48s - loss: 4.8460 - acc: 0.01 - ETA: 49s - loss: 4.8462 - acc: 0.01 - ETA: 49s - loss: 4.8472 - acc: 0.01 - ETA: 50s - loss: 4.8425 - acc: 0.01 - ETA: 50s - loss: 4.8418 - acc: 0.01 - ETA: 50s - loss: 4.8426 - acc: 0.01 - ETA: 51s - loss: 4.8432 - acc: 0.01 - ETA: 51s - loss: 4.8450 - acc: 0.01 - ETA: 51s - loss: 4.8432 - acc: 0.01 - ETA: 51s - loss: 4.8414 - acc: 0.01 - ETA: 52s - loss: 4.8418 - acc: 0.01 - ETA: 52s - loss: 4.8426 - acc: 0.01 - ETA: 52s - loss: 4.8425 - acc: 0.01 - ETA: 52s - loss: 4.8410 - acc: 0.01 - ETA: 53s - loss: 4.8420 - acc: 0.01 - ETA: 52s - loss: 4.8422 - acc: 0.01 - ETA: 52s - loss: 4.8426 - acc: 0.01 - ETA: 52s - loss: 4.8433 - acc: 0.01 - ETA: 52s - loss: 4.8450 - acc: 0.01 - ETA: 52s - loss: 4.8454 - acc: 0.01 - ETA: 52s - loss: 4.8462 - acc: 0.01 - ETA: 52s - loss: 4.8453 - acc: 0.01 - ETA: 51s - loss: 4.8468 - acc: 0.01 - ETA: 51s - loss: 4.8461 - acc: 0.01 - ETA: 51s - loss: 4.8452 - acc: 0.01 - ETA: 51s - loss: 4.8455 - acc: 0.01 - ETA: 51s - loss: 4.8455 - acc: 0.01 - ETA: 51s - loss: 4.8463 - acc: 0.01 - ETA: 51s - loss: 4.8465 - acc: 0.01 - ETA: 51s - loss: 4.8450 - acc: 0.01 - ETA: 51s - loss: 4.8455 - acc: 0.01 - ETA: 51s - loss: 4.8452 - acc: 0.01 - ETA: 51s - loss: 4.8452 - acc: 0.01 - ETA: 51s - loss: 4.8467 - acc: 0.01 - ETA: 51s - loss: 4.8461 - acc: 0.01 - ETA: 51s - loss: 4.8458 - acc: 0.01 - ETA: 51s - loss: 4.8457 - acc: 0.01 - ETA: 51s - loss: 4.8456 - acc: 0.01 - ETA: 51s - loss: 4.8435 - acc: 0.01 - ETA: 50s - loss: 4.8430 - acc: 0.01 - ETA: 50s - loss: 4.8432 - acc: 0.01 - ETA: 51s - loss: 4.8427 - acc: 0.01 - ETA: 51s - loss: 4.8430 - acc: 0.01 - ETA: 50s - loss: 4.8438 - acc: 0.01 - ETA: 51s - loss: 4.8434 - acc: 0.01 - ETA: 51s - loss: 4.8435 - acc: 0.01 - ETA: 51s - loss: 4.8437 - acc: 0.01 - ETA: 51s - loss: 4.8444 - acc: 0.01 - ETA: 51s - loss: 4.8437 - acc: 0.01 - ETA: 51s - loss: 4.8435 - acc: 0.01 - ETA: 51s - loss: 4.8424 - acc: 0.01 - ETA: 51s - loss: 4.8420 - acc: 0.01 - ETA: 51s - loss: 4.8416 - acc: 0.01 - ETA: 51s - loss: 4.8415 - acc: 0.01 - ETA: 50s - loss: 4.8420 - acc: 0.01 - ETA: 50s - loss: 4.8418 - acc: 0.01 - ETA: 50s - loss: 4.8406 - acc: 0.01 - ETA: 50s - loss: 4.8412 - acc: 0.01 - ETA: 50s - loss: 4.8414 - acc: 0.01 - ETA: 49s - loss: 4.8409 - acc: 0.01 - ETA: 49s - loss: 4.8409 - acc: 0.01 - ETA: 49s - loss: 4.8405 - acc: 0.01 - ETA: 49s - loss: 4.8400 - acc: 0.01 - ETA: 49s - loss: 4.8395 - acc: 0.01 - ETA: 49s - loss: 4.8394 - acc: 0.01 - ETA: 49s - loss: 4.8400 - acc: 0.01 - ETA: 48s - loss: 4.8406 - acc: 0.01 - ETA: 48s - loss: 4.8413 - acc: 0.01 - ETA: 48s - loss: 4.8413 - acc: 0.01 - ETA: 48s - loss: 4.8404 - acc: 0.01 - ETA: 48s - loss: 4.8408 - acc: 0.01 - ETA: 48s - loss: 4.8416 - acc: 0.01 - ETA: 48s - loss: 4.8415 - acc: 0.01 - ETA: 47s - loss: 4.8424 - acc: 0.01 - ETA: 47s - loss: 4.8420 - acc: 0.01 - ETA: 48s - loss: 4.8416 - acc: 0.01 - ETA: 47s - loss: 4.8421 - acc: 0.01 - ETA: 47s - loss: 4.8419 - acc: 0.01 - ETA: 47s - loss: 4.8422 - acc: 0.01 - ETA: 47s - loss: 4.8435 - acc: 0.01 - ETA: 47s - loss: 4.8427 - acc: 0.01 - ETA: 46s - loss: 4.8432 - acc: 0.01 - ETA: 46s - loss: 4.8438 - acc: 0.01 - ETA: 46s - loss: 4.8443 - acc: 0.01 - ETA: 46s - loss: 4.8448 - acc: 0.01 - ETA: 46s - loss: 4.8449 - acc: 0.01 - ETA: 46s - loss: 4.8445 - acc: 0.01 - ETA: 46s - loss: 4.8450 - acc: 0.01 - ETA: 46s - loss: 4.8447 - acc: 0.01 - ETA: 46s - loss: 4.8446 - acc: 0.01 - ETA: 46s - loss: 4.8430 - acc: 0.01 - ETA: 45s - loss: 4.8435 - acc: 0.01 - ETA: 45s - loss: 4.8434 - acc: 0.01 - ETA: 45s - loss: 4.8440 - acc: 0.01 - ETA: 45s - loss: 4.8444 - acc: 0.01 - ETA: 45s - loss: 4.8440 - acc: 0.01 - ETA: 45s - loss: 4.8435 - acc: 0.01 - ETA: 45s - loss: 4.8430 - acc: 0.01 - ETA: 45s - loss: 4.8432 - acc: 0.01 - ETA: 44s - loss: 4.8433 - acc: 0.01 - ETA: 44s - loss: 4.8435 - acc: 0.01 - ETA: 44s - loss: 4.8436 - acc: 0.01 - ETA: 44s - loss: 4.8440 - acc: 0.01 - ETA: 44s - loss: 4.8444 - acc: 0.01 - ETA: 44s - loss: 4.8438 - acc: 0.01 - ETA: 43s - loss: 4.8442 - acc: 0.01 - ETA: 43s - loss: 4.8438 - acc: 0.01 - ETA: 43s - loss: 4.8435 - acc: 0.01 - ETA: 43s - loss: 4.8439 - acc: 0.01 - ETA: 43s - loss: 4.8432 - acc: 0.01 - ETA: 43s - loss: 4.8425 - acc: 0.01 - ETA: 42s - loss: 4.8426 - acc: 0.01 - ETA: 42s - loss: 4.8418 - acc: 0.01 - ETA: 42s - loss: 4.8411 - acc: 0.01 - ETA: 42s - loss: 4.8414 - acc: 0.01 - ETA: 42s - loss: 4.8423 - acc: 0.01 - ETA: 42s - loss: 4.8421 - acc: 0.01 - ETA: 42s - loss: 4.8413 - acc: 0.01 - ETA: 41s - loss: 4.8415 - acc: 0.01 - ETA: 41s - loss: 4.8418 - acc: 0.01 - ETA: 41s - loss: 4.8413 - acc: 0.01 - ETA: 41s - loss: 4.8410 - acc: 0.01 - ETA: 41s - loss: 4.8414 - acc: 0.01 - ETA: 41s - loss: 4.8418 - acc: 0.01 - ETA: 40s - loss: 4.8417 - acc: 0.01 - ETA: 40s - loss: 4.8416 - acc: 0.01 - ETA: 40s - loss: 4.8414 - acc: 0.01 - ETA: 40s - loss: 4.8414 - acc: 0.01 - ETA: 40s - loss: 4.8416 - acc: 0.01 - ETA: 40s - loss: 4.8419 - acc: 0.01 - ETA: 39s - loss: 4.8420 - acc: 0.01 - ETA: 39s - loss: 4.8414 - acc: 0.01 - ETA: 39s - loss: 4.8414 - acc: 0.01 - ETA: 39s - loss: 4.8414 - acc: 0.01 - ETA: 39s - loss: 4.8416 - acc: 0.01 - ETA: 39s - loss: 4.8421 - acc: 0.01 - ETA: 39s - loss: 4.8424 - acc: 0.01 - ETA: 39s - loss: 4.8428 - acc: 0.01 - ETA: 39s - loss: 4.8421 - acc: 0.01 - ETA: 38s - loss: 4.8422 - acc: 0.01 - ETA: 38s - loss: 4.8421 - acc: 0.01 - ETA: 38s - loss: 4.8422 - acc: 0.01 - ETA: 38s - loss: 4.8427 - acc: 0.01 - ETA: 38s - loss: 4.8427 - acc: 0.01 - ETA: 38s - loss: 4.8422 - acc: 0.01 - ETA: 38s - loss: 4.8424 - acc: 0.01 - ETA: 37s - loss: 4.8420 - acc: 0.01 - ETA: 37s - loss: 4.8418 - acc: 0.01 - ETA: 37s - loss: 4.8417 - acc: 0.01 - ETA: 37s - loss: 4.8416 - acc: 0.01 - ETA: 37s - loss: 4.8415 - acc: 0.01 - ETA: 37s - loss: 4.8411 - acc: 0.01 - ETA: 36s - loss: 4.8412 - acc: 0.01 - ETA: 36s - loss: 4.8407 - acc: 0.01 - ETA: 36s - loss: 4.8407 - acc: 0.01 - ETA: 36s - loss: 4.8406 - acc: 0.01 - ETA: 36s - loss: 4.8403 - acc: 0.01 - ETA: 36s - loss: 4.8404 - acc: 0.01 - ETA: 35s - loss: 4.8402 - acc: 0.01 - ETA: 35s - loss: 4.8403 - acc: 0.01 - ETA: 35s - loss: 4.8396 - acc: 0.01 - ETA: 35s - loss: 4.8389 - acc: 0.01 - ETA: 35s - loss: 4.8391 - acc: 0.01 - ETA: 34s - loss: 4.8389 - acc: 0.01 - ETA: 34s - loss: 4.8388 - acc: 0.01 - ETA: 34s - loss: 4.8387 - acc: 0.01 - ETA: 34s - loss: 4.8387 - acc: 0.01 - ETA: 34s - loss: 4.8385 - acc: 0.01 - ETA: 34s - loss: 4.8382 - acc: 0.01 - ETA: 33s - loss: 4.8383 - acc: 0.01 - ETA: 33s - loss: 4.8385 - acc: 0.01 - ETA: 33s - loss: 4.8388 - acc: 0.0166"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 33s - loss: 4.8387 - acc: 0.01 - ETA: 33s - loss: 4.8385 - acc: 0.01 - ETA: 33s - loss: 4.8384 - acc: 0.01 - ETA: 33s - loss: 4.8383 - acc: 0.01 - ETA: 32s - loss: 4.8388 - acc: 0.01 - ETA: 32s - loss: 4.8386 - acc: 0.01 - ETA: 32s - loss: 4.8383 - acc: 0.01 - ETA: 32s - loss: 4.8377 - acc: 0.01 - ETA: 32s - loss: 4.8374 - acc: 0.01 - ETA: 32s - loss: 4.8372 - acc: 0.01 - ETA: 32s - loss: 4.8372 - acc: 0.01 - ETA: 31s - loss: 4.8376 - acc: 0.01 - ETA: 31s - loss: 4.8375 - acc: 0.01 - ETA: 31s - loss: 4.8377 - acc: 0.01 - ETA: 31s - loss: 4.8377 - acc: 0.01 - ETA: 31s - loss: 4.8381 - acc: 0.01 - ETA: 31s - loss: 4.8380 - acc: 0.01 - ETA: 30s - loss: 4.8382 - acc: 0.01 - ETA: 30s - loss: 4.8384 - acc: 0.01 - ETA: 30s - loss: 4.8382 - acc: 0.01 - ETA: 30s - loss: 4.8379 - acc: 0.01 - ETA: 30s - loss: 4.8377 - acc: 0.01 - ETA: 30s - loss: 4.8374 - acc: 0.01 - ETA: 29s - loss: 4.8375 - acc: 0.01 - ETA: 29s - loss: 4.8371 - acc: 0.01 - ETA: 29s - loss: 4.8369 - acc: 0.01 - ETA: 29s - loss: 4.8371 - acc: 0.01 - ETA: 29s - loss: 4.8369 - acc: 0.01 - ETA: 29s - loss: 4.8369 - acc: 0.01 - ETA: 29s - loss: 4.8364 - acc: 0.01 - ETA: 28s - loss: 4.8369 - acc: 0.01 - ETA: 28s - loss: 4.8366 - acc: 0.01 - ETA: 28s - loss: 4.8372 - acc: 0.01 - ETA: 28s - loss: 4.8375 - acc: 0.01 - ETA: 28s - loss: 4.8383 - acc: 0.01 - ETA: 28s - loss: 4.8381 - acc: 0.01 - ETA: 27s - loss: 4.8385 - acc: 0.01 - ETA: 27s - loss: 4.8385 - acc: 0.01 - ETA: 27s - loss: 4.8383 - acc: 0.01 - ETA: 27s - loss: 4.8382 - acc: 0.01 - ETA: 27s - loss: 4.8378 - acc: 0.01 - ETA: 26s - loss: 4.8380 - acc: 0.01 - ETA: 26s - loss: 4.8380 - acc: 0.01 - ETA: 26s - loss: 4.8378 - acc: 0.01 - ETA: 26s - loss: 4.8379 - acc: 0.01 - ETA: 26s - loss: 4.8378 - acc: 0.01 - ETA: 26s - loss: 4.8380 - acc: 0.01 - ETA: 25s - loss: 4.8380 - acc: 0.01 - ETA: 25s - loss: 4.8381 - acc: 0.01 - ETA: 25s - loss: 4.8376 - acc: 0.01 - ETA: 25s - loss: 4.8379 - acc: 0.01 - ETA: 25s - loss: 4.8377 - acc: 0.01 - ETA: 24s - loss: 4.8379 - acc: 0.01 - ETA: 24s - loss: 4.8378 - acc: 0.01 - ETA: 24s - loss: 4.8370 - acc: 0.01 - ETA: 24s - loss: 4.8371 - acc: 0.01 - ETA: 24s - loss: 4.8370 - acc: 0.01 - ETA: 24s - loss: 4.8375 - acc: 0.01 - ETA: 23s - loss: 4.8377 - acc: 0.01 - ETA: 23s - loss: 4.8377 - acc: 0.01 - ETA: 23s - loss: 4.8372 - acc: 0.01 - ETA: 23s - loss: 4.8374 - acc: 0.01 - ETA: 23s - loss: 4.8377 - acc: 0.01 - ETA: 23s - loss: 4.8376 - acc: 0.01 - ETA: 22s - loss: 4.8379 - acc: 0.01 - ETA: 22s - loss: 4.8380 - acc: 0.01 - ETA: 22s - loss: 4.8376 - acc: 0.01 - ETA: 22s - loss: 4.8377 - acc: 0.01 - ETA: 22s - loss: 4.8379 - acc: 0.01 - ETA: 22s - loss: 4.8378 - acc: 0.01 - ETA: 21s - loss: 4.8381 - acc: 0.01 - ETA: 21s - loss: 4.8384 - acc: 0.01 - ETA: 21s - loss: 4.8383 - acc: 0.01 - ETA: 21s - loss: 4.8384 - acc: 0.01 - ETA: 21s - loss: 4.8386 - acc: 0.01 - ETA: 21s - loss: 4.8388 - acc: 0.01 - ETA: 20s - loss: 4.8387 - acc: 0.01 - ETA: 20s - loss: 4.8385 - acc: 0.01 - ETA: 20s - loss: 4.8385 - acc: 0.01 - ETA: 20s - loss: 4.8386 - acc: 0.01 - ETA: 20s - loss: 4.8387 - acc: 0.01 - ETA: 20s - loss: 4.8390 - acc: 0.01 - ETA: 19s - loss: 4.8392 - acc: 0.01 - ETA: 19s - loss: 4.8392 - acc: 0.01 - ETA: 19s - loss: 4.8393 - acc: 0.01 - ETA: 19s - loss: 4.8391 - acc: 0.01 - ETA: 19s - loss: 4.8391 - acc: 0.01 - ETA: 19s - loss: 4.8391 - acc: 0.01 - ETA: 18s - loss: 4.8393 - acc: 0.01 - ETA: 18s - loss: 4.8388 - acc: 0.01 - ETA: 18s - loss: 4.8388 - acc: 0.01 - ETA: 18s - loss: 4.8387 - acc: 0.01 - ETA: 18s - loss: 4.8384 - acc: 0.01 - ETA: 18s - loss: 4.8385 - acc: 0.01 - ETA: 17s - loss: 4.8389 - acc: 0.01 - ETA: 17s - loss: 4.8391 - acc: 0.01 - ETA: 17s - loss: 4.8392 - acc: 0.01 - ETA: 17s - loss: 4.8393 - acc: 0.01 - ETA: 17s - loss: 4.8395 - acc: 0.01 - ETA: 17s - loss: 4.8392 - acc: 0.01 - ETA: 16s - loss: 4.8396 - acc: 0.01 - ETA: 16s - loss: 4.8395 - acc: 0.01 - ETA: 16s - loss: 4.8397 - acc: 0.01 - ETA: 16s - loss: 4.8396 - acc: 0.01 - ETA: 16s - loss: 4.8396 - acc: 0.01 - ETA: 16s - loss: 4.8395 - acc: 0.01 - ETA: 15s - loss: 4.8396 - acc: 0.01 - ETA: 15s - loss: 4.8396 - acc: 0.01 - ETA: 15s - loss: 4.8395 - acc: 0.01 - ETA: 15s - loss: 4.8395 - acc: 0.01 - ETA: 15s - loss: 4.8396 - acc: 0.01 - ETA: 15s - loss: 4.8397 - acc: 0.01 - ETA: 14s - loss: 4.8397 - acc: 0.01 - ETA: 14s - loss: 4.8396 - acc: 0.01 - ETA: 14s - loss: 4.8401 - acc: 0.01 - ETA: 14s - loss: 4.8401 - acc: 0.01 - ETA: 14s - loss: 4.8403 - acc: 0.01 - ETA: 14s - loss: 4.8405 - acc: 0.01 - ETA: 13s - loss: 4.8400 - acc: 0.01 - ETA: 13s - loss: 4.8401 - acc: 0.01 - ETA: 13s - loss: 4.8399 - acc: 0.01 - ETA: 13s - loss: 4.8399 - acc: 0.01 - ETA: 13s - loss: 4.8400 - acc: 0.01 - ETA: 13s - loss: 4.8400 - acc: 0.01 - ETA: 12s - loss: 4.8402 - acc: 0.01 - ETA: 12s - loss: 4.8402 - acc: 0.01 - ETA: 12s - loss: 4.8401 - acc: 0.01 - ETA: 12s - loss: 4.8398 - acc: 0.01 - ETA: 12s - loss: 4.8396 - acc: 0.01 - ETA: 12s - loss: 4.8394 - acc: 0.01 - ETA: 11s - loss: 4.8390 - acc: 0.01 - ETA: 11s - loss: 4.8388 - acc: 0.01 - ETA: 11s - loss: 4.8389 - acc: 0.01 - ETA: 11s - loss: 4.8385 - acc: 0.01 - ETA: 11s - loss: 4.8385 - acc: 0.01 - ETA: 11s - loss: 4.8384 - acc: 0.01 - ETA: 10s - loss: 4.8384 - acc: 0.01 - ETA: 10s - loss: 4.8382 - acc: 0.01 - ETA: 10s - loss: 4.8382 - acc: 0.01 - ETA: 10s - loss: 4.8385 - acc: 0.01 - ETA: 10s - loss: 4.8384 - acc: 0.01 - ETA: 10s - loss: 4.8384 - acc: 0.01 - ETA: 9s - loss: 4.8380 - acc: 0.0173 - ETA: 9s - loss: 4.8380 - acc: 0.017 - ETA: 9s - loss: 4.8379 - acc: 0.017 - ETA: 9s - loss: 4.8379 - acc: 0.017 - ETA: 9s - loss: 4.8378 - acc: 0.017 - ETA: 9s - loss: 4.8378 - acc: 0.017 - ETA: 8s - loss: 4.8379 - acc: 0.017 - ETA: 8s - loss: 4.8378 - acc: 0.017 - ETA: 8s - loss: 4.8379 - acc: 0.017 - ETA: 8s - loss: 4.8379 - acc: 0.017 - ETA: 8s - loss: 4.8378 - acc: 0.017 - ETA: 8s - loss: 4.8379 - acc: 0.017 - ETA: 7s - loss: 4.8383 - acc: 0.017 - ETA: 7s - loss: 4.8381 - acc: 0.017 - ETA: 7s - loss: 4.8384 - acc: 0.017 - ETA: 7s - loss: 4.8383 - acc: 0.017 - ETA: 7s - loss: 4.8382 - acc: 0.017 - ETA: 7s - loss: 4.8382 - acc: 0.017 - ETA: 6s - loss: 4.8384 - acc: 0.017 - ETA: 6s - loss: 4.8381 - acc: 0.017 - ETA: 6s - loss: 4.8383 - acc: 0.017 - ETA: 6s - loss: 4.8385 - acc: 0.017 - ETA: 6s - loss: 4.8389 - acc: 0.017 - ETA: 6s - loss: 4.8388 - acc: 0.017 - ETA: 5s - loss: 4.8388 - acc: 0.017 - ETA: 5s - loss: 4.8390 - acc: 0.017 - ETA: 5s - loss: 4.8390 - acc: 0.017 - ETA: 5s - loss: 4.8389 - acc: 0.017 - ETA: 5s - loss: 4.8390 - acc: 0.017 - ETA: 5s - loss: 4.8392 - acc: 0.017 - ETA: 4s - loss: 4.8392 - acc: 0.017 - ETA: 4s - loss: 4.8392 - acc: 0.017 - ETA: 4s - loss: 4.8398 - acc: 0.017 - ETA: 4s - loss: 4.8395 - acc: 0.016 - ETA: 4s - loss: 4.8396 - acc: 0.016 - ETA: 4s - loss: 4.8397 - acc: 0.016 - ETA: 3s - loss: 4.8396 - acc: 0.017 - ETA: 3s - loss: 4.8398 - acc: 0.017 - ETA: 3s - loss: 4.8397 - acc: 0.017 - ETA: 3s - loss: 4.8396 - acc: 0.017 - ETA: 3s - loss: 4.8396 - acc: 0.017 - ETA: 3s - loss: 4.8399 - acc: 0.016 - ETA: 2s - loss: 4.8398 - acc: 0.016 - ETA: 2s - loss: 4.8399 - acc: 0.017 - ETA: 2s - loss: 4.8401 - acc: 0.016 - ETA: 2s - loss: 4.8402 - acc: 0.016 - ETA: 2s - loss: 4.8402 - acc: 0.016 - ETA: 2s - loss: 4.8402 - acc: 0.016 - ETA: 1s - loss: 4.8404 - acc: 0.016 - ETA: 1s - loss: 4.8399 - acc: 0.016 - ETA: 1s - loss: 4.8401 - acc: 0.016 - ETA: 1s - loss: 4.8403 - acc: 0.016 - ETA: 1s - loss: 4.8402 - acc: 0.016 - ETA: 1s - loss: 4.8399 - acc: 0.016 - ETA: 0s - loss: 4.8400 - acc: 0.016 - ETA: 0s - loss: 4.8399 - acc: 0.016 - ETA: 0s - loss: 4.8403 - acc: 0.016 - ETA: 0s - loss: 4.8404 - acc: 0.016 - ETA: 0s - loss: 4.8401 - acc: 0.017 - 74s 177ms/step - loss: 4.8401 - acc: 0.0169 - val_loss: 4.8212 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00035: val_loss improved from 4.82132 to 4.82115, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/417 [==============>...............] - ETA: 41s - loss: 4.9658 - acc: 0.0000e+ - ETA: 41s - loss: 4.8666 - acc: 0.0625   - ETA: 41s - loss: 4.8426 - acc: 0.04 - ETA: 41s - loss: 4.8255 - acc: 0.04 - ETA: 41s - loss: 4.8375 - acc: 0.03 - ETA: 41s - loss: 4.8501 - acc: 0.03 - ETA: 41s - loss: 4.8430 - acc: 0.02 - ETA: 41s - loss: 4.8427 - acc: 0.02 - ETA: 41s - loss: 4.8353 - acc: 0.02 - ETA: 40s - loss: 4.8363 - acc: 0.02 - ETA: 40s - loss: 4.8377 - acc: 0.02 - ETA: 40s - loss: 4.8459 - acc: 0.02 - ETA: 40s - loss: 4.8409 - acc: 0.02 - ETA: 40s - loss: 4.8393 - acc: 0.02 - ETA: 40s - loss: 4.8428 - acc: 0.02 - ETA: 40s - loss: 4.8369 - acc: 0.02 - ETA: 40s - loss: 4.8402 - acc: 0.02 - ETA: 39s - loss: 4.8420 - acc: 0.02 - ETA: 39s - loss: 4.8340 - acc: 0.02 - ETA: 39s - loss: 4.8373 - acc: 0.02 - ETA: 39s - loss: 4.8368 - acc: 0.02 - ETA: 39s - loss: 4.8357 - acc: 0.02 - ETA: 39s - loss: 4.8347 - acc: 0.02 - ETA: 39s - loss: 4.8319 - acc: 0.02 - ETA: 39s - loss: 4.8368 - acc: 0.02 - ETA: 41s - loss: 4.8393 - acc: 0.02 - ETA: 42s - loss: 4.8398 - acc: 0.02 - ETA: 43s - loss: 4.8393 - acc: 0.02 - ETA: 44s - loss: 4.8402 - acc: 0.02 - ETA: 44s - loss: 4.8406 - acc: 0.02 - ETA: 45s - loss: 4.8391 - acc: 0.02 - ETA: 45s - loss: 4.8377 - acc: 0.02 - ETA: 45s - loss: 4.8352 - acc: 0.02 - ETA: 46s - loss: 4.8373 - acc: 0.02 - ETA: 46s - loss: 4.8392 - acc: 0.02 - ETA: 46s - loss: 4.8348 - acc: 0.02 - ETA: 46s - loss: 4.8356 - acc: 0.02 - ETA: 46s - loss: 4.8381 - acc: 0.02 - ETA: 46s - loss: 4.8405 - acc: 0.02 - ETA: 47s - loss: 4.8390 - acc: 0.02 - ETA: 48s - loss: 4.8406 - acc: 0.02 - ETA: 49s - loss: 4.8399 - acc: 0.02 - ETA: 48s - loss: 4.8374 - acc: 0.02 - ETA: 48s - loss: 4.8385 - acc: 0.01 - ETA: 48s - loss: 4.8394 - acc: 0.02 - ETA: 48s - loss: 4.8410 - acc: 0.02 - ETA: 48s - loss: 4.8439 - acc: 0.01 - ETA: 50s - loss: 4.8445 - acc: 0.01 - ETA: 51s - loss: 4.8417 - acc: 0.01 - ETA: 51s - loss: 4.8391 - acc: 0.01 - ETA: 51s - loss: 4.8388 - acc: 0.02 - ETA: 52s - loss: 4.8411 - acc: 0.02 - ETA: 52s - loss: 4.8413 - acc: 0.02 - ETA: 52s - loss: 4.8392 - acc: 0.02 - ETA: 52s - loss: 4.8399 - acc: 0.02 - ETA: 52s - loss: 4.8379 - acc: 0.02 - ETA: 52s - loss: 4.8381 - acc: 0.02 - ETA: 52s - loss: 4.8367 - acc: 0.02 - ETA: 52s - loss: 4.8368 - acc: 0.02 - ETA: 52s - loss: 4.8358 - acc: 0.02 - ETA: 52s - loss: 4.8353 - acc: 0.02 - ETA: 52s - loss: 4.8350 - acc: 0.02 - ETA: 52s - loss: 4.8350 - acc: 0.02 - ETA: 52s - loss: 4.8338 - acc: 0.02 - ETA: 51s - loss: 4.8335 - acc: 0.02 - ETA: 51s - loss: 4.8331 - acc: 0.02 - ETA: 51s - loss: 4.8331 - acc: 0.02 - ETA: 51s - loss: 4.8347 - acc: 0.02 - ETA: 51s - loss: 4.8330 - acc: 0.02 - ETA: 51s - loss: 4.8313 - acc: 0.02 - ETA: 51s - loss: 4.8318 - acc: 0.02 - ETA: 51s - loss: 4.8329 - acc: 0.02 - ETA: 51s - loss: 4.8325 - acc: 0.01 - ETA: 51s - loss: 4.8339 - acc: 0.02 - ETA: 51s - loss: 4.8347 - acc: 0.02 - ETA: 51s - loss: 4.8346 - acc: 0.01 - ETA: 51s - loss: 4.8351 - acc: 0.01 - ETA: 51s - loss: 4.8359 - acc: 0.01 - ETA: 51s - loss: 4.8351 - acc: 0.01 - ETA: 51s - loss: 4.8345 - acc: 0.01 - ETA: 51s - loss: 4.8352 - acc: 0.01 - ETA: 51s - loss: 4.8342 - acc: 0.01 - ETA: 51s - loss: 4.8338 - acc: 0.01 - ETA: 51s - loss: 4.8327 - acc: 0.02 - ETA: 51s - loss: 4.8325 - acc: 0.02 - ETA: 51s - loss: 4.8323 - acc: 0.02 - ETA: 50s - loss: 4.8326 - acc: 0.02 - ETA: 50s - loss: 4.8334 - acc: 0.01 - ETA: 50s - loss: 4.8335 - acc: 0.01 - ETA: 50s - loss: 4.8341 - acc: 0.01 - ETA: 50s - loss: 4.8337 - acc: 0.01 - ETA: 50s - loss: 4.8331 - acc: 0.01 - ETA: 50s - loss: 4.8325 - acc: 0.01 - ETA: 51s - loss: 4.8349 - acc: 0.01 - ETA: 50s - loss: 4.8339 - acc: 0.01 - ETA: 50s - loss: 4.8344 - acc: 0.01 - ETA: 50s - loss: 4.8344 - acc: 0.01 - ETA: 50s - loss: 4.8342 - acc: 0.01 - ETA: 50s - loss: 4.8332 - acc: 0.01 - ETA: 50s - loss: 4.8322 - acc: 0.02 - ETA: 49s - loss: 4.8329 - acc: 0.01 - ETA: 49s - loss: 4.8330 - acc: 0.01 - ETA: 49s - loss: 4.8343 - acc: 0.02 - ETA: 49s - loss: 4.8351 - acc: 0.01 - ETA: 49s - loss: 4.8336 - acc: 0.01 - ETA: 49s - loss: 4.8330 - acc: 0.01 - ETA: 48s - loss: 4.8338 - acc: 0.01 - ETA: 48s - loss: 4.8337 - acc: 0.02 - ETA: 48s - loss: 4.8333 - acc: 0.02 - ETA: 48s - loss: 4.8330 - acc: 0.02 - ETA: 48s - loss: 4.8324 - acc: 0.02 - ETA: 48s - loss: 4.8316 - acc: 0.02 - ETA: 48s - loss: 4.8318 - acc: 0.02 - ETA: 48s - loss: 4.8325 - acc: 0.02 - ETA: 48s - loss: 4.8331 - acc: 0.02 - ETA: 48s - loss: 4.8336 - acc: 0.01 - ETA: 48s - loss: 4.8333 - acc: 0.01 - ETA: 48s - loss: 4.8332 - acc: 0.01 - ETA: 48s - loss: 4.8320 - acc: 0.02 - ETA: 47s - loss: 4.8315 - acc: 0.02 - ETA: 47s - loss: 4.8326 - acc: 0.02 - ETA: 47s - loss: 4.8318 - acc: 0.02 - ETA: 47s - loss: 4.8313 - acc: 0.02 - ETA: 48s - loss: 4.8310 - acc: 0.02 - ETA: 47s - loss: 4.8310 - acc: 0.02 - ETA: 47s - loss: 4.8310 - acc: 0.02 - ETA: 47s - loss: 4.8305 - acc: 0.02 - ETA: 47s - loss: 4.8303 - acc: 0.02 - ETA: 47s - loss: 4.8305 - acc: 0.01 - ETA: 47s - loss: 4.8310 - acc: 0.01 - ETA: 47s - loss: 4.8312 - acc: 0.01 - ETA: 47s - loss: 4.8306 - acc: 0.01 - ETA: 46s - loss: 4.8304 - acc: 0.01 - ETA: 46s - loss: 4.8310 - acc: 0.01 - ETA: 46s - loss: 4.8317 - acc: 0.01 - ETA: 46s - loss: 4.8325 - acc: 0.01 - ETA: 46s - loss: 4.8332 - acc: 0.01 - ETA: 46s - loss: 4.8330 - acc: 0.01 - ETA: 45s - loss: 4.8326 - acc: 0.01 - ETA: 45s - loss: 4.8326 - acc: 0.01 - ETA: 45s - loss: 4.8324 - acc: 0.01 - ETA: 45s - loss: 4.8318 - acc: 0.01 - ETA: 45s - loss: 4.8317 - acc: 0.01 - ETA: 45s - loss: 4.8313 - acc: 0.01 - ETA: 44s - loss: 4.8319 - acc: 0.01 - ETA: 44s - loss: 4.8323 - acc: 0.01 - ETA: 44s - loss: 4.8317 - acc: 0.01 - ETA: 44s - loss: 4.8308 - acc: 0.01 - ETA: 44s - loss: 4.8315 - acc: 0.01 - ETA: 44s - loss: 4.8316 - acc: 0.01 - ETA: 43s - loss: 4.8316 - acc: 0.01 - ETA: 43s - loss: 4.8315 - acc: 0.01 - ETA: 43s - loss: 4.8311 - acc: 0.01 - ETA: 43s - loss: 4.8312 - acc: 0.01 - ETA: 43s - loss: 4.8301 - acc: 0.01 - ETA: 43s - loss: 4.8302 - acc: 0.01 - ETA: 43s - loss: 4.8299 - acc: 0.01 - ETA: 43s - loss: 4.8303 - acc: 0.01 - ETA: 43s - loss: 4.8310 - acc: 0.01 - ETA: 42s - loss: 4.8313 - acc: 0.01 - ETA: 42s - loss: 4.8308 - acc: 0.01 - ETA: 42s - loss: 4.8321 - acc: 0.01 - ETA: 42s - loss: 4.8324 - acc: 0.01 - ETA: 42s - loss: 4.8323 - acc: 0.01 - ETA: 42s - loss: 4.8328 - acc: 0.01 - ETA: 41s - loss: 4.8314 - acc: 0.02 - ETA: 41s - loss: 4.8317 - acc: 0.01 - ETA: 41s - loss: 4.8325 - acc: 0.01 - ETA: 41s - loss: 4.8322 - acc: 0.01 - ETA: 41s - loss: 4.8319 - acc: 0.01 - ETA: 40s - loss: 4.8319 - acc: 0.01 - ETA: 40s - loss: 4.8321 - acc: 0.01 - ETA: 40s - loss: 4.8325 - acc: 0.01 - ETA: 40s - loss: 4.8327 - acc: 0.01 - ETA: 40s - loss: 4.8329 - acc: 0.01 - ETA: 39s - loss: 4.8328 - acc: 0.01 - ETA: 39s - loss: 4.8325 - acc: 0.01 - ETA: 39s - loss: 4.8323 - acc: 0.01 - ETA: 39s - loss: 4.8323 - acc: 0.01 - ETA: 39s - loss: 4.8324 - acc: 0.01 - ETA: 38s - loss: 4.8317 - acc: 0.01 - ETA: 38s - loss: 4.8320 - acc: 0.01 - ETA: 38s - loss: 4.8325 - acc: 0.01 - ETA: 38s - loss: 4.8326 - acc: 0.01 - ETA: 38s - loss: 4.8323 - acc: 0.01 - ETA: 38s - loss: 4.8323 - acc: 0.01 - ETA: 37s - loss: 4.8318 - acc: 0.01 - ETA: 37s - loss: 4.8314 - acc: 0.01 - ETA: 37s - loss: 4.8311 - acc: 0.01 - ETA: 37s - loss: 4.8317 - acc: 0.01 - ETA: 37s - loss: 4.8323 - acc: 0.01 - ETA: 36s - loss: 4.8317 - acc: 0.01 - ETA: 36s - loss: 4.8318 - acc: 0.01 - ETA: 36s - loss: 4.8323 - acc: 0.01 - ETA: 36s - loss: 4.8325 - acc: 0.01 - ETA: 36s - loss: 4.8328 - acc: 0.01 - ETA: 36s - loss: 4.8327 - acc: 0.01 - ETA: 36s - loss: 4.8334 - acc: 0.01 - ETA: 35s - loss: 4.8332 - acc: 0.01 - ETA: 35s - loss: 4.8335 - acc: 0.01 - ETA: 35s - loss: 4.8336 - acc: 0.01 - ETA: 35s - loss: 4.8328 - acc: 0.01 - ETA: 35s - loss: 4.8331 - acc: 0.01 - ETA: 35s - loss: 4.8332 - acc: 0.01 - ETA: 34s - loss: 4.8329 - acc: 0.01 - ETA: 34s - loss: 4.8326 - acc: 0.01 - ETA: 34s - loss: 4.8329 - acc: 0.01 - ETA: 34s - loss: 4.8322 - acc: 0.01 - ETA: 34s - loss: 4.8330 - acc: 0.01 - ETA: 34s - loss: 4.8328 - acc: 0.01 - ETA: 33s - loss: 4.8331 - acc: 0.01 - ETA: 33s - loss: 4.8328 - acc: 0.01 - ETA: 33s - loss: 4.8327 - acc: 0.01 - ETA: 33s - loss: 4.8330 - acc: 0.01 - ETA: 33s - loss: 4.8336 - acc: 0.0174"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 33s - loss: 4.8346 - acc: 0.01 - ETA: 33s - loss: 4.8350 - acc: 0.01 - ETA: 32s - loss: 4.8352 - acc: 0.01 - ETA: 32s - loss: 4.8351 - acc: 0.01 - ETA: 32s - loss: 4.8352 - acc: 0.01 - ETA: 32s - loss: 4.8358 - acc: 0.01 - ETA: 32s - loss: 4.8353 - acc: 0.01 - ETA: 32s - loss: 4.8350 - acc: 0.01 - ETA: 31s - loss: 4.8356 - acc: 0.01 - ETA: 31s - loss: 4.8348 - acc: 0.01 - ETA: 31s - loss: 4.8346 - acc: 0.01 - ETA: 31s - loss: 4.8350 - acc: 0.01 - ETA: 31s - loss: 4.8347 - acc: 0.01 - ETA: 30s - loss: 4.8353 - acc: 0.01 - ETA: 30s - loss: 4.8354 - acc: 0.01 - ETA: 30s - loss: 4.8352 - acc: 0.01 - ETA: 30s - loss: 4.8359 - acc: 0.01 - ETA: 30s - loss: 4.8362 - acc: 0.01 - ETA: 30s - loss: 4.8365 - acc: 0.01 - ETA: 29s - loss: 4.8365 - acc: 0.01 - ETA: 29s - loss: 4.8365 - acc: 0.01 - ETA: 29s - loss: 4.8365 - acc: 0.01 - ETA: 29s - loss: 4.8367 - acc: 0.01 - ETA: 29s - loss: 4.8369 - acc: 0.01 - ETA: 29s - loss: 4.8367 - acc: 0.01 - ETA: 28s - loss: 4.8365 - acc: 0.01 - ETA: 28s - loss: 4.8365 - acc: 0.01 - ETA: 28s - loss: 4.8367 - acc: 0.01 - ETA: 28s - loss: 4.8365 - acc: 0.01 - ETA: 28s - loss: 4.8362 - acc: 0.01 - ETA: 28s - loss: 4.8354 - acc: 0.01 - ETA: 27s - loss: 4.8353 - acc: 0.01 - ETA: 27s - loss: 4.8351 - acc: 0.01 - ETA: 27s - loss: 4.8348 - acc: 0.01 - ETA: 27s - loss: 4.8348 - acc: 0.01 - ETA: 27s - loss: 4.8348 - acc: 0.01 - ETA: 27s - loss: 4.8346 - acc: 0.01 - ETA: 27s - loss: 4.8346 - acc: 0.01 - ETA: 26s - loss: 4.8349 - acc: 0.01 - ETA: 26s - loss: 4.8350 - acc: 0.01 - ETA: 26s - loss: 4.8353 - acc: 0.01 - ETA: 26s - loss: 4.8351 - acc: 0.01 - ETA: 26s - loss: 4.8351 - acc: 0.01 - ETA: 26s - loss: 4.8352 - acc: 0.01 - ETA: 25s - loss: 4.8348 - acc: 0.01 - ETA: 25s - loss: 4.8347 - acc: 0.01 - ETA: 25s - loss: 4.8345 - acc: 0.01 - ETA: 25s - loss: 4.8344 - acc: 0.01 - ETA: 25s - loss: 4.8342 - acc: 0.01 - ETA: 25s - loss: 4.8342 - acc: 0.01 - ETA: 25s - loss: 4.8342 - acc: 0.01 - ETA: 24s - loss: 4.8342 - acc: 0.01 - ETA: 24s - loss: 4.8342 - acc: 0.01 - ETA: 24s - loss: 4.8344 - acc: 0.01 - ETA: 24s - loss: 4.8347 - acc: 0.01 - ETA: 24s - loss: 4.8349 - acc: 0.01 - ETA: 24s - loss: 4.8350 - acc: 0.01 - ETA: 23s - loss: 4.8348 - acc: 0.01 - ETA: 23s - loss: 4.8349 - acc: 0.01 - ETA: 23s - loss: 4.8348 - acc: 0.01 - ETA: 23s - loss: 4.8352 - acc: 0.01 - ETA: 23s - loss: 4.8348 - acc: 0.01 - ETA: 23s - loss: 4.8354 - acc: 0.01 - ETA: 22s - loss: 4.8356 - acc: 0.01 - ETA: 22s - loss: 4.8352 - acc: 0.01 - ETA: 22s - loss: 4.8350 - acc: 0.01 - ETA: 22s - loss: 4.8350 - acc: 0.01 - ETA: 22s - loss: 4.8347 - acc: 0.01 - ETA: 22s - loss: 4.8351 - acc: 0.01 - ETA: 21s - loss: 4.8353 - acc: 0.01 - ETA: 21s - loss: 4.8351 - acc: 0.01 - ETA: 21s - loss: 4.8351 - acc: 0.01 - ETA: 21s - loss: 4.8346 - acc: 0.01 - ETA: 21s - loss: 4.8348 - acc: 0.01 - ETA: 21s - loss: 4.8348 - acc: 0.01 - ETA: 20s - loss: 4.8349 - acc: 0.01 - ETA: 20s - loss: 4.8348 - acc: 0.01 - ETA: 20s - loss: 4.8349 - acc: 0.01 - ETA: 20s - loss: 4.8353 - acc: 0.01 - ETA: 20s - loss: 4.8352 - acc: 0.01 - ETA: 20s - loss: 4.8350 - acc: 0.01 - ETA: 19s - loss: 4.8351 - acc: 0.01 - ETA: 19s - loss: 4.8351 - acc: 0.01 - ETA: 19s - loss: 4.8350 - acc: 0.01 - ETA: 19s - loss: 4.8353 - acc: 0.01 - ETA: 19s - loss: 4.8354 - acc: 0.01 - ETA: 19s - loss: 4.8355 - acc: 0.01 - ETA: 18s - loss: 4.8355 - acc: 0.01 - ETA: 18s - loss: 4.8352 - acc: 0.01 - ETA: 18s - loss: 4.8351 - acc: 0.01 - ETA: 18s - loss: 4.8352 - acc: 0.01 - ETA: 18s - loss: 4.8352 - acc: 0.01 - ETA: 18s - loss: 4.8354 - acc: 0.01 - ETA: 17s - loss: 4.8354 - acc: 0.01 - ETA: 17s - loss: 4.8351 - acc: 0.01 - ETA: 17s - loss: 4.8348 - acc: 0.01 - ETA: 17s - loss: 4.8350 - acc: 0.01 - ETA: 17s - loss: 4.8352 - acc: 0.01 - ETA: 17s - loss: 4.8350 - acc: 0.01 - ETA: 16s - loss: 4.8347 - acc: 0.01 - ETA: 16s - loss: 4.8354 - acc: 0.01 - ETA: 16s - loss: 4.8354 - acc: 0.01 - ETA: 16s - loss: 4.8354 - acc: 0.01 - ETA: 16s - loss: 4.8354 - acc: 0.01 - ETA: 16s - loss: 4.8354 - acc: 0.01 - ETA: 16s - loss: 4.8353 - acc: 0.01 - ETA: 15s - loss: 4.8356 - acc: 0.01 - ETA: 15s - loss: 4.8353 - acc: 0.01 - ETA: 15s - loss: 4.8351 - acc: 0.01 - ETA: 15s - loss: 4.8349 - acc: 0.01 - ETA: 15s - loss: 4.8351 - acc: 0.01 - ETA: 15s - loss: 4.8353 - acc: 0.01 - ETA: 14s - loss: 4.8353 - acc: 0.01 - ETA: 14s - loss: 4.8356 - acc: 0.01 - ETA: 14s - loss: 4.8354 - acc: 0.01 - ETA: 14s - loss: 4.8358 - acc: 0.01 - ETA: 14s - loss: 4.8357 - acc: 0.01 - ETA: 13s - loss: 4.8358 - acc: 0.01 - ETA: 13s - loss: 4.8356 - acc: 0.01 - ETA: 13s - loss: 4.8358 - acc: 0.01 - ETA: 13s - loss: 4.8354 - acc: 0.01 - ETA: 13s - loss: 4.8351 - acc: 0.01 - ETA: 13s - loss: 4.8352 - acc: 0.01 - ETA: 12s - loss: 4.8352 - acc: 0.01 - ETA: 12s - loss: 4.8353 - acc: 0.01 - ETA: 12s - loss: 4.8355 - acc: 0.01 - ETA: 12s - loss: 4.8352 - acc: 0.01 - ETA: 12s - loss: 4.8348 - acc: 0.01 - ETA: 12s - loss: 4.8352 - acc: 0.01 - ETA: 11s - loss: 4.8353 - acc: 0.01 - ETA: 11s - loss: 4.8356 - acc: 0.01 - ETA: 11s - loss: 4.8352 - acc: 0.01 - ETA: 11s - loss: 4.8353 - acc: 0.01 - ETA: 11s - loss: 4.8349 - acc: 0.01 - ETA: 11s - loss: 4.8349 - acc: 0.01 - ETA: 11s - loss: 4.8354 - acc: 0.01 - ETA: 10s - loss: 4.8355 - acc: 0.01 - ETA: 10s - loss: 4.8356 - acc: 0.01 - ETA: 10s - loss: 4.8355 - acc: 0.01 - ETA: 10s - loss: 4.8357 - acc: 0.01 - ETA: 10s - loss: 4.8357 - acc: 0.01 - ETA: 10s - loss: 4.8355 - acc: 0.01 - ETA: 9s - loss: 4.8355 - acc: 0.0182 - ETA: 9s - loss: 4.8353 - acc: 0.018 - ETA: 9s - loss: 4.8353 - acc: 0.018 - ETA: 9s - loss: 4.8353 - acc: 0.018 - ETA: 9s - loss: 4.8351 - acc: 0.018 - ETA: 9s - loss: 4.8348 - acc: 0.018 - ETA: 8s - loss: 4.8349 - acc: 0.018 - ETA: 8s - loss: 4.8348 - acc: 0.018 - ETA: 8s - loss: 4.8346 - acc: 0.017 - ETA: 8s - loss: 4.8347 - acc: 0.017 - ETA: 8s - loss: 4.8348 - acc: 0.017 - ETA: 8s - loss: 4.8348 - acc: 0.017 - ETA: 7s - loss: 4.8351 - acc: 0.017 - ETA: 7s - loss: 4.8350 - acc: 0.017 - ETA: 7s - loss: 4.8351 - acc: 0.017 - ETA: 7s - loss: 4.8351 - acc: 0.017 - ETA: 7s - loss: 4.8348 - acc: 0.017 - ETA: 7s - loss: 4.8346 - acc: 0.017 - ETA: 6s - loss: 4.8345 - acc: 0.017 - ETA: 6s - loss: 4.8345 - acc: 0.017 - ETA: 6s - loss: 4.8341 - acc: 0.017 - ETA: 6s - loss: 4.8342 - acc: 0.017 - ETA: 6s - loss: 4.8343 - acc: 0.017 - ETA: 6s - loss: 4.8344 - acc: 0.017 - ETA: 5s - loss: 4.8344 - acc: 0.017 - ETA: 5s - loss: 4.8343 - acc: 0.017 - ETA: 5s - loss: 4.8342 - acc: 0.017 - ETA: 5s - loss: 4.8342 - acc: 0.017 - ETA: 5s - loss: 4.8342 - acc: 0.017 - ETA: 5s - loss: 4.8342 - acc: 0.017 - ETA: 4s - loss: 4.8346 - acc: 0.017 - ETA: 4s - loss: 4.8346 - acc: 0.017 - ETA: 4s - loss: 4.8345 - acc: 0.017 - ETA: 4s - loss: 4.8345 - acc: 0.017 - ETA: 4s - loss: 4.8346 - acc: 0.017 - ETA: 4s - loss: 4.8344 - acc: 0.017 - ETA: 3s - loss: 4.8344 - acc: 0.017 - ETA: 3s - loss: 4.8342 - acc: 0.017 - ETA: 3s - loss: 4.8342 - acc: 0.017 - ETA: 3s - loss: 4.8345 - acc: 0.017 - ETA: 3s - loss: 4.8347 - acc: 0.017 - ETA: 3s - loss: 4.8345 - acc: 0.017 - ETA: 2s - loss: 4.8348 - acc: 0.017 - ETA: 2s - loss: 4.8348 - acc: 0.017 - ETA: 2s - loss: 4.8349 - acc: 0.017 - ETA: 2s - loss: 4.8350 - acc: 0.017 - ETA: 2s - loss: 4.8353 - acc: 0.017 - ETA: 2s - loss: 4.8356 - acc: 0.017 - ETA: 1s - loss: 4.8359 - acc: 0.017 - ETA: 1s - loss: 4.8360 - acc: 0.017 - ETA: 1s - loss: 4.8359 - acc: 0.017 - ETA: 1s - loss: 4.8358 - acc: 0.017 - ETA: 1s - loss: 4.8359 - acc: 0.017 - ETA: 1s - loss: 4.8362 - acc: 0.017 - ETA: 0s - loss: 4.8362 - acc: 0.017 - ETA: 0s - loss: 4.8362 - acc: 0.017 - ETA: 0s - loss: 4.8364 - acc: 0.017 - ETA: 0s - loss: 4.8363 - acc: 0.017 - ETA: 0s - loss: 4.8367 - acc: 0.017 - 74s 177ms/step - loss: 4.8365 - acc: 0.0174 - val_loss: 4.8226 - val_acc: 0.0269\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 4.82115\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/417 [==============>...............] - ETA: 39s - loss: 4.8161 - acc: 0.0000e+ - ETA: 39s - loss: 4.8421 - acc: 0.0000e+ - ETA: 39s - loss: 4.8464 - acc: 0.0000e+ - ETA: 40s - loss: 4.8221 - acc: 0.0000e+ - ETA: 40s - loss: 4.8512 - acc: 0.0000e+ - ETA: 40s - loss: 4.8047 - acc: 0.0104   - ETA: 40s - loss: 4.8096 - acc: 0.00 - ETA: 40s - loss: 4.7932 - acc: 0.01 - ETA: 40s - loss: 4.7931 - acc: 0.02 - ETA: 40s - loss: 4.7952 - acc: 0.01 - ETA: 39s - loss: 4.7904 - acc: 0.02 - ETA: 39s - loss: 4.7960 - acc: 0.02 - ETA: 39s - loss: 4.7979 - acc: 0.02 - ETA: 39s - loss: 4.8044 - acc: 0.02 - ETA: 39s - loss: 4.8050 - acc: 0.02 - ETA: 38s - loss: 4.8131 - acc: 0.02 - ETA: 38s - loss: 4.8137 - acc: 0.02 - ETA: 38s - loss: 4.8207 - acc: 0.02 - ETA: 38s - loss: 4.8169 - acc: 0.02 - ETA: 38s - loss: 4.8166 - acc: 0.02 - ETA: 38s - loss: 4.8203 - acc: 0.02 - ETA: 38s - loss: 4.8231 - acc: 0.02 - ETA: 38s - loss: 4.8207 - acc: 0.02 - ETA: 37s - loss: 4.8186 - acc: 0.02 - ETA: 37s - loss: 4.8157 - acc: 0.02 - ETA: 37s - loss: 4.8183 - acc: 0.02 - ETA: 39s - loss: 4.8199 - acc: 0.02 - ETA: 39s - loss: 4.8211 - acc: 0.02 - ETA: 41s - loss: 4.8240 - acc: 0.02 - ETA: 41s - loss: 4.8221 - acc: 0.02 - ETA: 42s - loss: 4.8256 - acc: 0.02 - ETA: 42s - loss: 4.8277 - acc: 0.02 - ETA: 42s - loss: 4.8281 - acc: 0.02 - ETA: 43s - loss: 4.8242 - acc: 0.02 - ETA: 43s - loss: 4.8263 - acc: 0.01 - ETA: 43s - loss: 4.8282 - acc: 0.01 - ETA: 43s - loss: 4.8287 - acc: 0.01 - ETA: 43s - loss: 4.8320 - acc: 0.01 - ETA: 43s - loss: 4.8244 - acc: 0.02 - ETA: 43s - loss: 4.8242 - acc: 0.02 - ETA: 43s - loss: 4.8268 - acc: 0.02 - ETA: 43s - loss: 4.8260 - acc: 0.02 - ETA: 44s - loss: 4.8249 - acc: 0.02 - ETA: 44s - loss: 4.8249 - acc: 0.02 - ETA: 44s - loss: 4.8274 - acc: 0.02 - ETA: 44s - loss: 4.8273 - acc: 0.02 - ETA: 45s - loss: 4.8285 - acc: 0.02 - ETA: 45s - loss: 4.8271 - acc: 0.02 - ETA: 45s - loss: 4.8278 - acc: 0.02 - ETA: 45s - loss: 4.8279 - acc: 0.02 - ETA: 45s - loss: 4.8286 - acc: 0.02 - ETA: 45s - loss: 4.8299 - acc: 0.02 - ETA: 45s - loss: 4.8310 - acc: 0.02 - ETA: 45s - loss: 4.8319 - acc: 0.02 - ETA: 45s - loss: 4.8329 - acc: 0.02 - ETA: 48s - loss: 4.8336 - acc: 0.02 - ETA: 48s - loss: 4.8326 - acc: 0.02 - ETA: 48s - loss: 4.8312 - acc: 0.02 - ETA: 48s - loss: 4.8308 - acc: 0.02 - ETA: 48s - loss: 4.8325 - acc: 0.02 - ETA: 47s - loss: 4.8325 - acc: 0.02 - ETA: 47s - loss: 4.8333 - acc: 0.02 - ETA: 47s - loss: 4.8343 - acc: 0.02 - ETA: 47s - loss: 4.8335 - acc: 0.02 - ETA: 46s - loss: 4.8316 - acc: 0.02 - ETA: 46s - loss: 4.8310 - acc: 0.02 - ETA: 46s - loss: 4.8303 - acc: 0.02 - ETA: 46s - loss: 4.8298 - acc: 0.02 - ETA: 46s - loss: 4.8309 - acc: 0.02 - ETA: 46s - loss: 4.8318 - acc: 0.02 - ETA: 46s - loss: 4.8327 - acc: 0.02 - ETA: 46s - loss: 4.8331 - acc: 0.02 - ETA: 46s - loss: 4.8330 - acc: 0.02 - ETA: 46s - loss: 4.8336 - acc: 0.02 - ETA: 46s - loss: 4.8317 - acc: 0.02 - ETA: 47s - loss: 4.8324 - acc: 0.02 - ETA: 47s - loss: 4.8320 - acc: 0.02 - ETA: 48s - loss: 4.8303 - acc: 0.02 - ETA: 48s - loss: 4.8293 - acc: 0.02 - ETA: 48s - loss: 4.8290 - acc: 0.02 - ETA: 47s - loss: 4.8304 - acc: 0.02 - ETA: 47s - loss: 4.8296 - acc: 0.02 - ETA: 47s - loss: 4.8293 - acc: 0.02 - ETA: 47s - loss: 4.8293 - acc: 0.02 - ETA: 47s - loss: 4.8301 - acc: 0.02 - ETA: 47s - loss: 4.8297 - acc: 0.02 - ETA: 47s - loss: 4.8302 - acc: 0.02 - ETA: 46s - loss: 4.8301 - acc: 0.02 - ETA: 46s - loss: 4.8287 - acc: 0.02 - ETA: 46s - loss: 4.8292 - acc: 0.02 - ETA: 46s - loss: 4.8294 - acc: 0.02 - ETA: 46s - loss: 4.8293 - acc: 0.02 - ETA: 46s - loss: 4.8303 - acc: 0.02 - ETA: 46s - loss: 4.8303 - acc: 0.02 - ETA: 46s - loss: 4.8299 - acc: 0.02 - ETA: 45s - loss: 4.8299 - acc: 0.02 - ETA: 46s - loss: 4.8302 - acc: 0.02 - ETA: 46s - loss: 4.8305 - acc: 0.02 - ETA: 45s - loss: 4.8302 - acc: 0.02 - ETA: 45s - loss: 4.8304 - acc: 0.02 - ETA: 45s - loss: 4.8290 - acc: 0.02 - ETA: 45s - loss: 4.8291 - acc: 0.02 - ETA: 45s - loss: 4.8294 - acc: 0.02 - ETA: 45s - loss: 4.8299 - acc: 0.02 - ETA: 45s - loss: 4.8293 - acc: 0.02 - ETA: 45s - loss: 4.8290 - acc: 0.02 - ETA: 45s - loss: 4.8268 - acc: 0.02 - ETA: 46s - loss: 4.8267 - acc: 0.02 - ETA: 46s - loss: 4.8267 - acc: 0.02 - ETA: 46s - loss: 4.8267 - acc: 0.02 - ETA: 45s - loss: 4.8265 - acc: 0.02 - ETA: 45s - loss: 4.8274 - acc: 0.02 - ETA: 45s - loss: 4.8265 - acc: 0.02 - ETA: 45s - loss: 4.8263 - acc: 0.02 - ETA: 45s - loss: 4.8265 - acc: 0.02 - ETA: 45s - loss: 4.8266 - acc: 0.02 - ETA: 45s - loss: 4.8269 - acc: 0.02 - ETA: 45s - loss: 4.8276 - acc: 0.02 - ETA: 44s - loss: 4.8272 - acc: 0.02 - ETA: 44s - loss: 4.8273 - acc: 0.02 - ETA: 44s - loss: 4.8268 - acc: 0.02 - ETA: 44s - loss: 4.8264 - acc: 0.02 - ETA: 44s - loss: 4.8273 - acc: 0.02 - ETA: 44s - loss: 4.8277 - acc: 0.02 - ETA: 44s - loss: 4.8270 - acc: 0.02 - ETA: 44s - loss: 4.8265 - acc: 0.02 - ETA: 44s - loss: 4.8276 - acc: 0.02 - ETA: 44s - loss: 4.8269 - acc: 0.02 - ETA: 44s - loss: 4.8273 - acc: 0.02 - ETA: 44s - loss: 4.8268 - acc: 0.02 - ETA: 43s - loss: 4.8275 - acc: 0.02 - ETA: 43s - loss: 4.8280 - acc: 0.02 - ETA: 43s - loss: 4.8280 - acc: 0.02 - ETA: 43s - loss: 4.8275 - acc: 0.02 - ETA: 43s - loss: 4.8268 - acc: 0.02 - ETA: 43s - loss: 4.8260 - acc: 0.02 - ETA: 42s - loss: 4.8266 - acc: 0.02 - ETA: 42s - loss: 4.8273 - acc: 0.02 - ETA: 42s - loss: 4.8271 - acc: 0.02 - ETA: 42s - loss: 4.8266 - acc: 0.02 - ETA: 42s - loss: 4.8269 - acc: 0.02 - ETA: 42s - loss: 4.8265 - acc: 0.02 - ETA: 42s - loss: 4.8266 - acc: 0.02 - ETA: 41s - loss: 4.8261 - acc: 0.02 - ETA: 41s - loss: 4.8270 - acc: 0.02 - ETA: 41s - loss: 4.8274 - acc: 0.02 - ETA: 41s - loss: 4.8275 - acc: 0.02 - ETA: 41s - loss: 4.8278 - acc: 0.02 - ETA: 41s - loss: 4.8274 - acc: 0.02 - ETA: 41s - loss: 4.8297 - acc: 0.02 - ETA: 41s - loss: 4.8301 - acc: 0.02 - ETA: 41s - loss: 4.8295 - acc: 0.02 - ETA: 40s - loss: 4.8293 - acc: 0.02 - ETA: 40s - loss: 4.8306 - acc: 0.02 - ETA: 40s - loss: 4.8301 - acc: 0.02 - ETA: 40s - loss: 4.8303 - acc: 0.02 - ETA: 40s - loss: 4.8305 - acc: 0.02 - ETA: 40s - loss: 4.8312 - acc: 0.02 - ETA: 40s - loss: 4.8316 - acc: 0.02 - ETA: 40s - loss: 4.8316 - acc: 0.02 - ETA: 39s - loss: 4.8313 - acc: 0.02 - ETA: 39s - loss: 4.8307 - acc: 0.02 - ETA: 39s - loss: 4.8313 - acc: 0.02 - ETA: 39s - loss: 4.8314 - acc: 0.02 - ETA: 39s - loss: 4.8310 - acc: 0.02 - ETA: 39s - loss: 4.8312 - acc: 0.02 - ETA: 39s - loss: 4.8311 - acc: 0.02 - ETA: 39s - loss: 4.8314 - acc: 0.02 - ETA: 39s - loss: 4.8322 - acc: 0.02 - ETA: 38s - loss: 4.8322 - acc: 0.02 - ETA: 38s - loss: 4.8325 - acc: 0.02 - ETA: 38s - loss: 4.8332 - acc: 0.02 - ETA: 38s - loss: 4.8328 - acc: 0.02 - ETA: 38s - loss: 4.8329 - acc: 0.02 - ETA: 38s - loss: 4.8330 - acc: 0.02 - ETA: 38s - loss: 4.8330 - acc: 0.02 - ETA: 37s - loss: 4.8333 - acc: 0.02 - ETA: 37s - loss: 4.8331 - acc: 0.02 - ETA: 37s - loss: 4.8326 - acc: 0.02 - ETA: 37s - loss: 4.8325 - acc: 0.02 - ETA: 37s - loss: 4.8323 - acc: 0.02 - ETA: 37s - loss: 4.8326 - acc: 0.02 - ETA: 36s - loss: 4.8319 - acc: 0.02 - ETA: 36s - loss: 4.8319 - acc: 0.02 - ETA: 36s - loss: 4.8318 - acc: 0.02 - ETA: 36s - loss: 4.8322 - acc: 0.02 - ETA: 36s - loss: 4.8326 - acc: 0.02 - ETA: 36s - loss: 4.8330 - acc: 0.02 - ETA: 36s - loss: 4.8326 - acc: 0.02 - ETA: 35s - loss: 4.8328 - acc: 0.02 - ETA: 35s - loss: 4.8321 - acc: 0.02 - ETA: 35s - loss: 4.8325 - acc: 0.02 - ETA: 35s - loss: 4.8329 - acc: 0.02 - ETA: 35s - loss: 4.8325 - acc: 0.02 - ETA: 35s - loss: 4.8322 - acc: 0.02 - ETA: 35s - loss: 4.8327 - acc: 0.02 - ETA: 35s - loss: 4.8326 - acc: 0.02 - ETA: 35s - loss: 4.8328 - acc: 0.02 - ETA: 34s - loss: 4.8324 - acc: 0.02 - ETA: 34s - loss: 4.8325 - acc: 0.02 - ETA: 34s - loss: 4.8323 - acc: 0.02 - ETA: 34s - loss: 4.8326 - acc: 0.02 - ETA: 34s - loss: 4.8321 - acc: 0.02 - ETA: 34s - loss: 4.8322 - acc: 0.02 - ETA: 34s - loss: 4.8327 - acc: 0.02 - ETA: 33s - loss: 4.8332 - acc: 0.02 - ETA: 33s - loss: 4.8331 - acc: 0.02 - ETA: 33s - loss: 4.8324 - acc: 0.02 - ETA: 33s - loss: 4.8326 - acc: 0.02 - ETA: 33s - loss: 4.8326 - acc: 0.02 - ETA: 33s - loss: 4.8326 - acc: 0.02 - ETA: 32s - loss: 4.8328 - acc: 0.02 - ETA: 32s - loss: 4.8328 - acc: 0.02 - ETA: 32s - loss: 4.8329 - acc: 0.0219"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 32s - loss: 4.8335 - acc: 0.02 - ETA: 32s - loss: 4.8336 - acc: 0.02 - ETA: 32s - loss: 4.8334 - acc: 0.02 - ETA: 32s - loss: 4.8336 - acc: 0.02 - ETA: 31s - loss: 4.8341 - acc: 0.02 - ETA: 31s - loss: 4.8343 - acc: 0.02 - ETA: 31s - loss: 4.8347 - acc: 0.02 - ETA: 31s - loss: 4.8348 - acc: 0.02 - ETA: 31s - loss: 4.8348 - acc: 0.02 - ETA: 31s - loss: 4.8350 - acc: 0.02 - ETA: 31s - loss: 4.8358 - acc: 0.02 - ETA: 30s - loss: 4.8357 - acc: 0.02 - ETA: 30s - loss: 4.8361 - acc: 0.02 - ETA: 30s - loss: 4.8358 - acc: 0.02 - ETA: 30s - loss: 4.8350 - acc: 0.02 - ETA: 30s - loss: 4.8353 - acc: 0.02 - ETA: 30s - loss: 4.8359 - acc: 0.02 - ETA: 29s - loss: 4.8360 - acc: 0.02 - ETA: 29s - loss: 4.8359 - acc: 0.02 - ETA: 29s - loss: 4.8359 - acc: 0.02 - ETA: 29s - loss: 4.8355 - acc: 0.02 - ETA: 29s - loss: 4.8356 - acc: 0.02 - ETA: 29s - loss: 4.8356 - acc: 0.02 - ETA: 29s - loss: 4.8358 - acc: 0.02 - ETA: 28s - loss: 4.8360 - acc: 0.02 - ETA: 28s - loss: 4.8361 - acc: 0.02 - ETA: 28s - loss: 4.8363 - acc: 0.02 - ETA: 28s - loss: 4.8359 - acc: 0.02 - ETA: 28s - loss: 4.8361 - acc: 0.02 - ETA: 28s - loss: 4.8357 - acc: 0.02 - ETA: 28s - loss: 4.8358 - acc: 0.02 - ETA: 27s - loss: 4.8359 - acc: 0.02 - ETA: 27s - loss: 4.8364 - acc: 0.02 - ETA: 27s - loss: 4.8363 - acc: 0.02 - ETA: 27s - loss: 4.8360 - acc: 0.02 - ETA: 27s - loss: 4.8360 - acc: 0.02 - ETA: 27s - loss: 4.8357 - acc: 0.02 - ETA: 26s - loss: 4.8354 - acc: 0.02 - ETA: 26s - loss: 4.8352 - acc: 0.02 - ETA: 26s - loss: 4.8350 - acc: 0.02 - ETA: 26s - loss: 4.8340 - acc: 0.02 - ETA: 26s - loss: 4.8340 - acc: 0.02 - ETA: 26s - loss: 4.8345 - acc: 0.02 - ETA: 25s - loss: 4.8346 - acc: 0.02 - ETA: 25s - loss: 4.8345 - acc: 0.02 - ETA: 25s - loss: 4.8347 - acc: 0.02 - ETA: 25s - loss: 4.8347 - acc: 0.02 - ETA: 25s - loss: 4.8346 - acc: 0.02 - ETA: 25s - loss: 4.8342 - acc: 0.02 - ETA: 25s - loss: 4.8341 - acc: 0.02 - ETA: 24s - loss: 4.8343 - acc: 0.02 - ETA: 24s - loss: 4.8343 - acc: 0.02 - ETA: 24s - loss: 4.8342 - acc: 0.02 - ETA: 24s - loss: 4.8341 - acc: 0.02 - ETA: 24s - loss: 4.8342 - acc: 0.02 - ETA: 24s - loss: 4.8341 - acc: 0.02 - ETA: 23s - loss: 4.8342 - acc: 0.02 - ETA: 23s - loss: 4.8347 - acc: 0.02 - ETA: 23s - loss: 4.8350 - acc: 0.02 - ETA: 23s - loss: 4.8348 - acc: 0.02 - ETA: 23s - loss: 4.8346 - acc: 0.02 - ETA: 23s - loss: 4.8348 - acc: 0.02 - ETA: 22s - loss: 4.8346 - acc: 0.02 - ETA: 22s - loss: 4.8344 - acc: 0.02 - ETA: 22s - loss: 4.8347 - acc: 0.02 - ETA: 22s - loss: 4.8344 - acc: 0.02 - ETA: 22s - loss: 4.8342 - acc: 0.02 - ETA: 22s - loss: 4.8342 - acc: 0.02 - ETA: 21s - loss: 4.8343 - acc: 0.02 - ETA: 21s - loss: 4.8342 - acc: 0.02 - ETA: 21s - loss: 4.8343 - acc: 0.02 - ETA: 21s - loss: 4.8340 - acc: 0.02 - ETA: 21s - loss: 4.8342 - acc: 0.02 - ETA: 21s - loss: 4.8342 - acc: 0.02 - ETA: 20s - loss: 4.8341 - acc: 0.02 - ETA: 20s - loss: 4.8341 - acc: 0.02 - ETA: 20s - loss: 4.8341 - acc: 0.02 - ETA: 20s - loss: 4.8342 - acc: 0.02 - ETA: 20s - loss: 4.8339 - acc: 0.02 - ETA: 20s - loss: 4.8342 - acc: 0.02 - ETA: 19s - loss: 4.8343 - acc: 0.02 - ETA: 19s - loss: 4.8341 - acc: 0.02 - ETA: 19s - loss: 4.8341 - acc: 0.02 - ETA: 19s - loss: 4.8343 - acc: 0.02 - ETA: 19s - loss: 4.8341 - acc: 0.02 - ETA: 19s - loss: 4.8343 - acc: 0.02 - ETA: 18s - loss: 4.8345 - acc: 0.02 - ETA: 18s - loss: 4.8347 - acc: 0.02 - ETA: 18s - loss: 4.8350 - acc: 0.02 - ETA: 18s - loss: 4.8352 - acc: 0.02 - ETA: 18s - loss: 4.8353 - acc: 0.02 - ETA: 18s - loss: 4.8354 - acc: 0.02 - ETA: 18s - loss: 4.8354 - acc: 0.02 - ETA: 17s - loss: 4.8354 - acc: 0.02 - ETA: 17s - loss: 4.8355 - acc: 0.02 - ETA: 17s - loss: 4.8358 - acc: 0.02 - ETA: 17s - loss: 4.8358 - acc: 0.02 - ETA: 17s - loss: 4.8360 - acc: 0.02 - ETA: 17s - loss: 4.8355 - acc: 0.02 - ETA: 16s - loss: 4.8358 - acc: 0.02 - ETA: 16s - loss: 4.8356 - acc: 0.02 - ETA: 16s - loss: 4.8356 - acc: 0.02 - ETA: 16s - loss: 4.8359 - acc: 0.02 - ETA: 16s - loss: 4.8355 - acc: 0.02 - ETA: 16s - loss: 4.8356 - acc: 0.02 - ETA: 15s - loss: 4.8357 - acc: 0.02 - ETA: 15s - loss: 4.8355 - acc: 0.02 - ETA: 15s - loss: 4.8355 - acc: 0.02 - ETA: 15s - loss: 4.8352 - acc: 0.02 - ETA: 15s - loss: 4.8354 - acc: 0.02 - ETA: 15s - loss: 4.8353 - acc: 0.02 - ETA: 14s - loss: 4.8351 - acc: 0.02 - ETA: 14s - loss: 4.8350 - acc: 0.02 - ETA: 14s - loss: 4.8352 - acc: 0.02 - ETA: 14s - loss: 4.8350 - acc: 0.02 - ETA: 14s - loss: 4.8350 - acc: 0.02 - ETA: 14s - loss: 4.8348 - acc: 0.02 - ETA: 13s - loss: 4.8352 - acc: 0.02 - ETA: 13s - loss: 4.8355 - acc: 0.02 - ETA: 13s - loss: 4.8351 - acc: 0.02 - ETA: 13s - loss: 4.8352 - acc: 0.02 - ETA: 13s - loss: 4.8350 - acc: 0.02 - ETA: 13s - loss: 4.8348 - acc: 0.02 - ETA: 13s - loss: 4.8346 - acc: 0.02 - ETA: 12s - loss: 4.8343 - acc: 0.02 - ETA: 12s - loss: 4.8344 - acc: 0.02 - ETA: 12s - loss: 4.8340 - acc: 0.02 - ETA: 12s - loss: 4.8342 - acc: 0.02 - ETA: 12s - loss: 4.8345 - acc: 0.02 - ETA: 12s - loss: 4.8346 - acc: 0.02 - ETA: 11s - loss: 4.8344 - acc: 0.02 - ETA: 11s - loss: 4.8341 - acc: 0.02 - ETA: 11s - loss: 4.8344 - acc: 0.02 - ETA: 11s - loss: 4.8342 - acc: 0.02 - ETA: 11s - loss: 4.8342 - acc: 0.02 - ETA: 11s - loss: 4.8338 - acc: 0.02 - ETA: 10s - loss: 4.8340 - acc: 0.02 - ETA: 10s - loss: 4.8338 - acc: 0.02 - ETA: 10s - loss: 4.8338 - acc: 0.02 - ETA: 10s - loss: 4.8337 - acc: 0.02 - ETA: 10s - loss: 4.8339 - acc: 0.02 - ETA: 10s - loss: 4.8344 - acc: 0.02 - ETA: 9s - loss: 4.8345 - acc: 0.0203 - ETA: 9s - loss: 4.8347 - acc: 0.020 - ETA: 9s - loss: 4.8344 - acc: 0.020 - ETA: 9s - loss: 4.8346 - acc: 0.020 - ETA: 9s - loss: 4.8350 - acc: 0.020 - ETA: 9s - loss: 4.8351 - acc: 0.020 - ETA: 8s - loss: 4.8351 - acc: 0.020 - ETA: 8s - loss: 4.8349 - acc: 0.020 - ETA: 8s - loss: 4.8349 - acc: 0.020 - ETA: 8s - loss: 4.8347 - acc: 0.020 - ETA: 8s - loss: 4.8347 - acc: 0.019 - ETA: 8s - loss: 4.8346 - acc: 0.020 - ETA: 7s - loss: 4.8346 - acc: 0.020 - ETA: 7s - loss: 4.8347 - acc: 0.020 - ETA: 7s - loss: 4.8346 - acc: 0.020 - ETA: 7s - loss: 4.8348 - acc: 0.020 - ETA: 7s - loss: 4.8342 - acc: 0.020 - ETA: 7s - loss: 4.8343 - acc: 0.020 - ETA: 6s - loss: 4.8343 - acc: 0.020 - ETA: 6s - loss: 4.8343 - acc: 0.020 - ETA: 6s - loss: 4.8344 - acc: 0.020 - ETA: 6s - loss: 4.8344 - acc: 0.020 - ETA: 6s - loss: 4.8345 - acc: 0.020 - ETA: 6s - loss: 4.8346 - acc: 0.020 - ETA: 5s - loss: 4.8348 - acc: 0.020 - ETA: 5s - loss: 4.8349 - acc: 0.020 - ETA: 5s - loss: 4.8350 - acc: 0.020 - ETA: 5s - loss: 4.8350 - acc: 0.020 - ETA: 5s - loss: 4.8349 - acc: 0.020 - ETA: 5s - loss: 4.8347 - acc: 0.020 - ETA: 4s - loss: 4.8348 - acc: 0.020 - ETA: 4s - loss: 4.8347 - acc: 0.020 - ETA: 4s - loss: 4.8349 - acc: 0.020 - ETA: 4s - loss: 4.8348 - acc: 0.020 - ETA: 4s - loss: 4.8348 - acc: 0.020 - ETA: 4s - loss: 4.8347 - acc: 0.019 - ETA: 3s - loss: 4.8347 - acc: 0.019 - ETA: 3s - loss: 4.8348 - acc: 0.019 - ETA: 3s - loss: 4.8347 - acc: 0.019 - ETA: 3s - loss: 4.8346 - acc: 0.019 - ETA: 3s - loss: 4.8345 - acc: 0.019 - ETA: 3s - loss: 4.8345 - acc: 0.019 - ETA: 2s - loss: 4.8344 - acc: 0.019 - ETA: 2s - loss: 4.8342 - acc: 0.019 - ETA: 2s - loss: 4.8342 - acc: 0.019 - ETA: 2s - loss: 4.8342 - acc: 0.019 - ETA: 2s - loss: 4.8340 - acc: 0.019 - ETA: 2s - loss: 4.8340 - acc: 0.019 - ETA: 1s - loss: 4.8340 - acc: 0.019 - ETA: 1s - loss: 4.8343 - acc: 0.019 - ETA: 1s - loss: 4.8347 - acc: 0.019 - ETA: 1s - loss: 4.8350 - acc: 0.019 - ETA: 1s - loss: 4.8348 - acc: 0.019 - ETA: 1s - loss: 4.8348 - acc: 0.019 - ETA: 0s - loss: 4.8350 - acc: 0.019 - ETA: 0s - loss: 4.8352 - acc: 0.019 - ETA: 0s - loss: 4.8354 - acc: 0.019 - ETA: 0s - loss: 4.8354 - acc: 0.019 - ETA: 0s - loss: 4.8353 - acc: 0.019 - ETA: 0s - loss: 4.8355 - acc: 0.019 - 73s 176ms/step - loss: 4.8356 - acc: 0.0193 - val_loss: 4.8105 - val_acc: 0.0330\n",
      "\n",
      "Epoch 00037: val_loss improved from 4.82115 to 4.81050, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214/417 [==============>...............] - ETA: 56s - loss: 4.8212 - acc: 0.0000e+ - ETA: 55s - loss: 4.8432 - acc: 0.0000e+ - ETA: 54s - loss: 4.8397 - acc: 0.0000e+ - ETA: 54s - loss: 4.8214 - acc: 0.0000e+ - ETA: 53s - loss: 4.8353 - acc: 0.0000e+ - ETA: 53s - loss: 4.8442 - acc: 0.0000e+ - ETA: 53s - loss: 4.8332 - acc: 0.0000e+ - ETA: 52s - loss: 4.8516 - acc: 0.0000e+ - ETA: 52s - loss: 4.8563 - acc: 0.0000e+ - ETA: 51s - loss: 4.8628 - acc: 0.0000e+ - ETA: 51s - loss: 4.8575 - acc: 0.0057   - ETA: 50s - loss: 4.8640 - acc: 0.00 - ETA: 50s - loss: 4.8613 - acc: 0.00 - ETA: 50s - loss: 4.8622 - acc: 0.00 - ETA: 50s - loss: 4.8660 - acc: 0.00 - ETA: 49s - loss: 4.8609 - acc: 0.00 - ETA: 49s - loss: 4.8641 - acc: 0.00 - ETA: 49s - loss: 4.8650 - acc: 0.01 - ETA: 49s - loss: 4.8631 - acc: 0.00 - ETA: 48s - loss: 4.8618 - acc: 0.00 - ETA: 48s - loss: 4.8619 - acc: 0.00 - ETA: 48s - loss: 4.8576 - acc: 0.01 - ETA: 48s - loss: 4.8576 - acc: 0.01 - ETA: 48s - loss: 4.8592 - acc: 0.01 - ETA: 48s - loss: 4.8573 - acc: 0.01 - ETA: 48s - loss: 4.8604 - acc: 0.00 - ETA: 47s - loss: 4.8600 - acc: 0.00 - ETA: 47s - loss: 4.8612 - acc: 0.00 - ETA: 47s - loss: 4.8637 - acc: 0.00 - ETA: 47s - loss: 4.8619 - acc: 0.01 - ETA: 47s - loss: 4.8645 - acc: 0.01 - ETA: 48s - loss: 4.8653 - acc: 0.00 - ETA: 49s - loss: 4.8672 - acc: 0.00 - ETA: 49s - loss: 4.8660 - acc: 0.00 - ETA: 50s - loss: 4.8620 - acc: 0.01 - ETA: 50s - loss: 4.8589 - acc: 0.01 - ETA: 50s - loss: 4.8607 - acc: 0.01 - ETA: 50s - loss: 4.8598 - acc: 0.00 - ETA: 50s - loss: 4.8627 - acc: 0.00 - ETA: 49s - loss: 4.8619 - acc: 0.01 - ETA: 50s - loss: 4.8617 - acc: 0.01 - ETA: 50s - loss: 4.8593 - acc: 0.01 - ETA: 50s - loss: 4.8586 - acc: 0.01 - ETA: 50s - loss: 4.8580 - acc: 0.01 - ETA: 50s - loss: 4.8577 - acc: 0.01 - ETA: 50s - loss: 4.8536 - acc: 0.01 - ETA: 50s - loss: 4.8538 - acc: 0.01 - ETA: 50s - loss: 4.8532 - acc: 0.01 - ETA: 50s - loss: 4.8529 - acc: 0.01 - ETA: 50s - loss: 4.8515 - acc: 0.01 - ETA: 50s - loss: 4.8524 - acc: 0.01 - ETA: 50s - loss: 4.8534 - acc: 0.01 - ETA: 50s - loss: 4.8531 - acc: 0.01 - ETA: 50s - loss: 4.8512 - acc: 0.01 - ETA: 50s - loss: 4.8508 - acc: 0.01 - ETA: 50s - loss: 4.8523 - acc: 0.01 - ETA: 50s - loss: 4.8536 - acc: 0.01 - ETA: 50s - loss: 4.8526 - acc: 0.01 - ETA: 50s - loss: 4.8519 - acc: 0.01 - ETA: 49s - loss: 4.8511 - acc: 0.01 - ETA: 49s - loss: 4.8500 - acc: 0.01 - ETA: 49s - loss: 4.8496 - acc: 0.01 - ETA: 49s - loss: 4.8492 - acc: 0.01 - ETA: 49s - loss: 4.8503 - acc: 0.01 - ETA: 49s - loss: 4.8511 - acc: 0.01 - ETA: 49s - loss: 4.8493 - acc: 0.01 - ETA: 49s - loss: 4.8497 - acc: 0.01 - ETA: 49s - loss: 4.8489 - acc: 0.01 - ETA: 49s - loss: 4.8482 - acc: 0.01 - ETA: 49s - loss: 4.8486 - acc: 0.01 - ETA: 49s - loss: 4.8478 - acc: 0.01 - ETA: 49s - loss: 4.8483 - acc: 0.01 - ETA: 48s - loss: 4.8461 - acc: 0.01 - ETA: 48s - loss: 4.8453 - acc: 0.01 - ETA: 48s - loss: 4.8454 - acc: 0.01 - ETA: 49s - loss: 4.8445 - acc: 0.01 - ETA: 48s - loss: 4.8462 - acc: 0.01 - ETA: 48s - loss: 4.8455 - acc: 0.01 - ETA: 48s - loss: 4.8448 - acc: 0.01 - ETA: 48s - loss: 4.8446 - acc: 0.01 - ETA: 48s - loss: 4.8451 - acc: 0.01 - ETA: 48s - loss: 4.8444 - acc: 0.01 - ETA: 48s - loss: 4.8433 - acc: 0.01 - ETA: 48s - loss: 4.8411 - acc: 0.01 - ETA: 47s - loss: 4.8417 - acc: 0.01 - ETA: 47s - loss: 4.8416 - acc: 0.01 - ETA: 47s - loss: 4.8413 - acc: 0.01 - ETA: 47s - loss: 4.8414 - acc: 0.01 - ETA: 47s - loss: 4.8412 - acc: 0.01 - ETA: 47s - loss: 4.8411 - acc: 0.01 - ETA: 47s - loss: 4.8405 - acc: 0.01 - ETA: 47s - loss: 4.8399 - acc: 0.01 - ETA: 47s - loss: 4.8390 - acc: 0.01 - ETA: 47s - loss: 4.8395 - acc: 0.01 - ETA: 47s - loss: 4.8395 - acc: 0.01 - ETA: 46s - loss: 4.8397 - acc: 0.01 - ETA: 47s - loss: 4.8383 - acc: 0.01 - ETA: 47s - loss: 4.8392 - acc: 0.01 - ETA: 46s - loss: 4.8393 - acc: 0.01 - ETA: 46s - loss: 4.8387 - acc: 0.01 - ETA: 46s - loss: 4.8384 - acc: 0.01 - ETA: 46s - loss: 4.8369 - acc: 0.01 - ETA: 46s - loss: 4.8365 - acc: 0.01 - ETA: 46s - loss: 4.8374 - acc: 0.01 - ETA: 45s - loss: 4.8370 - acc: 0.01 - ETA: 45s - loss: 4.8372 - acc: 0.01 - ETA: 46s - loss: 4.8366 - acc: 0.01 - ETA: 45s - loss: 4.8358 - acc: 0.01 - ETA: 45s - loss: 4.8359 - acc: 0.01 - ETA: 45s - loss: 4.8340 - acc: 0.02 - ETA: 45s - loss: 4.8337 - acc: 0.02 - ETA: 45s - loss: 4.8339 - acc: 0.02 - ETA: 45s - loss: 4.8337 - acc: 0.02 - ETA: 45s - loss: 4.8332 - acc: 0.02 - ETA: 45s - loss: 4.8333 - acc: 0.02 - ETA: 45s - loss: 4.8332 - acc: 0.02 - ETA: 45s - loss: 4.8323 - acc: 0.02 - ETA: 45s - loss: 4.8325 - acc: 0.02 - ETA: 44s - loss: 4.8326 - acc: 0.02 - ETA: 44s - loss: 4.8315 - acc: 0.02 - ETA: 44s - loss: 4.8314 - acc: 0.02 - ETA: 44s - loss: 4.8315 - acc: 0.02 - ETA: 44s - loss: 4.8306 - acc: 0.02 - ETA: 44s - loss: 4.8305 - acc: 0.02 - ETA: 43s - loss: 4.8300 - acc: 0.02 - ETA: 44s - loss: 4.8296 - acc: 0.02 - ETA: 43s - loss: 4.8307 - acc: 0.02 - ETA: 43s - loss: 4.8308 - acc: 0.02 - ETA: 43s - loss: 4.8315 - acc: 0.02 - ETA: 43s - loss: 4.8306 - acc: 0.02 - ETA: 43s - loss: 4.8297 - acc: 0.02 - ETA: 43s - loss: 4.8294 - acc: 0.02 - ETA: 43s - loss: 4.8288 - acc: 0.02 - ETA: 42s - loss: 4.8290 - acc: 0.02 - ETA: 42s - loss: 4.8294 - acc: 0.02 - ETA: 42s - loss: 4.8292 - acc: 0.02 - ETA: 42s - loss: 4.8288 - acc: 0.02 - ETA: 42s - loss: 4.8290 - acc: 0.02 - ETA: 42s - loss: 4.8289 - acc: 0.02 - ETA: 41s - loss: 4.8285 - acc: 0.02 - ETA: 41s - loss: 4.8282 - acc: 0.02 - ETA: 41s - loss: 4.8272 - acc: 0.02 - ETA: 41s - loss: 4.8264 - acc: 0.02 - ETA: 41s - loss: 4.8265 - acc: 0.02 - ETA: 41s - loss: 4.8272 - acc: 0.02 - ETA: 41s - loss: 4.8270 - acc: 0.02 - ETA: 41s - loss: 4.8283 - acc: 0.02 - ETA: 41s - loss: 4.8278 - acc: 0.02 - ETA: 40s - loss: 4.8275 - acc: 0.02 - ETA: 41s - loss: 4.8270 - acc: 0.02 - ETA: 40s - loss: 4.8265 - acc: 0.02 - ETA: 40s - loss: 4.8266 - acc: 0.02 - ETA: 40s - loss: 4.8268 - acc: 0.02 - ETA: 40s - loss: 4.8261 - acc: 0.02 - ETA: 40s - loss: 4.8262 - acc: 0.02 - ETA: 40s - loss: 4.8267 - acc: 0.02 - ETA: 40s - loss: 4.8273 - acc: 0.02 - ETA: 39s - loss: 4.8269 - acc: 0.02 - ETA: 39s - loss: 4.8270 - acc: 0.02 - ETA: 39s - loss: 4.8275 - acc: 0.02 - ETA: 39s - loss: 4.8269 - acc: 0.02 - ETA: 39s - loss: 4.8269 - acc: 0.02 - ETA: 39s - loss: 4.8269 - acc: 0.02 - ETA: 39s - loss: 4.8274 - acc: 0.02 - ETA: 39s - loss: 4.8278 - acc: 0.02 - ETA: 38s - loss: 4.8273 - acc: 0.02 - ETA: 38s - loss: 4.8269 - acc: 0.02 - ETA: 38s - loss: 4.8271 - acc: 0.02 - ETA: 38s - loss: 4.8276 - acc: 0.02 - ETA: 38s - loss: 4.8282 - acc: 0.02 - ETA: 38s - loss: 4.8281 - acc: 0.02 - ETA: 38s - loss: 4.8284 - acc: 0.02 - ETA: 38s - loss: 4.8277 - acc: 0.02 - ETA: 38s - loss: 4.8280 - acc: 0.02 - ETA: 38s - loss: 4.8282 - acc: 0.02 - ETA: 37s - loss: 4.8279 - acc: 0.02 - ETA: 37s - loss: 4.8286 - acc: 0.02 - ETA: 37s - loss: 4.8288 - acc: 0.02 - ETA: 37s - loss: 4.8282 - acc: 0.02 - ETA: 37s - loss: 4.8283 - acc: 0.02 - ETA: 37s - loss: 4.8281 - acc: 0.02 - ETA: 37s - loss: 4.8285 - acc: 0.02 - ETA: 37s - loss: 4.8286 - acc: 0.02 - ETA: 36s - loss: 4.8285 - acc: 0.02 - ETA: 36s - loss: 4.8285 - acc: 0.02 - ETA: 36s - loss: 4.8283 - acc: 0.02 - ETA: 36s - loss: 4.8278 - acc: 0.02 - ETA: 36s - loss: 4.8281 - acc: 0.02 - ETA: 36s - loss: 4.8286 - acc: 0.02 - ETA: 35s - loss: 4.8289 - acc: 0.02 - ETA: 35s - loss: 4.8285 - acc: 0.02 - ETA: 35s - loss: 4.8287 - acc: 0.02 - ETA: 35s - loss: 4.8293 - acc: 0.02 - ETA: 35s - loss: 4.8308 - acc: 0.02 - ETA: 35s - loss: 4.8306 - acc: 0.02 - ETA: 35s - loss: 4.8306 - acc: 0.02 - ETA: 35s - loss: 4.8308 - acc: 0.02 - ETA: 35s - loss: 4.8307 - acc: 0.02 - ETA: 35s - loss: 4.8308 - acc: 0.02 - ETA: 34s - loss: 4.8310 - acc: 0.02 - ETA: 34s - loss: 4.8313 - acc: 0.02 - ETA: 34s - loss: 4.8323 - acc: 0.02 - ETA: 34s - loss: 4.8323 - acc: 0.02 - ETA: 34s - loss: 4.8323 - acc: 0.02 - ETA: 34s - loss: 4.8327 - acc: 0.02 - ETA: 34s - loss: 4.8333 - acc: 0.02 - ETA: 34s - loss: 4.8333 - acc: 0.02 - ETA: 33s - loss: 4.8335 - acc: 0.02 - ETA: 33s - loss: 4.8332 - acc: 0.02 - ETA: 33s - loss: 4.8335 - acc: 0.02 - ETA: 33s - loss: 4.8334 - acc: 0.02 - ETA: 33s - loss: 4.8330 - acc: 0.02 - ETA: 32s - loss: 4.8326 - acc: 0.02 - ETA: 32s - loss: 4.8323 - acc: 0.0210"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 32s - loss: 4.8326 - acc: 0.02 - ETA: 32s - loss: 4.8325 - acc: 0.02 - ETA: 32s - loss: 4.8324 - acc: 0.02 - ETA: 32s - loss: 4.8325 - acc: 0.02 - ETA: 31s - loss: 4.8317 - acc: 0.02 - ETA: 31s - loss: 4.8325 - acc: 0.02 - ETA: 31s - loss: 4.8325 - acc: 0.02 - ETA: 31s - loss: 4.8322 - acc: 0.02 - ETA: 31s - loss: 4.8321 - acc: 0.02 - ETA: 31s - loss: 4.8323 - acc: 0.02 - ETA: 31s - loss: 4.8323 - acc: 0.02 - ETA: 31s - loss: 4.8325 - acc: 0.02 - ETA: 30s - loss: 4.8329 - acc: 0.02 - ETA: 30s - loss: 4.8332 - acc: 0.02 - ETA: 30s - loss: 4.8330 - acc: 0.02 - ETA: 30s - loss: 4.8328 - acc: 0.02 - ETA: 30s - loss: 4.8334 - acc: 0.02 - ETA: 30s - loss: 4.8331 - acc: 0.02 - ETA: 29s - loss: 4.8335 - acc: 0.02 - ETA: 29s - loss: 4.8336 - acc: 0.02 - ETA: 29s - loss: 4.8336 - acc: 0.02 - ETA: 29s - loss: 4.8334 - acc: 0.02 - ETA: 29s - loss: 4.8333 - acc: 0.02 - ETA: 29s - loss: 4.8332 - acc: 0.02 - ETA: 28s - loss: 4.8332 - acc: 0.02 - ETA: 28s - loss: 4.8336 - acc: 0.02 - ETA: 28s - loss: 4.8338 - acc: 0.02 - ETA: 28s - loss: 4.8336 - acc: 0.02 - ETA: 28s - loss: 4.8336 - acc: 0.02 - ETA: 28s - loss: 4.8334 - acc: 0.02 - ETA: 28s - loss: 4.8339 - acc: 0.02 - ETA: 27s - loss: 4.8336 - acc: 0.02 - ETA: 27s - loss: 4.8339 - acc: 0.02 - ETA: 27s - loss: 4.8337 - acc: 0.02 - ETA: 27s - loss: 4.8337 - acc: 0.02 - ETA: 27s - loss: 4.8341 - acc: 0.02 - ETA: 27s - loss: 4.8341 - acc: 0.02 - ETA: 27s - loss: 4.8339 - acc: 0.02 - ETA: 26s - loss: 4.8340 - acc: 0.02 - ETA: 26s - loss: 4.8340 - acc: 0.02 - ETA: 26s - loss: 4.8340 - acc: 0.02 - ETA: 26s - loss: 4.8343 - acc: 0.02 - ETA: 26s - loss: 4.8345 - acc: 0.02 - ETA: 26s - loss: 4.8345 - acc: 0.02 - ETA: 25s - loss: 4.8344 - acc: 0.02 - ETA: 25s - loss: 4.8346 - acc: 0.02 - ETA: 25s - loss: 4.8347 - acc: 0.02 - ETA: 25s - loss: 4.8345 - acc: 0.02 - ETA: 25s - loss: 4.8341 - acc: 0.02 - ETA: 25s - loss: 4.8344 - acc: 0.02 - ETA: 25s - loss: 4.8345 - acc: 0.02 - ETA: 24s - loss: 4.8346 - acc: 0.02 - ETA: 24s - loss: 4.8343 - acc: 0.02 - ETA: 24s - loss: 4.8344 - acc: 0.02 - ETA: 24s - loss: 4.8341 - acc: 0.02 - ETA: 24s - loss: 4.8344 - acc: 0.02 - ETA: 24s - loss: 4.8344 - acc: 0.02 - ETA: 24s - loss: 4.8345 - acc: 0.02 - ETA: 23s - loss: 4.8345 - acc: 0.02 - ETA: 23s - loss: 4.8346 - acc: 0.02 - ETA: 23s - loss: 4.8348 - acc: 0.02 - ETA: 23s - loss: 4.8347 - acc: 0.02 - ETA: 23s - loss: 4.8343 - acc: 0.02 - ETA: 23s - loss: 4.8342 - acc: 0.02 - ETA: 22s - loss: 4.8345 - acc: 0.02 - ETA: 22s - loss: 4.8346 - acc: 0.02 - ETA: 22s - loss: 4.8351 - acc: 0.02 - ETA: 22s - loss: 4.8349 - acc: 0.02 - ETA: 22s - loss: 4.8352 - acc: 0.02 - ETA: 22s - loss: 4.8351 - acc: 0.02 - ETA: 22s - loss: 4.8353 - acc: 0.02 - ETA: 21s - loss: 4.8350 - acc: 0.02 - ETA: 21s - loss: 4.8351 - acc: 0.02 - ETA: 21s - loss: 4.8353 - acc: 0.02 - ETA: 21s - loss: 4.8349 - acc: 0.02 - ETA: 21s - loss: 4.8349 - acc: 0.02 - ETA: 21s - loss: 4.8354 - acc: 0.02 - ETA: 20s - loss: 4.8349 - acc: 0.02 - ETA: 20s - loss: 4.8348 - acc: 0.02 - ETA: 20s - loss: 4.8348 - acc: 0.02 - ETA: 20s - loss: 4.8350 - acc: 0.02 - ETA: 20s - loss: 4.8352 - acc: 0.02 - ETA: 20s - loss: 4.8350 - acc: 0.02 - ETA: 19s - loss: 4.8354 - acc: 0.02 - ETA: 19s - loss: 4.8352 - acc: 0.02 - ETA: 19s - loss: 4.8356 - acc: 0.02 - ETA: 19s - loss: 4.8358 - acc: 0.01 - ETA: 19s - loss: 4.8357 - acc: 0.01 - ETA: 19s - loss: 4.8359 - acc: 0.01 - ETA: 18s - loss: 4.8362 - acc: 0.01 - ETA: 18s - loss: 4.8363 - acc: 0.01 - ETA: 18s - loss: 4.8365 - acc: 0.01 - ETA: 18s - loss: 4.8361 - acc: 0.01 - ETA: 18s - loss: 4.8360 - acc: 0.01 - ETA: 17s - loss: 4.8359 - acc: 0.01 - ETA: 17s - loss: 4.8360 - acc: 0.01 - ETA: 17s - loss: 4.8363 - acc: 0.01 - ETA: 17s - loss: 4.8362 - acc: 0.01 - ETA: 17s - loss: 4.8360 - acc: 0.01 - ETA: 17s - loss: 4.8361 - acc: 0.01 - ETA: 17s - loss: 4.8360 - acc: 0.01 - ETA: 16s - loss: 4.8355 - acc: 0.01 - ETA: 16s - loss: 4.8353 - acc: 0.01 - ETA: 16s - loss: 4.8350 - acc: 0.01 - ETA: 16s - loss: 4.8351 - acc: 0.01 - ETA: 16s - loss: 4.8353 - acc: 0.01 - ETA: 16s - loss: 4.8358 - acc: 0.01 - ETA: 15s - loss: 4.8357 - acc: 0.01 - ETA: 15s - loss: 4.8357 - acc: 0.01 - ETA: 15s - loss: 4.8357 - acc: 0.01 - ETA: 15s - loss: 4.8356 - acc: 0.01 - ETA: 15s - loss: 4.8355 - acc: 0.01 - ETA: 15s - loss: 4.8354 - acc: 0.01 - ETA: 14s - loss: 4.8358 - acc: 0.01 - ETA: 14s - loss: 4.8351 - acc: 0.01 - ETA: 14s - loss: 4.8350 - acc: 0.01 - ETA: 14s - loss: 4.8349 - acc: 0.01 - ETA: 14s - loss: 4.8348 - acc: 0.01 - ETA: 13s - loss: 4.8350 - acc: 0.01 - ETA: 13s - loss: 4.8350 - acc: 0.01 - ETA: 13s - loss: 4.8348 - acc: 0.01 - ETA: 13s - loss: 4.8348 - acc: 0.01 - ETA: 13s - loss: 4.8346 - acc: 0.01 - ETA: 13s - loss: 4.8348 - acc: 0.01 - ETA: 13s - loss: 4.8348 - acc: 0.01 - ETA: 12s - loss: 4.8348 - acc: 0.01 - ETA: 12s - loss: 4.8344 - acc: 0.01 - ETA: 12s - loss: 4.8344 - acc: 0.01 - ETA: 12s - loss: 4.8341 - acc: 0.01 - ETA: 12s - loss: 4.8341 - acc: 0.01 - ETA: 12s - loss: 4.8339 - acc: 0.01 - ETA: 11s - loss: 4.8341 - acc: 0.01 - ETA: 11s - loss: 4.8338 - acc: 0.01 - ETA: 11s - loss: 4.8339 - acc: 0.01 - ETA: 11s - loss: 4.8344 - acc: 0.01 - ETA: 11s - loss: 4.8344 - acc: 0.01 - ETA: 11s - loss: 4.8343 - acc: 0.01 - ETA: 10s - loss: 4.8344 - acc: 0.01 - ETA: 10s - loss: 4.8346 - acc: 0.01 - ETA: 10s - loss: 4.8346 - acc: 0.01 - ETA: 10s - loss: 4.8346 - acc: 0.01 - ETA: 10s - loss: 4.8347 - acc: 0.01 - ETA: 10s - loss: 4.8347 - acc: 0.01 - ETA: 9s - loss: 4.8344 - acc: 0.0189 - ETA: 9s - loss: 4.8342 - acc: 0.018 - ETA: 9s - loss: 4.8342 - acc: 0.018 - ETA: 9s - loss: 4.8343 - acc: 0.018 - ETA: 9s - loss: 4.8341 - acc: 0.018 - ETA: 9s - loss: 4.8342 - acc: 0.018 - ETA: 8s - loss: 4.8345 - acc: 0.018 - ETA: 8s - loss: 4.8343 - acc: 0.018 - ETA: 8s - loss: 4.8342 - acc: 0.018 - ETA: 8s - loss: 4.8343 - acc: 0.018 - ETA: 8s - loss: 4.8342 - acc: 0.018 - ETA: 8s - loss: 4.8341 - acc: 0.018 - ETA: 7s - loss: 4.8342 - acc: 0.018 - ETA: 7s - loss: 4.8344 - acc: 0.018 - ETA: 7s - loss: 4.8341 - acc: 0.018 - ETA: 7s - loss: 4.8340 - acc: 0.018 - ETA: 7s - loss: 4.8340 - acc: 0.018 - ETA: 7s - loss: 4.8342 - acc: 0.018 - ETA: 6s - loss: 4.8341 - acc: 0.018 - ETA: 6s - loss: 4.8343 - acc: 0.018 - ETA: 6s - loss: 4.8345 - acc: 0.018 - ETA: 6s - loss: 4.8345 - acc: 0.018 - ETA: 6s - loss: 4.8345 - acc: 0.018 - ETA: 6s - loss: 4.8345 - acc: 0.018 - ETA: 5s - loss: 4.8346 - acc: 0.018 - ETA: 5s - loss: 4.8348 - acc: 0.018 - ETA: 5s - loss: 4.8344 - acc: 0.018 - ETA: 5s - loss: 4.8345 - acc: 0.018 - ETA: 5s - loss: 4.8346 - acc: 0.018 - ETA: 5s - loss: 4.8351 - acc: 0.017 - ETA: 4s - loss: 4.8350 - acc: 0.017 - ETA: 4s - loss: 4.8349 - acc: 0.018 - ETA: 4s - loss: 4.8353 - acc: 0.018 - ETA: 4s - loss: 4.8352 - acc: 0.018 - ETA: 4s - loss: 4.8351 - acc: 0.018 - ETA: 4s - loss: 4.8352 - acc: 0.018 - ETA: 3s - loss: 4.8356 - acc: 0.018 - ETA: 3s - loss: 4.8358 - acc: 0.018 - ETA: 3s - loss: 4.8358 - acc: 0.018 - ETA: 3s - loss: 4.8356 - acc: 0.018 - ETA: 3s - loss: 4.8353 - acc: 0.018 - ETA: 3s - loss: 4.8354 - acc: 0.018 - ETA: 2s - loss: 4.8357 - acc: 0.018 - ETA: 2s - loss: 4.8355 - acc: 0.018 - ETA: 2s - loss: 4.8354 - acc: 0.018 - ETA: 2s - loss: 4.8354 - acc: 0.018 - ETA: 2s - loss: 4.8354 - acc: 0.017 - ETA: 2s - loss: 4.8353 - acc: 0.018 - ETA: 1s - loss: 4.8355 - acc: 0.018 - ETA: 1s - loss: 4.8354 - acc: 0.018 - ETA: 1s - loss: 4.8352 - acc: 0.018 - ETA: 1s - loss: 4.8352 - acc: 0.018 - ETA: 1s - loss: 4.8350 - acc: 0.018 - ETA: 1s - loss: 4.8345 - acc: 0.018 - ETA: 0s - loss: 4.8341 - acc: 0.018 - ETA: 0s - loss: 4.8339 - acc: 0.018 - ETA: 0s - loss: 4.8342 - acc: 0.018 - ETA: 0s - loss: 4.8343 - acc: 0.017 - ETA: 0s - loss: 4.8345 - acc: 0.017 - 74s 178ms/step - loss: 4.8345 - acc: 0.0178 - val_loss: 4.8235 - val_acc: 0.0232\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 4.81050\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/417 [==============>...............] - ETA: 52s - loss: 4.8820 - acc: 0.06 - ETA: 52s - loss: 4.7973 - acc: 0.06 - ETA: 52s - loss: 4.8191 - acc: 0.06 - ETA: 52s - loss: 4.8318 - acc: 0.04 - ETA: 52s - loss: 4.8109 - acc: 0.03 - ETA: 52s - loss: 4.8214 - acc: 0.04 - ETA: 52s - loss: 4.8434 - acc: 0.03 - ETA: 51s - loss: 4.8331 - acc: 0.03 - ETA: 51s - loss: 4.8248 - acc: 0.04 - ETA: 50s - loss: 4.8216 - acc: 0.03 - ETA: 50s - loss: 4.8337 - acc: 0.03 - ETA: 50s - loss: 4.8285 - acc: 0.03 - ETA: 49s - loss: 4.8341 - acc: 0.03 - ETA: 49s - loss: 4.8368 - acc: 0.03 - ETA: 49s - loss: 4.8366 - acc: 0.02 - ETA: 49s - loss: 4.8345 - acc: 0.02 - ETA: 48s - loss: 4.8415 - acc: 0.02 - ETA: 48s - loss: 4.8450 - acc: 0.02 - ETA: 48s - loss: 4.8464 - acc: 0.02 - ETA: 48s - loss: 4.8448 - acc: 0.02 - ETA: 48s - loss: 4.8464 - acc: 0.02 - ETA: 48s - loss: 4.8489 - acc: 0.02 - ETA: 47s - loss: 4.8513 - acc: 0.02 - ETA: 47s - loss: 4.8516 - acc: 0.02 - ETA: 47s - loss: 4.8519 - acc: 0.02 - ETA: 47s - loss: 4.8528 - acc: 0.01 - ETA: 47s - loss: 4.8547 - acc: 0.01 - ETA: 47s - loss: 4.8464 - acc: 0.02 - ETA: 47s - loss: 4.8443 - acc: 0.02 - ETA: 47s - loss: 4.8463 - acc: 0.02 - ETA: 47s - loss: 4.8494 - acc: 0.02 - ETA: 48s - loss: 4.8511 - acc: 0.02 - ETA: 48s - loss: 4.8517 - acc: 0.02 - ETA: 47s - loss: 4.8485 - acc: 0.02 - ETA: 48s - loss: 4.8448 - acc: 0.02 - ETA: 50s - loss: 4.8427 - acc: 0.02 - ETA: 50s - loss: 4.8402 - acc: 0.02 - ETA: 51s - loss: 4.8363 - acc: 0.01 - ETA: 51s - loss: 4.8351 - acc: 0.02 - ETA: 51s - loss: 4.8338 - acc: 0.02 - ETA: 50s - loss: 4.8323 - acc: 0.02 - ETA: 50s - loss: 4.8300 - acc: 0.02 - ETA: 50s - loss: 4.8310 - acc: 0.02 - ETA: 50s - loss: 4.8313 - acc: 0.02 - ETA: 50s - loss: 4.8339 - acc: 0.02 - ETA: 50s - loss: 4.8314 - acc: 0.02 - ETA: 50s - loss: 4.8331 - acc: 0.02 - ETA: 50s - loss: 4.8332 - acc: 0.02 - ETA: 50s - loss: 4.8351 - acc: 0.02 - ETA: 50s - loss: 4.8352 - acc: 0.02 - ETA: 50s - loss: 4.8350 - acc: 0.02 - ETA: 50s - loss: 4.8335 - acc: 0.02 - ETA: 50s - loss: 4.8342 - acc: 0.02 - ETA: 50s - loss: 4.8333 - acc: 0.02 - ETA: 50s - loss: 4.8332 - acc: 0.02 - ETA: 50s - loss: 4.8324 - acc: 0.02 - ETA: 49s - loss: 4.8322 - acc: 0.02 - ETA: 49s - loss: 4.8336 - acc: 0.02 - ETA: 49s - loss: 4.8316 - acc: 0.02 - ETA: 49s - loss: 4.8320 - acc: 0.02 - ETA: 50s - loss: 4.8315 - acc: 0.02 - ETA: 49s - loss: 4.8326 - acc: 0.02 - ETA: 49s - loss: 4.8309 - acc: 0.02 - ETA: 49s - loss: 4.8311 - acc: 0.02 - ETA: 49s - loss: 4.8299 - acc: 0.02 - ETA: 49s - loss: 4.8316 - acc: 0.02 - ETA: 49s - loss: 4.8311 - acc: 0.02 - ETA: 49s - loss: 4.8320 - acc: 0.02 - ETA: 49s - loss: 4.8317 - acc: 0.02 - ETA: 49s - loss: 4.8323 - acc: 0.02 - ETA: 49s - loss: 4.8316 - acc: 0.02 - ETA: 49s - loss: 4.8319 - acc: 0.02 - ETA: 49s - loss: 4.8326 - acc: 0.02 - ETA: 49s - loss: 4.8341 - acc: 0.02 - ETA: 49s - loss: 4.8353 - acc: 0.02 - ETA: 49s - loss: 4.8351 - acc: 0.02 - ETA: 49s - loss: 4.8354 - acc: 0.02 - ETA: 49s - loss: 4.8355 - acc: 0.02 - ETA: 49s - loss: 4.8360 - acc: 0.01 - ETA: 49s - loss: 4.8359 - acc: 0.01 - ETA: 49s - loss: 4.8356 - acc: 0.02 - ETA: 48s - loss: 4.8352 - acc: 0.01 - ETA: 48s - loss: 4.8359 - acc: 0.01 - ETA: 48s - loss: 4.8358 - acc: 0.01 - ETA: 48s - loss: 4.8337 - acc: 0.01 - ETA: 48s - loss: 4.8326 - acc: 0.01 - ETA: 48s - loss: 4.8329 - acc: 0.01 - ETA: 48s - loss: 4.8335 - acc: 0.01 - ETA: 48s - loss: 4.8328 - acc: 0.01 - ETA: 48s - loss: 4.8338 - acc: 0.01 - ETA: 48s - loss: 4.8339 - acc: 0.01 - ETA: 48s - loss: 4.8335 - acc: 0.01 - ETA: 48s - loss: 4.8342 - acc: 0.01 - ETA: 48s - loss: 4.8340 - acc: 0.01 - ETA: 48s - loss: 4.8303 - acc: 0.01 - ETA: 48s - loss: 4.8306 - acc: 0.01 - ETA: 48s - loss: 4.8312 - acc: 0.01 - ETA: 48s - loss: 4.8311 - acc: 0.01 - ETA: 48s - loss: 4.8314 - acc: 0.01 - ETA: 48s - loss: 4.8309 - acc: 0.01 - ETA: 48s - loss: 4.8311 - acc: 0.01 - ETA: 48s - loss: 4.8310 - acc: 0.01 - ETA: 48s - loss: 4.8299 - acc: 0.01 - ETA: 48s - loss: 4.8314 - acc: 0.01 - ETA: 48s - loss: 4.8302 - acc: 0.01 - ETA: 48s - loss: 4.8305 - acc: 0.01 - ETA: 47s - loss: 4.8314 - acc: 0.01 - ETA: 47s - loss: 4.8312 - acc: 0.01 - ETA: 47s - loss: 4.8321 - acc: 0.01 - ETA: 47s - loss: 4.8320 - acc: 0.01 - ETA: 47s - loss: 4.8318 - acc: 0.01 - ETA: 47s - loss: 4.8330 - acc: 0.01 - ETA: 47s - loss: 4.8335 - acc: 0.01 - ETA: 47s - loss: 4.8340 - acc: 0.01 - ETA: 47s - loss: 4.8331 - acc: 0.01 - ETA: 47s - loss: 4.8315 - acc: 0.01 - ETA: 47s - loss: 4.8305 - acc: 0.01 - ETA: 47s - loss: 4.8319 - acc: 0.01 - ETA: 47s - loss: 4.8320 - acc: 0.01 - ETA: 46s - loss: 4.8319 - acc: 0.01 - ETA: 47s - loss: 4.8320 - acc: 0.01 - ETA: 46s - loss: 4.8330 - acc: 0.01 - ETA: 46s - loss: 4.8324 - acc: 0.01 - ETA: 46s - loss: 4.8343 - acc: 0.01 - ETA: 46s - loss: 4.8343 - acc: 0.01 - ETA: 46s - loss: 4.8349 - acc: 0.01 - ETA: 45s - loss: 4.8357 - acc: 0.01 - ETA: 45s - loss: 4.8366 - acc: 0.01 - ETA: 45s - loss: 4.8358 - acc: 0.01 - ETA: 45s - loss: 4.8360 - acc: 0.01 - ETA: 45s - loss: 4.8364 - acc: 0.01 - ETA: 45s - loss: 4.8346 - acc: 0.01 - ETA: 45s - loss: 4.8330 - acc: 0.01 - ETA: 45s - loss: 4.8318 - acc: 0.01 - ETA: 44s - loss: 4.8314 - acc: 0.01 - ETA: 44s - loss: 4.8320 - acc: 0.01 - ETA: 44s - loss: 4.8312 - acc: 0.01 - ETA: 44s - loss: 4.8314 - acc: 0.01 - ETA: 44s - loss: 4.8321 - acc: 0.01 - ETA: 44s - loss: 4.8326 - acc: 0.01 - ETA: 44s - loss: 4.8324 - acc: 0.01 - ETA: 44s - loss: 4.8331 - acc: 0.01 - ETA: 44s - loss: 4.8324 - acc: 0.01 - ETA: 43s - loss: 4.8329 - acc: 0.01 - ETA: 43s - loss: 4.8336 - acc: 0.01 - ETA: 43s - loss: 4.8338 - acc: 0.01 - ETA: 43s - loss: 4.8345 - acc: 0.01 - ETA: 43s - loss: 4.8345 - acc: 0.01 - ETA: 43s - loss: 4.8350 - acc: 0.01 - ETA: 43s - loss: 4.8351 - acc: 0.01 - ETA: 42s - loss: 4.8345 - acc: 0.01 - ETA: 42s - loss: 4.8341 - acc: 0.01 - ETA: 42s - loss: 4.8338 - acc: 0.01 - ETA: 42s - loss: 4.8348 - acc: 0.01 - ETA: 42s - loss: 4.8334 - acc: 0.01 - ETA: 42s - loss: 4.8331 - acc: 0.01 - ETA: 41s - loss: 4.8331 - acc: 0.01 - ETA: 41s - loss: 4.8331 - acc: 0.01 - ETA: 41s - loss: 4.8336 - acc: 0.01 - ETA: 41s - loss: 4.8330 - acc: 0.01 - ETA: 41s - loss: 4.8332 - acc: 0.01 - ETA: 41s - loss: 4.8330 - acc: 0.01 - ETA: 41s - loss: 4.8331 - acc: 0.01 - ETA: 40s - loss: 4.8334 - acc: 0.01 - ETA: 40s - loss: 4.8334 - acc: 0.01 - ETA: 40s - loss: 4.8339 - acc: 0.01 - ETA: 40s - loss: 4.8340 - acc: 0.01 - ETA: 40s - loss: 4.8345 - acc: 0.01 - ETA: 40s - loss: 4.8353 - acc: 0.01 - ETA: 39s - loss: 4.8355 - acc: 0.01 - ETA: 39s - loss: 4.8359 - acc: 0.01 - ETA: 39s - loss: 4.8352 - acc: 0.01 - ETA: 39s - loss: 4.8358 - acc: 0.01 - ETA: 39s - loss: 4.8363 - acc: 0.01 - ETA: 39s - loss: 4.8365 - acc: 0.01 - ETA: 39s - loss: 4.8369 - acc: 0.01 - ETA: 38s - loss: 4.8367 - acc: 0.01 - ETA: 38s - loss: 4.8370 - acc: 0.01 - ETA: 38s - loss: 4.8367 - acc: 0.01 - ETA: 38s - loss: 4.8363 - acc: 0.01 - ETA: 38s - loss: 4.8362 - acc: 0.01 - ETA: 38s - loss: 4.8362 - acc: 0.01 - ETA: 38s - loss: 4.8361 - acc: 0.01 - ETA: 37s - loss: 4.8366 - acc: 0.01 - ETA: 37s - loss: 4.8366 - acc: 0.01 - ETA: 37s - loss: 4.8369 - acc: 0.01 - ETA: 37s - loss: 4.8368 - acc: 0.01 - ETA: 37s - loss: 4.8370 - acc: 0.01 - ETA: 37s - loss: 4.8368 - acc: 0.01 - ETA: 36s - loss: 4.8374 - acc: 0.01 - ETA: 36s - loss: 4.8369 - acc: 0.01 - ETA: 36s - loss: 4.8362 - acc: 0.01 - ETA: 36s - loss: 4.8362 - acc: 0.01 - ETA: 36s - loss: 4.8359 - acc: 0.01 - ETA: 36s - loss: 4.8353 - acc: 0.01 - ETA: 36s - loss: 4.8349 - acc: 0.01 - ETA: 35s - loss: 4.8353 - acc: 0.01 - ETA: 35s - loss: 4.8354 - acc: 0.01 - ETA: 35s - loss: 4.8354 - acc: 0.01 - ETA: 35s - loss: 4.8359 - acc: 0.01 - ETA: 35s - loss: 4.8356 - acc: 0.01 - ETA: 35s - loss: 4.8357 - acc: 0.01 - ETA: 34s - loss: 4.8357 - acc: 0.01 - ETA: 34s - loss: 4.8358 - acc: 0.01 - ETA: 34s - loss: 4.8357 - acc: 0.01 - ETA: 34s - loss: 4.8356 - acc: 0.01 - ETA: 34s - loss: 4.8358 - acc: 0.01 - ETA: 34s - loss: 4.8356 - acc: 0.01 - ETA: 33s - loss: 4.8358 - acc: 0.01 - ETA: 33s - loss: 4.8356 - acc: 0.01 - ETA: 33s - loss: 4.8358 - acc: 0.01 - ETA: 33s - loss: 4.8355 - acc: 0.01 - ETA: 33s - loss: 4.8352 - acc: 0.01 - ETA: 33s - loss: 4.8353 - acc: 0.01 - ETA: 33s - loss: 4.8354 - acc: 0.0195"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 32s - loss: 4.8357 - acc: 0.01 - ETA: 32s - loss: 4.8355 - acc: 0.01 - ETA: 32s - loss: 4.8355 - acc: 0.01 - ETA: 32s - loss: 4.8352 - acc: 0.01 - ETA: 32s - loss: 4.8357 - acc: 0.01 - ETA: 32s - loss: 4.8353 - acc: 0.01 - ETA: 31s - loss: 4.8355 - acc: 0.01 - ETA: 31s - loss: 4.8357 - acc: 0.01 - ETA: 31s - loss: 4.8356 - acc: 0.01 - ETA: 31s - loss: 4.8357 - acc: 0.01 - ETA: 31s - loss: 4.8359 - acc: 0.01 - ETA: 31s - loss: 4.8361 - acc: 0.01 - ETA: 30s - loss: 4.8359 - acc: 0.01 - ETA: 30s - loss: 4.8358 - acc: 0.01 - ETA: 30s - loss: 4.8357 - acc: 0.01 - ETA: 30s - loss: 4.8354 - acc: 0.01 - ETA: 30s - loss: 4.8359 - acc: 0.01 - ETA: 30s - loss: 4.8358 - acc: 0.02 - ETA: 30s - loss: 4.8360 - acc: 0.02 - ETA: 29s - loss: 4.8357 - acc: 0.01 - ETA: 29s - loss: 4.8357 - acc: 0.02 - ETA: 29s - loss: 4.8356 - acc: 0.02 - ETA: 29s - loss: 4.8355 - acc: 0.02 - ETA: 29s - loss: 4.8353 - acc: 0.01 - ETA: 29s - loss: 4.8352 - acc: 0.01 - ETA: 28s - loss: 4.8354 - acc: 0.01 - ETA: 28s - loss: 4.8354 - acc: 0.01 - ETA: 28s - loss: 4.8356 - acc: 0.01 - ETA: 28s - loss: 4.8353 - acc: 0.01 - ETA: 28s - loss: 4.8357 - acc: 0.01 - ETA: 28s - loss: 4.8350 - acc: 0.01 - ETA: 27s - loss: 4.8351 - acc: 0.01 - ETA: 27s - loss: 4.8351 - acc: 0.01 - ETA: 27s - loss: 4.8348 - acc: 0.01 - ETA: 27s - loss: 4.8345 - acc: 0.01 - ETA: 27s - loss: 4.8341 - acc: 0.01 - ETA: 27s - loss: 4.8342 - acc: 0.01 - ETA: 26s - loss: 4.8335 - acc: 0.01 - ETA: 26s - loss: 4.8336 - acc: 0.01 - ETA: 26s - loss: 4.8339 - acc: 0.01 - ETA: 26s - loss: 4.8337 - acc: 0.01 - ETA: 26s - loss: 4.8335 - acc: 0.01 - ETA: 26s - loss: 4.8334 - acc: 0.01 - ETA: 26s - loss: 4.8332 - acc: 0.01 - ETA: 25s - loss: 4.8329 - acc: 0.01 - ETA: 25s - loss: 4.8333 - acc: 0.01 - ETA: 25s - loss: 4.8328 - acc: 0.01 - ETA: 25s - loss: 4.8327 - acc: 0.01 - ETA: 25s - loss: 4.8323 - acc: 0.01 - ETA: 25s - loss: 4.8330 - acc: 0.01 - ETA: 24s - loss: 4.8327 - acc: 0.01 - ETA: 24s - loss: 4.8330 - acc: 0.01 - ETA: 24s - loss: 4.8329 - acc: 0.01 - ETA: 24s - loss: 4.8331 - acc: 0.01 - ETA: 24s - loss: 4.8333 - acc: 0.01 - ETA: 24s - loss: 4.8330 - acc: 0.01 - ETA: 23s - loss: 4.8329 - acc: 0.01 - ETA: 23s - loss: 4.8333 - acc: 0.01 - ETA: 23s - loss: 4.8331 - acc: 0.01 - ETA: 23s - loss: 4.8341 - acc: 0.01 - ETA: 23s - loss: 4.8339 - acc: 0.01 - ETA: 23s - loss: 4.8342 - acc: 0.01 - ETA: 22s - loss: 4.8341 - acc: 0.01 - ETA: 22s - loss: 4.8342 - acc: 0.01 - ETA: 22s - loss: 4.8341 - acc: 0.01 - ETA: 22s - loss: 4.8341 - acc: 0.01 - ETA: 22s - loss: 4.8339 - acc: 0.01 - ETA: 22s - loss: 4.8336 - acc: 0.01 - ETA: 22s - loss: 4.8336 - acc: 0.01 - ETA: 21s - loss: 4.8335 - acc: 0.01 - ETA: 21s - loss: 4.8333 - acc: 0.01 - ETA: 21s - loss: 4.8331 - acc: 0.01 - ETA: 21s - loss: 4.8331 - acc: 0.01 - ETA: 21s - loss: 4.8330 - acc: 0.01 - ETA: 21s - loss: 4.8329 - acc: 0.01 - ETA: 20s - loss: 4.8333 - acc: 0.01 - ETA: 20s - loss: 4.8334 - acc: 0.01 - ETA: 20s - loss: 4.8330 - acc: 0.01 - ETA: 20s - loss: 4.8328 - acc: 0.01 - ETA: 20s - loss: 4.8328 - acc: 0.01 - ETA: 20s - loss: 4.8328 - acc: 0.01 - ETA: 19s - loss: 4.8325 - acc: 0.01 - ETA: 19s - loss: 4.8327 - acc: 0.01 - ETA: 19s - loss: 4.8328 - acc: 0.01 - ETA: 19s - loss: 4.8327 - acc: 0.01 - ETA: 19s - loss: 4.8327 - acc: 0.01 - ETA: 19s - loss: 4.8328 - acc: 0.01 - ETA: 18s - loss: 4.8327 - acc: 0.01 - ETA: 18s - loss: 4.8325 - acc: 0.01 - ETA: 18s - loss: 4.8322 - acc: 0.01 - ETA: 18s - loss: 4.8325 - acc: 0.01 - ETA: 18s - loss: 4.8322 - acc: 0.01 - ETA: 18s - loss: 4.8323 - acc: 0.01 - ETA: 17s - loss: 4.8325 - acc: 0.01 - ETA: 17s - loss: 4.8325 - acc: 0.01 - ETA: 17s - loss: 4.8329 - acc: 0.01 - ETA: 17s - loss: 4.8323 - acc: 0.01 - ETA: 17s - loss: 4.8322 - acc: 0.01 - ETA: 17s - loss: 4.8319 - acc: 0.01 - ETA: 16s - loss: 4.8315 - acc: 0.01 - ETA: 16s - loss: 4.8316 - acc: 0.01 - ETA: 16s - loss: 4.8316 - acc: 0.01 - ETA: 16s - loss: 4.8315 - acc: 0.01 - ETA: 16s - loss: 4.8313 - acc: 0.01 - ETA: 16s - loss: 4.8308 - acc: 0.01 - ETA: 15s - loss: 4.8310 - acc: 0.01 - ETA: 15s - loss: 4.8310 - acc: 0.01 - ETA: 15s - loss: 4.8310 - acc: 0.01 - ETA: 15s - loss: 4.8312 - acc: 0.01 - ETA: 15s - loss: 4.8305 - acc: 0.01 - ETA: 15s - loss: 4.8306 - acc: 0.01 - ETA: 14s - loss: 4.8308 - acc: 0.01 - ETA: 14s - loss: 4.8306 - acc: 0.01 - ETA: 14s - loss: 4.8307 - acc: 0.01 - ETA: 14s - loss: 4.8308 - acc: 0.01 - ETA: 14s - loss: 4.8310 - acc: 0.01 - ETA: 14s - loss: 4.8310 - acc: 0.01 - ETA: 14s - loss: 4.8308 - acc: 0.01 - ETA: 13s - loss: 4.8306 - acc: 0.01 - ETA: 13s - loss: 4.8305 - acc: 0.01 - ETA: 13s - loss: 4.8307 - acc: 0.01 - ETA: 13s - loss: 4.8310 - acc: 0.01 - ETA: 13s - loss: 4.8307 - acc: 0.01 - ETA: 13s - loss: 4.8307 - acc: 0.01 - ETA: 12s - loss: 4.8310 - acc: 0.01 - ETA: 12s - loss: 4.8311 - acc: 0.01 - ETA: 12s - loss: 4.8309 - acc: 0.01 - ETA: 12s - loss: 4.8312 - acc: 0.01 - ETA: 12s - loss: 4.8313 - acc: 0.01 - ETA: 11s - loss: 4.8309 - acc: 0.01 - ETA: 11s - loss: 4.8310 - acc: 0.01 - ETA: 11s - loss: 4.8310 - acc: 0.01 - ETA: 11s - loss: 4.8309 - acc: 0.01 - ETA: 11s - loss: 4.8309 - acc: 0.01 - ETA: 11s - loss: 4.8303 - acc: 0.01 - ETA: 11s - loss: 4.8299 - acc: 0.01 - ETA: 10s - loss: 4.8298 - acc: 0.01 - ETA: 10s - loss: 4.8298 - acc: 0.01 - ETA: 10s - loss: 4.8298 - acc: 0.01 - ETA: 10s - loss: 4.8292 - acc: 0.01 - ETA: 10s - loss: 4.8290 - acc: 0.01 - ETA: 10s - loss: 4.8287 - acc: 0.01 - ETA: 9s - loss: 4.8284 - acc: 0.0190 - ETA: 9s - loss: 4.8284 - acc: 0.019 - ETA: 9s - loss: 4.8283 - acc: 0.019 - ETA: 9s - loss: 4.8284 - acc: 0.019 - ETA: 9s - loss: 4.8287 - acc: 0.019 - ETA: 9s - loss: 4.8283 - acc: 0.019 - ETA: 8s - loss: 4.8287 - acc: 0.019 - ETA: 8s - loss: 4.8289 - acc: 0.019 - ETA: 8s - loss: 4.8291 - acc: 0.019 - ETA: 8s - loss: 4.8285 - acc: 0.019 - ETA: 8s - loss: 4.8284 - acc: 0.019 - ETA: 8s - loss: 4.8285 - acc: 0.019 - ETA: 7s - loss: 4.8284 - acc: 0.019 - ETA: 7s - loss: 4.8278 - acc: 0.019 - ETA: 7s - loss: 4.8278 - acc: 0.019 - ETA: 7s - loss: 4.8278 - acc: 0.019 - ETA: 7s - loss: 4.8278 - acc: 0.019 - ETA: 7s - loss: 4.8275 - acc: 0.019 - ETA: 6s - loss: 4.8277 - acc: 0.018 - ETA: 6s - loss: 4.8274 - acc: 0.018 - ETA: 6s - loss: 4.8276 - acc: 0.018 - ETA: 6s - loss: 4.8274 - acc: 0.019 - ETA: 6s - loss: 4.8277 - acc: 0.018 - ETA: 6s - loss: 4.8278 - acc: 0.018 - ETA: 5s - loss: 4.8277 - acc: 0.018 - ETA: 5s - loss: 4.8275 - acc: 0.018 - ETA: 5s - loss: 4.8277 - acc: 0.018 - ETA: 5s - loss: 4.8277 - acc: 0.018 - ETA: 5s - loss: 4.8275 - acc: 0.018 - ETA: 5s - loss: 4.8273 - acc: 0.018 - ETA: 4s - loss: 4.8272 - acc: 0.018 - ETA: 4s - loss: 4.8268 - acc: 0.018 - ETA: 4s - loss: 4.8268 - acc: 0.018 - ETA: 4s - loss: 4.8265 - acc: 0.018 - ETA: 4s - loss: 4.8266 - acc: 0.019 - ETA: 4s - loss: 4.8266 - acc: 0.018 - ETA: 3s - loss: 4.8271 - acc: 0.018 - ETA: 3s - loss: 4.8269 - acc: 0.019 - ETA: 3s - loss: 4.8275 - acc: 0.018 - ETA: 3s - loss: 4.8273 - acc: 0.018 - ETA: 3s - loss: 4.8272 - acc: 0.018 - ETA: 3s - loss: 4.8275 - acc: 0.018 - ETA: 2s - loss: 4.8280 - acc: 0.018 - ETA: 2s - loss: 4.8281 - acc: 0.018 - ETA: 2s - loss: 4.8284 - acc: 0.018 - ETA: 2s - loss: 4.8282 - acc: 0.018 - ETA: 2s - loss: 4.8281 - acc: 0.018 - ETA: 2s - loss: 4.8283 - acc: 0.018 - ETA: 1s - loss: 4.8286 - acc: 0.018 - ETA: 1s - loss: 4.8285 - acc: 0.018 - ETA: 1s - loss: 4.8286 - acc: 0.018 - ETA: 1s - loss: 4.8286 - acc: 0.018 - ETA: 1s - loss: 4.8285 - acc: 0.018 - ETA: 1s - loss: 4.8284 - acc: 0.018 - ETA: 0s - loss: 4.8286 - acc: 0.018 - ETA: 0s - loss: 4.8280 - acc: 0.019 - ETA: 0s - loss: 4.8282 - acc: 0.019 - ETA: 0s - loss: 4.8279 - acc: 0.019 - ETA: 0s - loss: 4.8278 - acc: 0.019 - 74s 177ms/step - loss: 4.8277 - acc: 0.0190 - val_loss: 4.7899 - val_acc: 0.0232\n",
      "\n",
      "Epoch 00039: val_loss improved from 4.81050 to 4.78987, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/417 [==============>...............] - ETA: 59s - loss: 4.9346 - acc: 0.0000e+ - ETA: 57s - loss: 4.9279 - acc: 0.0312   - ETA: 55s - loss: 4.9460 - acc: 0.02 - ETA: 55s - loss: 4.8620 - acc: 0.04 - ETA: 54s - loss: 4.8568 - acc: 0.03 - ETA: 54s - loss: 4.8370 - acc: 0.05 - ETA: 53s - loss: 4.8391 - acc: 0.04 - ETA: 53s - loss: 4.8404 - acc: 0.03 - ETA: 52s - loss: 4.8276 - acc: 0.03 - ETA: 52s - loss: 4.8300 - acc: 0.03 - ETA: 52s - loss: 4.8335 - acc: 0.02 - ETA: 51s - loss: 4.8300 - acc: 0.02 - ETA: 51s - loss: 4.8251 - acc: 0.02 - ETA: 50s - loss: 4.8191 - acc: 0.02 - ETA: 50s - loss: 4.8213 - acc: 0.02 - ETA: 50s - loss: 4.8226 - acc: 0.02 - ETA: 49s - loss: 4.8334 - acc: 0.02 - ETA: 49s - loss: 4.8295 - acc: 0.02 - ETA: 49s - loss: 4.8273 - acc: 0.02 - ETA: 48s - loss: 4.8120 - acc: 0.02 - ETA: 48s - loss: 4.8107 - acc: 0.02 - ETA: 48s - loss: 4.8108 - acc: 0.02 - ETA: 48s - loss: 4.8113 - acc: 0.02 - ETA: 47s - loss: 4.8103 - acc: 0.02 - ETA: 47s - loss: 4.8117 - acc: 0.02 - ETA: 47s - loss: 4.8128 - acc: 0.02 - ETA: 47s - loss: 4.8145 - acc: 0.02 - ETA: 46s - loss: 4.8145 - acc: 0.02 - ETA: 46s - loss: 4.8151 - acc: 0.02 - ETA: 46s - loss: 4.8162 - acc: 0.02 - ETA: 46s - loss: 4.8149 - acc: 0.02 - ETA: 46s - loss: 4.8177 - acc: 0.02 - ETA: 46s - loss: 4.8122 - acc: 0.02 - ETA: 46s - loss: 4.8079 - acc: 0.02 - ETA: 47s - loss: 4.8098 - acc: 0.02 - ETA: 50s - loss: 4.8097 - acc: 0.02 - ETA: 52s - loss: 4.8088 - acc: 0.02 - ETA: 52s - loss: 4.8086 - acc: 0.02 - ETA: 52s - loss: 4.8036 - acc: 0.02 - ETA: 52s - loss: 4.8040 - acc: 0.02 - ETA: 53s - loss: 4.8074 - acc: 0.02 - ETA: 53s - loss: 4.8064 - acc: 0.02 - ETA: 54s - loss: 4.8069 - acc: 0.02 - ETA: 55s - loss: 4.8066 - acc: 0.01 - ETA: 55s - loss: 4.8073 - acc: 0.01 - ETA: 55s - loss: 4.8100 - acc: 0.01 - ETA: 55s - loss: 4.8094 - acc: 0.01 - ETA: 55s - loss: 4.8067 - acc: 0.01 - ETA: 55s - loss: 4.8075 - acc: 0.02 - ETA: 55s - loss: 4.8086 - acc: 0.02 - ETA: 55s - loss: 4.8093 - acc: 0.02 - ETA: 54s - loss: 4.8094 - acc: 0.02 - ETA: 54s - loss: 4.8072 - acc: 0.02 - ETA: 55s - loss: 4.8072 - acc: 0.02 - ETA: 55s - loss: 4.8068 - acc: 0.02 - ETA: 55s - loss: 4.8059 - acc: 0.02 - ETA: 55s - loss: 4.8072 - acc: 0.01 - ETA: 55s - loss: 4.8061 - acc: 0.01 - ETA: 55s - loss: 4.8079 - acc: 0.01 - ETA: 55s - loss: 4.8072 - acc: 0.02 - ETA: 55s - loss: 4.8082 - acc: 0.02 - ETA: 55s - loss: 4.8060 - acc: 0.02 - ETA: 55s - loss: 4.8074 - acc: 0.02 - ETA: 55s - loss: 4.8105 - acc: 0.02 - ETA: 56s - loss: 4.8110 - acc: 0.02 - ETA: 56s - loss: 4.8110 - acc: 0.01 - ETA: 56s - loss: 4.8100 - acc: 0.02 - ETA: 55s - loss: 4.8112 - acc: 0.02 - ETA: 55s - loss: 4.8101 - acc: 0.01 - ETA: 55s - loss: 4.8111 - acc: 0.01 - ETA: 55s - loss: 4.8124 - acc: 0.01 - ETA: 55s - loss: 4.8117 - acc: 0.01 - ETA: 55s - loss: 4.8124 - acc: 0.01 - ETA: 55s - loss: 4.8139 - acc: 0.01 - ETA: 55s - loss: 4.8163 - acc: 0.01 - ETA: 55s - loss: 4.8167 - acc: 0.01 - ETA: 55s - loss: 4.8162 - acc: 0.01 - ETA: 54s - loss: 4.8168 - acc: 0.01 - ETA: 54s - loss: 4.8159 - acc: 0.01 - ETA: 54s - loss: 4.8181 - acc: 0.01 - ETA: 54s - loss: 4.8183 - acc: 0.01 - ETA: 54s - loss: 4.8191 - acc: 0.01 - ETA: 54s - loss: 4.8196 - acc: 0.01 - ETA: 53s - loss: 4.8182 - acc: 0.01 - ETA: 53s - loss: 4.8183 - acc: 0.01 - ETA: 53s - loss: 4.8187 - acc: 0.01 - ETA: 53s - loss: 4.8198 - acc: 0.01 - ETA: 53s - loss: 4.8195 - acc: 0.01 - ETA: 52s - loss: 4.8204 - acc: 0.01 - ETA: 52s - loss: 4.8196 - acc: 0.01 - ETA: 52s - loss: 4.8189 - acc: 0.01 - ETA: 52s - loss: 4.8180 - acc: 0.01 - ETA: 52s - loss: 4.8184 - acc: 0.01 - ETA: 52s - loss: 4.8192 - acc: 0.01 - ETA: 52s - loss: 4.8191 - acc: 0.01 - ETA: 52s - loss: 4.8190 - acc: 0.01 - ETA: 52s - loss: 4.8201 - acc: 0.01 - ETA: 51s - loss: 4.8200 - acc: 0.01 - ETA: 51s - loss: 4.8193 - acc: 0.01 - ETA: 51s - loss: 4.8187 - acc: 0.02 - ETA: 51s - loss: 4.8197 - acc: 0.02 - ETA: 51s - loss: 4.8199 - acc: 0.02 - ETA: 51s - loss: 4.8213 - acc: 0.02 - ETA: 51s - loss: 4.8215 - acc: 0.02 - ETA: 50s - loss: 4.8211 - acc: 0.02 - ETA: 50s - loss: 4.8221 - acc: 0.02 - ETA: 50s - loss: 4.8209 - acc: 0.01 - ETA: 50s - loss: 4.8214 - acc: 0.01 - ETA: 50s - loss: 4.8213 - acc: 0.01 - ETA: 50s - loss: 4.8216 - acc: 0.01 - ETA: 50s - loss: 4.8209 - acc: 0.01 - ETA: 49s - loss: 4.8201 - acc: 0.01 - ETA: 49s - loss: 4.8197 - acc: 0.01 - ETA: 49s - loss: 4.8200 - acc: 0.01 - ETA: 49s - loss: 4.8203 - acc: 0.01 - ETA: 49s - loss: 4.8203 - acc: 0.01 - ETA: 49s - loss: 4.8216 - acc: 0.01 - ETA: 49s - loss: 4.8230 - acc: 0.01 - ETA: 48s - loss: 4.8236 - acc: 0.02 - ETA: 48s - loss: 4.8239 - acc: 0.02 - ETA: 48s - loss: 4.8244 - acc: 0.02 - ETA: 48s - loss: 4.8252 - acc: 0.02 - ETA: 48s - loss: 4.8255 - acc: 0.01 - ETA: 48s - loss: 4.8252 - acc: 0.02 - ETA: 48s - loss: 4.8259 - acc: 0.02 - ETA: 47s - loss: 4.8264 - acc: 0.01 - ETA: 47s - loss: 4.8250 - acc: 0.02 - ETA: 47s - loss: 4.8260 - acc: 0.02 - ETA: 47s - loss: 4.8261 - acc: 0.02 - ETA: 47s - loss: 4.8258 - acc: 0.02 - ETA: 47s - loss: 4.8260 - acc: 0.02 - ETA: 47s - loss: 4.8243 - acc: 0.02 - ETA: 46s - loss: 4.8249 - acc: 0.02 - ETA: 46s - loss: 4.8245 - acc: 0.02 - ETA: 46s - loss: 4.8241 - acc: 0.02 - ETA: 46s - loss: 4.8240 - acc: 0.02 - ETA: 46s - loss: 4.8238 - acc: 0.02 - ETA: 46s - loss: 4.8236 - acc: 0.02 - ETA: 45s - loss: 4.8233 - acc: 0.02 - ETA: 45s - loss: 4.8222 - acc: 0.02 - ETA: 45s - loss: 4.8217 - acc: 0.02 - ETA: 45s - loss: 4.8208 - acc: 0.02 - ETA: 45s - loss: 4.8196 - acc: 0.02 - ETA: 45s - loss: 4.8191 - acc: 0.02 - ETA: 45s - loss: 4.8190 - acc: 0.02 - ETA: 45s - loss: 4.8192 - acc: 0.02 - ETA: 45s - loss: 4.8201 - acc: 0.02 - ETA: 45s - loss: 4.8196 - acc: 0.02 - ETA: 45s - loss: 4.8200 - acc: 0.02 - ETA: 45s - loss: 4.8194 - acc: 0.02 - ETA: 44s - loss: 4.8199 - acc: 0.02 - ETA: 44s - loss: 4.8203 - acc: 0.02 - ETA: 44s - loss: 4.8207 - acc: 0.02 - ETA: 44s - loss: 4.8207 - acc: 0.02 - ETA: 44s - loss: 4.8207 - acc: 0.02 - ETA: 44s - loss: 4.8201 - acc: 0.02 - ETA: 44s - loss: 4.8198 - acc: 0.02 - ETA: 43s - loss: 4.8198 - acc: 0.02 - ETA: 43s - loss: 4.8198 - acc: 0.02 - ETA: 43s - loss: 4.8201 - acc: 0.02 - ETA: 43s - loss: 4.8199 - acc: 0.02 - ETA: 43s - loss: 4.8193 - acc: 0.02 - ETA: 43s - loss: 4.8187 - acc: 0.02 - ETA: 42s - loss: 4.8191 - acc: 0.02 - ETA: 42s - loss: 4.8192 - acc: 0.02 - ETA: 42s - loss: 4.8195 - acc: 0.02 - ETA: 42s - loss: 4.8196 - acc: 0.02 - ETA: 42s - loss: 4.8198 - acc: 0.02 - ETA: 42s - loss: 4.8199 - acc: 0.02 - ETA: 41s - loss: 4.8200 - acc: 0.02 - ETA: 41s - loss: 4.8203 - acc: 0.02 - ETA: 41s - loss: 4.8209 - acc: 0.02 - ETA: 41s - loss: 4.8208 - acc: 0.02 - ETA: 41s - loss: 4.8201 - acc: 0.02 - ETA: 41s - loss: 4.8197 - acc: 0.02 - ETA: 40s - loss: 4.8192 - acc: 0.02 - ETA: 40s - loss: 4.8196 - acc: 0.02 - ETA: 40s - loss: 4.8185 - acc: 0.02 - ETA: 40s - loss: 4.8189 - acc: 0.02 - ETA: 40s - loss: 4.8196 - acc: 0.02 - ETA: 40s - loss: 4.8197 - acc: 0.02 - ETA: 39s - loss: 4.8200 - acc: 0.02 - ETA: 39s - loss: 4.8195 - acc: 0.02 - ETA: 39s - loss: 4.8197 - acc: 0.02 - ETA: 39s - loss: 4.8194 - acc: 0.02 - ETA: 39s - loss: 4.8199 - acc: 0.02 - ETA: 39s - loss: 4.8205 - acc: 0.02 - ETA: 39s - loss: 4.8200 - acc: 0.02 - ETA: 39s - loss: 4.8203 - acc: 0.02 - ETA: 38s - loss: 4.8203 - acc: 0.02 - ETA: 38s - loss: 4.8201 - acc: 0.02 - ETA: 38s - loss: 4.8201 - acc: 0.02 - ETA: 38s - loss: 4.8205 - acc: 0.02 - ETA: 38s - loss: 4.8201 - acc: 0.02 - ETA: 38s - loss: 4.8202 - acc: 0.02 - ETA: 37s - loss: 4.8203 - acc: 0.02 - ETA: 37s - loss: 4.8200 - acc: 0.02 - ETA: 37s - loss: 4.8196 - acc: 0.02 - ETA: 37s - loss: 4.8200 - acc: 0.02 - ETA: 37s - loss: 4.8206 - acc: 0.02 - ETA: 37s - loss: 4.8202 - acc: 0.02 - ETA: 36s - loss: 4.8200 - acc: 0.02 - ETA: 36s - loss: 4.8202 - acc: 0.02 - ETA: 36s - loss: 4.8203 - acc: 0.02 - ETA: 36s - loss: 4.8198 - acc: 0.02 - ETA: 36s - loss: 4.8197 - acc: 0.02 - ETA: 36s - loss: 4.8195 - acc: 0.02 - ETA: 35s - loss: 4.8203 - acc: 0.02 - ETA: 35s - loss: 4.8200 - acc: 0.02 - ETA: 35s - loss: 4.8205 - acc: 0.02 - ETA: 35s - loss: 4.8210 - acc: 0.02 - ETA: 35s - loss: 4.8209 - acc: 0.02 - ETA: 35s - loss: 4.8204 - acc: 0.02 - ETA: 34s - loss: 4.8200 - acc: 0.02 - ETA: 34s - loss: 4.8208 - acc: 0.0212"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 34s - loss: 4.8206 - acc: 0.02 - ETA: 34s - loss: 4.8209 - acc: 0.02 - ETA: 34s - loss: 4.8209 - acc: 0.02 - ETA: 34s - loss: 4.8209 - acc: 0.02 - ETA: 33s - loss: 4.8209 - acc: 0.02 - ETA: 33s - loss: 4.8217 - acc: 0.02 - ETA: 33s - loss: 4.8224 - acc: 0.02 - ETA: 33s - loss: 4.8221 - acc: 0.02 - ETA: 33s - loss: 4.8222 - acc: 0.02 - ETA: 33s - loss: 4.8224 - acc: 0.02 - ETA: 33s - loss: 4.8223 - acc: 0.02 - ETA: 32s - loss: 4.8220 - acc: 0.02 - ETA: 32s - loss: 4.8223 - acc: 0.02 - ETA: 32s - loss: 4.8220 - acc: 0.02 - ETA: 32s - loss: 4.8220 - acc: 0.02 - ETA: 32s - loss: 4.8222 - acc: 0.02 - ETA: 32s - loss: 4.8221 - acc: 0.02 - ETA: 31s - loss: 4.8220 - acc: 0.02 - ETA: 31s - loss: 4.8219 - acc: 0.02 - ETA: 31s - loss: 4.8216 - acc: 0.02 - ETA: 31s - loss: 4.8211 - acc: 0.02 - ETA: 31s - loss: 4.8219 - acc: 0.02 - ETA: 30s - loss: 4.8227 - acc: 0.02 - ETA: 30s - loss: 4.8229 - acc: 0.02 - ETA: 30s - loss: 4.8232 - acc: 0.02 - ETA: 30s - loss: 4.8230 - acc: 0.02 - ETA: 30s - loss: 4.8229 - acc: 0.02 - ETA: 30s - loss: 4.8226 - acc: 0.02 - ETA: 29s - loss: 4.8229 - acc: 0.02 - ETA: 29s - loss: 4.8233 - acc: 0.02 - ETA: 29s - loss: 4.8229 - acc: 0.02 - ETA: 29s - loss: 4.8228 - acc: 0.02 - ETA: 29s - loss: 4.8230 - acc: 0.02 - ETA: 29s - loss: 4.8234 - acc: 0.02 - ETA: 28s - loss: 4.8237 - acc: 0.02 - ETA: 28s - loss: 4.8236 - acc: 0.02 - ETA: 28s - loss: 4.8237 - acc: 0.02 - ETA: 28s - loss: 4.8241 - acc: 0.02 - ETA: 28s - loss: 4.8243 - acc: 0.02 - ETA: 28s - loss: 4.8244 - acc: 0.02 - ETA: 27s - loss: 4.8241 - acc: 0.02 - ETA: 27s - loss: 4.8238 - acc: 0.02 - ETA: 27s - loss: 4.8240 - acc: 0.02 - ETA: 27s - loss: 4.8239 - acc: 0.02 - ETA: 27s - loss: 4.8242 - acc: 0.02 - ETA: 27s - loss: 4.8240 - acc: 0.02 - ETA: 26s - loss: 4.8232 - acc: 0.02 - ETA: 26s - loss: 4.8224 - acc: 0.02 - ETA: 26s - loss: 4.8225 - acc: 0.02 - ETA: 26s - loss: 4.8223 - acc: 0.02 - ETA: 26s - loss: 4.8220 - acc: 0.02 - ETA: 26s - loss: 4.8222 - acc: 0.02 - ETA: 25s - loss: 4.8227 - acc: 0.02 - ETA: 25s - loss: 4.8232 - acc: 0.02 - ETA: 25s - loss: 4.8224 - acc: 0.02 - ETA: 25s - loss: 4.8226 - acc: 0.02 - ETA: 25s - loss: 4.8230 - acc: 0.02 - ETA: 25s - loss: 4.8230 - acc: 0.02 - ETA: 24s - loss: 4.8226 - acc: 0.02 - ETA: 24s - loss: 4.8219 - acc: 0.02 - ETA: 24s - loss: 4.8222 - acc: 0.02 - ETA: 24s - loss: 4.8219 - acc: 0.02 - ETA: 24s - loss: 4.8225 - acc: 0.02 - ETA: 24s - loss: 4.8227 - acc: 0.02 - ETA: 23s - loss: 4.8226 - acc: 0.02 - ETA: 23s - loss: 4.8222 - acc: 0.02 - ETA: 23s - loss: 4.8223 - acc: 0.02 - ETA: 23s - loss: 4.8224 - acc: 0.02 - ETA: 23s - loss: 4.8222 - acc: 0.02 - ETA: 22s - loss: 4.8221 - acc: 0.02 - ETA: 22s - loss: 4.8223 - acc: 0.02 - ETA: 22s - loss: 4.8222 - acc: 0.02 - ETA: 22s - loss: 4.8220 - acc: 0.02 - ETA: 22s - loss: 4.8222 - acc: 0.02 - ETA: 22s - loss: 4.8220 - acc: 0.02 - ETA: 21s - loss: 4.8217 - acc: 0.02 - ETA: 21s - loss: 4.8220 - acc: 0.02 - ETA: 21s - loss: 4.8216 - acc: 0.02 - ETA: 21s - loss: 4.8218 - acc: 0.02 - ETA: 21s - loss: 4.8220 - acc: 0.02 - ETA: 21s - loss: 4.8220 - acc: 0.02 - ETA: 20s - loss: 4.8223 - acc: 0.02 - ETA: 20s - loss: 4.8222 - acc: 0.02 - ETA: 20s - loss: 4.8221 - acc: 0.02 - ETA: 20s - loss: 4.8218 - acc: 0.02 - ETA: 20s - loss: 4.8219 - acc: 0.02 - ETA: 19s - loss: 4.8221 - acc: 0.02 - ETA: 19s - loss: 4.8220 - acc: 0.02 - ETA: 19s - loss: 4.8219 - acc: 0.02 - ETA: 19s - loss: 4.8220 - acc: 0.02 - ETA: 19s - loss: 4.8218 - acc: 0.02 - ETA: 19s - loss: 4.8216 - acc: 0.02 - ETA: 18s - loss: 4.8212 - acc: 0.02 - ETA: 18s - loss: 4.8208 - acc: 0.02 - ETA: 18s - loss: 4.8209 - acc: 0.02 - ETA: 18s - loss: 4.8210 - acc: 0.02 - ETA: 18s - loss: 4.8207 - acc: 0.02 - ETA: 18s - loss: 4.8207 - acc: 0.02 - ETA: 17s - loss: 4.8210 - acc: 0.02 - ETA: 17s - loss: 4.8206 - acc: 0.02 - ETA: 17s - loss: 4.8206 - acc: 0.02 - ETA: 17s - loss: 4.8203 - acc: 0.02 - ETA: 17s - loss: 4.8203 - acc: 0.02 - ETA: 17s - loss: 4.8203 - acc: 0.02 - ETA: 16s - loss: 4.8205 - acc: 0.02 - ETA: 16s - loss: 4.8202 - acc: 0.02 - ETA: 16s - loss: 4.8202 - acc: 0.02 - ETA: 16s - loss: 4.8204 - acc: 0.02 - ETA: 16s - loss: 4.8202 - acc: 0.02 - ETA: 16s - loss: 4.8201 - acc: 0.02 - ETA: 15s - loss: 4.8197 - acc: 0.02 - ETA: 15s - loss: 4.8195 - acc: 0.02 - ETA: 15s - loss: 4.8200 - acc: 0.02 - ETA: 15s - loss: 4.8200 - acc: 0.02 - ETA: 15s - loss: 4.8202 - acc: 0.02 - ETA: 15s - loss: 4.8203 - acc: 0.02 - ETA: 14s - loss: 4.8208 - acc: 0.02 - ETA: 14s - loss: 4.8210 - acc: 0.02 - ETA: 14s - loss: 4.8213 - acc: 0.02 - ETA: 14s - loss: 4.8211 - acc: 0.02 - ETA: 14s - loss: 4.8211 - acc: 0.02 - ETA: 14s - loss: 4.8214 - acc: 0.02 - ETA: 13s - loss: 4.8212 - acc: 0.02 - ETA: 13s - loss: 4.8214 - acc: 0.02 - ETA: 13s - loss: 4.8215 - acc: 0.02 - ETA: 13s - loss: 4.8211 - acc: 0.02 - ETA: 13s - loss: 4.8212 - acc: 0.02 - ETA: 13s - loss: 4.8210 - acc: 0.02 - ETA: 12s - loss: 4.8211 - acc: 0.02 - ETA: 12s - loss: 4.8213 - acc: 0.02 - ETA: 12s - loss: 4.8207 - acc: 0.02 - ETA: 12s - loss: 4.8207 - acc: 0.02 - ETA: 12s - loss: 4.8207 - acc: 0.02 - ETA: 11s - loss: 4.8205 - acc: 0.02 - ETA: 11s - loss: 4.8208 - acc: 0.02 - ETA: 11s - loss: 4.8206 - acc: 0.02 - ETA: 11s - loss: 4.8204 - acc: 0.02 - ETA: 11s - loss: 4.8204 - acc: 0.02 - ETA: 11s - loss: 4.8208 - acc: 0.02 - ETA: 10s - loss: 4.8213 - acc: 0.02 - ETA: 10s - loss: 4.8210 - acc: 0.02 - ETA: 10s - loss: 4.8209 - acc: 0.02 - ETA: 10s - loss: 4.8208 - acc: 0.02 - ETA: 10s - loss: 4.8208 - acc: 0.02 - ETA: 10s - loss: 4.8209 - acc: 0.02 - ETA: 9s - loss: 4.8211 - acc: 0.0220 - ETA: 9s - loss: 4.8213 - acc: 0.021 - ETA: 9s - loss: 4.8212 - acc: 0.022 - ETA: 9s - loss: 4.8213 - acc: 0.022 - ETA: 9s - loss: 4.8212 - acc: 0.021 - ETA: 8s - loss: 4.8212 - acc: 0.021 - ETA: 8s - loss: 4.8213 - acc: 0.021 - ETA: 8s - loss: 4.8214 - acc: 0.021 - ETA: 8s - loss: 4.8211 - acc: 0.021 - ETA: 8s - loss: 4.8207 - acc: 0.021 - ETA: 8s - loss: 4.8205 - acc: 0.021 - ETA: 7s - loss: 4.8203 - acc: 0.021 - ETA: 7s - loss: 4.8203 - acc: 0.021 - ETA: 7s - loss: 4.8203 - acc: 0.021 - ETA: 7s - loss: 4.8205 - acc: 0.021 - ETA: 7s - loss: 4.8206 - acc: 0.021 - ETA: 7s - loss: 4.8201 - acc: 0.021 - ETA: 6s - loss: 4.8203 - acc: 0.021 - ETA: 6s - loss: 4.8204 - acc: 0.021 - ETA: 6s - loss: 4.8205 - acc: 0.021 - ETA: 6s - loss: 4.8206 - acc: 0.021 - ETA: 6s - loss: 4.8204 - acc: 0.021 - ETA: 5s - loss: 4.8207 - acc: 0.021 - ETA: 5s - loss: 4.8209 - acc: 0.021 - ETA: 5s - loss: 4.8210 - acc: 0.021 - ETA: 5s - loss: 4.8212 - acc: 0.021 - ETA: 5s - loss: 4.8214 - acc: 0.021 - ETA: 5s - loss: 4.8212 - acc: 0.021 - ETA: 4s - loss: 4.8212 - acc: 0.021 - ETA: 4s - loss: 4.8209 - acc: 0.021 - ETA: 4s - loss: 4.8203 - acc: 0.021 - ETA: 4s - loss: 4.8203 - acc: 0.021 - ETA: 4s - loss: 4.8203 - acc: 0.021 - ETA: 4s - loss: 4.8202 - acc: 0.021 - ETA: 3s - loss: 4.8203 - acc: 0.021 - ETA: 3s - loss: 4.8202 - acc: 0.021 - ETA: 3s - loss: 4.8204 - acc: 0.021 - ETA: 3s - loss: 4.8203 - acc: 0.021 - ETA: 3s - loss: 4.8205 - acc: 0.021 - ETA: 2s - loss: 4.8202 - acc: 0.021 - ETA: 2s - loss: 4.8200 - acc: 0.021 - ETA: 2s - loss: 4.8200 - acc: 0.021 - ETA: 2s - loss: 4.8200 - acc: 0.021 - ETA: 2s - loss: 4.8203 - acc: 0.021 - ETA: 2s - loss: 4.8203 - acc: 0.021 - ETA: 1s - loss: 4.8205 - acc: 0.021 - ETA: 1s - loss: 4.8206 - acc: 0.021 - ETA: 1s - loss: 4.8205 - acc: 0.021 - ETA: 1s - loss: 4.8206 - acc: 0.021 - ETA: 1s - loss: 4.8203 - acc: 0.021 - ETA: 1s - loss: 4.8204 - acc: 0.021 - ETA: 0s - loss: 4.8205 - acc: 0.021 - ETA: 0s - loss: 4.8205 - acc: 0.021 - ETA: 0s - loss: 4.8205 - acc: 0.021 - ETA: 0s - loss: 4.8208 - acc: 0.021 - ETA: 0s - loss: 4.8209 - acc: 0.021 - 78s 187ms/step - loss: 4.8208 - acc: 0.0214 - val_loss: 4.8084 - val_acc: 0.0171\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 4.78987\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212/417 [==============>...............] - ETA: 1:15 - loss: 4.8833 - acc: 0.0000e+0 - ETA: 1:14 - loss: 4.9016 - acc: 0.0000e+0 - ETA: 1:13 - loss: 4.9350 - acc: 0.0000e+0 - ETA: 1:13 - loss: 4.9038 - acc: 0.0156    - ETA: 1:12 - loss: 4.8820 - acc: 0.012 - ETA: 1:12 - loss: 4.8815 - acc: 0.020 - ETA: 1:11 - loss: 4.8719 - acc: 0.017 - ETA: 1:11 - loss: 4.8513 - acc: 0.015 - ETA: 1:10 - loss: 4.8754 - acc: 0.013 - ETA: 1:10 - loss: 4.8661 - acc: 0.012 - ETA: 1:10 - loss: 4.8663 - acc: 0.011 - ETA: 1:09 - loss: 4.8603 - acc: 0.010 - ETA: 1:09 - loss: 4.8444 - acc: 0.019 - ETA: 1:09 - loss: 4.8436 - acc: 0.017 - ETA: 1:08 - loss: 4.8425 - acc: 0.016 - ETA: 1:08 - loss: 4.8356 - acc: 0.015 - ETA: 1:08 - loss: 4.8354 - acc: 0.018 - ETA: 1:07 - loss: 4.8356 - acc: 0.017 - ETA: 1:07 - loss: 4.8412 - acc: 0.016 - ETA: 1:07 - loss: 4.8444 - acc: 0.015 - ETA: 1:07 - loss: 4.8441 - acc: 0.014 - ETA: 1:07 - loss: 4.8436 - acc: 0.017 - ETA: 1:06 - loss: 4.8464 - acc: 0.016 - ETA: 1:06 - loss: 4.8419 - acc: 0.015 - ETA: 1:06 - loss: 4.8454 - acc: 0.015 - ETA: 1:06 - loss: 4.8479 - acc: 0.014 - ETA: 1:05 - loss: 4.8474 - acc: 0.013 - ETA: 1:05 - loss: 4.8489 - acc: 0.013 - ETA: 1:05 - loss: 4.8488 - acc: 0.012 - ETA: 1:05 - loss: 4.8479 - acc: 0.016 - ETA: 1:05 - loss: 4.8499 - acc: 0.016 - ETA: 1:05 - loss: 4.8495 - acc: 0.015 - ETA: 1:04 - loss: 4.8508 - acc: 0.017 - ETA: 1:04 - loss: 4.8503 - acc: 0.016 - ETA: 1:04 - loss: 4.8503 - acc: 0.016 - ETA: 1:04 - loss: 4.8517 - acc: 0.015 - ETA: 1:04 - loss: 4.8497 - acc: 0.015 - ETA: 1:04 - loss: 4.8478 - acc: 0.016 - ETA: 1:03 - loss: 4.8498 - acc: 0.016 - ETA: 1:03 - loss: 4.8487 - acc: 0.017 - ETA: 1:03 - loss: 4.8487 - acc: 0.018 - ETA: 1:03 - loss: 4.8487 - acc: 0.019 - ETA: 1:02 - loss: 4.8484 - acc: 0.018 - ETA: 1:02 - loss: 4.8466 - acc: 0.019 - ETA: 1:01 - loss: 4.8461 - acc: 0.019 - ETA: 1:01 - loss: 4.8462 - acc: 0.019 - ETA: 1:01 - loss: 4.8409 - acc: 0.019 - ETA: 1:01 - loss: 4.8397 - acc: 0.019 - ETA: 1:01 - loss: 4.8393 - acc: 0.020 - ETA: 1:01 - loss: 4.8388 - acc: 0.021 - ETA: 1:00 - loss: 4.8332 - acc: 0.022 - ETA: 1:00 - loss: 4.8349 - acc: 0.021 - ETA: 1:00 - loss: 4.8362 - acc: 0.021 - ETA: 1:00 - loss: 4.8359 - acc: 0.020 - ETA: 1:00 - loss: 4.8371 - acc: 0.020 - ETA: 1:00 - loss: 4.8358 - acc: 0.021 - ETA: 1:00 - loss: 4.8353 - acc: 0.021 - ETA: 59s - loss: 4.8353 - acc: 0.021 - ETA: 59s - loss: 4.8350 - acc: 0.02 - ETA: 59s - loss: 4.8374 - acc: 0.02 - ETA: 59s - loss: 4.8357 - acc: 0.02 - ETA: 59s - loss: 4.8321 - acc: 0.02 - ETA: 59s - loss: 4.8339 - acc: 0.02 - ETA: 58s - loss: 4.8349 - acc: 0.02 - ETA: 58s - loss: 4.8358 - acc: 0.02 - ETA: 58s - loss: 4.8360 - acc: 0.02 - ETA: 58s - loss: 4.8364 - acc: 0.02 - ETA: 58s - loss: 4.8367 - acc: 0.02 - ETA: 58s - loss: 4.8365 - acc: 0.02 - ETA: 57s - loss: 4.8365 - acc: 0.02 - ETA: 57s - loss: 4.8367 - acc: 0.02 - ETA: 57s - loss: 4.8375 - acc: 0.02 - ETA: 57s - loss: 4.8374 - acc: 0.02 - ETA: 57s - loss: 4.8381 - acc: 0.02 - ETA: 57s - loss: 4.8349 - acc: 0.02 - ETA: 56s - loss: 4.8351 - acc: 0.02 - ETA: 56s - loss: 4.8361 - acc: 0.02 - ETA: 56s - loss: 4.8357 - acc: 0.02 - ETA: 56s - loss: 4.8352 - acc: 0.02 - ETA: 56s - loss: 4.8357 - acc: 0.02 - ETA: 56s - loss: 4.8343 - acc: 0.02 - ETA: 55s - loss: 4.8339 - acc: 0.02 - ETA: 55s - loss: 4.8326 - acc: 0.02 - ETA: 55s - loss: 4.8343 - acc: 0.02 - ETA: 55s - loss: 4.8332 - acc: 0.02 - ETA: 55s - loss: 4.8323 - acc: 0.02 - ETA: 55s - loss: 4.8311 - acc: 0.02 - ETA: 54s - loss: 4.8312 - acc: 0.02 - ETA: 54s - loss: 4.8320 - acc: 0.02 - ETA: 54s - loss: 4.8326 - acc: 0.02 - ETA: 54s - loss: 4.8340 - acc: 0.02 - ETA: 54s - loss: 4.8350 - acc: 0.02 - ETA: 54s - loss: 4.8354 - acc: 0.02 - ETA: 54s - loss: 4.8359 - acc: 0.02 - ETA: 53s - loss: 4.8338 - acc: 0.02 - ETA: 53s - loss: 4.8338 - acc: 0.02 - ETA: 53s - loss: 4.8328 - acc: 0.02 - ETA: 53s - loss: 4.8340 - acc: 0.02 - ETA: 53s - loss: 4.8345 - acc: 0.02 - ETA: 53s - loss: 4.8340 - acc: 0.02 - ETA: 53s - loss: 4.8335 - acc: 0.02 - ETA: 52s - loss: 4.8325 - acc: 0.02 - ETA: 52s - loss: 4.8329 - acc: 0.02 - ETA: 52s - loss: 4.8330 - acc: 0.02 - ETA: 52s - loss: 4.8330 - acc: 0.02 - ETA: 52s - loss: 4.8317 - acc: 0.02 - ETA: 52s - loss: 4.8316 - acc: 0.02 - ETA: 52s - loss: 4.8304 - acc: 0.02 - ETA: 51s - loss: 4.8307 - acc: 0.02 - ETA: 51s - loss: 4.8314 - acc: 0.02 - ETA: 51s - loss: 4.8327 - acc: 0.02 - ETA: 51s - loss: 4.8326 - acc: 0.02 - ETA: 51s - loss: 4.8327 - acc: 0.02 - ETA: 51s - loss: 4.8316 - acc: 0.02 - ETA: 50s - loss: 4.8313 - acc: 0.02 - ETA: 50s - loss: 4.8311 - acc: 0.02 - ETA: 50s - loss: 4.8304 - acc: 0.02 - ETA: 50s - loss: 4.8309 - acc: 0.02 - ETA: 50s - loss: 4.8312 - acc: 0.02 - ETA: 50s - loss: 4.8310 - acc: 0.02 - ETA: 49s - loss: 4.8301 - acc: 0.02 - ETA: 49s - loss: 4.8286 - acc: 0.02 - ETA: 49s - loss: 4.8297 - acc: 0.02 - ETA: 49s - loss: 4.8284 - acc: 0.02 - ETA: 49s - loss: 4.8286 - acc: 0.02 - ETA: 48s - loss: 4.8277 - acc: 0.02 - ETA: 48s - loss: 4.8272 - acc: 0.02 - ETA: 48s - loss: 4.8271 - acc: 0.02 - ETA: 48s - loss: 4.8273 - acc: 0.02 - ETA: 48s - loss: 4.8258 - acc: 0.02 - ETA: 48s - loss: 4.8259 - acc: 0.02 - ETA: 47s - loss: 4.8259 - acc: 0.02 - ETA: 47s - loss: 4.8254 - acc: 0.02 - ETA: 47s - loss: 4.8265 - acc: 0.02 - ETA: 47s - loss: 4.8264 - acc: 0.02 - ETA: 47s - loss: 4.8263 - acc: 0.02 - ETA: 47s - loss: 4.8271 - acc: 0.02 - ETA: 46s - loss: 4.8269 - acc: 0.02 - ETA: 46s - loss: 4.8273 - acc: 0.02 - ETA: 46s - loss: 4.8273 - acc: 0.02 - ETA: 46s - loss: 4.8271 - acc: 0.02 - ETA: 46s - loss: 4.8278 - acc: 0.02 - ETA: 46s - loss: 4.8273 - acc: 0.02 - ETA: 45s - loss: 4.8277 - acc: 0.02 - ETA: 45s - loss: 4.8282 - acc: 0.02 - ETA: 45s - loss: 4.8282 - acc: 0.02 - ETA: 45s - loss: 4.8286 - acc: 0.02 - ETA: 45s - loss: 4.8293 - acc: 0.02 - ETA: 45s - loss: 4.8298 - acc: 0.02 - ETA: 44s - loss: 4.8291 - acc: 0.02 - ETA: 44s - loss: 4.8288 - acc: 0.02 - ETA: 44s - loss: 4.8275 - acc: 0.02 - ETA: 44s - loss: 4.8277 - acc: 0.02 - ETA: 44s - loss: 4.8274 - acc: 0.02 - ETA: 44s - loss: 4.8261 - acc: 0.02 - ETA: 43s - loss: 4.8262 - acc: 0.02 - ETA: 43s - loss: 4.8257 - acc: 0.02 - ETA: 43s - loss: 4.8254 - acc: 0.02 - ETA: 43s - loss: 4.8249 - acc: 0.02 - ETA: 43s - loss: 4.8245 - acc: 0.02 - ETA: 43s - loss: 4.8244 - acc: 0.02 - ETA: 42s - loss: 4.8237 - acc: 0.02 - ETA: 42s - loss: 4.8236 - acc: 0.02 - ETA: 42s - loss: 4.8235 - acc: 0.02 - ETA: 42s - loss: 4.8237 - acc: 0.02 - ETA: 42s - loss: 4.8248 - acc: 0.02 - ETA: 42s - loss: 4.8249 - acc: 0.02 - ETA: 41s - loss: 4.8244 - acc: 0.02 - ETA: 41s - loss: 4.8242 - acc: 0.02 - ETA: 41s - loss: 4.8243 - acc: 0.02 - ETA: 41s - loss: 4.8240 - acc: 0.02 - ETA: 41s - loss: 4.8234 - acc: 0.02 - ETA: 41s - loss: 4.8232 - acc: 0.02 - ETA: 40s - loss: 4.8235 - acc: 0.02 - ETA: 40s - loss: 4.8228 - acc: 0.02 - ETA: 40s - loss: 4.8234 - acc: 0.02 - ETA: 40s - loss: 4.8241 - acc: 0.02 - ETA: 40s - loss: 4.8238 - acc: 0.02 - ETA: 40s - loss: 4.8235 - acc: 0.02 - ETA: 39s - loss: 4.8234 - acc: 0.02 - ETA: 39s - loss: 4.8232 - acc: 0.02 - ETA: 39s - loss: 4.8233 - acc: 0.02 - ETA: 39s - loss: 4.8235 - acc: 0.02 - ETA: 39s - loss: 4.8241 - acc: 0.02 - ETA: 39s - loss: 4.8242 - acc: 0.02 - ETA: 38s - loss: 4.8239 - acc: 0.02 - ETA: 38s - loss: 4.8234 - acc: 0.02 - ETA: 38s - loss: 4.8229 - acc: 0.02 - ETA: 38s - loss: 4.8230 - acc: 0.02 - ETA: 38s - loss: 4.8228 - acc: 0.02 - ETA: 38s - loss: 4.8235 - acc: 0.02 - ETA: 37s - loss: 4.8236 - acc: 0.02 - ETA: 37s - loss: 4.8238 - acc: 0.02 - ETA: 37s - loss: 4.8226 - acc: 0.02 - ETA: 37s - loss: 4.8225 - acc: 0.02 - ETA: 37s - loss: 4.8227 - acc: 0.02 - ETA: 37s - loss: 4.8231 - acc: 0.02 - ETA: 37s - loss: 4.8229 - acc: 0.02 - ETA: 36s - loss: 4.8228 - acc: 0.02 - ETA: 36s - loss: 4.8221 - acc: 0.02 - ETA: 36s - loss: 4.8216 - acc: 0.02 - ETA: 36s - loss: 4.8221 - acc: 0.02 - ETA: 36s - loss: 4.8222 - acc: 0.02 - ETA: 36s - loss: 4.8218 - acc: 0.02 - ETA: 36s - loss: 4.8216 - acc: 0.02 - ETA: 35s - loss: 4.8222 - acc: 0.02 - ETA: 35s - loss: 4.8225 - acc: 0.02 - ETA: 35s - loss: 4.8228 - acc: 0.02 - ETA: 35s - loss: 4.8231 - acc: 0.02 - ETA: 35s - loss: 4.8233 - acc: 0.02 - ETA: 35s - loss: 4.8229 - acc: 0.02 - ETA: 34s - loss: 4.8224 - acc: 0.0236"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 34s - loss: 4.8224 - acc: 0.02 - ETA: 34s - loss: 4.8227 - acc: 0.02 - ETA: 34s - loss: 4.8221 - acc: 0.02 - ETA: 34s - loss: 4.8222 - acc: 0.02 - ETA: 34s - loss: 4.8217 - acc: 0.02 - ETA: 34s - loss: 4.8214 - acc: 0.02 - ETA: 34s - loss: 4.8226 - acc: 0.02 - ETA: 33s - loss: 4.8229 - acc: 0.02 - ETA: 33s - loss: 4.8231 - acc: 0.02 - ETA: 33s - loss: 4.8230 - acc: 0.02 - ETA: 33s - loss: 4.8232 - acc: 0.02 - ETA: 33s - loss: 4.8232 - acc: 0.02 - ETA: 33s - loss: 4.8230 - acc: 0.02 - ETA: 32s - loss: 4.8232 - acc: 0.02 - ETA: 32s - loss: 4.8231 - acc: 0.02 - ETA: 32s - loss: 4.8230 - acc: 0.02 - ETA: 32s - loss: 4.8231 - acc: 0.02 - ETA: 32s - loss: 4.8237 - acc: 0.02 - ETA: 32s - loss: 4.8247 - acc: 0.02 - ETA: 32s - loss: 4.8248 - acc: 0.02 - ETA: 31s - loss: 4.8251 - acc: 0.02 - ETA: 31s - loss: 4.8250 - acc: 0.02 - ETA: 31s - loss: 4.8247 - acc: 0.02 - ETA: 31s - loss: 4.8249 - acc: 0.02 - ETA: 31s - loss: 4.8248 - acc: 0.02 - ETA: 30s - loss: 4.8251 - acc: 0.02 - ETA: 30s - loss: 4.8245 - acc: 0.02 - ETA: 30s - loss: 4.8246 - acc: 0.02 - ETA: 30s - loss: 4.8246 - acc: 0.02 - ETA: 30s - loss: 4.8242 - acc: 0.02 - ETA: 30s - loss: 4.8240 - acc: 0.02 - ETA: 29s - loss: 4.8239 - acc: 0.02 - ETA: 29s - loss: 4.8244 - acc: 0.02 - ETA: 29s - loss: 4.8237 - acc: 0.02 - ETA: 29s - loss: 4.8238 - acc: 0.02 - ETA: 29s - loss: 4.8237 - acc: 0.02 - ETA: 29s - loss: 4.8242 - acc: 0.02 - ETA: 28s - loss: 4.8247 - acc: 0.02 - ETA: 28s - loss: 4.8249 - acc: 0.02 - ETA: 28s - loss: 4.8250 - acc: 0.02 - ETA: 28s - loss: 4.8248 - acc: 0.02 - ETA: 28s - loss: 4.8248 - acc: 0.02 - ETA: 28s - loss: 4.8246 - acc: 0.02 - ETA: 27s - loss: 4.8247 - acc: 0.02 - ETA: 27s - loss: 4.8246 - acc: 0.02 - ETA: 27s - loss: 4.8246 - acc: 0.02 - ETA: 27s - loss: 4.8243 - acc: 0.02 - ETA: 27s - loss: 4.8244 - acc: 0.02 - ETA: 26s - loss: 4.8241 - acc: 0.02 - ETA: 26s - loss: 4.8238 - acc: 0.02 - ETA: 26s - loss: 4.8235 - acc: 0.02 - ETA: 26s - loss: 4.8238 - acc: 0.02 - ETA: 26s - loss: 4.8237 - acc: 0.02 - ETA: 26s - loss: 4.8234 - acc: 0.02 - ETA: 25s - loss: 4.8238 - acc: 0.02 - ETA: 25s - loss: 4.8235 - acc: 0.02 - ETA: 25s - loss: 4.8238 - acc: 0.02 - ETA: 25s - loss: 4.8238 - acc: 0.02 - ETA: 25s - loss: 4.8234 - acc: 0.02 - ETA: 25s - loss: 4.8234 - acc: 0.02 - ETA: 24s - loss: 4.8236 - acc: 0.02 - ETA: 24s - loss: 4.8236 - acc: 0.02 - ETA: 24s - loss: 4.8235 - acc: 0.02 - ETA: 24s - loss: 4.8234 - acc: 0.02 - ETA: 24s - loss: 4.8232 - acc: 0.02 - ETA: 24s - loss: 4.8232 - acc: 0.02 - ETA: 23s - loss: 4.8240 - acc: 0.02 - ETA: 23s - loss: 4.8242 - acc: 0.02 - ETA: 23s - loss: 4.8243 - acc: 0.02 - ETA: 23s - loss: 4.8244 - acc: 0.02 - ETA: 23s - loss: 4.8241 - acc: 0.02 - ETA: 23s - loss: 4.8247 - acc: 0.02 - ETA: 22s - loss: 4.8247 - acc: 0.02 - ETA: 22s - loss: 4.8247 - acc: 0.02 - ETA: 22s - loss: 4.8250 - acc: 0.02 - ETA: 22s - loss: 4.8249 - acc: 0.02 - ETA: 22s - loss: 4.8251 - acc: 0.02 - ETA: 21s - loss: 4.8247 - acc: 0.02 - ETA: 21s - loss: 4.8245 - acc: 0.02 - ETA: 21s - loss: 4.8248 - acc: 0.02 - ETA: 21s - loss: 4.8252 - acc: 0.02 - ETA: 21s - loss: 4.8253 - acc: 0.02 - ETA: 21s - loss: 4.8251 - acc: 0.02 - ETA: 20s - loss: 4.8249 - acc: 0.02 - ETA: 20s - loss: 4.8251 - acc: 0.02 - ETA: 20s - loss: 4.8249 - acc: 0.02 - ETA: 20s - loss: 4.8246 - acc: 0.02 - ETA: 20s - loss: 4.8246 - acc: 0.02 - ETA: 20s - loss: 4.8242 - acc: 0.02 - ETA: 19s - loss: 4.8242 - acc: 0.02 - ETA: 19s - loss: 4.8240 - acc: 0.02 - ETA: 19s - loss: 4.8243 - acc: 0.02 - ETA: 19s - loss: 4.8243 - acc: 0.02 - ETA: 19s - loss: 4.8240 - acc: 0.02 - ETA: 19s - loss: 4.8241 - acc: 0.02 - ETA: 18s - loss: 4.8239 - acc: 0.02 - ETA: 18s - loss: 4.8244 - acc: 0.02 - ETA: 18s - loss: 4.8242 - acc: 0.02 - ETA: 18s - loss: 4.8238 - acc: 0.02 - ETA: 18s - loss: 4.8237 - acc: 0.02 - ETA: 18s - loss: 4.8239 - acc: 0.02 - ETA: 17s - loss: 4.8242 - acc: 0.02 - ETA: 17s - loss: 4.8244 - acc: 0.02 - ETA: 17s - loss: 4.8245 - acc: 0.02 - ETA: 17s - loss: 4.8245 - acc: 0.02 - ETA: 17s - loss: 4.8249 - acc: 0.02 - ETA: 17s - loss: 4.8249 - acc: 0.02 - ETA: 16s - loss: 4.8247 - acc: 0.02 - ETA: 16s - loss: 4.8250 - acc: 0.02 - ETA: 16s - loss: 4.8246 - acc: 0.02 - ETA: 16s - loss: 4.8244 - acc: 0.02 - ETA: 16s - loss: 4.8243 - acc: 0.02 - ETA: 16s - loss: 4.8247 - acc: 0.02 - ETA: 15s - loss: 4.8247 - acc: 0.02 - ETA: 15s - loss: 4.8247 - acc: 0.02 - ETA: 15s - loss: 4.8246 - acc: 0.02 - ETA: 15s - loss: 4.8247 - acc: 0.02 - ETA: 15s - loss: 4.8242 - acc: 0.02 - ETA: 15s - loss: 4.8240 - acc: 0.02 - ETA: 14s - loss: 4.8240 - acc: 0.02 - ETA: 14s - loss: 4.8240 - acc: 0.02 - ETA: 14s - loss: 4.8238 - acc: 0.02 - ETA: 14s - loss: 4.8235 - acc: 0.02 - ETA: 14s - loss: 4.8234 - acc: 0.02 - ETA: 14s - loss: 4.8233 - acc: 0.02 - ETA: 13s - loss: 4.8236 - acc: 0.02 - ETA: 13s - loss: 4.8233 - acc: 0.02 - ETA: 13s - loss: 4.8235 - acc: 0.02 - ETA: 13s - loss: 4.8235 - acc: 0.02 - ETA: 13s - loss: 4.8238 - acc: 0.02 - ETA: 13s - loss: 4.8240 - acc: 0.02 - ETA: 12s - loss: 4.8237 - acc: 0.02 - ETA: 12s - loss: 4.8237 - acc: 0.02 - ETA: 12s - loss: 4.8239 - acc: 0.02 - ETA: 12s - loss: 4.8242 - acc: 0.02 - ETA: 12s - loss: 4.8242 - acc: 0.02 - ETA: 11s - loss: 4.8238 - acc: 0.02 - ETA: 11s - loss: 4.8240 - acc: 0.02 - ETA: 11s - loss: 4.8237 - acc: 0.02 - ETA: 11s - loss: 4.8234 - acc: 0.02 - ETA: 11s - loss: 4.8232 - acc: 0.02 - ETA: 11s - loss: 4.8232 - acc: 0.02 - ETA: 10s - loss: 4.8235 - acc: 0.02 - ETA: 10s - loss: 4.8236 - acc: 0.02 - ETA: 10s - loss: 4.8234 - acc: 0.02 - ETA: 10s - loss: 4.8233 - acc: 0.02 - ETA: 10s - loss: 4.8231 - acc: 0.02 - ETA: 10s - loss: 4.8232 - acc: 0.02 - ETA: 9s - loss: 4.8230 - acc: 0.0216 - ETA: 9s - loss: 4.8229 - acc: 0.021 - ETA: 9s - loss: 4.8228 - acc: 0.021 - ETA: 9s - loss: 4.8227 - acc: 0.021 - ETA: 9s - loss: 4.8227 - acc: 0.021 - ETA: 9s - loss: 4.8228 - acc: 0.021 - ETA: 8s - loss: 4.8231 - acc: 0.021 - ETA: 8s - loss: 4.8229 - acc: 0.021 - ETA: 8s - loss: 4.8230 - acc: 0.021 - ETA: 8s - loss: 4.8232 - acc: 0.021 - ETA: 8s - loss: 4.8232 - acc: 0.021 - ETA: 7s - loss: 4.8237 - acc: 0.021 - ETA: 7s - loss: 4.8236 - acc: 0.021 - ETA: 7s - loss: 4.8235 - acc: 0.021 - ETA: 7s - loss: 4.8239 - acc: 0.021 - ETA: 7s - loss: 4.8239 - acc: 0.020 - ETA: 7s - loss: 4.8241 - acc: 0.020 - ETA: 6s - loss: 4.8244 - acc: 0.020 - ETA: 6s - loss: 4.8243 - acc: 0.020 - ETA: 6s - loss: 4.8244 - acc: 0.020 - ETA: 6s - loss: 4.8243 - acc: 0.020 - ETA: 6s - loss: 4.8241 - acc: 0.020 - ETA: 6s - loss: 4.8243 - acc: 0.020 - ETA: 5s - loss: 4.8243 - acc: 0.020 - ETA: 5s - loss: 4.8242 - acc: 0.020 - ETA: 5s - loss: 4.8240 - acc: 0.020 - ETA: 5s - loss: 4.8242 - acc: 0.020 - ETA: 5s - loss: 4.8245 - acc: 0.020 - ETA: 4s - loss: 4.8240 - acc: 0.020 - ETA: 4s - loss: 4.8240 - acc: 0.021 - ETA: 4s - loss: 4.8241 - acc: 0.020 - ETA: 4s - loss: 4.8239 - acc: 0.020 - ETA: 4s - loss: 4.8237 - acc: 0.020 - ETA: 4s - loss: 4.8234 - acc: 0.020 - ETA: 3s - loss: 4.8237 - acc: 0.020 - ETA: 3s - loss: 4.8241 - acc: 0.021 - ETA: 3s - loss: 4.8240 - acc: 0.020 - ETA: 3s - loss: 4.8241 - acc: 0.020 - ETA: 3s - loss: 4.8241 - acc: 0.021 - ETA: 2s - loss: 4.8239 - acc: 0.021 - ETA: 2s - loss: 4.8243 - acc: 0.021 - ETA: 2s - loss: 4.8243 - acc: 0.021 - ETA: 2s - loss: 4.8244 - acc: 0.021 - ETA: 2s - loss: 4.8246 - acc: 0.021 - ETA: 2s - loss: 4.8245 - acc: 0.021 - ETA: 1s - loss: 4.8245 - acc: 0.021 - ETA: 1s - loss: 4.8246 - acc: 0.021 - ETA: 1s - loss: 4.8245 - acc: 0.021 - ETA: 1s - loss: 4.8246 - acc: 0.021 - ETA: 1s - loss: 4.8248 - acc: 0.021 - ETA: 1s - loss: 4.8251 - acc: 0.021 - ETA: 0s - loss: 4.8247 - acc: 0.021 - ETA: 0s - loss: 4.8248 - acc: 0.021 - ETA: 0s - loss: 4.8247 - acc: 0.021 - ETA: 0s - loss: 4.8249 - acc: 0.021 - ETA: 0s - loss: 4.8249 - acc: 0.021 - 77s 185ms/step - loss: 4.8250 - acc: 0.0213 - val_loss: 4.7975 - val_acc: 0.0305\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 4.78987\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/417 [==============>...............] - ETA: 1:17 - loss: 4.9625 - acc: 0.0000e+0 - ETA: 1:17 - loss: 4.9498 - acc: 0.0000e+0 - ETA: 1:15 - loss: 4.8978 - acc: 0.0000e+0 - ETA: 1:14 - loss: 4.8683 - acc: 0.0000e+0 - ETA: 1:13 - loss: 4.8948 - acc: 0.0000e+0 - ETA: 1:13 - loss: 4.8850 - acc: 0.0000e+0 - ETA: 1:13 - loss: 4.8743 - acc: 0.0000e+0 - ETA: 1:12 - loss: 4.8719 - acc: 0.0000e+0 - ETA: 1:11 - loss: 4.8808 - acc: 0.0000e+0 - ETA: 1:11 - loss: 4.8882 - acc: 0.0000e+0 - ETA: 1:10 - loss: 4.8820 - acc: 0.0000e+0 - ETA: 1:10 - loss: 4.8733 - acc: 0.0052    - ETA: 1:09 - loss: 4.8708 - acc: 0.004 - ETA: 1:09 - loss: 4.8651 - acc: 0.004 - ETA: 1:09 - loss: 4.8637 - acc: 0.004 - ETA: 1:08 - loss: 4.8503 - acc: 0.003 - ETA: 1:08 - loss: 4.8493 - acc: 0.007 - ETA: 1:08 - loss: 4.8440 - acc: 0.006 - ETA: 1:08 - loss: 4.8397 - acc: 0.009 - ETA: 1:07 - loss: 4.8460 - acc: 0.009 - ETA: 1:07 - loss: 4.8449 - acc: 0.008 - ETA: 1:07 - loss: 4.8490 - acc: 0.008 - ETA: 1:07 - loss: 4.8461 - acc: 0.008 - ETA: 1:06 - loss: 4.8471 - acc: 0.007 - ETA: 1:06 - loss: 4.8371 - acc: 0.007 - ETA: 1:06 - loss: 4.8402 - acc: 0.009 - ETA: 1:06 - loss: 4.8432 - acc: 0.009 - ETA: 1:06 - loss: 4.8423 - acc: 0.008 - ETA: 1:05 - loss: 4.8406 - acc: 0.012 - ETA: 1:05 - loss: 4.8405 - acc: 0.012 - ETA: 1:05 - loss: 4.8411 - acc: 0.012 - ETA: 1:05 - loss: 4.8396 - acc: 0.013 - ETA: 1:05 - loss: 4.8360 - acc: 0.015 - ETA: 1:04 - loss: 4.8361 - acc: 0.014 - ETA: 1:04 - loss: 4.8370 - acc: 0.014 - ETA: 1:04 - loss: 4.8319 - acc: 0.013 - ETA: 1:04 - loss: 4.8295 - acc: 0.013 - ETA: 1:04 - loss: 4.8297 - acc: 0.014 - ETA: 1:04 - loss: 4.8272 - acc: 0.016 - ETA: 1:04 - loss: 4.8307 - acc: 0.015 - ETA: 1:03 - loss: 4.8317 - acc: 0.015 - ETA: 1:03 - loss: 4.8303 - acc: 0.014 - ETA: 1:03 - loss: 4.8294 - acc: 0.016 - ETA: 1:02 - loss: 4.8269 - acc: 0.015 - ETA: 1:02 - loss: 4.8282 - acc: 0.015 - ETA: 1:02 - loss: 4.8266 - acc: 0.014 - ETA: 1:01 - loss: 4.8281 - acc: 0.014 - ETA: 1:01 - loss: 4.8277 - acc: 0.014 - ETA: 1:01 - loss: 4.8271 - acc: 0.014 - ETA: 1:01 - loss: 4.8247 - acc: 0.015 - ETA: 1:01 - loss: 4.8256 - acc: 0.015 - ETA: 1:01 - loss: 4.8248 - acc: 0.015 - ETA: 1:01 - loss: 4.8261 - acc: 0.015 - ETA: 1:00 - loss: 4.8278 - acc: 0.015 - ETA: 1:00 - loss: 4.8275 - acc: 0.017 - ETA: 1:00 - loss: 4.8270 - acc: 0.016 - ETA: 1:00 - loss: 4.8284 - acc: 0.016 - ETA: 1:00 - loss: 4.8289 - acc: 0.016 - ETA: 59s - loss: 4.8282 - acc: 0.015 - ETA: 59s - loss: 4.8263 - acc: 0.01 - ETA: 59s - loss: 4.8285 - acc: 0.01 - ETA: 59s - loss: 4.8295 - acc: 0.01 - ETA: 59s - loss: 4.8320 - acc: 0.01 - ETA: 59s - loss: 4.8319 - acc: 0.01 - ETA: 58s - loss: 4.8339 - acc: 0.01 - ETA: 58s - loss: 4.8354 - acc: 0.01 - ETA: 58s - loss: 4.8337 - acc: 0.01 - ETA: 58s - loss: 4.8346 - acc: 0.01 - ETA: 58s - loss: 4.8341 - acc: 0.01 - ETA: 58s - loss: 4.8344 - acc: 0.01 - ETA: 57s - loss: 4.8330 - acc: 0.01 - ETA: 57s - loss: 4.8333 - acc: 0.01 - ETA: 57s - loss: 4.8340 - acc: 0.01 - ETA: 57s - loss: 4.8330 - acc: 0.01 - ETA: 57s - loss: 4.8341 - acc: 0.01 - ETA: 57s - loss: 4.8351 - acc: 0.01 - ETA: 56s - loss: 4.8349 - acc: 0.01 - ETA: 56s - loss: 4.8330 - acc: 0.01 - ETA: 56s - loss: 4.8346 - acc: 0.01 - ETA: 56s - loss: 4.8341 - acc: 0.01 - ETA: 56s - loss: 4.8337 - acc: 0.01 - ETA: 56s - loss: 4.8329 - acc: 0.01 - ETA: 55s - loss: 4.8324 - acc: 0.01 - ETA: 55s - loss: 4.8325 - acc: 0.01 - ETA: 55s - loss: 4.8331 - acc: 0.01 - ETA: 55s - loss: 4.8327 - acc: 0.01 - ETA: 55s - loss: 4.8331 - acc: 0.01 - ETA: 55s - loss: 4.8347 - acc: 0.01 - ETA: 54s - loss: 4.8322 - acc: 0.01 - ETA: 54s - loss: 4.8325 - acc: 0.01 - ETA: 54s - loss: 4.8322 - acc: 0.01 - ETA: 54s - loss: 4.8315 - acc: 0.01 - ETA: 54s - loss: 4.8317 - acc: 0.01 - ETA: 54s - loss: 4.8308 - acc: 0.01 - ETA: 53s - loss: 4.8319 - acc: 0.01 - ETA: 53s - loss: 4.8337 - acc: 0.01 - ETA: 53s - loss: 4.8334 - acc: 0.01 - ETA: 53s - loss: 4.8331 - acc: 0.01 - ETA: 53s - loss: 4.8327 - acc: 0.01 - ETA: 53s - loss: 4.8312 - acc: 0.01 - ETA: 52s - loss: 4.8301 - acc: 0.01 - ETA: 53s - loss: 4.8294 - acc: 0.01 - ETA: 52s - loss: 4.8296 - acc: 0.01 - ETA: 52s - loss: 4.8306 - acc: 0.01 - ETA: 52s - loss: 4.8312 - acc: 0.01 - ETA: 52s - loss: 4.8316 - acc: 0.01 - ETA: 52s - loss: 4.8314 - acc: 0.01 - ETA: 52s - loss: 4.8322 - acc: 0.01 - ETA: 52s - loss: 4.8329 - acc: 0.01 - ETA: 52s - loss: 4.8314 - acc: 0.01 - ETA: 51s - loss: 4.8315 - acc: 0.01 - ETA: 51s - loss: 4.8313 - acc: 0.01 - ETA: 51s - loss: 4.8321 - acc: 0.01 - ETA: 51s - loss: 4.8313 - acc: 0.01 - ETA: 51s - loss: 4.8316 - acc: 0.01 - ETA: 51s - loss: 4.8312 - acc: 0.01 - ETA: 51s - loss: 4.8312 - acc: 0.01 - ETA: 50s - loss: 4.8313 - acc: 0.01 - ETA: 50s - loss: 4.8320 - acc: 0.01 - ETA: 50s - loss: 4.8324 - acc: 0.01 - ETA: 50s - loss: 4.8318 - acc: 0.01 - ETA: 50s - loss: 4.8318 - acc: 0.01 - ETA: 50s - loss: 4.8318 - acc: 0.01 - ETA: 49s - loss: 4.8315 - acc: 0.01 - ETA: 49s - loss: 4.8319 - acc: 0.01 - ETA: 49s - loss: 4.8309 - acc: 0.01 - ETA: 49s - loss: 4.8311 - acc: 0.01 - ETA: 49s - loss: 4.8309 - acc: 0.01 - ETA: 48s - loss: 4.8305 - acc: 0.01 - ETA: 48s - loss: 4.8309 - acc: 0.01 - ETA: 48s - loss: 4.8310 - acc: 0.01 - ETA: 48s - loss: 4.8306 - acc: 0.01 - ETA: 48s - loss: 4.8301 - acc: 0.01 - ETA: 48s - loss: 4.8296 - acc: 0.01 - ETA: 48s - loss: 4.8292 - acc: 0.01 - ETA: 47s - loss: 4.8301 - acc: 0.01 - ETA: 47s - loss: 4.8303 - acc: 0.01 - ETA: 47s - loss: 4.8302 - acc: 0.01 - ETA: 47s - loss: 4.8298 - acc: 0.01 - ETA: 47s - loss: 4.8302 - acc: 0.01 - ETA: 47s - loss: 4.8303 - acc: 0.01 - ETA: 47s - loss: 4.8304 - acc: 0.01 - ETA: 47s - loss: 4.8305 - acc: 0.01 - ETA: 47s - loss: 4.8311 - acc: 0.01 - ETA: 47s - loss: 4.8312 - acc: 0.01 - ETA: 46s - loss: 4.8317 - acc: 0.01 - ETA: 46s - loss: 4.8315 - acc: 0.01 - ETA: 46s - loss: 4.8308 - acc: 0.01 - ETA: 46s - loss: 4.8301 - acc: 0.01 - ETA: 46s - loss: 4.8295 - acc: 0.01 - ETA: 46s - loss: 4.8291 - acc: 0.01 - ETA: 45s - loss: 4.8297 - acc: 0.01 - ETA: 45s - loss: 4.8292 - acc: 0.01 - ETA: 45s - loss: 4.8295 - acc: 0.01 - ETA: 45s - loss: 4.8290 - acc: 0.01 - ETA: 45s - loss: 4.8296 - acc: 0.01 - ETA: 44s - loss: 4.8305 - acc: 0.01 - ETA: 44s - loss: 4.8300 - acc: 0.01 - ETA: 44s - loss: 4.8304 - acc: 0.01 - ETA: 44s - loss: 4.8304 - acc: 0.01 - ETA: 44s - loss: 4.8302 - acc: 0.01 - ETA: 44s - loss: 4.8302 - acc: 0.01 - ETA: 43s - loss: 4.8301 - acc: 0.01 - ETA: 43s - loss: 4.8302 - acc: 0.01 - ETA: 43s - loss: 4.8308 - acc: 0.01 - ETA: 43s - loss: 4.8317 - acc: 0.01 - ETA: 43s - loss: 4.8312 - acc: 0.01 - ETA: 43s - loss: 4.8320 - acc: 0.01 - ETA: 43s - loss: 4.8319 - acc: 0.01 - ETA: 42s - loss: 4.8321 - acc: 0.01 - ETA: 42s - loss: 4.8329 - acc: 0.01 - ETA: 42s - loss: 4.8335 - acc: 0.01 - ETA: 42s - loss: 4.8340 - acc: 0.01 - ETA: 42s - loss: 4.8337 - acc: 0.01 - ETA: 42s - loss: 4.8331 - acc: 0.01 - ETA: 42s - loss: 4.8338 - acc: 0.01 - ETA: 41s - loss: 4.8341 - acc: 0.01 - ETA: 41s - loss: 4.8340 - acc: 0.01 - ETA: 41s - loss: 4.8334 - acc: 0.01 - ETA: 41s - loss: 4.8337 - acc: 0.01 - ETA: 41s - loss: 4.8333 - acc: 0.01 - ETA: 41s - loss: 4.8331 - acc: 0.01 - ETA: 40s - loss: 4.8329 - acc: 0.01 - ETA: 40s - loss: 4.8334 - acc: 0.01 - ETA: 40s - loss: 4.8332 - acc: 0.01 - ETA: 40s - loss: 4.8331 - acc: 0.01 - ETA: 40s - loss: 4.8321 - acc: 0.01 - ETA: 40s - loss: 4.8315 - acc: 0.01 - ETA: 39s - loss: 4.8312 - acc: 0.01 - ETA: 39s - loss: 4.8312 - acc: 0.01 - ETA: 39s - loss: 4.8315 - acc: 0.01 - ETA: 39s - loss: 4.8316 - acc: 0.01 - ETA: 39s - loss: 4.8317 - acc: 0.01 - ETA: 39s - loss: 4.8319 - acc: 0.01 - ETA: 38s - loss: 4.8324 - acc: 0.01 - ETA: 38s - loss: 4.8323 - acc: 0.01 - ETA: 38s - loss: 4.8320 - acc: 0.01 - ETA: 38s - loss: 4.8311 - acc: 0.01 - ETA: 38s - loss: 4.8313 - acc: 0.01 - ETA: 37s - loss: 4.8317 - acc: 0.01 - ETA: 37s - loss: 4.8315 - acc: 0.01 - ETA: 37s - loss: 4.8309 - acc: 0.01 - ETA: 37s - loss: 4.8306 - acc: 0.01 - ETA: 37s - loss: 4.8301 - acc: 0.01 - ETA: 37s - loss: 4.8302 - acc: 0.01 - ETA: 36s - loss: 4.8305 - acc: 0.01 - ETA: 36s - loss: 4.8307 - acc: 0.01 - ETA: 36s - loss: 4.8303 - acc: 0.01 - ETA: 36s - loss: 4.8299 - acc: 0.01 - ETA: 36s - loss: 4.8299 - acc: 0.01 - ETA: 35s - loss: 4.8297 - acc: 0.0169"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 35s - loss: 4.8293 - acc: 0.01 - ETA: 35s - loss: 4.8293 - acc: 0.01 - ETA: 35s - loss: 4.8289 - acc: 0.01 - ETA: 35s - loss: 4.8292 - acc: 0.01 - ETA: 35s - loss: 4.8291 - acc: 0.01 - ETA: 34s - loss: 4.8295 - acc: 0.01 - ETA: 34s - loss: 4.8292 - acc: 0.01 - ETA: 34s - loss: 4.8294 - acc: 0.01 - ETA: 34s - loss: 4.8297 - acc: 0.01 - ETA: 34s - loss: 4.8293 - acc: 0.01 - ETA: 34s - loss: 4.8292 - acc: 0.01 - ETA: 33s - loss: 4.8290 - acc: 0.01 - ETA: 33s - loss: 4.8290 - acc: 0.01 - ETA: 33s - loss: 4.8288 - acc: 0.01 - ETA: 33s - loss: 4.8289 - acc: 0.01 - ETA: 33s - loss: 4.8297 - acc: 0.01 - ETA: 33s - loss: 4.8299 - acc: 0.01 - ETA: 32s - loss: 4.8304 - acc: 0.01 - ETA: 32s - loss: 4.8296 - acc: 0.01 - ETA: 32s - loss: 4.8301 - acc: 0.01 - ETA: 32s - loss: 4.8304 - acc: 0.01 - ETA: 32s - loss: 4.8305 - acc: 0.01 - ETA: 31s - loss: 4.8303 - acc: 0.01 - ETA: 31s - loss: 4.8306 - acc: 0.01 - ETA: 31s - loss: 4.8307 - acc: 0.01 - ETA: 31s - loss: 4.8316 - acc: 0.01 - ETA: 31s - loss: 4.8314 - acc: 0.01 - ETA: 31s - loss: 4.8314 - acc: 0.01 - ETA: 30s - loss: 4.8312 - acc: 0.01 - ETA: 30s - loss: 4.8310 - acc: 0.01 - ETA: 30s - loss: 4.8309 - acc: 0.01 - ETA: 30s - loss: 4.8313 - acc: 0.01 - ETA: 30s - loss: 4.8307 - acc: 0.01 - ETA: 30s - loss: 4.8313 - acc: 0.01 - ETA: 29s - loss: 4.8311 - acc: 0.01 - ETA: 29s - loss: 4.8311 - acc: 0.01 - ETA: 29s - loss: 4.8315 - acc: 0.01 - ETA: 29s - loss: 4.8311 - acc: 0.01 - ETA: 29s - loss: 4.8307 - acc: 0.01 - ETA: 29s - loss: 4.8304 - acc: 0.01 - ETA: 28s - loss: 4.8296 - acc: 0.01 - ETA: 28s - loss: 4.8296 - acc: 0.01 - ETA: 28s - loss: 4.8293 - acc: 0.01 - ETA: 28s - loss: 4.8288 - acc: 0.01 - ETA: 28s - loss: 4.8286 - acc: 0.01 - ETA: 28s - loss: 4.8285 - acc: 0.01 - ETA: 27s - loss: 4.8291 - acc: 0.01 - ETA: 27s - loss: 4.8290 - acc: 0.01 - ETA: 27s - loss: 4.8284 - acc: 0.01 - ETA: 27s - loss: 4.8289 - acc: 0.01 - ETA: 27s - loss: 4.8284 - acc: 0.01 - ETA: 27s - loss: 4.8285 - acc: 0.01 - ETA: 26s - loss: 4.8284 - acc: 0.01 - ETA: 26s - loss: 4.8283 - acc: 0.01 - ETA: 26s - loss: 4.8273 - acc: 0.01 - ETA: 26s - loss: 4.8271 - acc: 0.01 - ETA: 26s - loss: 4.8278 - acc: 0.01 - ETA: 25s - loss: 4.8278 - acc: 0.01 - ETA: 25s - loss: 4.8275 - acc: 0.01 - ETA: 25s - loss: 4.8271 - acc: 0.01 - ETA: 25s - loss: 4.8272 - acc: 0.01 - ETA: 25s - loss: 4.8274 - acc: 0.01 - ETA: 25s - loss: 4.8281 - acc: 0.01 - ETA: 25s - loss: 4.8278 - acc: 0.01 - ETA: 24s - loss: 4.8281 - acc: 0.01 - ETA: 24s - loss: 4.8276 - acc: 0.01 - ETA: 24s - loss: 4.8282 - acc: 0.01 - ETA: 24s - loss: 4.8277 - acc: 0.01 - ETA: 24s - loss: 4.8272 - acc: 0.01 - ETA: 23s - loss: 4.8267 - acc: 0.01 - ETA: 23s - loss: 4.8269 - acc: 0.01 - ETA: 23s - loss: 4.8267 - acc: 0.01 - ETA: 23s - loss: 4.8264 - acc: 0.01 - ETA: 23s - loss: 4.8266 - acc: 0.01 - ETA: 23s - loss: 4.8268 - acc: 0.01 - ETA: 22s - loss: 4.8269 - acc: 0.01 - ETA: 22s - loss: 4.8275 - acc: 0.01 - ETA: 22s - loss: 4.8274 - acc: 0.01 - ETA: 22s - loss: 4.8268 - acc: 0.01 - ETA: 22s - loss: 4.8266 - acc: 0.01 - ETA: 21s - loss: 4.8261 - acc: 0.01 - ETA: 21s - loss: 4.8258 - acc: 0.01 - ETA: 21s - loss: 4.8258 - acc: 0.01 - ETA: 21s - loss: 4.8260 - acc: 0.01 - ETA: 21s - loss: 4.8263 - acc: 0.01 - ETA: 21s - loss: 4.8267 - acc: 0.01 - ETA: 20s - loss: 4.8262 - acc: 0.01 - ETA: 20s - loss: 4.8264 - acc: 0.01 - ETA: 20s - loss: 4.8262 - acc: 0.01 - ETA: 20s - loss: 4.8262 - acc: 0.01 - ETA: 20s - loss: 4.8267 - acc: 0.01 - ETA: 20s - loss: 4.8273 - acc: 0.01 - ETA: 19s - loss: 4.8269 - acc: 0.01 - ETA: 19s - loss: 4.8268 - acc: 0.01 - ETA: 19s - loss: 4.8268 - acc: 0.01 - ETA: 19s - loss: 4.8272 - acc: 0.01 - ETA: 19s - loss: 4.8275 - acc: 0.01 - ETA: 19s - loss: 4.8272 - acc: 0.01 - ETA: 18s - loss: 4.8269 - acc: 0.01 - ETA: 18s - loss: 4.8272 - acc: 0.01 - ETA: 18s - loss: 4.8270 - acc: 0.01 - ETA: 18s - loss: 4.8267 - acc: 0.01 - ETA: 18s - loss: 4.8262 - acc: 0.01 - ETA: 17s - loss: 4.8259 - acc: 0.01 - ETA: 17s - loss: 4.8264 - acc: 0.01 - ETA: 17s - loss: 4.8263 - acc: 0.01 - ETA: 17s - loss: 4.8261 - acc: 0.01 - ETA: 17s - loss: 4.8261 - acc: 0.01 - ETA: 17s - loss: 4.8259 - acc: 0.01 - ETA: 16s - loss: 4.8260 - acc: 0.01 - ETA: 16s - loss: 4.8261 - acc: 0.01 - ETA: 16s - loss: 4.8261 - acc: 0.01 - ETA: 16s - loss: 4.8263 - acc: 0.01 - ETA: 16s - loss: 4.8264 - acc: 0.01 - ETA: 16s - loss: 4.8263 - acc: 0.01 - ETA: 15s - loss: 4.8263 - acc: 0.01 - ETA: 15s - loss: 4.8261 - acc: 0.01 - ETA: 15s - loss: 4.8264 - acc: 0.01 - ETA: 15s - loss: 4.8267 - acc: 0.01 - ETA: 15s - loss: 4.8268 - acc: 0.01 - ETA: 14s - loss: 4.8269 - acc: 0.01 - ETA: 14s - loss: 4.8269 - acc: 0.01 - ETA: 14s - loss: 4.8267 - acc: 0.01 - ETA: 14s - loss: 4.8268 - acc: 0.01 - ETA: 14s - loss: 4.8271 - acc: 0.01 - ETA: 14s - loss: 4.8269 - acc: 0.01 - ETA: 13s - loss: 4.8267 - acc: 0.01 - ETA: 13s - loss: 4.8269 - acc: 0.01 - ETA: 13s - loss: 4.8269 - acc: 0.01 - ETA: 13s - loss: 4.8269 - acc: 0.01 - ETA: 13s - loss: 4.8266 - acc: 0.01 - ETA: 13s - loss: 4.8266 - acc: 0.01 - ETA: 12s - loss: 4.8263 - acc: 0.01 - ETA: 12s - loss: 4.8265 - acc: 0.01 - ETA: 12s - loss: 4.8266 - acc: 0.01 - ETA: 12s - loss: 4.8268 - acc: 0.01 - ETA: 12s - loss: 4.8266 - acc: 0.01 - ETA: 11s - loss: 4.8267 - acc: 0.01 - ETA: 11s - loss: 4.8264 - acc: 0.01 - ETA: 11s - loss: 4.8258 - acc: 0.01 - ETA: 11s - loss: 4.8256 - acc: 0.01 - ETA: 11s - loss: 4.8256 - acc: 0.01 - ETA: 11s - loss: 4.8258 - acc: 0.01 - ETA: 10s - loss: 4.8257 - acc: 0.01 - ETA: 10s - loss: 4.8256 - acc: 0.01 - ETA: 10s - loss: 4.8254 - acc: 0.01 - ETA: 10s - loss: 4.8253 - acc: 0.01 - ETA: 10s - loss: 4.8253 - acc: 0.01 - ETA: 10s - loss: 4.8254 - acc: 0.01 - ETA: 9s - loss: 4.8259 - acc: 0.0184 - ETA: 9s - loss: 4.8261 - acc: 0.018 - ETA: 9s - loss: 4.8259 - acc: 0.018 - ETA: 9s - loss: 4.8256 - acc: 0.018 - ETA: 9s - loss: 4.8256 - acc: 0.018 - ETA: 8s - loss: 4.8257 - acc: 0.018 - ETA: 8s - loss: 4.8258 - acc: 0.018 - ETA: 8s - loss: 4.8256 - acc: 0.018 - ETA: 8s - loss: 4.8259 - acc: 0.018 - ETA: 8s - loss: 4.8258 - acc: 0.017 - ETA: 8s - loss: 4.8255 - acc: 0.018 - ETA: 7s - loss: 4.8254 - acc: 0.018 - ETA: 7s - loss: 4.8256 - acc: 0.018 - ETA: 7s - loss: 4.8257 - acc: 0.018 - ETA: 7s - loss: 4.8257 - acc: 0.018 - ETA: 7s - loss: 4.8259 - acc: 0.018 - ETA: 7s - loss: 4.8257 - acc: 0.018 - ETA: 6s - loss: 4.8258 - acc: 0.018 - ETA: 6s - loss: 4.8255 - acc: 0.018 - ETA: 6s - loss: 4.8256 - acc: 0.017 - ETA: 6s - loss: 4.8256 - acc: 0.017 - ETA: 6s - loss: 4.8256 - acc: 0.017 - ETA: 5s - loss: 4.8255 - acc: 0.018 - ETA: 5s - loss: 4.8252 - acc: 0.018 - ETA: 5s - loss: 4.8252 - acc: 0.018 - ETA: 5s - loss: 4.8253 - acc: 0.018 - ETA: 5s - loss: 4.8252 - acc: 0.018 - ETA: 5s - loss: 4.8255 - acc: 0.018 - ETA: 4s - loss: 4.8253 - acc: 0.018 - ETA: 4s - loss: 4.8253 - acc: 0.017 - ETA: 4s - loss: 4.8250 - acc: 0.018 - ETA: 4s - loss: 4.8250 - acc: 0.018 - ETA: 4s - loss: 4.8250 - acc: 0.018 - ETA: 4s - loss: 4.8252 - acc: 0.018 - ETA: 3s - loss: 4.8252 - acc: 0.018 - ETA: 3s - loss: 4.8255 - acc: 0.018 - ETA: 3s - loss: 4.8255 - acc: 0.018 - ETA: 3s - loss: 4.8257 - acc: 0.018 - ETA: 3s - loss: 4.8259 - acc: 0.018 - ETA: 2s - loss: 4.8259 - acc: 0.018 - ETA: 2s - loss: 4.8256 - acc: 0.018 - ETA: 2s - loss: 4.8250 - acc: 0.018 - ETA: 2s - loss: 4.8253 - acc: 0.018 - ETA: 2s - loss: 4.8254 - acc: 0.018 - ETA: 2s - loss: 4.8255 - acc: 0.018 - ETA: 1s - loss: 4.8251 - acc: 0.018 - ETA: 1s - loss: 4.8249 - acc: 0.018 - ETA: 1s - loss: 4.8246 - acc: 0.018 - ETA: 1s - loss: 4.8245 - acc: 0.018 - ETA: 1s - loss: 4.8246 - acc: 0.018 - ETA: 1s - loss: 4.8243 - acc: 0.018 - ETA: 0s - loss: 4.8241 - acc: 0.018 - ETA: 0s - loss: 4.8240 - acc: 0.018 - ETA: 0s - loss: 4.8241 - acc: 0.018 - ETA: 0s - loss: 4.8242 - acc: 0.018 - ETA: 0s - loss: 4.8241 - acc: 0.018 - 78s 186ms/step - loss: 4.8242 - acc: 0.0186 - val_loss: 4.8024 - val_acc: 0.0220\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 4.78987\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211/417 [==============>...............] - ETA: 1:21 - loss: 4.8803 - acc: 0.062 - ETA: 1:18 - loss: 4.8433 - acc: 0.031 - ETA: 1:16 - loss: 4.8856 - acc: 0.020 - ETA: 1:16 - loss: 4.8475 - acc: 0.031 - ETA: 1:15 - loss: 4.8353 - acc: 0.037 - ETA: 1:15 - loss: 4.8335 - acc: 0.041 - ETA: 1:15 - loss: 4.8230 - acc: 0.044 - ETA: 1:14 - loss: 4.8213 - acc: 0.039 - ETA: 1:13 - loss: 4.8292 - acc: 0.041 - ETA: 1:13 - loss: 4.8286 - acc: 0.043 - ETA: 1:12 - loss: 4.8322 - acc: 0.039 - ETA: 1:12 - loss: 4.8212 - acc: 0.036 - ETA: 1:12 - loss: 4.8192 - acc: 0.033 - ETA: 1:11 - loss: 4.8086 - acc: 0.031 - ETA: 1:11 - loss: 4.8111 - acc: 0.029 - ETA: 1:11 - loss: 4.8042 - acc: 0.027 - ETA: 1:10 - loss: 4.8108 - acc: 0.025 - ETA: 1:10 - loss: 4.8155 - acc: 0.024 - ETA: 1:10 - loss: 4.8160 - acc: 0.026 - ETA: 1:09 - loss: 4.8171 - acc: 0.031 - ETA: 1:09 - loss: 4.8153 - acc: 0.029 - ETA: 1:09 - loss: 4.8103 - acc: 0.028 - ETA: 1:09 - loss: 4.8133 - acc: 0.027 - ETA: 1:08 - loss: 4.8101 - acc: 0.028 - ETA: 1:08 - loss: 4.8147 - acc: 0.027 - ETA: 1:08 - loss: 4.8098 - acc: 0.026 - ETA: 1:07 - loss: 4.8118 - acc: 0.025 - ETA: 1:07 - loss: 4.8095 - acc: 0.024 - ETA: 1:07 - loss: 4.8147 - acc: 0.023 - ETA: 1:07 - loss: 4.8170 - acc: 0.022 - ETA: 1:07 - loss: 4.8200 - acc: 0.022 - ETA: 1:06 - loss: 4.8182 - acc: 0.023 - ETA: 1:06 - loss: 4.8216 - acc: 0.022 - ETA: 1:06 - loss: 4.8216 - acc: 0.022 - ETA: 1:06 - loss: 4.8243 - acc: 0.021 - ETA: 1:05 - loss: 4.8204 - acc: 0.020 - ETA: 1:05 - loss: 4.8247 - acc: 0.020 - ETA: 1:05 - loss: 4.8253 - acc: 0.021 - ETA: 1:05 - loss: 4.8265 - acc: 0.020 - ETA: 1:05 - loss: 4.8272 - acc: 0.020 - ETA: 1:05 - loss: 4.8275 - acc: 0.019 - ETA: 1:05 - loss: 4.8222 - acc: 0.022 - ETA: 1:04 - loss: 4.8215 - acc: 0.021 - ETA: 1:04 - loss: 4.8203 - acc: 0.021 - ETA: 1:03 - loss: 4.8195 - acc: 0.020 - ETA: 1:03 - loss: 4.8227 - acc: 0.023 - ETA: 1:03 - loss: 4.8225 - acc: 0.022 - ETA: 1:03 - loss: 4.8207 - acc: 0.022 - ETA: 1:02 - loss: 4.8214 - acc: 0.021 - ETA: 1:02 - loss: 4.8195 - acc: 0.021 - ETA: 1:02 - loss: 4.8188 - acc: 0.020 - ETA: 1:02 - loss: 4.8166 - acc: 0.020 - ETA: 1:02 - loss: 4.8158 - acc: 0.020 - ETA: 1:02 - loss: 4.8136 - acc: 0.022 - ETA: 1:02 - loss: 4.8121 - acc: 0.023 - ETA: 1:01 - loss: 4.8106 - acc: 0.023 - ETA: 1:01 - loss: 4.8097 - acc: 0.023 - ETA: 1:01 - loss: 4.8102 - acc: 0.022 - ETA: 1:01 - loss: 4.8108 - acc: 0.022 - ETA: 1:01 - loss: 4.8105 - acc: 0.021 - ETA: 1:01 - loss: 4.8104 - acc: 0.021 - ETA: 1:00 - loss: 4.8114 - acc: 0.021 - ETA: 1:00 - loss: 4.8091 - acc: 0.020 - ETA: 1:00 - loss: 4.8085 - acc: 0.020 - ETA: 1:00 - loss: 4.8073 - acc: 0.020 - ETA: 1:00 - loss: 4.8080 - acc: 0.019 - ETA: 1:00 - loss: 4.8074 - acc: 0.020 - ETA: 1:00 - loss: 4.8069 - acc: 0.020 - ETA: 59s - loss: 4.8078 - acc: 0.020 - ETA: 59s - loss: 4.8059 - acc: 0.02 - ETA: 59s - loss: 4.8064 - acc: 0.02 - ETA: 59s - loss: 4.8082 - acc: 0.02 - ETA: 59s - loss: 4.8075 - acc: 0.02 - ETA: 59s - loss: 4.8062 - acc: 0.02 - ETA: 58s - loss: 4.8037 - acc: 0.02 - ETA: 58s - loss: 4.8046 - acc: 0.01 - ETA: 58s - loss: 4.8049 - acc: 0.01 - ETA: 58s - loss: 4.8045 - acc: 0.01 - ETA: 58s - loss: 4.8029 - acc: 0.01 - ETA: 58s - loss: 4.8038 - acc: 0.01 - ETA: 58s - loss: 4.8047 - acc: 0.02 - ETA: 58s - loss: 4.8049 - acc: 0.01 - ETA: 57s - loss: 4.8048 - acc: 0.01 - ETA: 57s - loss: 4.8064 - acc: 0.01 - ETA: 57s - loss: 4.8062 - acc: 0.01 - ETA: 57s - loss: 4.8075 - acc: 0.01 - ETA: 57s - loss: 4.8073 - acc: 0.01 - ETA: 57s - loss: 4.8082 - acc: 0.01 - ETA: 56s - loss: 4.8083 - acc: 0.01 - ETA: 56s - loss: 4.8091 - acc: 0.02 - ETA: 56s - loss: 4.8086 - acc: 0.01 - ETA: 56s - loss: 4.8085 - acc: 0.01 - ETA: 56s - loss: 4.8105 - acc: 0.01 - ETA: 56s - loss: 4.8112 - acc: 0.01 - ETA: 55s - loss: 4.8098 - acc: 0.01 - ETA: 55s - loss: 4.8091 - acc: 0.01 - ETA: 55s - loss: 4.8089 - acc: 0.01 - ETA: 55s - loss: 4.8105 - acc: 0.01 - ETA: 55s - loss: 4.8095 - acc: 0.01 - ETA: 55s - loss: 4.8085 - acc: 0.01 - ETA: 54s - loss: 4.8084 - acc: 0.01 - ETA: 54s - loss: 4.8084 - acc: 0.01 - ETA: 54s - loss: 4.8086 - acc: 0.01 - ETA: 54s - loss: 4.8093 - acc: 0.01 - ETA: 54s - loss: 4.8089 - acc: 0.01 - ETA: 54s - loss: 4.8106 - acc: 0.01 - ETA: 53s - loss: 4.8115 - acc: 0.01 - ETA: 53s - loss: 4.8117 - acc: 0.01 - ETA: 53s - loss: 4.8116 - acc: 0.01 - ETA: 53s - loss: 4.8130 - acc: 0.01 - ETA: 53s - loss: 4.8122 - acc: 0.01 - ETA: 53s - loss: 4.8114 - acc: 0.02 - ETA: 52s - loss: 4.8118 - acc: 0.01 - ETA: 52s - loss: 4.8130 - acc: 0.01 - ETA: 52s - loss: 4.8130 - acc: 0.01 - ETA: 52s - loss: 4.8132 - acc: 0.01 - ETA: 52s - loss: 4.8125 - acc: 0.01 - ETA: 52s - loss: 4.8139 - acc: 0.01 - ETA: 51s - loss: 4.8158 - acc: 0.01 - ETA: 51s - loss: 4.8169 - acc: 0.01 - ETA: 51s - loss: 4.8178 - acc: 0.01 - ETA: 51s - loss: 4.8182 - acc: 0.02 - ETA: 51s - loss: 4.8175 - acc: 0.02 - ETA: 50s - loss: 4.8182 - acc: 0.02 - ETA: 50s - loss: 4.8173 - acc: 0.02 - ETA: 50s - loss: 4.8177 - acc: 0.02 - ETA: 50s - loss: 4.8168 - acc: 0.02 - ETA: 50s - loss: 4.8164 - acc: 0.02 - ETA: 50s - loss: 4.8161 - acc: 0.02 - ETA: 49s - loss: 4.8173 - acc: 0.02 - ETA: 49s - loss: 4.8183 - acc: 0.02 - ETA: 49s - loss: 4.8180 - acc: 0.01 - ETA: 49s - loss: 4.8175 - acc: 0.02 - ETA: 49s - loss: 4.8174 - acc: 0.02 - ETA: 49s - loss: 4.8174 - acc: 0.01 - ETA: 48s - loss: 4.8183 - acc: 0.01 - ETA: 48s - loss: 4.8184 - acc: 0.01 - ETA: 48s - loss: 4.8192 - acc: 0.01 - ETA: 48s - loss: 4.8194 - acc: 0.01 - ETA: 48s - loss: 4.8200 - acc: 0.01 - ETA: 48s - loss: 4.8205 - acc: 0.01 - ETA: 47s - loss: 4.8192 - acc: 0.02 - ETA: 47s - loss: 4.8194 - acc: 0.02 - ETA: 47s - loss: 4.8191 - acc: 0.02 - ETA: 47s - loss: 4.8197 - acc: 0.01 - ETA: 47s - loss: 4.8204 - acc: 0.01 - ETA: 46s - loss: 4.8205 - acc: 0.01 - ETA: 46s - loss: 4.8207 - acc: 0.01 - ETA: 46s - loss: 4.8212 - acc: 0.01 - ETA: 46s - loss: 4.8216 - acc: 0.01 - ETA: 46s - loss: 4.8214 - acc: 0.01 - ETA: 46s - loss: 4.8206 - acc: 0.01 - ETA: 46s - loss: 4.8198 - acc: 0.01 - ETA: 45s - loss: 4.8194 - acc: 0.01 - ETA: 45s - loss: 4.8197 - acc: 0.01 - ETA: 45s - loss: 4.8192 - acc: 0.01 - ETA: 45s - loss: 4.8184 - acc: 0.01 - ETA: 45s - loss: 4.8184 - acc: 0.01 - ETA: 45s - loss: 4.8181 - acc: 0.01 - ETA: 44s - loss: 4.8185 - acc: 0.01 - ETA: 44s - loss: 4.8185 - acc: 0.01 - ETA: 44s - loss: 4.8181 - acc: 0.01 - ETA: 44s - loss: 4.8188 - acc: 0.01 - ETA: 44s - loss: 4.8179 - acc: 0.01 - ETA: 44s - loss: 4.8180 - acc: 0.01 - ETA: 43s - loss: 4.8181 - acc: 0.01 - ETA: 43s - loss: 4.8185 - acc: 0.01 - ETA: 43s - loss: 4.8194 - acc: 0.01 - ETA: 43s - loss: 4.8201 - acc: 0.01 - ETA: 43s - loss: 4.8198 - acc: 0.01 - ETA: 43s - loss: 4.8203 - acc: 0.01 - ETA: 42s - loss: 4.8200 - acc: 0.01 - ETA: 42s - loss: 4.8197 - acc: 0.01 - ETA: 42s - loss: 4.8195 - acc: 0.01 - ETA: 42s - loss: 4.8191 - acc: 0.01 - ETA: 42s - loss: 4.8184 - acc: 0.01 - ETA: 42s - loss: 4.8187 - acc: 0.01 - ETA: 42s - loss: 4.8190 - acc: 0.01 - ETA: 41s - loss: 4.8184 - acc: 0.01 - ETA: 41s - loss: 4.8191 - acc: 0.01 - ETA: 41s - loss: 4.8178 - acc: 0.01 - ETA: 41s - loss: 4.8170 - acc: 0.01 - ETA: 41s - loss: 4.8173 - acc: 0.01 - ETA: 41s - loss: 4.8174 - acc: 0.01 - ETA: 41s - loss: 4.8171 - acc: 0.01 - ETA: 40s - loss: 4.8173 - acc: 0.01 - ETA: 40s - loss: 4.8170 - acc: 0.01 - ETA: 40s - loss: 4.8169 - acc: 0.01 - ETA: 40s - loss: 4.8168 - acc: 0.01 - ETA: 40s - loss: 4.8176 - acc: 0.01 - ETA: 39s - loss: 4.8178 - acc: 0.01 - ETA: 39s - loss: 4.8170 - acc: 0.01 - ETA: 39s - loss: 4.8169 - acc: 0.01 - ETA: 39s - loss: 4.8170 - acc: 0.01 - ETA: 39s - loss: 4.8163 - acc: 0.01 - ETA: 39s - loss: 4.8166 - acc: 0.01 - ETA: 38s - loss: 4.8167 - acc: 0.01 - ETA: 38s - loss: 4.8167 - acc: 0.01 - ETA: 38s - loss: 4.8167 - acc: 0.01 - ETA: 38s - loss: 4.8166 - acc: 0.01 - ETA: 38s - loss: 4.8165 - acc: 0.01 - ETA: 38s - loss: 4.8157 - acc: 0.01 - ETA: 38s - loss: 4.8161 - acc: 0.01 - ETA: 37s - loss: 4.8164 - acc: 0.01 - ETA: 37s - loss: 4.8164 - acc: 0.01 - ETA: 37s - loss: 4.8164 - acc: 0.01 - ETA: 37s - loss: 4.8166 - acc: 0.01 - ETA: 37s - loss: 4.8161 - acc: 0.01 - ETA: 37s - loss: 4.8163 - acc: 0.01 - ETA: 36s - loss: 4.8164 - acc: 0.01 - ETA: 36s - loss: 4.8164 - acc: 0.0184"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 36s - loss: 4.8165 - acc: 0.01 - ETA: 36s - loss: 4.8171 - acc: 0.01 - ETA: 36s - loss: 4.8171 - acc: 0.01 - ETA: 36s - loss: 4.8174 - acc: 0.01 - ETA: 35s - loss: 4.8169 - acc: 0.01 - ETA: 35s - loss: 4.8170 - acc: 0.01 - ETA: 35s - loss: 4.8165 - acc: 0.01 - ETA: 35s - loss: 4.8161 - acc: 0.01 - ETA: 35s - loss: 4.8163 - acc: 0.01 - ETA: 34s - loss: 4.8159 - acc: 0.01 - ETA: 34s - loss: 4.8164 - acc: 0.01 - ETA: 34s - loss: 4.8167 - acc: 0.01 - ETA: 34s - loss: 4.8168 - acc: 0.01 - ETA: 34s - loss: 4.8167 - acc: 0.01 - ETA: 34s - loss: 4.8168 - acc: 0.01 - ETA: 33s - loss: 4.8169 - acc: 0.01 - ETA: 33s - loss: 4.8160 - acc: 0.01 - ETA: 33s - loss: 4.8163 - acc: 0.01 - ETA: 33s - loss: 4.8166 - acc: 0.01 - ETA: 33s - loss: 4.8171 - acc: 0.01 - ETA: 33s - loss: 4.8172 - acc: 0.01 - ETA: 32s - loss: 4.8168 - acc: 0.01 - ETA: 32s - loss: 4.8167 - acc: 0.01 - ETA: 32s - loss: 4.8169 - acc: 0.01 - ETA: 32s - loss: 4.8172 - acc: 0.01 - ETA: 32s - loss: 4.8177 - acc: 0.01 - ETA: 31s - loss: 4.8178 - acc: 0.01 - ETA: 31s - loss: 4.8177 - acc: 0.01 - ETA: 31s - loss: 4.8172 - acc: 0.01 - ETA: 31s - loss: 4.8177 - acc: 0.01 - ETA: 31s - loss: 4.8179 - acc: 0.01 - ETA: 31s - loss: 4.8180 - acc: 0.01 - ETA: 30s - loss: 4.8179 - acc: 0.01 - ETA: 30s - loss: 4.8178 - acc: 0.01 - ETA: 30s - loss: 4.8182 - acc: 0.01 - ETA: 30s - loss: 4.8177 - acc: 0.01 - ETA: 30s - loss: 4.8175 - acc: 0.01 - ETA: 30s - loss: 4.8175 - acc: 0.01 - ETA: 29s - loss: 4.8176 - acc: 0.01 - ETA: 29s - loss: 4.8179 - acc: 0.01 - ETA: 29s - loss: 4.8179 - acc: 0.01 - ETA: 29s - loss: 4.8182 - acc: 0.01 - ETA: 29s - loss: 4.8181 - acc: 0.01 - ETA: 29s - loss: 4.8179 - acc: 0.01 - ETA: 28s - loss: 4.8181 - acc: 0.01 - ETA: 28s - loss: 4.8180 - acc: 0.01 - ETA: 28s - loss: 4.8180 - acc: 0.01 - ETA: 28s - loss: 4.8178 - acc: 0.01 - ETA: 28s - loss: 4.8186 - acc: 0.01 - ETA: 28s - loss: 4.8186 - acc: 0.01 - ETA: 27s - loss: 4.8180 - acc: 0.01 - ETA: 27s - loss: 4.8182 - acc: 0.01 - ETA: 27s - loss: 4.8179 - acc: 0.01 - ETA: 27s - loss: 4.8179 - acc: 0.01 - ETA: 27s - loss: 4.8175 - acc: 0.01 - ETA: 26s - loss: 4.8171 - acc: 0.01 - ETA: 26s - loss: 4.8168 - acc: 0.01 - ETA: 26s - loss: 4.8165 - acc: 0.01 - ETA: 26s - loss: 4.8166 - acc: 0.01 - ETA: 26s - loss: 4.8164 - acc: 0.01 - ETA: 26s - loss: 4.8166 - acc: 0.01 - ETA: 25s - loss: 4.8169 - acc: 0.01 - ETA: 25s - loss: 4.8172 - acc: 0.01 - ETA: 25s - loss: 4.8172 - acc: 0.01 - ETA: 25s - loss: 4.8172 - acc: 0.01 - ETA: 25s - loss: 4.8173 - acc: 0.01 - ETA: 25s - loss: 4.8175 - acc: 0.01 - ETA: 24s - loss: 4.8174 - acc: 0.01 - ETA: 24s - loss: 4.8171 - acc: 0.01 - ETA: 24s - loss: 4.8172 - acc: 0.01 - ETA: 24s - loss: 4.8181 - acc: 0.01 - ETA: 24s - loss: 4.8179 - acc: 0.01 - ETA: 23s - loss: 4.8181 - acc: 0.01 - ETA: 23s - loss: 4.8184 - acc: 0.01 - ETA: 23s - loss: 4.8184 - acc: 0.01 - ETA: 23s - loss: 4.8188 - acc: 0.01 - ETA: 23s - loss: 4.8188 - acc: 0.01 - ETA: 23s - loss: 4.8189 - acc: 0.01 - ETA: 22s - loss: 4.8184 - acc: 0.01 - ETA: 22s - loss: 4.8181 - acc: 0.01 - ETA: 22s - loss: 4.8171 - acc: 0.01 - ETA: 22s - loss: 4.8175 - acc: 0.01 - ETA: 22s - loss: 4.8171 - acc: 0.01 - ETA: 22s - loss: 4.8169 - acc: 0.01 - ETA: 21s - loss: 4.8167 - acc: 0.01 - ETA: 21s - loss: 4.8169 - acc: 0.01 - ETA: 21s - loss: 4.8164 - acc: 0.01 - ETA: 21s - loss: 4.8161 - acc: 0.01 - ETA: 21s - loss: 4.8160 - acc: 0.01 - ETA: 21s - loss: 4.8157 - acc: 0.01 - ETA: 20s - loss: 4.8156 - acc: 0.01 - ETA: 20s - loss: 4.8160 - acc: 0.01 - ETA: 20s - loss: 4.8163 - acc: 0.01 - ETA: 20s - loss: 4.8166 - acc: 0.01 - ETA: 20s - loss: 4.8163 - acc: 0.01 - ETA: 19s - loss: 4.8162 - acc: 0.01 - ETA: 19s - loss: 4.8162 - acc: 0.01 - ETA: 19s - loss: 4.8165 - acc: 0.01 - ETA: 19s - loss: 4.8165 - acc: 0.01 - ETA: 19s - loss: 4.8165 - acc: 0.01 - ETA: 19s - loss: 4.8165 - acc: 0.01 - ETA: 18s - loss: 4.8169 - acc: 0.01 - ETA: 18s - loss: 4.8172 - acc: 0.01 - ETA: 18s - loss: 4.8170 - acc: 0.01 - ETA: 18s - loss: 4.8169 - acc: 0.01 - ETA: 18s - loss: 4.8167 - acc: 0.01 - ETA: 17s - loss: 4.8170 - acc: 0.01 - ETA: 17s - loss: 4.8170 - acc: 0.01 - ETA: 17s - loss: 4.8168 - acc: 0.01 - ETA: 17s - loss: 4.8169 - acc: 0.01 - ETA: 17s - loss: 4.8172 - acc: 0.01 - ETA: 17s - loss: 4.8169 - acc: 0.01 - ETA: 16s - loss: 4.8170 - acc: 0.01 - ETA: 16s - loss: 4.8168 - acc: 0.01 - ETA: 16s - loss: 4.8170 - acc: 0.01 - ETA: 16s - loss: 4.8171 - acc: 0.01 - ETA: 16s - loss: 4.8173 - acc: 0.01 - ETA: 15s - loss: 4.8175 - acc: 0.01 - ETA: 15s - loss: 4.8174 - acc: 0.01 - ETA: 15s - loss: 4.8178 - acc: 0.01 - ETA: 15s - loss: 4.8175 - acc: 0.01 - ETA: 15s - loss: 4.8176 - acc: 0.01 - ETA: 15s - loss: 4.8173 - acc: 0.01 - ETA: 14s - loss: 4.8174 - acc: 0.01 - ETA: 14s - loss: 4.8169 - acc: 0.01 - ETA: 14s - loss: 4.8171 - acc: 0.01 - ETA: 14s - loss: 4.8170 - acc: 0.01 - ETA: 14s - loss: 4.8167 - acc: 0.01 - ETA: 13s - loss: 4.8163 - acc: 0.01 - ETA: 13s - loss: 4.8161 - acc: 0.01 - ETA: 13s - loss: 4.8163 - acc: 0.01 - ETA: 13s - loss: 4.8164 - acc: 0.01 - ETA: 13s - loss: 4.8162 - acc: 0.01 - ETA: 13s - loss: 4.8163 - acc: 0.01 - ETA: 12s - loss: 4.8159 - acc: 0.01 - ETA: 12s - loss: 4.8157 - acc: 0.01 - ETA: 12s - loss: 4.8159 - acc: 0.01 - ETA: 12s - loss: 4.8161 - acc: 0.01 - ETA: 12s - loss: 4.8163 - acc: 0.01 - ETA: 11s - loss: 4.8164 - acc: 0.01 - ETA: 11s - loss: 4.8161 - acc: 0.01 - ETA: 11s - loss: 4.8162 - acc: 0.01 - ETA: 11s - loss: 4.8160 - acc: 0.01 - ETA: 11s - loss: 4.8158 - acc: 0.01 - ETA: 11s - loss: 4.8160 - acc: 0.01 - ETA: 10s - loss: 4.8160 - acc: 0.01 - ETA: 10s - loss: 4.8156 - acc: 0.01 - ETA: 10s - loss: 4.8157 - acc: 0.01 - ETA: 10s - loss: 4.8158 - acc: 0.01 - ETA: 10s - loss: 4.8158 - acc: 0.01 - ETA: 9s - loss: 4.8159 - acc: 0.0192 - ETA: 9s - loss: 4.8157 - acc: 0.019 - ETA: 9s - loss: 4.8159 - acc: 0.019 - ETA: 9s - loss: 4.8161 - acc: 0.019 - ETA: 9s - loss: 4.8162 - acc: 0.019 - ETA: 9s - loss: 4.8165 - acc: 0.019 - ETA: 8s - loss: 4.8166 - acc: 0.019 - ETA: 8s - loss: 4.8166 - acc: 0.019 - ETA: 8s - loss: 4.8165 - acc: 0.019 - ETA: 8s - loss: 4.8167 - acc: 0.019 - ETA: 8s - loss: 4.8166 - acc: 0.019 - ETA: 7s - loss: 4.8168 - acc: 0.018 - ETA: 7s - loss: 4.8170 - acc: 0.018 - ETA: 7s - loss: 4.8170 - acc: 0.018 - ETA: 7s - loss: 4.8170 - acc: 0.018 - ETA: 7s - loss: 4.8175 - acc: 0.018 - ETA: 6s - loss: 4.8171 - acc: 0.018 - ETA: 6s - loss: 4.8172 - acc: 0.018 - ETA: 6s - loss: 4.8172 - acc: 0.018 - ETA: 6s - loss: 4.8173 - acc: 0.018 - ETA: 6s - loss: 4.8177 - acc: 0.019 - ETA: 6s - loss: 4.8180 - acc: 0.019 - ETA: 5s - loss: 4.8176 - acc: 0.019 - ETA: 5s - loss: 4.8176 - acc: 0.019 - ETA: 5s - loss: 4.8176 - acc: 0.019 - ETA: 5s - loss: 4.8176 - acc: 0.019 - ETA: 5s - loss: 4.8178 - acc: 0.019 - ETA: 5s - loss: 4.8178 - acc: 0.019 - ETA: 4s - loss: 4.8173 - acc: 0.019 - ETA: 4s - loss: 4.8178 - acc: 0.019 - ETA: 4s - loss: 4.8178 - acc: 0.019 - ETA: 4s - loss: 4.8179 - acc: 0.019 - ETA: 4s - loss: 4.8182 - acc: 0.019 - ETA: 3s - loss: 4.8183 - acc: 0.019 - ETA: 3s - loss: 4.8183 - acc: 0.019 - ETA: 3s - loss: 4.8182 - acc: 0.019 - ETA: 3s - loss: 4.8182 - acc: 0.019 - ETA: 3s - loss: 4.8181 - acc: 0.019 - ETA: 3s - loss: 4.8185 - acc: 0.019 - ETA: 2s - loss: 4.8184 - acc: 0.019 - ETA: 2s - loss: 4.8180 - acc: 0.019 - ETA: 2s - loss: 4.8177 - acc: 0.019 - ETA: 2s - loss: 4.8178 - acc: 0.019 - ETA: 2s - loss: 4.8181 - acc: 0.019 - ETA: 1s - loss: 4.8183 - acc: 0.019 - ETA: 1s - loss: 4.8178 - acc: 0.019 - ETA: 1s - loss: 4.8176 - acc: 0.019 - ETA: 1s - loss: 4.8179 - acc: 0.019 - ETA: 1s - loss: 4.8178 - acc: 0.019 - ETA: 1s - loss: 4.8177 - acc: 0.019 - ETA: 0s - loss: 4.8178 - acc: 0.019 - ETA: 0s - loss: 4.8180 - acc: 0.019 - ETA: 0s - loss: 4.8179 - acc: 0.019 - ETA: 0s - loss: 4.8181 - acc: 0.019 - ETA: 0s - loss: 4.8181 - acc: 0.019 - 79s 188ms/step - loss: 4.8175 - acc: 0.0195 - val_loss: 4.7907 - val_acc: 0.0281\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 4.78987\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/417 [==============>...............] - ETA: 54s - loss: 4.7841 - acc: 0.0000e+ - ETA: 53s - loss: 4.7452 - acc: 0.0312   - ETA: 53s - loss: 4.8159 - acc: 0.02 - ETA: 54s - loss: 4.8557 - acc: 0.01 - ETA: 54s - loss: 4.8221 - acc: 0.03 - ETA: 54s - loss: 4.8294 - acc: 0.03 - ETA: 54s - loss: 4.8282 - acc: 0.02 - ETA: 53s - loss: 4.8437 - acc: 0.03 - ETA: 53s - loss: 4.8358 - acc: 0.02 - ETA: 53s - loss: 4.8378 - acc: 0.02 - ETA: 53s - loss: 4.8292 - acc: 0.02 - ETA: 52s - loss: 4.8199 - acc: 0.02 - ETA: 52s - loss: 4.8241 - acc: 0.02 - ETA: 51s - loss: 4.8223 - acc: 0.02 - ETA: 51s - loss: 4.8201 - acc: 0.02 - ETA: 51s - loss: 4.8122 - acc: 0.02 - ETA: 51s - loss: 4.8054 - acc: 0.02 - ETA: 50s - loss: 4.8061 - acc: 0.02 - ETA: 50s - loss: 4.8128 - acc: 0.02 - ETA: 50s - loss: 4.8109 - acc: 0.02 - ETA: 50s - loss: 4.8138 - acc: 0.02 - ETA: 50s - loss: 4.8169 - acc: 0.02 - ETA: 50s - loss: 4.8164 - acc: 0.02 - ETA: 49s - loss: 4.8191 - acc: 0.02 - ETA: 49s - loss: 4.8176 - acc: 0.02 - ETA: 49s - loss: 4.8153 - acc: 0.02 - ETA: 49s - loss: 4.8168 - acc: 0.02 - ETA: 49s - loss: 4.8185 - acc: 0.02 - ETA: 48s - loss: 4.8196 - acc: 0.02 - ETA: 48s - loss: 4.8173 - acc: 0.02 - ETA: 48s - loss: 4.8134 - acc: 0.02 - ETA: 48s - loss: 4.8141 - acc: 0.02 - ETA: 48s - loss: 4.8150 - acc: 0.02 - ETA: 49s - loss: 4.8157 - acc: 0.02 - ETA: 49s - loss: 4.8174 - acc: 0.02 - ETA: 49s - loss: 4.8196 - acc: 0.02 - ETA: 49s - loss: 4.8242 - acc: 0.02 - ETA: 50s - loss: 4.8228 - acc: 0.02 - ETA: 50s - loss: 4.8202 - acc: 0.02 - ETA: 51s - loss: 4.8190 - acc: 0.02 - ETA: 51s - loss: 4.8190 - acc: 0.02 - ETA: 51s - loss: 4.8193 - acc: 0.02 - ETA: 52s - loss: 4.8174 - acc: 0.02 - ETA: 53s - loss: 4.8168 - acc: 0.02 - ETA: 53s - loss: 4.8169 - acc: 0.02 - ETA: 52s - loss: 4.8211 - acc: 0.02 - ETA: 52s - loss: 4.8184 - acc: 0.02 - ETA: 52s - loss: 4.8191 - acc: 0.02 - ETA: 52s - loss: 4.8154 - acc: 0.02 - ETA: 52s - loss: 4.8161 - acc: 0.02 - ETA: 54s - loss: 4.8132 - acc: 0.02 - ETA: 54s - loss: 4.8129 - acc: 0.02 - ETA: 53s - loss: 4.8133 - acc: 0.02 - ETA: 54s - loss: 4.8133 - acc: 0.02 - ETA: 53s - loss: 4.8135 - acc: 0.02 - ETA: 53s - loss: 4.8148 - acc: 0.02 - ETA: 53s - loss: 4.8160 - acc: 0.02 - ETA: 53s - loss: 4.8149 - acc: 0.02 - ETA: 53s - loss: 4.8117 - acc: 0.02 - ETA: 53s - loss: 4.8101 - acc: 0.02 - ETA: 53s - loss: 4.8101 - acc: 0.02 - ETA: 53s - loss: 4.8120 - acc: 0.02 - ETA: 54s - loss: 4.8115 - acc: 0.02 - ETA: 54s - loss: 4.8135 - acc: 0.02 - ETA: 53s - loss: 4.8133 - acc: 0.02 - ETA: 53s - loss: 4.8125 - acc: 0.02 - ETA: 54s - loss: 4.8135 - acc: 0.02 - ETA: 54s - loss: 4.8142 - acc: 0.02 - ETA: 53s - loss: 4.8146 - acc: 0.02 - ETA: 54s - loss: 4.8142 - acc: 0.02 - ETA: 54s - loss: 4.8122 - acc: 0.02 - ETA: 54s - loss: 4.8112 - acc: 0.02 - ETA: 54s - loss: 4.8094 - acc: 0.02 - ETA: 54s - loss: 4.8096 - acc: 0.02 - ETA: 54s - loss: 4.8094 - acc: 0.02 - ETA: 54s - loss: 4.8092 - acc: 0.02 - ETA: 54s - loss: 4.8097 - acc: 0.02 - ETA: 54s - loss: 4.8105 - acc: 0.02 - ETA: 53s - loss: 4.8102 - acc: 0.02 - ETA: 53s - loss: 4.8091 - acc: 0.02 - ETA: 53s - loss: 4.8110 - acc: 0.02 - ETA: 53s - loss: 4.8098 - acc: 0.02 - ETA: 53s - loss: 4.8092 - acc: 0.02 - ETA: 53s - loss: 4.8081 - acc: 0.02 - ETA: 52s - loss: 4.8075 - acc: 0.02 - ETA: 52s - loss: 4.8082 - acc: 0.02 - ETA: 52s - loss: 4.8087 - acc: 0.02 - ETA: 52s - loss: 4.8091 - acc: 0.02 - ETA: 52s - loss: 4.8085 - acc: 0.02 - ETA: 51s - loss: 4.8096 - acc: 0.02 - ETA: 51s - loss: 4.8103 - acc: 0.02 - ETA: 51s - loss: 4.8114 - acc: 0.02 - ETA: 51s - loss: 4.8134 - acc: 0.02 - ETA: 51s - loss: 4.8134 - acc: 0.02 - ETA: 51s - loss: 4.8128 - acc: 0.02 - ETA: 51s - loss: 4.8137 - acc: 0.02 - ETA: 51s - loss: 4.8139 - acc: 0.02 - ETA: 51s - loss: 4.8128 - acc: 0.02 - ETA: 50s - loss: 4.8131 - acc: 0.02 - ETA: 50s - loss: 4.8125 - acc: 0.02 - ETA: 50s - loss: 4.8130 - acc: 0.02 - ETA: 50s - loss: 4.8136 - acc: 0.02 - ETA: 50s - loss: 4.8112 - acc: 0.02 - ETA: 50s - loss: 4.8117 - acc: 0.02 - ETA: 50s - loss: 4.8109 - acc: 0.02 - ETA: 49s - loss: 4.8103 - acc: 0.02 - ETA: 49s - loss: 4.8105 - acc: 0.02 - ETA: 49s - loss: 4.8113 - acc: 0.02 - ETA: 49s - loss: 4.8111 - acc: 0.02 - ETA: 49s - loss: 4.8118 - acc: 0.02 - ETA: 49s - loss: 4.8116 - acc: 0.02 - ETA: 49s - loss: 4.8120 - acc: 0.02 - ETA: 49s - loss: 4.8119 - acc: 0.02 - ETA: 49s - loss: 4.8136 - acc: 0.02 - ETA: 49s - loss: 4.8142 - acc: 0.02 - ETA: 48s - loss: 4.8143 - acc: 0.02 - ETA: 48s - loss: 4.8140 - acc: 0.02 - ETA: 48s - loss: 4.8157 - acc: 0.02 - ETA: 48s - loss: 4.8162 - acc: 0.02 - ETA: 48s - loss: 4.8159 - acc: 0.02 - ETA: 48s - loss: 4.8157 - acc: 0.02 - ETA: 48s - loss: 4.8161 - acc: 0.02 - ETA: 48s - loss: 4.8160 - acc: 0.02 - ETA: 47s - loss: 4.8166 - acc: 0.02 - ETA: 47s - loss: 4.8170 - acc: 0.02 - ETA: 47s - loss: 4.8168 - acc: 0.02 - ETA: 47s - loss: 4.8160 - acc: 0.02 - ETA: 47s - loss: 4.8151 - acc: 0.02 - ETA: 47s - loss: 4.8149 - acc: 0.02 - ETA: 47s - loss: 4.8152 - acc: 0.02 - ETA: 47s - loss: 4.8155 - acc: 0.02 - ETA: 47s - loss: 4.8142 - acc: 0.02 - ETA: 47s - loss: 4.8151 - acc: 0.02 - ETA: 46s - loss: 4.8148 - acc: 0.02 - ETA: 46s - loss: 4.8150 - acc: 0.02 - ETA: 46s - loss: 4.8139 - acc: 0.02 - ETA: 46s - loss: 4.8139 - acc: 0.02 - ETA: 46s - loss: 4.8135 - acc: 0.02 - ETA: 45s - loss: 4.8131 - acc: 0.02 - ETA: 45s - loss: 4.8137 - acc: 0.02 - ETA: 45s - loss: 4.8137 - acc: 0.02 - ETA: 45s - loss: 4.8140 - acc: 0.02 - ETA: 45s - loss: 4.8133 - acc: 0.02 - ETA: 44s - loss: 4.8131 - acc: 0.02 - ETA: 44s - loss: 4.8121 - acc: 0.02 - ETA: 44s - loss: 4.8129 - acc: 0.02 - ETA: 44s - loss: 4.8134 - acc: 0.02 - ETA: 44s - loss: 4.8121 - acc: 0.02 - ETA: 44s - loss: 4.8120 - acc: 0.02 - ETA: 43s - loss: 4.8121 - acc: 0.02 - ETA: 43s - loss: 4.8122 - acc: 0.02 - ETA: 43s - loss: 4.8125 - acc: 0.02 - ETA: 43s - loss: 4.8115 - acc: 0.02 - ETA: 43s - loss: 4.8113 - acc: 0.02 - ETA: 43s - loss: 4.8117 - acc: 0.02 - ETA: 42s - loss: 4.8112 - acc: 0.02 - ETA: 42s - loss: 4.8123 - acc: 0.02 - ETA: 42s - loss: 4.8120 - acc: 0.02 - ETA: 42s - loss: 4.8122 - acc: 0.02 - ETA: 42s - loss: 4.8132 - acc: 0.02 - ETA: 42s - loss: 4.8138 - acc: 0.02 - ETA: 42s - loss: 4.8124 - acc: 0.02 - ETA: 41s - loss: 4.8117 - acc: 0.02 - ETA: 41s - loss: 4.8124 - acc: 0.02 - ETA: 41s - loss: 4.8123 - acc: 0.02 - ETA: 41s - loss: 4.8122 - acc: 0.02 - ETA: 41s - loss: 4.8120 - acc: 0.02 - ETA: 41s - loss: 4.8123 - acc: 0.02 - ETA: 41s - loss: 4.8120 - acc: 0.02 - ETA: 40s - loss: 4.8121 - acc: 0.02 - ETA: 40s - loss: 4.8128 - acc: 0.02 - ETA: 40s - loss: 4.8125 - acc: 0.02 - ETA: 40s - loss: 4.8126 - acc: 0.02 - ETA: 40s - loss: 4.8118 - acc: 0.02 - ETA: 40s - loss: 4.8113 - acc: 0.02 - ETA: 40s - loss: 4.8121 - acc: 0.02 - ETA: 40s - loss: 4.8126 - acc: 0.02 - ETA: 40s - loss: 4.8128 - acc: 0.02 - ETA: 39s - loss: 4.8129 - acc: 0.02 - ETA: 39s - loss: 4.8134 - acc: 0.02 - ETA: 39s - loss: 4.8144 - acc: 0.02 - ETA: 39s - loss: 4.8142 - acc: 0.02 - ETA: 39s - loss: 4.8149 - acc: 0.02 - ETA: 39s - loss: 4.8150 - acc: 0.02 - ETA: 39s - loss: 4.8145 - acc: 0.02 - ETA: 39s - loss: 4.8146 - acc: 0.02 - ETA: 38s - loss: 4.8144 - acc: 0.02 - ETA: 38s - loss: 4.8145 - acc: 0.02 - ETA: 38s - loss: 4.8145 - acc: 0.02 - ETA: 38s - loss: 4.8147 - acc: 0.02 - ETA: 38s - loss: 4.8148 - acc: 0.02 - ETA: 38s - loss: 4.8140 - acc: 0.02 - ETA: 38s - loss: 4.8135 - acc: 0.02 - ETA: 37s - loss: 4.8141 - acc: 0.02 - ETA: 37s - loss: 4.8141 - acc: 0.02 - ETA: 37s - loss: 4.8137 - acc: 0.02 - ETA: 37s - loss: 4.8139 - acc: 0.02 - ETA: 37s - loss: 4.8138 - acc: 0.02 - ETA: 37s - loss: 4.8135 - acc: 0.02 - ETA: 36s - loss: 4.8139 - acc: 0.02 - ETA: 36s - loss: 4.8131 - acc: 0.02 - ETA: 36s - loss: 4.8129 - acc: 0.02 - ETA: 36s - loss: 4.8127 - acc: 0.02 - ETA: 36s - loss: 4.8126 - acc: 0.02 - ETA: 35s - loss: 4.8136 - acc: 0.02 - ETA: 35s - loss: 4.8146 - acc: 0.02 - ETA: 35s - loss: 4.8144 - acc: 0.02 - ETA: 35s - loss: 4.8144 - acc: 0.02 - ETA: 35s - loss: 4.8143 - acc: 0.02 - ETA: 35s - loss: 4.8144 - acc: 0.02 - ETA: 34s - loss: 4.8136 - acc: 0.02 - ETA: 34s - loss: 4.8135 - acc: 0.02 - ETA: 34s - loss: 4.8137 - acc: 0.02 - ETA: 34s - loss: 4.8133 - acc: 0.02 - ETA: 34s - loss: 4.8130 - acc: 0.0244"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 34s - loss: 4.8134 - acc: 0.02 - ETA: 33s - loss: 4.8136 - acc: 0.02 - ETA: 33s - loss: 4.8138 - acc: 0.02 - ETA: 33s - loss: 4.8141 - acc: 0.02 - ETA: 33s - loss: 4.8138 - acc: 0.02 - ETA: 33s - loss: 4.8135 - acc: 0.02 - ETA: 33s - loss: 4.8131 - acc: 0.02 - ETA: 32s - loss: 4.8127 - acc: 0.02 - ETA: 32s - loss: 4.8124 - acc: 0.02 - ETA: 32s - loss: 4.8124 - acc: 0.02 - ETA: 32s - loss: 4.8122 - acc: 0.02 - ETA: 32s - loss: 4.8123 - acc: 0.02 - ETA: 32s - loss: 4.8121 - acc: 0.02 - ETA: 32s - loss: 4.8116 - acc: 0.02 - ETA: 31s - loss: 4.8113 - acc: 0.02 - ETA: 31s - loss: 4.8114 - acc: 0.02 - ETA: 31s - loss: 4.8119 - acc: 0.02 - ETA: 31s - loss: 4.8130 - acc: 0.02 - ETA: 31s - loss: 4.8128 - acc: 0.02 - ETA: 30s - loss: 4.8126 - acc: 0.02 - ETA: 30s - loss: 4.8123 - acc: 0.02 - ETA: 30s - loss: 4.8131 - acc: 0.02 - ETA: 30s - loss: 4.8127 - acc: 0.02 - ETA: 30s - loss: 4.8132 - acc: 0.02 - ETA: 29s - loss: 4.8135 - acc: 0.02 - ETA: 29s - loss: 4.8135 - acc: 0.02 - ETA: 29s - loss: 4.8135 - acc: 0.02 - ETA: 29s - loss: 4.8133 - acc: 0.02 - ETA: 29s - loss: 4.8130 - acc: 0.02 - ETA: 29s - loss: 4.8126 - acc: 0.02 - ETA: 28s - loss: 4.8129 - acc: 0.02 - ETA: 28s - loss: 4.8134 - acc: 0.02 - ETA: 28s - loss: 4.8139 - acc: 0.02 - ETA: 28s - loss: 4.8136 - acc: 0.02 - ETA: 28s - loss: 4.8133 - acc: 0.02 - ETA: 28s - loss: 4.8132 - acc: 0.02 - ETA: 27s - loss: 4.8132 - acc: 0.02 - ETA: 27s - loss: 4.8134 - acc: 0.02 - ETA: 27s - loss: 4.8131 - acc: 0.02 - ETA: 27s - loss: 4.8132 - acc: 0.02 - ETA: 27s - loss: 4.8130 - acc: 0.02 - ETA: 27s - loss: 4.8122 - acc: 0.02 - ETA: 26s - loss: 4.8120 - acc: 0.02 - ETA: 26s - loss: 4.8127 - acc: 0.02 - ETA: 26s - loss: 4.8128 - acc: 0.02 - ETA: 26s - loss: 4.8127 - acc: 0.02 - ETA: 26s - loss: 4.8125 - acc: 0.02 - ETA: 26s - loss: 4.8127 - acc: 0.02 - ETA: 25s - loss: 4.8132 - acc: 0.02 - ETA: 25s - loss: 4.8131 - acc: 0.02 - ETA: 25s - loss: 4.8136 - acc: 0.02 - ETA: 25s - loss: 4.8136 - acc: 0.02 - ETA: 25s - loss: 4.8131 - acc: 0.02 - ETA: 25s - loss: 4.8129 - acc: 0.02 - ETA: 24s - loss: 4.8133 - acc: 0.02 - ETA: 24s - loss: 4.8130 - acc: 0.02 - ETA: 24s - loss: 4.8130 - acc: 0.02 - ETA: 24s - loss: 4.8131 - acc: 0.02 - ETA: 24s - loss: 4.8135 - acc: 0.02 - ETA: 24s - loss: 4.8133 - acc: 0.02 - ETA: 23s - loss: 4.8138 - acc: 0.02 - ETA: 23s - loss: 4.8137 - acc: 0.02 - ETA: 23s - loss: 4.8136 - acc: 0.02 - ETA: 23s - loss: 4.8138 - acc: 0.02 - ETA: 23s - loss: 4.8135 - acc: 0.02 - ETA: 23s - loss: 4.8132 - acc: 0.02 - ETA: 22s - loss: 4.8131 - acc: 0.02 - ETA: 22s - loss: 4.8128 - acc: 0.02 - ETA: 22s - loss: 4.8130 - acc: 0.02 - ETA: 22s - loss: 4.8131 - acc: 0.02 - ETA: 22s - loss: 4.8124 - acc: 0.02 - ETA: 22s - loss: 4.8127 - acc: 0.02 - ETA: 21s - loss: 4.8125 - acc: 0.02 - ETA: 21s - loss: 4.8126 - acc: 0.02 - ETA: 21s - loss: 4.8128 - acc: 0.02 - ETA: 21s - loss: 4.8133 - acc: 0.02 - ETA: 21s - loss: 4.8132 - acc: 0.02 - ETA: 21s - loss: 4.8135 - acc: 0.02 - ETA: 20s - loss: 4.8137 - acc: 0.02 - ETA: 20s - loss: 4.8137 - acc: 0.02 - ETA: 20s - loss: 4.8140 - acc: 0.02 - ETA: 20s - loss: 4.8142 - acc: 0.02 - ETA: 20s - loss: 4.8149 - acc: 0.02 - ETA: 19s - loss: 4.8155 - acc: 0.02 - ETA: 19s - loss: 4.8156 - acc: 0.02 - ETA: 19s - loss: 4.8156 - acc: 0.02 - ETA: 19s - loss: 4.8156 - acc: 0.02 - ETA: 19s - loss: 4.8162 - acc: 0.02 - ETA: 19s - loss: 4.8164 - acc: 0.02 - ETA: 19s - loss: 4.8164 - acc: 0.02 - ETA: 18s - loss: 4.8167 - acc: 0.02 - ETA: 18s - loss: 4.8165 - acc: 0.02 - ETA: 18s - loss: 4.8166 - acc: 0.02 - ETA: 18s - loss: 4.8166 - acc: 0.02 - ETA: 18s - loss: 4.8169 - acc: 0.02 - ETA: 17s - loss: 4.8169 - acc: 0.02 - ETA: 17s - loss: 4.8172 - acc: 0.02 - ETA: 17s - loss: 4.8175 - acc: 0.02 - ETA: 17s - loss: 4.8173 - acc: 0.02 - ETA: 17s - loss: 4.8168 - acc: 0.02 - ETA: 17s - loss: 4.8171 - acc: 0.02 - ETA: 16s - loss: 4.8171 - acc: 0.02 - ETA: 16s - loss: 4.8166 - acc: 0.02 - ETA: 16s - loss: 4.8167 - acc: 0.02 - ETA: 16s - loss: 4.8171 - acc: 0.02 - ETA: 16s - loss: 4.8170 - acc: 0.02 - ETA: 16s - loss: 4.8170 - acc: 0.02 - ETA: 15s - loss: 4.8171 - acc: 0.02 - ETA: 15s - loss: 4.8167 - acc: 0.02 - ETA: 15s - loss: 4.8165 - acc: 0.02 - ETA: 15s - loss: 4.8168 - acc: 0.02 - ETA: 15s - loss: 4.8164 - acc: 0.02 - ETA: 15s - loss: 4.8166 - acc: 0.02 - ETA: 15s - loss: 4.8168 - acc: 0.02 - ETA: 14s - loss: 4.8164 - acc: 0.02 - ETA: 14s - loss: 4.8166 - acc: 0.02 - ETA: 14s - loss: 4.8163 - acc: 0.02 - ETA: 14s - loss: 4.8159 - acc: 0.02 - ETA: 14s - loss: 4.8162 - acc: 0.02 - ETA: 14s - loss: 4.8163 - acc: 0.02 - ETA: 13s - loss: 4.8163 - acc: 0.02 - ETA: 13s - loss: 4.8162 - acc: 0.02 - ETA: 13s - loss: 4.8163 - acc: 0.02 - ETA: 13s - loss: 4.8159 - acc: 0.02 - ETA: 13s - loss: 4.8159 - acc: 0.02 - ETA: 12s - loss: 4.8159 - acc: 0.02 - ETA: 12s - loss: 4.8161 - acc: 0.02 - ETA: 12s - loss: 4.8166 - acc: 0.02 - ETA: 12s - loss: 4.8168 - acc: 0.02 - ETA: 12s - loss: 4.8164 - acc: 0.02 - ETA: 12s - loss: 4.8162 - acc: 0.02 - ETA: 11s - loss: 4.8165 - acc: 0.02 - ETA: 11s - loss: 4.8164 - acc: 0.02 - ETA: 11s - loss: 4.8165 - acc: 0.02 - ETA: 11s - loss: 4.8170 - acc: 0.02 - ETA: 11s - loss: 4.8173 - acc: 0.02 - ETA: 11s - loss: 4.8172 - acc: 0.02 - ETA: 10s - loss: 4.8171 - acc: 0.02 - ETA: 10s - loss: 4.8167 - acc: 0.02 - ETA: 10s - loss: 4.8170 - acc: 0.02 - ETA: 10s - loss: 4.8169 - acc: 0.02 - ETA: 10s - loss: 4.8168 - acc: 0.02 - ETA: 10s - loss: 4.8172 - acc: 0.02 - ETA: 9s - loss: 4.8171 - acc: 0.0205 - ETA: 9s - loss: 4.8171 - acc: 0.020 - ETA: 9s - loss: 4.8173 - acc: 0.020 - ETA: 9s - loss: 4.8172 - acc: 0.020 - ETA: 9s - loss: 4.8170 - acc: 0.020 - ETA: 9s - loss: 4.8168 - acc: 0.020 - ETA: 8s - loss: 4.8169 - acc: 0.020 - ETA: 8s - loss: 4.8169 - acc: 0.020 - ETA: 8s - loss: 4.8169 - acc: 0.020 - ETA: 8s - loss: 4.8170 - acc: 0.020 - ETA: 8s - loss: 4.8173 - acc: 0.020 - ETA: 8s - loss: 4.8173 - acc: 0.020 - ETA: 7s - loss: 4.8177 - acc: 0.020 - ETA: 7s - loss: 4.8180 - acc: 0.020 - ETA: 7s - loss: 4.8184 - acc: 0.020 - ETA: 7s - loss: 4.8183 - acc: 0.020 - ETA: 7s - loss: 4.8185 - acc: 0.020 - ETA: 6s - loss: 4.8187 - acc: 0.020 - ETA: 6s - loss: 4.8187 - acc: 0.020 - ETA: 6s - loss: 4.8190 - acc: 0.020 - ETA: 6s - loss: 4.8194 - acc: 0.020 - ETA: 6s - loss: 4.8195 - acc: 0.020 - ETA: 6s - loss: 4.8191 - acc: 0.020 - ETA: 5s - loss: 4.8191 - acc: 0.020 - ETA: 5s - loss: 4.8188 - acc: 0.020 - ETA: 5s - loss: 4.8190 - acc: 0.020 - ETA: 5s - loss: 4.8189 - acc: 0.020 - ETA: 5s - loss: 4.8189 - acc: 0.020 - ETA: 5s - loss: 4.8188 - acc: 0.020 - ETA: 4s - loss: 4.8190 - acc: 0.020 - ETA: 4s - loss: 4.8188 - acc: 0.020 - ETA: 4s - loss: 4.8187 - acc: 0.020 - ETA: 4s - loss: 4.8186 - acc: 0.020 - ETA: 4s - loss: 4.8185 - acc: 0.020 - ETA: 4s - loss: 4.8185 - acc: 0.020 - ETA: 3s - loss: 4.8184 - acc: 0.020 - ETA: 3s - loss: 4.8186 - acc: 0.020 - ETA: 3s - loss: 4.8184 - acc: 0.020 - ETA: 3s - loss: 4.8183 - acc: 0.020 - ETA: 3s - loss: 4.8185 - acc: 0.020 - ETA: 3s - loss: 4.8187 - acc: 0.020 - ETA: 2s - loss: 4.8188 - acc: 0.020 - ETA: 2s - loss: 4.8189 - acc: 0.020 - ETA: 2s - loss: 4.8190 - acc: 0.020 - ETA: 2s - loss: 4.8190 - acc: 0.020 - ETA: 2s - loss: 4.8194 - acc: 0.020 - ETA: 2s - loss: 4.8195 - acc: 0.020 - ETA: 1s - loss: 4.8195 - acc: 0.020 - ETA: 1s - loss: 4.8197 - acc: 0.020 - ETA: 1s - loss: 4.8199 - acc: 0.020 - ETA: 1s - loss: 4.8200 - acc: 0.020 - ETA: 1s - loss: 4.8199 - acc: 0.020 - ETA: 1s - loss: 4.8198 - acc: 0.020 - ETA: 0s - loss: 4.8201 - acc: 0.020 - ETA: 0s - loss: 4.8202 - acc: 0.020 - ETA: 0s - loss: 4.8200 - acc: 0.020 - ETA: 0s - loss: 4.8201 - acc: 0.020 - ETA: 0s - loss: 4.8200 - acc: 0.020 - 75s 179ms/step - loss: 4.8201 - acc: 0.0208 - val_loss: 4.7916 - val_acc: 0.0269\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 4.78987\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/417 [==============>...............] - ETA: 55s - loss: 4.7978 - acc: 0.0000e+ - ETA: 54s - loss: 4.7718 - acc: 0.0000e+ - ETA: 53s - loss: 4.7703 - acc: 0.0417   - ETA: 53s - loss: 4.8092 - acc: 0.03 - ETA: 53s - loss: 4.8306 - acc: 0.02 - ETA: 53s - loss: 4.8295 - acc: 0.02 - ETA: 52s - loss: 4.8247 - acc: 0.01 - ETA: 52s - loss: 4.8193 - acc: 0.02 - ETA: 52s - loss: 4.8211 - acc: 0.02 - ETA: 52s - loss: 4.8211 - acc: 0.01 - ETA: 52s - loss: 4.8310 - acc: 0.01 - ETA: 51s - loss: 4.8287 - acc: 0.01 - ETA: 51s - loss: 4.8324 - acc: 0.01 - ETA: 51s - loss: 4.8392 - acc: 0.01 - ETA: 51s - loss: 4.8410 - acc: 0.01 - ETA: 50s - loss: 4.8332 - acc: 0.01 - ETA: 50s - loss: 4.8369 - acc: 0.01 - ETA: 50s - loss: 4.8366 - acc: 0.01 - ETA: 50s - loss: 4.8368 - acc: 0.01 - ETA: 50s - loss: 4.8390 - acc: 0.01 - ETA: 49s - loss: 4.8411 - acc: 0.01 - ETA: 49s - loss: 4.8405 - acc: 0.01 - ETA: 49s - loss: 4.8340 - acc: 0.01 - ETA: 49s - loss: 4.8289 - acc: 0.01 - ETA: 49s - loss: 4.8319 - acc: 0.01 - ETA: 49s - loss: 4.8326 - acc: 0.01 - ETA: 49s - loss: 4.8347 - acc: 0.01 - ETA: 48s - loss: 4.8293 - acc: 0.01 - ETA: 48s - loss: 4.8276 - acc: 0.01 - ETA: 48s - loss: 4.8273 - acc: 0.01 - ETA: 48s - loss: 4.8244 - acc: 0.01 - ETA: 48s - loss: 4.8271 - acc: 0.01 - ETA: 48s - loss: 4.8249 - acc: 0.01 - ETA: 48s - loss: 4.8229 - acc: 0.01 - ETA: 48s - loss: 4.8193 - acc: 0.01 - ETA: 48s - loss: 4.8217 - acc: 0.01 - ETA: 50s - loss: 4.8208 - acc: 0.01 - ETA: 49s - loss: 4.8258 - acc: 0.01 - ETA: 49s - loss: 4.8308 - acc: 0.01 - ETA: 50s - loss: 4.8306 - acc: 0.01 - ETA: 50s - loss: 4.8305 - acc: 0.01 - ETA: 50s - loss: 4.8271 - acc: 0.01 - ETA: 52s - loss: 4.8267 - acc: 0.01 - ETA: 52s - loss: 4.8236 - acc: 0.01 - ETA: 52s - loss: 4.8238 - acc: 0.01 - ETA: 52s - loss: 4.8233 - acc: 0.01 - ETA: 51s - loss: 4.8225 - acc: 0.01 - ETA: 52s - loss: 4.8209 - acc: 0.01 - ETA: 52s - loss: 4.8183 - acc: 0.01 - ETA: 52s - loss: 4.8186 - acc: 0.02 - ETA: 52s - loss: 4.8184 - acc: 0.01 - ETA: 54s - loss: 4.8177 - acc: 0.02 - ETA: 54s - loss: 4.8177 - acc: 0.02 - ETA: 54s - loss: 4.8194 - acc: 0.01 - ETA: 55s - loss: 4.8200 - acc: 0.01 - ETA: 55s - loss: 4.8195 - acc: 0.02 - ETA: 55s - loss: 4.8191 - acc: 0.01 - ETA: 55s - loss: 4.8187 - acc: 0.01 - ETA: 55s - loss: 4.8190 - acc: 0.01 - ETA: 55s - loss: 4.8199 - acc: 0.01 - ETA: 55s - loss: 4.8211 - acc: 0.01 - ETA: 54s - loss: 4.8200 - acc: 0.01 - ETA: 54s - loss: 4.8205 - acc: 0.01 - ETA: 54s - loss: 4.8206 - acc: 0.01 - ETA: 54s - loss: 4.8224 - acc: 0.01 - ETA: 54s - loss: 4.8249 - acc: 0.01 - ETA: 54s - loss: 4.8250 - acc: 0.01 - ETA: 54s - loss: 4.8246 - acc: 0.01 - ETA: 55s - loss: 4.8227 - acc: 0.01 - ETA: 54s - loss: 4.8223 - acc: 0.01 - ETA: 54s - loss: 4.8196 - acc: 0.02 - ETA: 54s - loss: 4.8203 - acc: 0.02 - ETA: 54s - loss: 4.8208 - acc: 0.02 - ETA: 54s - loss: 4.8212 - acc: 0.02 - ETA: 54s - loss: 4.8205 - acc: 0.02 - ETA: 54s - loss: 4.8202 - acc: 0.02 - ETA: 54s - loss: 4.8210 - acc: 0.02 - ETA: 53s - loss: 4.8205 - acc: 0.02 - ETA: 53s - loss: 4.8186 - acc: 0.02 - ETA: 53s - loss: 4.8183 - acc: 0.02 - ETA: 53s - loss: 4.8183 - acc: 0.02 - ETA: 53s - loss: 4.8206 - acc: 0.02 - ETA: 53s - loss: 4.8198 - acc: 0.02 - ETA: 52s - loss: 4.8204 - acc: 0.02 - ETA: 52s - loss: 4.8210 - acc: 0.02 - ETA: 52s - loss: 4.8214 - acc: 0.02 - ETA: 52s - loss: 4.8191 - acc: 0.02 - ETA: 52s - loss: 4.8193 - acc: 0.02 - ETA: 52s - loss: 4.8181 - acc: 0.02 - ETA: 52s - loss: 4.8183 - acc: 0.02 - ETA: 52s - loss: 4.8182 - acc: 0.02 - ETA: 52s - loss: 4.8183 - acc: 0.02 - ETA: 52s - loss: 4.8180 - acc: 0.02 - ETA: 51s - loss: 4.8177 - acc: 0.02 - ETA: 51s - loss: 4.8178 - acc: 0.02 - ETA: 51s - loss: 4.8182 - acc: 0.02 - ETA: 51s - loss: 4.8186 - acc: 0.02 - ETA: 51s - loss: 4.8176 - acc: 0.02 - ETA: 51s - loss: 4.8174 - acc: 0.02 - ETA: 51s - loss: 4.8173 - acc: 0.02 - ETA: 50s - loss: 4.8167 - acc: 0.02 - ETA: 50s - loss: 4.8175 - acc: 0.02 - ETA: 50s - loss: 4.8193 - acc: 0.02 - ETA: 50s - loss: 4.8201 - acc: 0.02 - ETA: 50s - loss: 4.8195 - acc: 0.02 - ETA: 50s - loss: 4.8212 - acc: 0.02 - ETA: 50s - loss: 4.8200 - acc: 0.02 - ETA: 50s - loss: 4.8189 - acc: 0.02 - ETA: 49s - loss: 4.8196 - acc: 0.02 - ETA: 49s - loss: 4.8193 - acc: 0.02 - ETA: 49s - loss: 4.8190 - acc: 0.02 - ETA: 49s - loss: 4.8191 - acc: 0.02 - ETA: 49s - loss: 4.8182 - acc: 0.02 - ETA: 49s - loss: 4.8176 - acc: 0.02 - ETA: 48s - loss: 4.8172 - acc: 0.02 - ETA: 48s - loss: 4.8172 - acc: 0.02 - ETA: 48s - loss: 4.8171 - acc: 0.02 - ETA: 48s - loss: 4.8162 - acc: 0.02 - ETA: 48s - loss: 4.8154 - acc: 0.02 - ETA: 48s - loss: 4.8156 - acc: 0.02 - ETA: 48s - loss: 4.8152 - acc: 0.02 - ETA: 47s - loss: 4.8150 - acc: 0.02 - ETA: 47s - loss: 4.8151 - acc: 0.02 - ETA: 47s - loss: 4.8141 - acc: 0.02 - ETA: 47s - loss: 4.8148 - acc: 0.02 - ETA: 47s - loss: 4.8144 - acc: 0.02 - ETA: 47s - loss: 4.8141 - acc: 0.02 - ETA: 47s - loss: 4.8145 - acc: 0.02 - ETA: 47s - loss: 4.8147 - acc: 0.02 - ETA: 46s - loss: 4.8140 - acc: 0.02 - ETA: 46s - loss: 4.8149 - acc: 0.02 - ETA: 46s - loss: 4.8155 - acc: 0.02 - ETA: 46s - loss: 4.8155 - acc: 0.02 - ETA: 46s - loss: 4.8141 - acc: 0.02 - ETA: 46s - loss: 4.8140 - acc: 0.01 - ETA: 46s - loss: 4.8145 - acc: 0.01 - ETA: 46s - loss: 4.8148 - acc: 0.02 - ETA: 45s - loss: 4.8154 - acc: 0.01 - ETA: 45s - loss: 4.8145 - acc: 0.02 - ETA: 45s - loss: 4.8152 - acc: 0.02 - ETA: 45s - loss: 4.8145 - acc: 0.01 - ETA: 45s - loss: 4.8154 - acc: 0.01 - ETA: 45s - loss: 4.8163 - acc: 0.01 - ETA: 45s - loss: 4.8167 - acc: 0.01 - ETA: 45s - loss: 4.8156 - acc: 0.01 - ETA: 45s - loss: 4.8156 - acc: 0.01 - ETA: 44s - loss: 4.8157 - acc: 0.01 - ETA: 44s - loss: 4.8153 - acc: 0.01 - ETA: 44s - loss: 4.8153 - acc: 0.01 - ETA: 44s - loss: 4.8149 - acc: 0.02 - ETA: 44s - loss: 4.8151 - acc: 0.02 - ETA: 43s - loss: 4.8153 - acc: 0.02 - ETA: 43s - loss: 4.8158 - acc: 0.02 - ETA: 43s - loss: 4.8165 - acc: 0.01 - ETA: 43s - loss: 4.8172 - acc: 0.01 - ETA: 43s - loss: 4.8170 - acc: 0.01 - ETA: 43s - loss: 4.8164 - acc: 0.01 - ETA: 43s - loss: 4.8165 - acc: 0.01 - ETA: 42s - loss: 4.8163 - acc: 0.02 - ETA: 42s - loss: 4.8163 - acc: 0.01 - ETA: 42s - loss: 4.8166 - acc: 0.01 - ETA: 42s - loss: 4.8171 - acc: 0.01 - ETA: 42s - loss: 4.8167 - acc: 0.01 - ETA: 42s - loss: 4.8160 - acc: 0.01 - ETA: 42s - loss: 4.8160 - acc: 0.01 - ETA: 42s - loss: 4.8156 - acc: 0.02 - ETA: 41s - loss: 4.8162 - acc: 0.01 - ETA: 41s - loss: 4.8169 - acc: 0.01 - ETA: 41s - loss: 4.8176 - acc: 0.01 - ETA: 41s - loss: 4.8181 - acc: 0.01 - ETA: 41s - loss: 4.8176 - acc: 0.02 - ETA: 41s - loss: 4.8176 - acc: 0.02 - ETA: 40s - loss: 4.8179 - acc: 0.01 - ETA: 40s - loss: 4.8187 - acc: 0.01 - ETA: 40s - loss: 4.8193 - acc: 0.01 - ETA: 40s - loss: 4.8190 - acc: 0.01 - ETA: 40s - loss: 4.8180 - acc: 0.02 - ETA: 40s - loss: 4.8189 - acc: 0.02 - ETA: 39s - loss: 4.8197 - acc: 0.02 - ETA: 39s - loss: 4.8199 - acc: 0.02 - ETA: 39s - loss: 4.8201 - acc: 0.02 - ETA: 39s - loss: 4.8201 - acc: 0.01 - ETA: 39s - loss: 4.8202 - acc: 0.01 - ETA: 39s - loss: 4.8205 - acc: 0.01 - ETA: 38s - loss: 4.8210 - acc: 0.01 - ETA: 38s - loss: 4.8206 - acc: 0.01 - ETA: 38s - loss: 4.8210 - acc: 0.01 - ETA: 38s - loss: 4.8214 - acc: 0.01 - ETA: 38s - loss: 4.8218 - acc: 0.01 - ETA: 38s - loss: 4.8221 - acc: 0.01 - ETA: 37s - loss: 4.8230 - acc: 0.01 - ETA: 37s - loss: 4.8227 - acc: 0.01 - ETA: 37s - loss: 4.8231 - acc: 0.01 - ETA: 37s - loss: 4.8224 - acc: 0.01 - ETA: 37s - loss: 4.8223 - acc: 0.01 - ETA: 37s - loss: 4.8221 - acc: 0.01 - ETA: 36s - loss: 4.8223 - acc: 0.01 - ETA: 36s - loss: 4.8227 - acc: 0.01 - ETA: 36s - loss: 4.8221 - acc: 0.01 - ETA: 36s - loss: 4.8222 - acc: 0.01 - ETA: 36s - loss: 4.8215 - acc: 0.01 - ETA: 36s - loss: 4.8217 - acc: 0.01 - ETA: 36s - loss: 4.8215 - acc: 0.01 - ETA: 35s - loss: 4.8211 - acc: 0.01 - ETA: 35s - loss: 4.8212 - acc: 0.01 - ETA: 35s - loss: 4.8212 - acc: 0.01 - ETA: 35s - loss: 4.8207 - acc: 0.01 - ETA: 35s - loss: 4.8210 - acc: 0.01 - ETA: 34s - loss: 4.8217 - acc: 0.01 - ETA: 34s - loss: 4.8209 - acc: 0.01 - ETA: 34s - loss: 4.8209 - acc: 0.01 - ETA: 34s - loss: 4.8212 - acc: 0.01 - ETA: 34s - loss: 4.8209 - acc: 0.01 - ETA: 34s - loss: 4.8209 - acc: 0.01 - ETA: 33s - loss: 4.8213 - acc: 0.0189"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 33s - loss: 4.8207 - acc: 0.01 - ETA: 33s - loss: 4.8210 - acc: 0.01 - ETA: 33s - loss: 4.8212 - acc: 0.01 - ETA: 33s - loss: 4.8211 - acc: 0.01 - ETA: 33s - loss: 4.8213 - acc: 0.01 - ETA: 32s - loss: 4.8205 - acc: 0.01 - ETA: 32s - loss: 4.8197 - acc: 0.01 - ETA: 32s - loss: 4.8202 - acc: 0.01 - ETA: 32s - loss: 4.8197 - acc: 0.01 - ETA: 32s - loss: 4.8193 - acc: 0.01 - ETA: 31s - loss: 4.8193 - acc: 0.01 - ETA: 31s - loss: 4.8188 - acc: 0.01 - ETA: 31s - loss: 4.8185 - acc: 0.01 - ETA: 31s - loss: 4.8179 - acc: 0.01 - ETA: 31s - loss: 4.8175 - acc: 0.01 - ETA: 31s - loss: 4.8172 - acc: 0.01 - ETA: 30s - loss: 4.8173 - acc: 0.01 - ETA: 30s - loss: 4.8174 - acc: 0.01 - ETA: 30s - loss: 4.8182 - acc: 0.01 - ETA: 30s - loss: 4.8179 - acc: 0.01 - ETA: 30s - loss: 4.8180 - acc: 0.01 - ETA: 30s - loss: 4.8178 - acc: 0.01 - ETA: 29s - loss: 4.8174 - acc: 0.01 - ETA: 29s - loss: 4.8177 - acc: 0.01 - ETA: 29s - loss: 4.8176 - acc: 0.01 - ETA: 29s - loss: 4.8175 - acc: 0.01 - ETA: 29s - loss: 4.8176 - acc: 0.01 - ETA: 29s - loss: 4.8175 - acc: 0.01 - ETA: 28s - loss: 4.8176 - acc: 0.01 - ETA: 28s - loss: 4.8176 - acc: 0.01 - ETA: 28s - loss: 4.8167 - acc: 0.01 - ETA: 28s - loss: 4.8170 - acc: 0.01 - ETA: 28s - loss: 4.8173 - acc: 0.01 - ETA: 28s - loss: 4.8175 - acc: 0.01 - ETA: 27s - loss: 4.8171 - acc: 0.01 - ETA: 27s - loss: 4.8171 - acc: 0.01 - ETA: 27s - loss: 4.8170 - acc: 0.01 - ETA: 27s - loss: 4.8165 - acc: 0.01 - ETA: 27s - loss: 4.8160 - acc: 0.01 - ETA: 26s - loss: 4.8158 - acc: 0.01 - ETA: 26s - loss: 4.8160 - acc: 0.01 - ETA: 26s - loss: 4.8158 - acc: 0.01 - ETA: 26s - loss: 4.8156 - acc: 0.01 - ETA: 26s - loss: 4.8158 - acc: 0.01 - ETA: 26s - loss: 4.8164 - acc: 0.01 - ETA: 25s - loss: 4.8168 - acc: 0.01 - ETA: 25s - loss: 4.8172 - acc: 0.01 - ETA: 25s - loss: 4.8169 - acc: 0.01 - ETA: 25s - loss: 4.8171 - acc: 0.01 - ETA: 25s - loss: 4.8175 - acc: 0.01 - ETA: 25s - loss: 4.8173 - acc: 0.01 - ETA: 24s - loss: 4.8177 - acc: 0.01 - ETA: 24s - loss: 4.8181 - acc: 0.01 - ETA: 24s - loss: 4.8181 - acc: 0.01 - ETA: 24s - loss: 4.8182 - acc: 0.01 - ETA: 24s - loss: 4.8183 - acc: 0.01 - ETA: 23s - loss: 4.8181 - acc: 0.01 - ETA: 23s - loss: 4.8179 - acc: 0.01 - ETA: 23s - loss: 4.8176 - acc: 0.01 - ETA: 23s - loss: 4.8169 - acc: 0.01 - ETA: 23s - loss: 4.8171 - acc: 0.01 - ETA: 23s - loss: 4.8172 - acc: 0.01 - ETA: 22s - loss: 4.8166 - acc: 0.01 - ETA: 22s - loss: 4.8163 - acc: 0.01 - ETA: 22s - loss: 4.8164 - acc: 0.01 - ETA: 22s - loss: 4.8166 - acc: 0.01 - ETA: 22s - loss: 4.8165 - acc: 0.01 - ETA: 22s - loss: 4.8165 - acc: 0.01 - ETA: 21s - loss: 4.8163 - acc: 0.01 - ETA: 21s - loss: 4.8164 - acc: 0.01 - ETA: 21s - loss: 4.8169 - acc: 0.01 - ETA: 21s - loss: 4.8169 - acc: 0.01 - ETA: 21s - loss: 4.8168 - acc: 0.01 - ETA: 21s - loss: 4.8167 - acc: 0.01 - ETA: 20s - loss: 4.8168 - acc: 0.01 - ETA: 20s - loss: 4.8178 - acc: 0.01 - ETA: 20s - loss: 4.8185 - acc: 0.01 - ETA: 20s - loss: 4.8179 - acc: 0.01 - ETA: 20s - loss: 4.8175 - acc: 0.01 - ETA: 19s - loss: 4.8179 - acc: 0.01 - ETA: 19s - loss: 4.8183 - acc: 0.01 - ETA: 19s - loss: 4.8183 - acc: 0.01 - ETA: 19s - loss: 4.8189 - acc: 0.01 - ETA: 19s - loss: 4.8194 - acc: 0.01 - ETA: 19s - loss: 4.8192 - acc: 0.01 - ETA: 18s - loss: 4.8185 - acc: 0.01 - ETA: 18s - loss: 4.8187 - acc: 0.01 - ETA: 18s - loss: 4.8183 - acc: 0.01 - ETA: 18s - loss: 4.8185 - acc: 0.01 - ETA: 18s - loss: 4.8185 - acc: 0.01 - ETA: 18s - loss: 4.8184 - acc: 0.01 - ETA: 17s - loss: 4.8186 - acc: 0.01 - ETA: 17s - loss: 4.8185 - acc: 0.01 - ETA: 17s - loss: 4.8180 - acc: 0.01 - ETA: 17s - loss: 4.8175 - acc: 0.01 - ETA: 17s - loss: 4.8173 - acc: 0.02 - ETA: 17s - loss: 4.8176 - acc: 0.02 - ETA: 16s - loss: 4.8176 - acc: 0.02 - ETA: 16s - loss: 4.8177 - acc: 0.02 - ETA: 16s - loss: 4.8178 - acc: 0.02 - ETA: 16s - loss: 4.8180 - acc: 0.02 - ETA: 16s - loss: 4.8176 - acc: 0.02 - ETA: 16s - loss: 4.8174 - acc: 0.02 - ETA: 15s - loss: 4.8175 - acc: 0.01 - ETA: 15s - loss: 4.8172 - acc: 0.01 - ETA: 15s - loss: 4.8170 - acc: 0.01 - ETA: 15s - loss: 4.8171 - acc: 0.01 - ETA: 15s - loss: 4.8169 - acc: 0.01 - ETA: 15s - loss: 4.8167 - acc: 0.02 - ETA: 14s - loss: 4.8169 - acc: 0.02 - ETA: 14s - loss: 4.8166 - acc: 0.02 - ETA: 14s - loss: 4.8165 - acc: 0.02 - ETA: 14s - loss: 4.8170 - acc: 0.02 - ETA: 14s - loss: 4.8169 - acc: 0.02 - ETA: 14s - loss: 4.8168 - acc: 0.02 - ETA: 13s - loss: 4.8166 - acc: 0.02 - ETA: 13s - loss: 4.8168 - acc: 0.01 - ETA: 13s - loss: 4.8165 - acc: 0.01 - ETA: 13s - loss: 4.8171 - acc: 0.01 - ETA: 13s - loss: 4.8178 - acc: 0.01 - ETA: 13s - loss: 4.8178 - acc: 0.02 - ETA: 12s - loss: 4.8175 - acc: 0.02 - ETA: 12s - loss: 4.8175 - acc: 0.02 - ETA: 12s - loss: 4.8176 - acc: 0.02 - ETA: 12s - loss: 4.8177 - acc: 0.02 - ETA: 12s - loss: 4.8179 - acc: 0.01 - ETA: 12s - loss: 4.8178 - acc: 0.01 - ETA: 11s - loss: 4.8176 - acc: 0.01 - ETA: 11s - loss: 4.8180 - acc: 0.01 - ETA: 11s - loss: 4.8181 - acc: 0.01 - ETA: 11s - loss: 4.8181 - acc: 0.02 - ETA: 11s - loss: 4.8180 - acc: 0.02 - ETA: 11s - loss: 4.8173 - acc: 0.02 - ETA: 11s - loss: 4.8175 - acc: 0.02 - ETA: 10s - loss: 4.8175 - acc: 0.02 - ETA: 10s - loss: 4.8174 - acc: 0.02 - ETA: 10s - loss: 4.8173 - acc: 0.02 - ETA: 10s - loss: 4.8174 - acc: 0.02 - ETA: 10s - loss: 4.8175 - acc: 0.02 - ETA: 9s - loss: 4.8174 - acc: 0.0202 - ETA: 9s - loss: 4.8173 - acc: 0.020 - ETA: 9s - loss: 4.8168 - acc: 0.020 - ETA: 9s - loss: 4.8166 - acc: 0.020 - ETA: 9s - loss: 4.8169 - acc: 0.020 - ETA: 9s - loss: 4.8170 - acc: 0.020 - ETA: 8s - loss: 4.8174 - acc: 0.020 - ETA: 8s - loss: 4.8175 - acc: 0.020 - ETA: 8s - loss: 4.8171 - acc: 0.020 - ETA: 8s - loss: 4.8174 - acc: 0.020 - ETA: 8s - loss: 4.8174 - acc: 0.020 - ETA: 8s - loss: 4.8175 - acc: 0.020 - ETA: 8s - loss: 4.8176 - acc: 0.020 - ETA: 7s - loss: 4.8180 - acc: 0.020 - ETA: 7s - loss: 4.8179 - acc: 0.020 - ETA: 7s - loss: 4.8178 - acc: 0.020 - ETA: 7s - loss: 4.8176 - acc: 0.020 - ETA: 7s - loss: 4.8179 - acc: 0.020 - ETA: 7s - loss: 4.8183 - acc: 0.020 - ETA: 6s - loss: 4.8183 - acc: 0.020 - ETA: 6s - loss: 4.8185 - acc: 0.019 - ETA: 6s - loss: 4.8183 - acc: 0.019 - ETA: 6s - loss: 4.8179 - acc: 0.019 - ETA: 6s - loss: 4.8180 - acc: 0.019 - ETA: 6s - loss: 4.8174 - acc: 0.019 - ETA: 5s - loss: 4.8174 - acc: 0.020 - ETA: 5s - loss: 4.8174 - acc: 0.020 - ETA: 5s - loss: 4.8175 - acc: 0.019 - ETA: 5s - loss: 4.8176 - acc: 0.019 - ETA: 5s - loss: 4.8177 - acc: 0.019 - ETA: 5s - loss: 4.8177 - acc: 0.019 - ETA: 4s - loss: 4.8176 - acc: 0.020 - ETA: 4s - loss: 4.8175 - acc: 0.020 - ETA: 4s - loss: 4.8175 - acc: 0.019 - ETA: 4s - loss: 4.8174 - acc: 0.019 - ETA: 4s - loss: 4.8175 - acc: 0.019 - ETA: 4s - loss: 4.8176 - acc: 0.019 - ETA: 3s - loss: 4.8181 - acc: 0.019 - ETA: 3s - loss: 4.8181 - acc: 0.019 - ETA: 3s - loss: 4.8179 - acc: 0.019 - ETA: 3s - loss: 4.8181 - acc: 0.019 - ETA: 3s - loss: 4.8180 - acc: 0.019 - ETA: 3s - loss: 4.8183 - acc: 0.019 - ETA: 2s - loss: 4.8182 - acc: 0.019 - ETA: 2s - loss: 4.8182 - acc: 0.019 - ETA: 2s - loss: 4.8182 - acc: 0.019 - ETA: 2s - loss: 4.8181 - acc: 0.019 - ETA: 2s - loss: 4.8180 - acc: 0.019 - ETA: 2s - loss: 4.8181 - acc: 0.019 - ETA: 1s - loss: 4.8183 - acc: 0.019 - ETA: 1s - loss: 4.8184 - acc: 0.019 - ETA: 1s - loss: 4.8184 - acc: 0.019 - ETA: 1s - loss: 4.8187 - acc: 0.019 - ETA: 1s - loss: 4.8188 - acc: 0.019 - ETA: 1s - loss: 4.8189 - acc: 0.019 - ETA: 0s - loss: 4.8188 - acc: 0.019 - ETA: 0s - loss: 4.8188 - acc: 0.019 - ETA: 0s - loss: 4.8189 - acc: 0.019 - ETA: 0s - loss: 4.8190 - acc: 0.019 - ETA: 0s - loss: 4.8189 - acc: 0.020 - ETA: 0s - loss: 4.8194 - acc: 0.020 - 71s 170ms/step - loss: 4.8191 - acc: 0.0201 - val_loss: 4.8002 - val_acc: 0.0379\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 4.78987\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/417 [===============>..............] - ETA: 5s - loss: 4.8539 - acc: 0.0000e+0 - ETA: 6s - loss: 4.7791 - acc: 0.0125    - ETA: 6s - loss: 4.7917 - acc: 0.006 - ETA: 8s - loss: 4.7657 - acc: 0.010 - ETA: 11s - loss: 4.7808 - acc: 0.00 - ETA: 15s - loss: 4.7835 - acc: 0.00 - ETA: 17s - loss: 4.7870 - acc: 0.00 - ETA: 21s - loss: 4.7919 - acc: 0.00 - ETA: 24s - loss: 4.8024 - acc: 0.00 - ETA: 27s - loss: 4.8044 - acc: 0.00 - ETA: 28s - loss: 4.7955 - acc: 0.00 - ETA: 30s - loss: 4.8043 - acc: 0.00 - ETA: 31s - loss: 4.8085 - acc: 0.01 - ETA: 32s - loss: 4.8047 - acc: 0.01 - ETA: 33s - loss: 4.8042 - acc: 0.01 - ETA: 35s - loss: 4.8077 - acc: 0.01 - ETA: 36s - loss: 4.8082 - acc: 0.01 - ETA: 37s - loss: 4.8054 - acc: 0.01 - ETA: 37s - loss: 4.8066 - acc: 0.01 - ETA: 37s - loss: 4.8068 - acc: 0.01 - ETA: 38s - loss: 4.8085 - acc: 0.01 - ETA: 39s - loss: 4.8068 - acc: 0.01 - ETA: 39s - loss: 4.8075 - acc: 0.01 - ETA: 40s - loss: 4.8118 - acc: 0.01 - ETA: 40s - loss: 4.8076 - acc: 0.01 - ETA: 41s - loss: 4.8096 - acc: 0.01 - ETA: 41s - loss: 4.8115 - acc: 0.01 - ETA: 41s - loss: 4.8083 - acc: 0.01 - ETA: 42s - loss: 4.8074 - acc: 0.01 - ETA: 42s - loss: 4.8061 - acc: 0.01 - ETA: 42s - loss: 4.8033 - acc: 0.01 - ETA: 45s - loss: 4.8046 - acc: 0.01 - ETA: 45s - loss: 4.8037 - acc: 0.01 - ETA: 45s - loss: 4.8017 - acc: 0.01 - ETA: 46s - loss: 4.7990 - acc: 0.01 - ETA: 46s - loss: 4.7985 - acc: 0.01 - ETA: 46s - loss: 4.7982 - acc: 0.01 - ETA: 46s - loss: 4.7999 - acc: 0.01 - ETA: 46s - loss: 4.7977 - acc: 0.01 - ETA: 45s - loss: 4.7908 - acc: 0.01 - ETA: 45s - loss: 4.7940 - acc: 0.01 - ETA: 45s - loss: 4.7937 - acc: 0.01 - ETA: 45s - loss: 4.7929 - acc: 0.01 - ETA: 45s - loss: 4.7871 - acc: 0.01 - ETA: 45s - loss: 4.7860 - acc: 0.01 - ETA: 45s - loss: 4.7884 - acc: 0.01 - ETA: 45s - loss: 4.7854 - acc: 0.01 - ETA: 45s - loss: 4.7837 - acc: 0.02 - ETA: 45s - loss: 4.7824 - acc: 0.02 - ETA: 46s - loss: 4.7833 - acc: 0.02 - ETA: 46s - loss: 4.7845 - acc: 0.02 - ETA: 47s - loss: 4.7847 - acc: 0.01 - ETA: 46s - loss: 4.7864 - acc: 0.01 - ETA: 47s - loss: 4.7868 - acc: 0.01 - ETA: 47s - loss: 4.7863 - acc: 0.01 - ETA: 47s - loss: 4.7834 - acc: 0.01 - ETA: 47s - loss: 4.7838 - acc: 0.01 - ETA: 47s - loss: 4.7838 - acc: 0.02 - ETA: 47s - loss: 4.7821 - acc: 0.02 - ETA: 47s - loss: 4.7811 - acc: 0.02 - ETA: 47s - loss: 4.7823 - acc: 0.02 - ETA: 47s - loss: 4.7822 - acc: 0.02 - ETA: 47s - loss: 4.7837 - acc: 0.02 - ETA: 47s - loss: 4.7847 - acc: 0.02 - ETA: 47s - loss: 4.7857 - acc: 0.02 - ETA: 47s - loss: 4.7869 - acc: 0.02 - ETA: 47s - loss: 4.7871 - acc: 0.02 - ETA: 47s - loss: 4.7885 - acc: 0.02 - ETA: 47s - loss: 4.7899 - acc: 0.02 - ETA: 47s - loss: 4.7920 - acc: 0.02 - ETA: 47s - loss: 4.7918 - acc: 0.02 - ETA: 47s - loss: 4.7926 - acc: 0.02 - ETA: 47s - loss: 4.7941 - acc: 0.02 - ETA: 47s - loss: 4.7964 - acc: 0.02 - ETA: 46s - loss: 4.7964 - acc: 0.02 - ETA: 46s - loss: 4.7982 - acc: 0.02 - ETA: 46s - loss: 4.7965 - acc: 0.02 - ETA: 46s - loss: 4.7972 - acc: 0.02 - ETA: 46s - loss: 4.7973 - acc: 0.02 - ETA: 46s - loss: 4.7973 - acc: 0.02 - ETA: 46s - loss: 4.7967 - acc: 0.02 - ETA: 46s - loss: 4.7974 - acc: 0.02 - ETA: 46s - loss: 4.7963 - acc: 0.01 - ETA: 46s - loss: 4.7944 - acc: 0.02 - ETA: 46s - loss: 4.7931 - acc: 0.02 - ETA: 46s - loss: 4.7934 - acc: 0.02 - ETA: 45s - loss: 4.7940 - acc: 0.02 - ETA: 45s - loss: 4.7944 - acc: 0.02 - ETA: 45s - loss: 4.7955 - acc: 0.02 - ETA: 45s - loss: 4.7960 - acc: 0.02 - ETA: 45s - loss: 4.7974 - acc: 0.02 - ETA: 45s - loss: 4.7961 - acc: 0.02 - ETA: 45s - loss: 4.7957 - acc: 0.02 - ETA: 45s - loss: 4.7958 - acc: 0.02 - ETA: 45s - loss: 4.7940 - acc: 0.02 - ETA: 45s - loss: 4.7941 - acc: 0.02 - ETA: 45s - loss: 4.7933 - acc: 0.02 - ETA: 45s - loss: 4.7929 - acc: 0.02 - ETA: 45s - loss: 4.7942 - acc: 0.02 - ETA: 45s - loss: 4.7960 - acc: 0.02 - ETA: 45s - loss: 4.7961 - acc: 0.02 - ETA: 45s - loss: 4.7950 - acc: 0.02 - ETA: 45s - loss: 4.7957 - acc: 0.02 - ETA: 45s - loss: 4.7960 - acc: 0.02 - ETA: 45s - loss: 4.7965 - acc: 0.02 - ETA: 44s - loss: 4.7959 - acc: 0.02 - ETA: 44s - loss: 4.7954 - acc: 0.02 - ETA: 44s - loss: 4.7951 - acc: 0.02 - ETA: 44s - loss: 4.7947 - acc: 0.02 - ETA: 44s - loss: 4.7930 - acc: 0.02 - ETA: 43s - loss: 4.7921 - acc: 0.02 - ETA: 43s - loss: 4.7931 - acc: 0.02 - ETA: 43s - loss: 4.7932 - acc: 0.02 - ETA: 43s - loss: 4.7906 - acc: 0.02 - ETA: 43s - loss: 4.7907 - acc: 0.02 - ETA: 43s - loss: 4.7909 - acc: 0.02 - ETA: 43s - loss: 4.7918 - acc: 0.02 - ETA: 43s - loss: 4.7919 - acc: 0.01 - ETA: 43s - loss: 4.7914 - acc: 0.01 - ETA: 43s - loss: 4.7925 - acc: 0.02 - ETA: 43s - loss: 4.7938 - acc: 0.01 - ETA: 42s - loss: 4.7930 - acc: 0.02 - ETA: 42s - loss: 4.7933 - acc: 0.02 - ETA: 42s - loss: 4.7940 - acc: 0.02 - ETA: 42s - loss: 4.7935 - acc: 0.02 - ETA: 42s - loss: 4.7936 - acc: 0.02 - ETA: 42s - loss: 4.7944 - acc: 0.02 - ETA: 42s - loss: 4.7945 - acc: 0.02 - ETA: 42s - loss: 4.7948 - acc: 0.02 - ETA: 41s - loss: 4.7954 - acc: 0.02 - ETA: 41s - loss: 4.7955 - acc: 0.02 - ETA: 41s - loss: 4.7948 - acc: 0.02 - ETA: 41s - loss: 4.7950 - acc: 0.02 - ETA: 41s - loss: 4.7960 - acc: 0.02 - ETA: 40s - loss: 4.7956 - acc: 0.02 - ETA: 40s - loss: 4.7944 - acc: 0.02 - ETA: 40s - loss: 4.7955 - acc: 0.02 - ETA: 40s - loss: 4.7958 - acc: 0.02 - ETA: 40s - loss: 4.7967 - acc: 0.02 - ETA: 40s - loss: 4.7963 - acc: 0.01 - ETA: 39s - loss: 4.7966 - acc: 0.01 - ETA: 39s - loss: 4.7955 - acc: 0.01 - ETA: 39s - loss: 4.7957 - acc: 0.01 - ETA: 39s - loss: 4.7961 - acc: 0.01 - ETA: 39s - loss: 4.7969 - acc: 0.01 - ETA: 39s - loss: 4.7963 - acc: 0.01 - ETA: 39s - loss: 4.7964 - acc: 0.01 - ETA: 39s - loss: 4.7953 - acc: 0.01 - ETA: 38s - loss: 4.7953 - acc: 0.01 - ETA: 38s - loss: 4.7959 - acc: 0.01 - ETA: 38s - loss: 4.7952 - acc: 0.01 - ETA: 38s - loss: 4.7961 - acc: 0.01 - ETA: 38s - loss: 4.7961 - acc: 0.01 - ETA: 38s - loss: 4.7963 - acc: 0.01 - ETA: 37s - loss: 4.7971 - acc: 0.01 - ETA: 37s - loss: 4.7963 - acc: 0.01 - ETA: 37s - loss: 4.7963 - acc: 0.01 - ETA: 37s - loss: 4.7961 - acc: 0.01 - ETA: 37s - loss: 4.7964 - acc: 0.01 - ETA: 37s - loss: 4.7963 - acc: 0.01 - ETA: 36s - loss: 4.7966 - acc: 0.01 - ETA: 36s - loss: 4.7977 - acc: 0.01 - ETA: 36s - loss: 4.7983 - acc: 0.01 - ETA: 36s - loss: 4.7989 - acc: 0.01 - ETA: 36s - loss: 4.7991 - acc: 0.01 - ETA: 36s - loss: 4.7997 - acc: 0.01 - ETA: 36s - loss: 4.8000 - acc: 0.01 - ETA: 36s - loss: 4.8003 - acc: 0.01 - ETA: 36s - loss: 4.8006 - acc: 0.01 - ETA: 35s - loss: 4.8003 - acc: 0.01 - ETA: 35s - loss: 4.8012 - acc: 0.01 - ETA: 35s - loss: 4.8021 - acc: 0.01 - ETA: 35s - loss: 4.8017 - acc: 0.01 - ETA: 35s - loss: 4.8021 - acc: 0.01 - ETA: 35s - loss: 4.8029 - acc: 0.01 - ETA: 34s - loss: 4.8030 - acc: 0.01 - ETA: 34s - loss: 4.8020 - acc: 0.01 - ETA: 34s - loss: 4.8023 - acc: 0.01 - ETA: 34s - loss: 4.8026 - acc: 0.01 - ETA: 34s - loss: 4.8030 - acc: 0.01 - ETA: 33s - loss: 4.8030 - acc: 0.01 - ETA: 33s - loss: 4.8034 - acc: 0.01 - ETA: 33s - loss: 4.8037 - acc: 0.01 - ETA: 33s - loss: 4.8026 - acc: 0.01 - ETA: 33s - loss: 4.8029 - acc: 0.01 - ETA: 33s - loss: 4.8022 - acc: 0.01 - ETA: 33s - loss: 4.8025 - acc: 0.01 - ETA: 32s - loss: 4.8027 - acc: 0.01 - ETA: 32s - loss: 4.8027 - acc: 0.01 - ETA: 32s - loss: 4.8030 - acc: 0.01 - ETA: 32s - loss: 4.8028 - acc: 0.01 - ETA: 32s - loss: 4.8025 - acc: 0.01 - ETA: 32s - loss: 4.8033 - acc: 0.01 - ETA: 32s - loss: 4.8031 - acc: 0.01 - ETA: 31s - loss: 4.8035 - acc: 0.01 - ETA: 31s - loss: 4.8039 - acc: 0.01 - ETA: 31s - loss: 4.8040 - acc: 0.01 - ETA: 31s - loss: 4.8037 - acc: 0.01 - ETA: 31s - loss: 4.8034 - acc: 0.01 - ETA: 31s - loss: 4.8029 - acc: 0.01 - ETA: 31s - loss: 4.8030 - acc: 0.01 - ETA: 30s - loss: 4.8037 - acc: 0.01 - ETA: 30s - loss: 4.8033 - acc: 0.01 - ETA: 30s - loss: 4.8031 - acc: 0.01 - ETA: 30s - loss: 4.8037 - acc: 0.01 - ETA: 30s - loss: 4.8040 - acc: 0.01 - ETA: 30s - loss: 4.8047 - acc: 0.01 - ETA: 29s - loss: 4.8062 - acc: 0.01 - ETA: 29s - loss: 4.8062 - acc: 0.01 - ETA: 29s - loss: 4.8062 - acc: 0.01 - ETA: 29s - loss: 4.8059 - acc: 0.01 - ETA: 29s - loss: 4.8060 - acc: 0.01 - ETA: 28s - loss: 4.8067 - acc: 0.01 - ETA: 28s - loss: 4.8067 - acc: 0.01 - ETA: 28s - loss: 4.8062 - acc: 0.0192"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8069 - acc: 0.01 - ETA: 28s - loss: 4.8071 - acc: 0.01 - ETA: 28s - loss: 4.8073 - acc: 0.01 - ETA: 28s - loss: 4.8073 - acc: 0.01 - ETA: 27s - loss: 4.8066 - acc: 0.01 - ETA: 27s - loss: 4.8067 - acc: 0.01 - ETA: 27s - loss: 4.8068 - acc: 0.01 - ETA: 27s - loss: 4.8070 - acc: 0.01 - ETA: 27s - loss: 4.8068 - acc: 0.01 - ETA: 27s - loss: 4.8068 - acc: 0.01 - ETA: 27s - loss: 4.8062 - acc: 0.01 - ETA: 26s - loss: 4.8071 - acc: 0.01 - ETA: 26s - loss: 4.8075 - acc: 0.01 - ETA: 26s - loss: 4.8080 - acc: 0.01 - ETA: 26s - loss: 4.8080 - acc: 0.01 - ETA: 26s - loss: 4.8083 - acc: 0.01 - ETA: 26s - loss: 4.8086 - acc: 0.01 - ETA: 26s - loss: 4.8092 - acc: 0.01 - ETA: 25s - loss: 4.8093 - acc: 0.01 - ETA: 25s - loss: 4.8094 - acc: 0.01 - ETA: 25s - loss: 4.8093 - acc: 0.01 - ETA: 25s - loss: 4.8095 - acc: 0.01 - ETA: 25s - loss: 4.8095 - acc: 0.01 - ETA: 25s - loss: 4.8093 - acc: 0.01 - ETA: 25s - loss: 4.8088 - acc: 0.01 - ETA: 24s - loss: 4.8080 - acc: 0.01 - ETA: 24s - loss: 4.8079 - acc: 0.01 - ETA: 24s - loss: 4.8073 - acc: 0.01 - ETA: 24s - loss: 4.8071 - acc: 0.01 - ETA: 24s - loss: 4.8067 - acc: 0.01 - ETA: 24s - loss: 4.8069 - acc: 0.01 - ETA: 24s - loss: 4.8071 - acc: 0.01 - ETA: 23s - loss: 4.8071 - acc: 0.01 - ETA: 23s - loss: 4.8077 - acc: 0.01 - ETA: 23s - loss: 4.8071 - acc: 0.01 - ETA: 23s - loss: 4.8080 - acc: 0.01 - ETA: 23s - loss: 4.8077 - acc: 0.01 - ETA: 23s - loss: 4.8081 - acc: 0.01 - ETA: 23s - loss: 4.8086 - acc: 0.01 - ETA: 22s - loss: 4.8084 - acc: 0.01 - ETA: 22s - loss: 4.8080 - acc: 0.01 - ETA: 22s - loss: 4.8077 - acc: 0.01 - ETA: 22s - loss: 4.8079 - acc: 0.01 - ETA: 22s - loss: 4.8080 - acc: 0.01 - ETA: 22s - loss: 4.8082 - acc: 0.01 - ETA: 22s - loss: 4.8082 - acc: 0.01 - ETA: 21s - loss: 4.8079 - acc: 0.01 - ETA: 21s - loss: 4.8078 - acc: 0.01 - ETA: 21s - loss: 4.8077 - acc: 0.01 - ETA: 21s - loss: 4.8081 - acc: 0.02 - ETA: 21s - loss: 4.8076 - acc: 0.02 - ETA: 21s - loss: 4.8075 - acc: 0.02 - ETA: 21s - loss: 4.8079 - acc: 0.02 - ETA: 21s - loss: 4.8077 - acc: 0.02 - ETA: 20s - loss: 4.8076 - acc: 0.02 - ETA: 20s - loss: 4.8072 - acc: 0.02 - ETA: 20s - loss: 4.8072 - acc: 0.02 - ETA: 20s - loss: 4.8066 - acc: 0.02 - ETA: 20s - loss: 4.8063 - acc: 0.02 - ETA: 20s - loss: 4.8062 - acc: 0.02 - ETA: 19s - loss: 4.8059 - acc: 0.02 - ETA: 19s - loss: 4.8057 - acc: 0.02 - ETA: 19s - loss: 4.8055 - acc: 0.02 - ETA: 19s - loss: 4.8057 - acc: 0.02 - ETA: 19s - loss: 4.8055 - acc: 0.02 - ETA: 19s - loss: 4.8053 - acc: 0.02 - ETA: 19s - loss: 4.8053 - acc: 0.02 - ETA: 18s - loss: 4.8053 - acc: 0.02 - ETA: 18s - loss: 4.8057 - acc: 0.02 - ETA: 18s - loss: 4.8058 - acc: 0.02 - ETA: 18s - loss: 4.8050 - acc: 0.02 - ETA: 18s - loss: 4.8044 - acc: 0.02 - ETA: 18s - loss: 4.8044 - acc: 0.02 - ETA: 17s - loss: 4.8042 - acc: 0.02 - ETA: 17s - loss: 4.8046 - acc: 0.02 - ETA: 17s - loss: 4.8048 - acc: 0.02 - ETA: 17s - loss: 4.8053 - acc: 0.02 - ETA: 17s - loss: 4.8051 - acc: 0.02 - ETA: 17s - loss: 4.8053 - acc: 0.02 - ETA: 17s - loss: 4.8051 - acc: 0.02 - ETA: 16s - loss: 4.8051 - acc: 0.02 - ETA: 16s - loss: 4.8051 - acc: 0.02 - ETA: 16s - loss: 4.8055 - acc: 0.02 - ETA: 16s - loss: 4.8053 - acc: 0.02 - ETA: 16s - loss: 4.8055 - acc: 0.02 - ETA: 16s - loss: 4.8050 - acc: 0.02 - ETA: 16s - loss: 4.8054 - acc: 0.02 - ETA: 15s - loss: 4.8054 - acc: 0.02 - ETA: 15s - loss: 4.8057 - acc: 0.02 - ETA: 15s - loss: 4.8050 - acc: 0.02 - ETA: 15s - loss: 4.8050 - acc: 0.02 - ETA: 15s - loss: 4.8046 - acc: 0.02 - ETA: 15s - loss: 4.8042 - acc: 0.02 - ETA: 15s - loss: 4.8042 - acc: 0.02 - ETA: 14s - loss: 4.8043 - acc: 0.02 - ETA: 14s - loss: 4.8048 - acc: 0.02 - ETA: 14s - loss: 4.8048 - acc: 0.02 - ETA: 14s - loss: 4.8052 - acc: 0.02 - ETA: 14s - loss: 4.8052 - acc: 0.02 - ETA: 14s - loss: 4.8053 - acc: 0.02 - ETA: 13s - loss: 4.8056 - acc: 0.02 - ETA: 13s - loss: 4.8058 - acc: 0.02 - ETA: 13s - loss: 4.8056 - acc: 0.02 - ETA: 13s - loss: 4.8054 - acc: 0.02 - ETA: 13s - loss: 4.8055 - acc: 0.02 - ETA: 13s - loss: 4.8059 - acc: 0.02 - ETA: 13s - loss: 4.8060 - acc: 0.02 - ETA: 12s - loss: 4.8058 - acc: 0.02 - ETA: 12s - loss: 4.8059 - acc: 0.02 - ETA: 12s - loss: 4.8062 - acc: 0.02 - ETA: 12s - loss: 4.8062 - acc: 0.02 - ETA: 12s - loss: 4.8063 - acc: 0.02 - ETA: 12s - loss: 4.8065 - acc: 0.02 - ETA: 11s - loss: 4.8071 - acc: 0.02 - ETA: 11s - loss: 4.8065 - acc: 0.02 - ETA: 11s - loss: 4.8068 - acc: 0.02 - ETA: 11s - loss: 4.8069 - acc: 0.02 - ETA: 11s - loss: 4.8066 - acc: 0.02 - ETA: 11s - loss: 4.8062 - acc: 0.02 - ETA: 11s - loss: 4.8057 - acc: 0.02 - ETA: 10s - loss: 4.8058 - acc: 0.02 - ETA: 10s - loss: 4.8056 - acc: 0.02 - ETA: 10s - loss: 4.8054 - acc: 0.02 - ETA: 10s - loss: 4.8052 - acc: 0.02 - ETA: 10s - loss: 4.8055 - acc: 0.02 - ETA: 10s - loss: 4.8054 - acc: 0.02 - ETA: 9s - loss: 4.8058 - acc: 0.0201 - ETA: 9s - loss: 4.8059 - acc: 0.020 - ETA: 9s - loss: 4.8058 - acc: 0.020 - ETA: 9s - loss: 4.8062 - acc: 0.020 - ETA: 9s - loss: 4.8065 - acc: 0.020 - ETA: 9s - loss: 4.8065 - acc: 0.020 - ETA: 9s - loss: 4.8062 - acc: 0.019 - ETA: 8s - loss: 4.8064 - acc: 0.019 - ETA: 8s - loss: 4.8067 - acc: 0.019 - ETA: 8s - loss: 4.8064 - acc: 0.020 - ETA: 8s - loss: 4.8067 - acc: 0.020 - ETA: 8s - loss: 4.8070 - acc: 0.019 - ETA: 7s - loss: 4.8068 - acc: 0.019 - ETA: 7s - loss: 4.8069 - acc: 0.020 - ETA: 7s - loss: 4.8071 - acc: 0.019 - ETA: 7s - loss: 4.8074 - acc: 0.019 - ETA: 7s - loss: 4.8076 - acc: 0.020 - ETA: 7s - loss: 4.8075 - acc: 0.019 - ETA: 7s - loss: 4.8076 - acc: 0.019 - ETA: 6s - loss: 4.8078 - acc: 0.020 - ETA: 6s - loss: 4.8080 - acc: 0.019 - ETA: 6s - loss: 4.8075 - acc: 0.020 - ETA: 6s - loss: 4.8072 - acc: 0.020 - ETA: 6s - loss: 4.8073 - acc: 0.020 - ETA: 6s - loss: 4.8072 - acc: 0.020 - ETA: 5s - loss: 4.8072 - acc: 0.020 - ETA: 5s - loss: 4.8070 - acc: 0.020 - ETA: 5s - loss: 4.8071 - acc: 0.020 - ETA: 5s - loss: 4.8073 - acc: 0.020 - ETA: 5s - loss: 4.8070 - acc: 0.020 - ETA: 5s - loss: 4.8069 - acc: 0.020 - ETA: 5s - loss: 4.8069 - acc: 0.020 - ETA: 4s - loss: 4.8070 - acc: 0.020 - ETA: 4s - loss: 4.8070 - acc: 0.020 - ETA: 4s - loss: 4.8072 - acc: 0.020 - ETA: 4s - loss: 4.8072 - acc: 0.020 - ETA: 4s - loss: 4.8074 - acc: 0.020 - ETA: 4s - loss: 4.8076 - acc: 0.020 - ETA: 3s - loss: 4.8075 - acc: 0.020 - ETA: 3s - loss: 4.8073 - acc: 0.020 - ETA: 3s - loss: 4.8068 - acc: 0.020 - ETA: 3s - loss: 4.8066 - acc: 0.020 - ETA: 3s - loss: 4.8065 - acc: 0.019 - ETA: 3s - loss: 4.8066 - acc: 0.019 - ETA: 3s - loss: 4.8069 - acc: 0.020 - ETA: 2s - loss: 4.8066 - acc: 0.020 - ETA: 2s - loss: 4.8065 - acc: 0.020 - ETA: 2s - loss: 4.8068 - acc: 0.020 - ETA: 2s - loss: 4.8071 - acc: 0.020 - ETA: 2s - loss: 4.8067 - acc: 0.019 - ETA: 2s - loss: 4.8063 - acc: 0.019 - ETA: 1s - loss: 4.8067 - acc: 0.019 - ETA: 1s - loss: 4.8064 - acc: 0.019 - ETA: 1s - loss: 4.8065 - acc: 0.019 - ETA: 1s - loss: 4.8064 - acc: 0.019 - ETA: 1s - loss: 4.8064 - acc: 0.019 - ETA: 1s - loss: 4.8066 - acc: 0.019 - ETA: 1s - loss: 4.8064 - acc: 0.019 - ETA: 0s - loss: 4.8065 - acc: 0.019 - ETA: 0s - loss: 4.8063 - acc: 0.019 - ETA: 0s - loss: 4.8063 - acc: 0.019 - ETA: 0s - loss: 4.8063 - acc: 0.019 - ETA: 0s - loss: 4.8065 - acc: 0.019 - ETA: 0s - loss: 4.8064 - acc: 0.020 - 68s 162ms/step - loss: 4.8069 - acc: 0.0199 - val_loss: 4.7847 - val_acc: 0.0208\n",
      "\n",
      "Epoch 00046: val_loss improved from 4.78987 to 4.78470, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224/417 [===============>..............] - ETA: 6s - loss: 4.8504 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8151 - acc: 0.0125    - ETA: 6s - loss: 4.8376 - acc: 0.013 - ETA: 12s - loss: 4.8200 - acc: 0.01 - ETA: 18s - loss: 4.8270 - acc: 0.01 - ETA: 21s - loss: 4.8212 - acc: 0.01 - ETA: 24s - loss: 4.8184 - acc: 0.01 - ETA: 27s - loss: 4.8237 - acc: 0.01 - ETA: 28s - loss: 4.8289 - acc: 0.01 - ETA: 31s - loss: 4.8263 - acc: 0.01 - ETA: 33s - loss: 4.8231 - acc: 0.01 - ETA: 34s - loss: 4.8177 - acc: 0.01 - ETA: 35s - loss: 4.8191 - acc: 0.01 - ETA: 36s - loss: 4.8207 - acc: 0.01 - ETA: 37s - loss: 4.8241 - acc: 0.01 - ETA: 37s - loss: 4.8273 - acc: 0.02 - ETA: 38s - loss: 4.8245 - acc: 0.02 - ETA: 39s - loss: 4.8188 - acc: 0.02 - ETA: 40s - loss: 4.8179 - acc: 0.02 - ETA: 40s - loss: 4.8185 - acc: 0.02 - ETA: 41s - loss: 4.8170 - acc: 0.02 - ETA: 41s - loss: 4.8214 - acc: 0.02 - ETA: 41s - loss: 4.8212 - acc: 0.02 - ETA: 41s - loss: 4.8181 - acc: 0.02 - ETA: 41s - loss: 4.8178 - acc: 0.02 - ETA: 43s - loss: 4.8206 - acc: 0.02 - ETA: 43s - loss: 4.8143 - acc: 0.02 - ETA: 43s - loss: 4.8161 - acc: 0.02 - ETA: 44s - loss: 4.8156 - acc: 0.02 - ETA: 44s - loss: 4.8178 - acc: 0.02 - ETA: 44s - loss: 4.8191 - acc: 0.02 - ETA: 44s - loss: 4.8171 - acc: 0.02 - ETA: 45s - loss: 4.8178 - acc: 0.02 - ETA: 46s - loss: 4.8163 - acc: 0.02 - ETA: 47s - loss: 4.8161 - acc: 0.02 - ETA: 47s - loss: 4.8128 - acc: 0.02 - ETA: 47s - loss: 4.8165 - acc: 0.02 - ETA: 47s - loss: 4.8132 - acc: 0.02 - ETA: 47s - loss: 4.8134 - acc: 0.02 - ETA: 47s - loss: 4.8140 - acc: 0.02 - ETA: 46s - loss: 4.8131 - acc: 0.02 - ETA: 46s - loss: 4.8159 - acc: 0.02 - ETA: 47s - loss: 4.8182 - acc: 0.02 - ETA: 47s - loss: 4.8182 - acc: 0.02 - ETA: 47s - loss: 4.8168 - acc: 0.02 - ETA: 47s - loss: 4.8141 - acc: 0.02 - ETA: 47s - loss: 4.8161 - acc: 0.02 - ETA: 47s - loss: 4.8178 - acc: 0.02 - ETA: 47s - loss: 4.8216 - acc: 0.02 - ETA: 47s - loss: 4.8222 - acc: 0.02 - ETA: 47s - loss: 4.8201 - acc: 0.02 - ETA: 47s - loss: 4.8215 - acc: 0.02 - ETA: 47s - loss: 4.8230 - acc: 0.02 - ETA: 47s - loss: 4.8241 - acc: 0.02 - ETA: 47s - loss: 4.8246 - acc: 0.02 - ETA: 47s - loss: 4.8245 - acc: 0.02 - ETA: 47s - loss: 4.8252 - acc: 0.02 - ETA: 48s - loss: 4.8261 - acc: 0.02 - ETA: 48s - loss: 4.8262 - acc: 0.02 - ETA: 48s - loss: 4.8266 - acc: 0.02 - ETA: 47s - loss: 4.8242 - acc: 0.02 - ETA: 47s - loss: 4.8241 - acc: 0.02 - ETA: 48s - loss: 4.8226 - acc: 0.02 - ETA: 47s - loss: 4.8214 - acc: 0.02 - ETA: 47s - loss: 4.8214 - acc: 0.02 - ETA: 47s - loss: 4.8208 - acc: 0.02 - ETA: 47s - loss: 4.8221 - acc: 0.02 - ETA: 47s - loss: 4.8230 - acc: 0.02 - ETA: 47s - loss: 4.8216 - acc: 0.02 - ETA: 48s - loss: 4.8197 - acc: 0.02 - ETA: 48s - loss: 4.8191 - acc: 0.02 - ETA: 47s - loss: 4.8196 - acc: 0.02 - ETA: 47s - loss: 4.8199 - acc: 0.02 - ETA: 47s - loss: 4.8205 - acc: 0.01 - ETA: 47s - loss: 4.8199 - acc: 0.02 - ETA: 47s - loss: 4.8191 - acc: 0.02 - ETA: 47s - loss: 4.8178 - acc: 0.02 - ETA: 47s - loss: 4.8192 - acc: 0.02 - ETA: 46s - loss: 4.8181 - acc: 0.02 - ETA: 47s - loss: 4.8186 - acc: 0.02 - ETA: 46s - loss: 4.8178 - acc: 0.02 - ETA: 46s - loss: 4.8179 - acc: 0.02 - ETA: 46s - loss: 4.8178 - acc: 0.01 - ETA: 46s - loss: 4.8174 - acc: 0.01 - ETA: 46s - loss: 4.8179 - acc: 0.01 - ETA: 46s - loss: 4.8154 - acc: 0.02 - ETA: 46s - loss: 4.8164 - acc: 0.02 - ETA: 46s - loss: 4.8162 - acc: 0.02 - ETA: 46s - loss: 4.8157 - acc: 0.02 - ETA: 46s - loss: 4.8167 - acc: 0.02 - ETA: 45s - loss: 4.8148 - acc: 0.02 - ETA: 45s - loss: 4.8149 - acc: 0.02 - ETA: 45s - loss: 4.8144 - acc: 0.02 - ETA: 45s - loss: 4.8150 - acc: 0.02 - ETA: 45s - loss: 4.8165 - acc: 0.02 - ETA: 45s - loss: 4.8162 - acc: 0.01 - ETA: 45s - loss: 4.8158 - acc: 0.02 - ETA: 44s - loss: 4.8149 - acc: 0.02 - ETA: 44s - loss: 4.8152 - acc: 0.02 - ETA: 44s - loss: 4.8161 - acc: 0.02 - ETA: 44s - loss: 4.8158 - acc: 0.02 - ETA: 44s - loss: 4.8147 - acc: 0.02 - ETA: 44s - loss: 4.8142 - acc: 0.02 - ETA: 44s - loss: 4.8124 - acc: 0.02 - ETA: 44s - loss: 4.8124 - acc: 0.02 - ETA: 44s - loss: 4.8128 - acc: 0.02 - ETA: 44s - loss: 4.8126 - acc: 0.02 - ETA: 43s - loss: 4.8130 - acc: 0.02 - ETA: 43s - loss: 4.8146 - acc: 0.02 - ETA: 43s - loss: 4.8157 - acc: 0.02 - ETA: 43s - loss: 4.8154 - acc: 0.02 - ETA: 43s - loss: 4.8170 - acc: 0.02 - ETA: 43s - loss: 4.8170 - acc: 0.02 - ETA: 42s - loss: 4.8170 - acc: 0.02 - ETA: 42s - loss: 4.8150 - acc: 0.02 - ETA: 42s - loss: 4.8148 - acc: 0.02 - ETA: 42s - loss: 4.8142 - acc: 0.02 - ETA: 42s - loss: 4.8146 - acc: 0.02 - ETA: 42s - loss: 4.8137 - acc: 0.02 - ETA: 41s - loss: 4.8133 - acc: 0.02 - ETA: 41s - loss: 4.8127 - acc: 0.02 - ETA: 41s - loss: 4.8132 - acc: 0.02 - ETA: 41s - loss: 4.8139 - acc: 0.02 - ETA: 41s - loss: 4.8130 - acc: 0.02 - ETA: 41s - loss: 4.8138 - acc: 0.02 - ETA: 41s - loss: 4.8150 - acc: 0.02 - ETA: 41s - loss: 4.8151 - acc: 0.02 - ETA: 41s - loss: 4.8140 - acc: 0.02 - ETA: 40s - loss: 4.8131 - acc: 0.02 - ETA: 40s - loss: 4.8129 - acc: 0.02 - ETA: 40s - loss: 4.8128 - acc: 0.02 - ETA: 40s - loss: 4.8137 - acc: 0.02 - ETA: 40s - loss: 4.8123 - acc: 0.02 - ETA: 40s - loss: 4.8125 - acc: 0.02 - ETA: 39s - loss: 4.8121 - acc: 0.02 - ETA: 39s - loss: 4.8121 - acc: 0.02 - ETA: 39s - loss: 4.8117 - acc: 0.02 - ETA: 39s - loss: 4.8117 - acc: 0.02 - ETA: 39s - loss: 4.8111 - acc: 0.02 - ETA: 39s - loss: 4.8110 - acc: 0.02 - ETA: 39s - loss: 4.8116 - acc: 0.02 - ETA: 39s - loss: 4.8114 - acc: 0.02 - ETA: 39s - loss: 4.8117 - acc: 0.02 - ETA: 39s - loss: 4.8115 - acc: 0.02 - ETA: 39s - loss: 4.8119 - acc: 0.02 - ETA: 38s - loss: 4.8121 - acc: 0.02 - ETA: 38s - loss: 4.8122 - acc: 0.02 - ETA: 38s - loss: 4.8121 - acc: 0.02 - ETA: 38s - loss: 4.8116 - acc: 0.02 - ETA: 38s - loss: 4.8120 - acc: 0.02 - ETA: 37s - loss: 4.8114 - acc: 0.02 - ETA: 37s - loss: 4.8116 - acc: 0.02 - ETA: 37s - loss: 4.8105 - acc: 0.02 - ETA: 37s - loss: 4.8097 - acc: 0.02 - ETA: 37s - loss: 4.8096 - acc: 0.02 - ETA: 37s - loss: 4.8097 - acc: 0.02 - ETA: 37s - loss: 4.8099 - acc: 0.02 - ETA: 36s - loss: 4.8094 - acc: 0.02 - ETA: 36s - loss: 4.8101 - acc: 0.02 - ETA: 36s - loss: 4.8099 - acc: 0.02 - ETA: 36s - loss: 4.8106 - acc: 0.02 - ETA: 36s - loss: 4.8104 - acc: 0.02 - ETA: 36s - loss: 4.8095 - acc: 0.02 - ETA: 36s - loss: 4.8095 - acc: 0.02 - ETA: 35s - loss: 4.8084 - acc: 0.02 - ETA: 35s - loss: 4.8084 - acc: 0.02 - ETA: 35s - loss: 4.8084 - acc: 0.02 - ETA: 35s - loss: 4.8074 - acc: 0.02 - ETA: 35s - loss: 4.8079 - acc: 0.02 - ETA: 35s - loss: 4.8083 - acc: 0.02 - ETA: 35s - loss: 4.8092 - acc: 0.02 - ETA: 34s - loss: 4.8086 - acc: 0.02 - ETA: 34s - loss: 4.8073 - acc: 0.02 - ETA: 34s - loss: 4.8063 - acc: 0.02 - ETA: 34s - loss: 4.8059 - acc: 0.02 - ETA: 34s - loss: 4.8059 - acc: 0.02 - ETA: 34s - loss: 4.8064 - acc: 0.02 - ETA: 34s - loss: 4.8064 - acc: 0.02 - ETA: 34s - loss: 4.8058 - acc: 0.02 - ETA: 33s - loss: 4.8061 - acc: 0.02 - ETA: 33s - loss: 4.8062 - acc: 0.02 - ETA: 33s - loss: 4.8063 - acc: 0.02 - ETA: 33s - loss: 4.8058 - acc: 0.02 - ETA: 33s - loss: 4.8064 - acc: 0.02 - ETA: 33s - loss: 4.8072 - acc: 0.02 - ETA: 33s - loss: 4.8070 - acc: 0.02 - ETA: 33s - loss: 4.8067 - acc: 0.02 - ETA: 33s - loss: 4.8067 - acc: 0.02 - ETA: 33s - loss: 4.8052 - acc: 0.02 - ETA: 32s - loss: 4.8047 - acc: 0.02 - ETA: 32s - loss: 4.8041 - acc: 0.02 - ETA: 32s - loss: 4.8049 - acc: 0.02 - ETA: 32s - loss: 4.8052 - acc: 0.02 - ETA: 32s - loss: 4.8048 - acc: 0.02 - ETA: 32s - loss: 4.8053 - acc: 0.02 - ETA: 31s - loss: 4.8047 - acc: 0.02 - ETA: 31s - loss: 4.8048 - acc: 0.02 - ETA: 31s - loss: 4.8040 - acc: 0.02 - ETA: 31s - loss: 4.8039 - acc: 0.02 - ETA: 31s - loss: 4.8033 - acc: 0.02 - ETA: 31s - loss: 4.8033 - acc: 0.02 - ETA: 30s - loss: 4.8032 - acc: 0.02 - ETA: 30s - loss: 4.8029 - acc: 0.02 - ETA: 30s - loss: 4.8035 - acc: 0.02 - ETA: 30s - loss: 4.8028 - acc: 0.02 - ETA: 30s - loss: 4.8030 - acc: 0.02 - ETA: 30s - loss: 4.8033 - acc: 0.02 - ETA: 29s - loss: 4.8038 - acc: 0.02 - ETA: 29s - loss: 4.8044 - acc: 0.02 - ETA: 29s - loss: 4.8045 - acc: 0.02 - ETA: 29s - loss: 4.8039 - acc: 0.02 - ETA: 29s - loss: 4.8042 - acc: 0.02 - ETA: 29s - loss: 4.8044 - acc: 0.02 - ETA: 29s - loss: 4.8040 - acc: 0.02 - ETA: 28s - loss: 4.8031 - acc: 0.0240"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8025 - acc: 0.02 - ETA: 28s - loss: 4.8026 - acc: 0.02 - ETA: 28s - loss: 4.8032 - acc: 0.02 - ETA: 28s - loss: 4.8029 - acc: 0.02 - ETA: 28s - loss: 4.8027 - acc: 0.02 - ETA: 28s - loss: 4.8024 - acc: 0.02 - ETA: 27s - loss: 4.8024 - acc: 0.02 - ETA: 27s - loss: 4.8028 - acc: 0.02 - ETA: 27s - loss: 4.8025 - acc: 0.02 - ETA: 27s - loss: 4.8026 - acc: 0.02 - ETA: 27s - loss: 4.8029 - acc: 0.02 - ETA: 27s - loss: 4.8031 - acc: 0.02 - ETA: 27s - loss: 4.8032 - acc: 0.02 - ETA: 26s - loss: 4.8035 - acc: 0.02 - ETA: 26s - loss: 4.8031 - acc: 0.02 - ETA: 26s - loss: 4.8028 - acc: 0.02 - ETA: 26s - loss: 4.8032 - acc: 0.02 - ETA: 26s - loss: 4.8027 - acc: 0.02 - ETA: 26s - loss: 4.8024 - acc: 0.02 - ETA: 26s - loss: 4.8025 - acc: 0.02 - ETA: 25s - loss: 4.8021 - acc: 0.02 - ETA: 25s - loss: 4.8019 - acc: 0.02 - ETA: 25s - loss: 4.8016 - acc: 0.02 - ETA: 25s - loss: 4.8011 - acc: 0.02 - ETA: 25s - loss: 4.8004 - acc: 0.02 - ETA: 25s - loss: 4.8002 - acc: 0.02 - ETA: 25s - loss: 4.8000 - acc: 0.02 - ETA: 24s - loss: 4.7993 - acc: 0.02 - ETA: 24s - loss: 4.7993 - acc: 0.02 - ETA: 24s - loss: 4.7989 - acc: 0.02 - ETA: 24s - loss: 4.7989 - acc: 0.02 - ETA: 24s - loss: 4.7990 - acc: 0.02 - ETA: 24s - loss: 4.7992 - acc: 0.02 - ETA: 24s - loss: 4.7996 - acc: 0.02 - ETA: 23s - loss: 4.7999 - acc: 0.02 - ETA: 23s - loss: 4.8007 - acc: 0.02 - ETA: 23s - loss: 4.8009 - acc: 0.02 - ETA: 23s - loss: 4.8009 - acc: 0.02 - ETA: 23s - loss: 4.8010 - acc: 0.02 - ETA: 23s - loss: 4.8007 - acc: 0.02 - ETA: 23s - loss: 4.8005 - acc: 0.02 - ETA: 22s - loss: 4.8006 - acc: 0.02 - ETA: 22s - loss: 4.8006 - acc: 0.02 - ETA: 22s - loss: 4.8001 - acc: 0.02 - ETA: 22s - loss: 4.7998 - acc: 0.02 - ETA: 22s - loss: 4.8004 - acc: 0.02 - ETA: 22s - loss: 4.7998 - acc: 0.02 - ETA: 21s - loss: 4.8007 - acc: 0.02 - ETA: 21s - loss: 4.8013 - acc: 0.02 - ETA: 21s - loss: 4.8010 - acc: 0.02 - ETA: 21s - loss: 4.8022 - acc: 0.02 - ETA: 21s - loss: 4.8019 - acc: 0.02 - ETA: 21s - loss: 4.8021 - acc: 0.02 - ETA: 20s - loss: 4.8022 - acc: 0.02 - ETA: 20s - loss: 4.8028 - acc: 0.02 - ETA: 20s - loss: 4.8032 - acc: 0.02 - ETA: 20s - loss: 4.8034 - acc: 0.02 - ETA: 20s - loss: 4.8034 - acc: 0.02 - ETA: 20s - loss: 4.8034 - acc: 0.02 - ETA: 20s - loss: 4.8029 - acc: 0.02 - ETA: 19s - loss: 4.8028 - acc: 0.02 - ETA: 19s - loss: 4.8027 - acc: 0.02 - ETA: 19s - loss: 4.8030 - acc: 0.02 - ETA: 19s - loss: 4.8028 - acc: 0.02 - ETA: 19s - loss: 4.8033 - acc: 0.02 - ETA: 19s - loss: 4.8026 - acc: 0.02 - ETA: 18s - loss: 4.8025 - acc: 0.02 - ETA: 18s - loss: 4.8025 - acc: 0.02 - ETA: 18s - loss: 4.8023 - acc: 0.02 - ETA: 18s - loss: 4.8025 - acc: 0.02 - ETA: 18s - loss: 4.8017 - acc: 0.02 - ETA: 18s - loss: 4.8010 - acc: 0.02 - ETA: 18s - loss: 4.8010 - acc: 0.02 - ETA: 18s - loss: 4.8011 - acc: 0.02 - ETA: 17s - loss: 4.8007 - acc: 0.02 - ETA: 17s - loss: 4.8004 - acc: 0.02 - ETA: 17s - loss: 4.8000 - acc: 0.02 - ETA: 17s - loss: 4.8000 - acc: 0.02 - ETA: 17s - loss: 4.8006 - acc: 0.02 - ETA: 17s - loss: 4.8005 - acc: 0.02 - ETA: 16s - loss: 4.8003 - acc: 0.02 - ETA: 16s - loss: 4.8006 - acc: 0.02 - ETA: 16s - loss: 4.8000 - acc: 0.02 - ETA: 16s - loss: 4.8003 - acc: 0.02 - ETA: 16s - loss: 4.7997 - acc: 0.02 - ETA: 16s - loss: 4.8001 - acc: 0.02 - ETA: 16s - loss: 4.8004 - acc: 0.02 - ETA: 15s - loss: 4.8002 - acc: 0.02 - ETA: 15s - loss: 4.8002 - acc: 0.02 - ETA: 15s - loss: 4.8006 - acc: 0.02 - ETA: 15s - loss: 4.8002 - acc: 0.02 - ETA: 15s - loss: 4.8004 - acc: 0.02 - ETA: 15s - loss: 4.8003 - acc: 0.02 - ETA: 15s - loss: 4.8001 - acc: 0.02 - ETA: 14s - loss: 4.8000 - acc: 0.02 - ETA: 14s - loss: 4.8002 - acc: 0.02 - ETA: 14s - loss: 4.8008 - acc: 0.02 - ETA: 14s - loss: 4.8011 - acc: 0.02 - ETA: 14s - loss: 4.8010 - acc: 0.02 - ETA: 14s - loss: 4.8004 - acc: 0.02 - ETA: 14s - loss: 4.7998 - acc: 0.02 - ETA: 13s - loss: 4.7990 - acc: 0.02 - ETA: 13s - loss: 4.7991 - acc: 0.02 - ETA: 13s - loss: 4.7989 - acc: 0.02 - ETA: 13s - loss: 4.7990 - acc: 0.02 - ETA: 13s - loss: 4.7986 - acc: 0.02 - ETA: 13s - loss: 4.7987 - acc: 0.02 - ETA: 12s - loss: 4.7989 - acc: 0.02 - ETA: 12s - loss: 4.7983 - acc: 0.02 - ETA: 12s - loss: 4.7980 - acc: 0.02 - ETA: 12s - loss: 4.7981 - acc: 0.02 - ETA: 12s - loss: 4.7979 - acc: 0.02 - ETA: 12s - loss: 4.7979 - acc: 0.02 - ETA: 11s - loss: 4.7979 - acc: 0.02 - ETA: 11s - loss: 4.7978 - acc: 0.02 - ETA: 11s - loss: 4.7975 - acc: 0.02 - ETA: 11s - loss: 4.7977 - acc: 0.02 - ETA: 11s - loss: 4.7980 - acc: 0.02 - ETA: 11s - loss: 4.7982 - acc: 0.02 - ETA: 11s - loss: 4.7990 - acc: 0.02 - ETA: 10s - loss: 4.7991 - acc: 0.02 - ETA: 10s - loss: 4.7992 - acc: 0.02 - ETA: 10s - loss: 4.7992 - acc: 0.02 - ETA: 10s - loss: 4.7997 - acc: 0.02 - ETA: 10s - loss: 4.7996 - acc: 0.02 - ETA: 10s - loss: 4.7997 - acc: 0.02 - ETA: 9s - loss: 4.7996 - acc: 0.0247 - ETA: 9s - loss: 4.7997 - acc: 0.024 - ETA: 9s - loss: 4.7998 - acc: 0.024 - ETA: 9s - loss: 4.7995 - acc: 0.024 - ETA: 9s - loss: 4.8000 - acc: 0.024 - ETA: 9s - loss: 4.8003 - acc: 0.024 - ETA: 9s - loss: 4.8008 - acc: 0.024 - ETA: 8s - loss: 4.8009 - acc: 0.024 - ETA: 8s - loss: 4.8010 - acc: 0.024 - ETA: 8s - loss: 4.8011 - acc: 0.024 - ETA: 8s - loss: 4.8009 - acc: 0.024 - ETA: 8s - loss: 4.8014 - acc: 0.024 - ETA: 8s - loss: 4.8017 - acc: 0.024 - ETA: 8s - loss: 4.8017 - acc: 0.024 - ETA: 7s - loss: 4.8016 - acc: 0.024 - ETA: 7s - loss: 4.8015 - acc: 0.024 - ETA: 7s - loss: 4.8016 - acc: 0.024 - ETA: 7s - loss: 4.8016 - acc: 0.024 - ETA: 7s - loss: 4.8019 - acc: 0.024 - ETA: 7s - loss: 4.8017 - acc: 0.024 - ETA: 6s - loss: 4.8018 - acc: 0.024 - ETA: 6s - loss: 4.8020 - acc: 0.024 - ETA: 6s - loss: 4.8019 - acc: 0.024 - ETA: 6s - loss: 4.8024 - acc: 0.024 - ETA: 6s - loss: 4.8022 - acc: 0.024 - ETA: 6s - loss: 4.8019 - acc: 0.024 - ETA: 6s - loss: 4.8023 - acc: 0.024 - ETA: 5s - loss: 4.8022 - acc: 0.024 - ETA: 5s - loss: 4.8018 - acc: 0.024 - ETA: 5s - loss: 4.8019 - acc: 0.024 - ETA: 5s - loss: 4.8017 - acc: 0.024 - ETA: 5s - loss: 4.8014 - acc: 0.024 - ETA: 5s - loss: 4.8016 - acc: 0.024 - ETA: 4s - loss: 4.8018 - acc: 0.024 - ETA: 4s - loss: 4.8019 - acc: 0.024 - ETA: 4s - loss: 4.8021 - acc: 0.024 - ETA: 4s - loss: 4.8019 - acc: 0.024 - ETA: 4s - loss: 4.8021 - acc: 0.023 - ETA: 4s - loss: 4.8019 - acc: 0.023 - ETA: 3s - loss: 4.8020 - acc: 0.023 - ETA: 3s - loss: 4.8021 - acc: 0.023 - ETA: 3s - loss: 4.8018 - acc: 0.024 - ETA: 3s - loss: 4.8017 - acc: 0.024 - ETA: 3s - loss: 4.8017 - acc: 0.024 - ETA: 3s - loss: 4.8020 - acc: 0.024 - ETA: 2s - loss: 4.8020 - acc: 0.024 - ETA: 2s - loss: 4.8019 - acc: 0.024 - ETA: 2s - loss: 4.8019 - acc: 0.024 - ETA: 2s - loss: 4.8021 - acc: 0.024 - ETA: 2s - loss: 4.8024 - acc: 0.024 - ETA: 2s - loss: 4.8021 - acc: 0.024 - ETA: 2s - loss: 4.8020 - acc: 0.024 - ETA: 1s - loss: 4.8018 - acc: 0.024 - ETA: 1s - loss: 4.8015 - acc: 0.024 - ETA: 1s - loss: 4.8016 - acc: 0.024 - ETA: 1s - loss: 4.8014 - acc: 0.023 - ETA: 1s - loss: 4.8016 - acc: 0.023 - ETA: 1s - loss: 4.8017 - acc: 0.023 - ETA: 0s - loss: 4.8020 - acc: 0.023 - ETA: 0s - loss: 4.8024 - acc: 0.023 - ETA: 0s - loss: 4.8025 - acc: 0.023 - ETA: 0s - loss: 4.8027 - acc: 0.023 - ETA: 0s - loss: 4.8028 - acc: 0.023 - ETA: 0s - loss: 4.8027 - acc: 0.023 - 69s 164ms/step - loss: 4.8025 - acc: 0.0235 - val_loss: 4.7568 - val_acc: 0.0342\n",
      "\n",
      "Epoch 00047: val_loss improved from 4.78470 to 4.75676, saving model to saved_models/weights.best.groundup_1.hdf5\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/417 [===============>..............] - ETA: 5s - loss: 4.8896 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8655 - acc: 0.0000e+0 - ETA: 6s - loss: 4.8376 - acc: 0.0069    - ETA: 10s - loss: 4.8615 - acc: 0.00 - ETA: 14s - loss: 4.8558 - acc: 0.00 - ETA: 16s - loss: 4.8545 - acc: 0.00 - ETA: 23s - loss: 4.8590 - acc: 0.00 - ETA: 23s - loss: 4.8505 - acc: 0.01 - ETA: 25s - loss: 4.8557 - acc: 0.01 - ETA: 28s - loss: 4.8562 - acc: 0.00 - ETA: 29s - loss: 4.8583 - acc: 0.01 - ETA: 30s - loss: 4.8587 - acc: 0.01 - ETA: 31s - loss: 4.8547 - acc: 0.01 - ETA: 33s - loss: 4.8538 - acc: 0.01 - ETA: 34s - loss: 4.8540 - acc: 0.01 - ETA: 35s - loss: 4.8531 - acc: 0.01 - ETA: 35s - loss: 4.8597 - acc: 0.01 - ETA: 36s - loss: 4.8571 - acc: 0.01 - ETA: 37s - loss: 4.8504 - acc: 0.01 - ETA: 37s - loss: 4.8502 - acc: 0.01 - ETA: 37s - loss: 4.8480 - acc: 0.01 - ETA: 37s - loss: 4.8478 - acc: 0.01 - ETA: 38s - loss: 4.8469 - acc: 0.01 - ETA: 38s - loss: 4.8493 - acc: 0.01 - ETA: 38s - loss: 4.8490 - acc: 0.01 - ETA: 39s - loss: 4.8502 - acc: 0.01 - ETA: 39s - loss: 4.8547 - acc: 0.01 - ETA: 39s - loss: 4.8519 - acc: 0.01 - ETA: 40s - loss: 4.8491 - acc: 0.01 - ETA: 40s - loss: 4.8503 - acc: 0.01 - ETA: 40s - loss: 4.8498 - acc: 0.01 - ETA: 40s - loss: 4.8458 - acc: 0.01 - ETA: 40s - loss: 4.8484 - acc: 0.01 - ETA: 40s - loss: 4.8486 - acc: 0.01 - ETA: 40s - loss: 4.8428 - acc: 0.01 - ETA: 40s - loss: 4.8408 - acc: 0.01 - ETA: 41s - loss: 4.8406 - acc: 0.01 - ETA: 40s - loss: 4.8410 - acc: 0.01 - ETA: 40s - loss: 4.8392 - acc: 0.01 - ETA: 40s - loss: 4.8362 - acc: 0.01 - ETA: 40s - loss: 4.8349 - acc: 0.01 - ETA: 41s - loss: 4.8343 - acc: 0.01 - ETA: 41s - loss: 4.8337 - acc: 0.02 - ETA: 41s - loss: 4.8322 - acc: 0.02 - ETA: 41s - loss: 4.8333 - acc: 0.02 - ETA: 41s - loss: 4.8326 - acc: 0.02 - ETA: 41s - loss: 4.8327 - acc: 0.02 - ETA: 41s - loss: 4.8326 - acc: 0.01 - ETA: 41s - loss: 4.8313 - acc: 0.01 - ETA: 41s - loss: 4.8313 - acc: 0.01 - ETA: 41s - loss: 4.8299 - acc: 0.01 - ETA: 41s - loss: 4.8303 - acc: 0.01 - ETA: 41s - loss: 4.8322 - acc: 0.01 - ETA: 41s - loss: 4.8330 - acc: 0.01 - ETA: 41s - loss: 4.8322 - acc: 0.01 - ETA: 41s - loss: 4.8314 - acc: 0.01 - ETA: 41s - loss: 4.8301 - acc: 0.01 - ETA: 41s - loss: 4.8287 - acc: 0.01 - ETA: 41s - loss: 4.8240 - acc: 0.02 - ETA: 41s - loss: 4.8247 - acc: 0.01 - ETA: 41s - loss: 4.8235 - acc: 0.01 - ETA: 41s - loss: 4.8233 - acc: 0.01 - ETA: 41s - loss: 4.8214 - acc: 0.01 - ETA: 42s - loss: 4.8225 - acc: 0.01 - ETA: 42s - loss: 4.8195 - acc: 0.01 - ETA: 42s - loss: 4.8193 - acc: 0.01 - ETA: 42s - loss: 4.8202 - acc: 0.01 - ETA: 42s - loss: 4.8207 - acc: 0.01 - ETA: 42s - loss: 4.8220 - acc: 0.01 - ETA: 42s - loss: 4.8231 - acc: 0.01 - ETA: 42s - loss: 4.8231 - acc: 0.01 - ETA: 43s - loss: 4.8212 - acc: 0.01 - ETA: 43s - loss: 4.8217 - acc: 0.01 - ETA: 43s - loss: 4.8213 - acc: 0.01 - ETA: 43s - loss: 4.8213 - acc: 0.01 - ETA: 43s - loss: 4.8195 - acc: 0.01 - ETA: 42s - loss: 4.8192 - acc: 0.01 - ETA: 43s - loss: 4.8174 - acc: 0.01 - ETA: 43s - loss: 4.8156 - acc: 0.01 - ETA: 43s - loss: 4.8145 - acc: 0.01 - ETA: 43s - loss: 4.8144 - acc: 0.01 - ETA: 43s - loss: 4.8143 - acc: 0.01 - ETA: 43s - loss: 4.8159 - acc: 0.01 - ETA: 42s - loss: 4.8154 - acc: 0.01 - ETA: 43s - loss: 4.8136 - acc: 0.01 - ETA: 43s - loss: 4.8143 - acc: 0.01 - ETA: 43s - loss: 4.8151 - acc: 0.01 - ETA: 43s - loss: 4.8154 - acc: 0.01 - ETA: 43s - loss: 4.8158 - acc: 0.01 - ETA: 43s - loss: 4.8175 - acc: 0.01 - ETA: 43s - loss: 4.8170 - acc: 0.01 - ETA: 42s - loss: 4.8162 - acc: 0.01 - ETA: 42s - loss: 4.8153 - acc: 0.01 - ETA: 42s - loss: 4.8164 - acc: 0.01 - ETA: 42s - loss: 4.8172 - acc: 0.01 - ETA: 42s - loss: 4.8178 - acc: 0.01 - ETA: 42s - loss: 4.8183 - acc: 0.01 - ETA: 42s - loss: 4.8165 - acc: 0.01 - ETA: 42s - loss: 4.8167 - acc: 0.01 - ETA: 42s - loss: 4.8163 - acc: 0.01 - ETA: 42s - loss: 4.8154 - acc: 0.01 - ETA: 42s - loss: 4.8155 - acc: 0.01 - ETA: 42s - loss: 4.8151 - acc: 0.01 - ETA: 42s - loss: 4.8164 - acc: 0.01 - ETA: 42s - loss: 4.8174 - acc: 0.01 - ETA: 42s - loss: 4.8179 - acc: 0.01 - ETA: 41s - loss: 4.8173 - acc: 0.01 - ETA: 41s - loss: 4.8174 - acc: 0.01 - ETA: 41s - loss: 4.8146 - acc: 0.01 - ETA: 41s - loss: 4.8142 - acc: 0.01 - ETA: 41s - loss: 4.8145 - acc: 0.01 - ETA: 41s - loss: 4.8158 - acc: 0.01 - ETA: 41s - loss: 4.8155 - acc: 0.01 - ETA: 41s - loss: 4.8160 - acc: 0.01 - ETA: 40s - loss: 4.8154 - acc: 0.01 - ETA: 40s - loss: 4.8148 - acc: 0.01 - ETA: 40s - loss: 4.8154 - acc: 0.01 - ETA: 40s - loss: 4.8152 - acc: 0.01 - ETA: 40s - loss: 4.8161 - acc: 0.01 - ETA: 40s - loss: 4.8162 - acc: 0.01 - ETA: 40s - loss: 4.8157 - acc: 0.01 - ETA: 39s - loss: 4.8152 - acc: 0.01 - ETA: 39s - loss: 4.8161 - acc: 0.01 - ETA: 40s - loss: 4.8163 - acc: 0.01 - ETA: 39s - loss: 4.8155 - acc: 0.01 - ETA: 39s - loss: 4.8152 - acc: 0.01 - ETA: 39s - loss: 4.8149 - acc: 0.01 - ETA: 39s - loss: 4.8144 - acc: 0.01 - ETA: 39s - loss: 4.8143 - acc: 0.01 - ETA: 39s - loss: 4.8152 - acc: 0.01 - ETA: 38s - loss: 4.8154 - acc: 0.01 - ETA: 38s - loss: 4.8154 - acc: 0.01 - ETA: 38s - loss: 4.8159 - acc: 0.01 - ETA: 38s - loss: 4.8164 - acc: 0.01 - ETA: 38s - loss: 4.8168 - acc: 0.01 - ETA: 38s - loss: 4.8162 - acc: 0.01 - ETA: 38s - loss: 4.8160 - acc: 0.01 - ETA: 37s - loss: 4.8166 - acc: 0.01 - ETA: 37s - loss: 4.8171 - acc: 0.01 - ETA: 37s - loss: 4.8170 - acc: 0.01 - ETA: 37s - loss: 4.8168 - acc: 0.01 - ETA: 37s - loss: 4.8157 - acc: 0.01 - ETA: 37s - loss: 4.8160 - acc: 0.01 - ETA: 37s - loss: 4.8165 - acc: 0.01 - ETA: 37s - loss: 4.8169 - acc: 0.01 - ETA: 36s - loss: 4.8163 - acc: 0.01 - ETA: 36s - loss: 4.8162 - acc: 0.01 - ETA: 36s - loss: 4.8158 - acc: 0.01 - ETA: 36s - loss: 4.8157 - acc: 0.01 - ETA: 36s - loss: 4.8168 - acc: 0.01 - ETA: 36s - loss: 4.8175 - acc: 0.01 - ETA: 36s - loss: 4.8164 - acc: 0.01 - ETA: 36s - loss: 4.8163 - acc: 0.01 - ETA: 36s - loss: 4.8157 - acc: 0.01 - ETA: 36s - loss: 4.8164 - acc: 0.01 - ETA: 36s - loss: 4.8157 - acc: 0.01 - ETA: 36s - loss: 4.8152 - acc: 0.01 - ETA: 35s - loss: 4.8162 - acc: 0.01 - ETA: 35s - loss: 4.8165 - acc: 0.01 - ETA: 35s - loss: 4.8158 - acc: 0.01 - ETA: 35s - loss: 4.8151 - acc: 0.01 - ETA: 35s - loss: 4.8151 - acc: 0.01 - ETA: 35s - loss: 4.8142 - acc: 0.01 - ETA: 35s - loss: 4.8147 - acc: 0.01 - ETA: 35s - loss: 4.8152 - acc: 0.01 - ETA: 34s - loss: 4.8149 - acc: 0.01 - ETA: 34s - loss: 4.8166 - acc: 0.01 - ETA: 34s - loss: 4.8157 - acc: 0.01 - ETA: 34s - loss: 4.8159 - acc: 0.01 - ETA: 34s - loss: 4.8163 - acc: 0.01 - ETA: 34s - loss: 4.8162 - acc: 0.01 - ETA: 33s - loss: 4.8160 - acc: 0.01 - ETA: 33s - loss: 4.8155 - acc: 0.01 - ETA: 33s - loss: 4.8148 - acc: 0.01 - ETA: 33s - loss: 4.8142 - acc: 0.01 - ETA: 33s - loss: 4.8145 - acc: 0.01 - ETA: 33s - loss: 4.8144 - acc: 0.01 - ETA: 33s - loss: 4.8153 - acc: 0.01 - ETA: 32s - loss: 4.8151 - acc: 0.01 - ETA: 32s - loss: 4.8148 - acc: 0.01 - ETA: 32s - loss: 4.8150 - acc: 0.01 - ETA: 32s - loss: 4.8149 - acc: 0.01 - ETA: 32s - loss: 4.8153 - acc: 0.01 - ETA: 32s - loss: 4.8153 - acc: 0.01 - ETA: 32s - loss: 4.8153 - acc: 0.01 - ETA: 31s - loss: 4.8157 - acc: 0.01 - ETA: 31s - loss: 4.8159 - acc: 0.01 - ETA: 31s - loss: 4.8151 - acc: 0.01 - ETA: 31s - loss: 4.8147 - acc: 0.01 - ETA: 31s - loss: 4.8147 - acc: 0.01 - ETA: 31s - loss: 4.8149 - acc: 0.01 - ETA: 31s - loss: 4.8146 - acc: 0.01 - ETA: 30s - loss: 4.8142 - acc: 0.01 - ETA: 30s - loss: 4.8137 - acc: 0.01 - ETA: 30s - loss: 4.8141 - acc: 0.01 - ETA: 30s - loss: 4.8142 - acc: 0.01 - ETA: 30s - loss: 4.8145 - acc: 0.02 - ETA: 30s - loss: 4.8142 - acc: 0.02 - ETA: 30s - loss: 4.8144 - acc: 0.02 - ETA: 30s - loss: 4.8148 - acc: 0.01 - ETA: 29s - loss: 4.8148 - acc: 0.01 - ETA: 29s - loss: 4.8141 - acc: 0.01 - ETA: 29s - loss: 4.8147 - acc: 0.01 - ETA: 29s - loss: 4.8146 - acc: 0.01 - ETA: 29s - loss: 4.8143 - acc: 0.01 - ETA: 29s - loss: 4.8143 - acc: 0.02 - ETA: 29s - loss: 4.8149 - acc: 0.02 - ETA: 29s - loss: 4.8154 - acc: 0.02 - ETA: 28s - loss: 4.8152 - acc: 0.02 - ETA: 28s - loss: 4.8147 - acc: 0.02 - ETA: 28s - loss: 4.8158 - acc: 0.02 - ETA: 28s - loss: 4.8159 - acc: 0.02 - ETA: 28s - loss: 4.8163 - acc: 0.02 - ETA: 28s - loss: 4.8166 - acc: 0.02 - ETA: 28s - loss: 4.8159 - acc: 0.0206"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 28s - loss: 4.8159 - acc: 0.02 - ETA: 27s - loss: 4.8151 - acc: 0.02 - ETA: 27s - loss: 4.8154 - acc: 0.02 - ETA: 27s - loss: 4.8159 - acc: 0.02 - ETA: 27s - loss: 4.8154 - acc: 0.02 - ETA: 27s - loss: 4.8144 - acc: 0.02 - ETA: 27s - loss: 4.8146 - acc: 0.02 - ETA: 27s - loss: 4.8143 - acc: 0.02 - ETA: 26s - loss: 4.8137 - acc: 0.02 - ETA: 26s - loss: 4.8139 - acc: 0.01 - ETA: 26s - loss: 4.8139 - acc: 0.02 - ETA: 26s - loss: 4.8128 - acc: 0.02 - ETA: 26s - loss: 4.8128 - acc: 0.02 - ETA: 26s - loss: 4.8128 - acc: 0.02 - ETA: 26s - loss: 4.8128 - acc: 0.02 - ETA: 26s - loss: 4.8122 - acc: 0.02 - ETA: 25s - loss: 4.8118 - acc: 0.02 - ETA: 25s - loss: 4.8116 - acc: 0.02 - ETA: 25s - loss: 4.8113 - acc: 0.02 - ETA: 25s - loss: 4.8113 - acc: 0.02 - ETA: 25s - loss: 4.8111 - acc: 0.02 - ETA: 25s - loss: 4.8118 - acc: 0.02 - ETA: 24s - loss: 4.8121 - acc: 0.02 - ETA: 24s - loss: 4.8124 - acc: 0.02 - ETA: 24s - loss: 4.8123 - acc: 0.02 - ETA: 24s - loss: 4.8125 - acc: 0.02 - ETA: 24s - loss: 4.8118 - acc: 0.02 - ETA: 24s - loss: 4.8119 - acc: 0.02 - ETA: 24s - loss: 4.8113 - acc: 0.02 - ETA: 23s - loss: 4.8110 - acc: 0.02 - ETA: 23s - loss: 4.8106 - acc: 0.02 - ETA: 23s - loss: 4.8104 - acc: 0.02 - ETA: 23s - loss: 4.8104 - acc: 0.02 - ETA: 23s - loss: 4.8105 - acc: 0.02 - ETA: 23s - loss: 4.8102 - acc: 0.02 - ETA: 23s - loss: 4.8097 - acc: 0.02 - ETA: 22s - loss: 4.8098 - acc: 0.02 - ETA: 22s - loss: 4.8099 - acc: 0.02 - ETA: 22s - loss: 4.8098 - acc: 0.02 - ETA: 22s - loss: 4.8098 - acc: 0.02 - ETA: 22s - loss: 4.8099 - acc: 0.02 - ETA: 21s - loss: 4.8094 - acc: 0.02 - ETA: 21s - loss: 4.8097 - acc: 0.02 - ETA: 21s - loss: 4.8094 - acc: 0.02 - ETA: 21s - loss: 4.8093 - acc: 0.02 - ETA: 21s - loss: 4.8092 - acc: 0.02 - ETA: 21s - loss: 4.8088 - acc: 0.02 - ETA: 21s - loss: 4.8089 - acc: 0.02 - ETA: 20s - loss: 4.8087 - acc: 0.02 - ETA: 20s - loss: 4.8089 - acc: 0.02 - ETA: 20s - loss: 4.8090 - acc: 0.02 - ETA: 20s - loss: 4.8086 - acc: 0.02 - ETA: 20s - loss: 4.8086 - acc: 0.02 - ETA: 20s - loss: 4.8087 - acc: 0.02 - ETA: 20s - loss: 4.8082 - acc: 0.02 - ETA: 19s - loss: 4.8080 - acc: 0.02 - ETA: 19s - loss: 4.8078 - acc: 0.02 - ETA: 19s - loss: 4.8077 - acc: 0.02 - ETA: 19s - loss: 4.8082 - acc: 0.02 - ETA: 19s - loss: 4.8084 - acc: 0.02 - ETA: 19s - loss: 4.8084 - acc: 0.02 - ETA: 18s - loss: 4.8080 - acc: 0.02 - ETA: 18s - loss: 4.8081 - acc: 0.02 - ETA: 18s - loss: 4.8079 - acc: 0.02 - ETA: 18s - loss: 4.8078 - acc: 0.02 - ETA: 18s - loss: 4.8076 - acc: 0.02 - ETA: 18s - loss: 4.8073 - acc: 0.02 - ETA: 18s - loss: 4.8080 - acc: 0.02 - ETA: 17s - loss: 4.8075 - acc: 0.02 - ETA: 17s - loss: 4.8073 - acc: 0.02 - ETA: 17s - loss: 4.8075 - acc: 0.02 - ETA: 17s - loss: 4.8074 - acc: 0.02 - ETA: 17s - loss: 4.8074 - acc: 0.02 - ETA: 17s - loss: 4.8074 - acc: 0.02 - ETA: 16s - loss: 4.8071 - acc: 0.02 - ETA: 16s - loss: 4.8072 - acc: 0.02 - ETA: 16s - loss: 4.8071 - acc: 0.02 - ETA: 16s - loss: 4.8070 - acc: 0.02 - ETA: 16s - loss: 4.8070 - acc: 0.02 - ETA: 16s - loss: 4.8068 - acc: 0.02 - ETA: 16s - loss: 4.8072 - acc: 0.02 - ETA: 16s - loss: 4.8070 - acc: 0.02 - ETA: 15s - loss: 4.8063 - acc: 0.02 - ETA: 15s - loss: 4.8060 - acc: 0.02 - ETA: 15s - loss: 4.8058 - acc: 0.02 - ETA: 15s - loss: 4.8060 - acc: 0.02 - ETA: 15s - loss: 4.8064 - acc: 0.02 - ETA: 15s - loss: 4.8068 - acc: 0.02 - ETA: 15s - loss: 4.8071 - acc: 0.02 - ETA: 14s - loss: 4.8076 - acc: 0.02 - ETA: 14s - loss: 4.8074 - acc: 0.02 - ETA: 14s - loss: 4.8071 - acc: 0.02 - ETA: 14s - loss: 4.8067 - acc: 0.02 - ETA: 14s - loss: 4.8062 - acc: 0.02 - ETA: 14s - loss: 4.8062 - acc: 0.02 - ETA: 14s - loss: 4.8066 - acc: 0.02 - ETA: 13s - loss: 4.8067 - acc: 0.02 - ETA: 13s - loss: 4.8067 - acc: 0.02 - ETA: 13s - loss: 4.8062 - acc: 0.02 - ETA: 13s - loss: 4.8069 - acc: 0.02 - ETA: 13s - loss: 4.8066 - acc: 0.02 - ETA: 13s - loss: 4.8059 - acc: 0.02 - ETA: 12s - loss: 4.8062 - acc: 0.02 - ETA: 12s - loss: 4.8065 - acc: 0.02 - ETA: 12s - loss: 4.8067 - acc: 0.02 - ETA: 12s - loss: 4.8068 - acc: 0.02 - ETA: 12s - loss: 4.8068 - acc: 0.02 - ETA: 12s - loss: 4.8071 - acc: 0.02 - ETA: 12s - loss: 4.8073 - acc: 0.02 - ETA: 12s - loss: 4.8075 - acc: 0.02 - ETA: 11s - loss: 4.8074 - acc: 0.02 - ETA: 11s - loss: 4.8072 - acc: 0.02 - ETA: 11s - loss: 4.8071 - acc: 0.02 - ETA: 11s - loss: 4.8075 - acc: 0.02 - ETA: 11s - loss: 4.8072 - acc: 0.02 - ETA: 11s - loss: 4.8073 - acc: 0.02 - ETA: 10s - loss: 4.8073 - acc: 0.02 - ETA: 10s - loss: 4.8071 - acc: 0.02 - ETA: 10s - loss: 4.8074 - acc: 0.02 - ETA: 10s - loss: 4.8073 - acc: 0.02 - ETA: 10s - loss: 4.8072 - acc: 0.02 - ETA: 10s - loss: 4.8075 - acc: 0.02 - ETA: 10s - loss: 4.8077 - acc: 0.02 - ETA: 9s - loss: 4.8077 - acc: 0.0218 - ETA: 9s - loss: 4.8075 - acc: 0.022 - ETA: 9s - loss: 4.8077 - acc: 0.021 - ETA: 9s - loss: 4.8080 - acc: 0.021 - ETA: 9s - loss: 4.8084 - acc: 0.021 - ETA: 9s - loss: 4.8086 - acc: 0.021 - ETA: 8s - loss: 4.8087 - acc: 0.021 - ETA: 8s - loss: 4.8088 - acc: 0.021 - ETA: 8s - loss: 4.8088 - acc: 0.021 - ETA: 8s - loss: 4.8087 - acc: 0.022 - ETA: 8s - loss: 4.8088 - acc: 0.021 - ETA: 8s - loss: 4.8089 - acc: 0.021 - ETA: 8s - loss: 4.8088 - acc: 0.021 - ETA: 7s - loss: 4.8088 - acc: 0.021 - ETA: 7s - loss: 4.8084 - acc: 0.022 - ETA: 7s - loss: 4.8086 - acc: 0.022 - ETA: 7s - loss: 4.8088 - acc: 0.021 - ETA: 7s - loss: 4.8087 - acc: 0.021 - ETA: 7s - loss: 4.8088 - acc: 0.021 - ETA: 6s - loss: 4.8090 - acc: 0.021 - ETA: 6s - loss: 4.8088 - acc: 0.021 - ETA: 6s - loss: 4.8085 - acc: 0.021 - ETA: 6s - loss: 4.8083 - acc: 0.021 - ETA: 6s - loss: 4.8086 - acc: 0.021 - ETA: 6s - loss: 4.8087 - acc: 0.021 - ETA: 6s - loss: 4.8084 - acc: 0.021 - ETA: 5s - loss: 4.8084 - acc: 0.021 - ETA: 5s - loss: 4.8084 - acc: 0.021 - ETA: 5s - loss: 4.8083 - acc: 0.021 - ETA: 5s - loss: 4.8081 - acc: 0.021 - ETA: 5s - loss: 4.8083 - acc: 0.021 - ETA: 5s - loss: 4.8084 - acc: 0.021 - ETA: 5s - loss: 4.8086 - acc: 0.021 - ETA: 4s - loss: 4.8081 - acc: 0.021 - ETA: 4s - loss: 4.8080 - acc: 0.022 - ETA: 4s - loss: 4.8081 - acc: 0.022 - ETA: 4s - loss: 4.8081 - acc: 0.021 - ETA: 4s - loss: 4.8081 - acc: 0.021 - ETA: 4s - loss: 4.8079 - acc: 0.022 - ETA: 3s - loss: 4.8078 - acc: 0.022 - ETA: 3s - loss: 4.8080 - acc: 0.022 - ETA: 3s - loss: 4.8082 - acc: 0.022 - ETA: 3s - loss: 4.8079 - acc: 0.022 - ETA: 3s - loss: 4.8081 - acc: 0.022 - ETA: 3s - loss: 4.8084 - acc: 0.022 - ETA: 3s - loss: 4.8085 - acc: 0.022 - ETA: 2s - loss: 4.8084 - acc: 0.022 - ETA: 2s - loss: 4.8082 - acc: 0.022 - ETA: 2s - loss: 4.8084 - acc: 0.022 - ETA: 2s - loss: 4.8085 - acc: 0.022 - ETA: 2s - loss: 4.8086 - acc: 0.022 - ETA: 2s - loss: 4.8085 - acc: 0.022 - ETA: 1s - loss: 4.8086 - acc: 0.022 - ETA: 1s - loss: 4.8084 - acc: 0.022 - ETA: 1s - loss: 4.8082 - acc: 0.022 - ETA: 1s - loss: 4.8082 - acc: 0.022 - ETA: 1s - loss: 4.8080 - acc: 0.022 - ETA: 1s - loss: 4.8083 - acc: 0.022 - ETA: 1s - loss: 4.8079 - acc: 0.022 - ETA: 0s - loss: 4.8080 - acc: 0.022 - ETA: 0s - loss: 4.8078 - acc: 0.022 - ETA: 0s - loss: 4.8080 - acc: 0.022 - ETA: 0s - loss: 4.8081 - acc: 0.022 - ETA: 0s - loss: 4.8080 - acc: 0.022 - ETA: 0s - loss: 4.8080 - acc: 0.022 - 67s 160ms/step - loss: 4.8079 - acc: 0.0225 - val_loss: 4.7869 - val_acc: 0.0256\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 4.75676\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/417 [===============>..............] - ETA: 5s - loss: 4.8295 - acc: 0.0000e+0 - ETA: 5s - loss: 4.7829 - acc: 0.0250    - ETA: 5s - loss: 4.8018 - acc: 0.020 - ETA: 7s - loss: 4.7940 - acc: 0.020 - ETA: 10s - loss: 4.7907 - acc: 0.02 - ETA: 13s - loss: 4.7951 - acc: 0.02 - ETA: 17s - loss: 4.8004 - acc: 0.02 - ETA: 20s - loss: 4.8035 - acc: 0.02 - ETA: 22s - loss: 4.7987 - acc: 0.02 - ETA: 24s - loss: 4.8010 - acc: 0.02 - ETA: 29s - loss: 4.7960 - acc: 0.02 - ETA: 30s - loss: 4.7985 - acc: 0.02 - ETA: 31s - loss: 4.8071 - acc: 0.02 - ETA: 34s - loss: 4.8082 - acc: 0.02 - ETA: 34s - loss: 4.8115 - acc: 0.03 - ETA: 36s - loss: 4.8052 - acc: 0.03 - ETA: 37s - loss: 4.8022 - acc: 0.03 - ETA: 38s - loss: 4.8034 - acc: 0.03 - ETA: 39s - loss: 4.8034 - acc: 0.02 - ETA: 39s - loss: 4.8024 - acc: 0.03 - ETA: 39s - loss: 4.8041 - acc: 0.02 - ETA: 39s - loss: 4.8027 - acc: 0.03 - ETA: 41s - loss: 4.8069 - acc: 0.03 - ETA: 41s - loss: 4.8117 - acc: 0.03 - ETA: 41s - loss: 4.8150 - acc: 0.03 - ETA: 41s - loss: 4.8146 - acc: 0.03 - ETA: 42s - loss: 4.8150 - acc: 0.02 - ETA: 42s - loss: 4.8205 - acc: 0.03 - ETA: 42s - loss: 4.8209 - acc: 0.02 - ETA: 43s - loss: 4.8216 - acc: 0.03 - ETA: 43s - loss: 4.8244 - acc: 0.03 - ETA: 43s - loss: 4.8260 - acc: 0.03 - ETA: 44s - loss: 4.8221 - acc: 0.03 - ETA: 44s - loss: 4.8198 - acc: 0.03 - ETA: 45s - loss: 4.8196 - acc: 0.03 - ETA: 45s - loss: 4.8198 - acc: 0.03 - ETA: 45s - loss: 4.8182 - acc: 0.03 - ETA: 45s - loss: 4.8184 - acc: 0.03 - ETA: 45s - loss: 4.8177 - acc: 0.03 - ETA: 45s - loss: 4.8182 - acc: 0.03 - ETA: 45s - loss: 4.8186 - acc: 0.03 - ETA: 44s - loss: 4.8186 - acc: 0.02 - ETA: 44s - loss: 4.8201 - acc: 0.02 - ETA: 44s - loss: 4.8197 - acc: 0.02 - ETA: 44s - loss: 4.8186 - acc: 0.02 - ETA: 45s - loss: 4.8181 - acc: 0.02 - ETA: 45s - loss: 4.8180 - acc: 0.02 - ETA: 45s - loss: 4.8189 - acc: 0.02 - ETA: 45s - loss: 4.8186 - acc: 0.02 - ETA: 44s - loss: 4.8185 - acc: 0.02 - ETA: 45s - loss: 4.8171 - acc: 0.02 - ETA: 44s - loss: 4.8181 - acc: 0.02 - ETA: 44s - loss: 4.8157 - acc: 0.02 - ETA: 44s - loss: 4.8156 - acc: 0.02 - ETA: 44s - loss: 4.8155 - acc: 0.02 - ETA: 45s - loss: 4.8153 - acc: 0.02 - ETA: 45s - loss: 4.8181 - acc: 0.02 - ETA: 45s - loss: 4.8175 - acc: 0.02 - ETA: 45s - loss: 4.8180 - acc: 0.02 - ETA: 45s - loss: 4.8173 - acc: 0.02 - ETA: 45s - loss: 4.8169 - acc: 0.02 - ETA: 45s - loss: 4.8164 - acc: 0.02 - ETA: 45s - loss: 4.8160 - acc: 0.02 - ETA: 44s - loss: 4.8140 - acc: 0.02 - ETA: 44s - loss: 4.8142 - acc: 0.02 - ETA: 44s - loss: 4.8128 - acc: 0.02 - ETA: 44s - loss: 4.8121 - acc: 0.02 - ETA: 44s - loss: 4.8117 - acc: 0.02 - ETA: 44s - loss: 4.8122 - acc: 0.02 - ETA: 44s - loss: 4.8125 - acc: 0.02 - ETA: 44s - loss: 4.8137 - acc: 0.02 - ETA: 44s - loss: 4.8122 - acc: 0.02 - ETA: 44s - loss: 4.8118 - acc: 0.02 - ETA: 44s - loss: 4.8112 - acc: 0.02 - ETA: 44s - loss: 4.8095 - acc: 0.02 - ETA: 44s - loss: 4.8113 - acc: 0.02 - ETA: 43s - loss: 4.8118 - acc: 0.02 - ETA: 44s - loss: 4.8095 - acc: 0.02 - ETA: 44s - loss: 4.8104 - acc: 0.02 - ETA: 44s - loss: 4.8091 - acc: 0.02 - ETA: 44s - loss: 4.8094 - acc: 0.02 - ETA: 43s - loss: 4.8091 - acc: 0.02 - ETA: 44s - loss: 4.8082 - acc: 0.02 - ETA: 43s - loss: 4.8092 - acc: 0.02 - ETA: 44s - loss: 4.8098 - acc: 0.02 - ETA: 43s - loss: 4.8090 - acc: 0.02 - ETA: 43s - loss: 4.8066 - acc: 0.02 - ETA: 43s - loss: 4.8048 - acc: 0.02 - ETA: 43s - loss: 4.8026 - acc: 0.02 - ETA: 43s - loss: 4.8025 - acc: 0.02 - ETA: 43s - loss: 4.8033 - acc: 0.02 - ETA: 43s - loss: 4.8028 - acc: 0.02 - ETA: 43s - loss: 4.8027 - acc: 0.02 - ETA: 43s - loss: 4.8048 - acc: 0.02 - ETA: 43s - loss: 4.8024 - acc: 0.02 - ETA: 43s - loss: 4.8020 - acc: 0.02 - ETA: 43s - loss: 4.8018 - acc: 0.02 - ETA: 43s - loss: 4.8003 - acc: 0.02 - ETA: 43s - loss: 4.8023 - acc: 0.02 - ETA: 43s - loss: 4.8018 - acc: 0.02 - ETA: 43s - loss: 4.8029 - acc: 0.02 - ETA: 43s - loss: 4.8029 - acc: 0.02 - ETA: 42s - loss: 4.8014 - acc: 0.02 - ETA: 42s - loss: 4.8017 - acc: 0.02 - ETA: 42s - loss: 4.8033 - acc: 0.02 - ETA: 42s - loss: 4.8029 - acc: 0.02 - ETA: 42s - loss: 4.8036 - acc: 0.02 - ETA: 42s - loss: 4.8033 - acc: 0.02 - ETA: 42s - loss: 4.8021 - acc: 0.02 - ETA: 42s - loss: 4.8029 - acc: 0.02 - ETA: 42s - loss: 4.8017 - acc: 0.02 - ETA: 41s - loss: 4.8032 - acc: 0.02 - ETA: 41s - loss: 4.8038 - acc: 0.02 - ETA: 41s - loss: 4.8023 - acc: 0.02 - ETA: 41s - loss: 4.8029 - acc: 0.02 - ETA: 41s - loss: 4.8022 - acc: 0.02 - ETA: 41s - loss: 4.8017 - acc: 0.02 - ETA: 41s - loss: 4.8024 - acc: 0.02 - ETA: 40s - loss: 4.8021 - acc: 0.02 - ETA: 40s - loss: 4.8031 - acc: 0.02 - ETA: 40s - loss: 4.8025 - acc: 0.02 - ETA: 40s - loss: 4.8029 - acc: 0.02 - ETA: 40s - loss: 4.8035 - acc: 0.02 - ETA: 40s - loss: 4.8040 - acc: 0.02 - ETA: 40s - loss: 4.8034 - acc: 0.02 - ETA: 39s - loss: 4.8023 - acc: 0.02 - ETA: 39s - loss: 4.8016 - acc: 0.02 - ETA: 39s - loss: 4.8014 - acc: 0.02 - ETA: 39s - loss: 4.8021 - acc: 0.02 - ETA: 39s - loss: 4.8027 - acc: 0.02 - ETA: 39s - loss: 4.8024 - acc: 0.02 - ETA: 39s - loss: 4.8039 - acc: 0.02 - ETA: 39s - loss: 4.8052 - acc: 0.02 - ETA: 38s - loss: 4.8048 - acc: 0.02 - ETA: 39s - loss: 4.8054 - acc: 0.02 - ETA: 38s - loss: 4.8052 - acc: 0.02 - ETA: 38s - loss: 4.8044 - acc: 0.02 - ETA: 38s - loss: 4.8058 - acc: 0.02 - ETA: 38s - loss: 4.8061 - acc: 0.02 - ETA: 38s - loss: 4.8055 - acc: 0.02 - ETA: 38s - loss: 4.8062 - acc: 0.02 - ETA: 38s - loss: 4.8063 - acc: 0.02 - ETA: 37s - loss: 4.8068 - acc: 0.02 - ETA: 37s - loss: 4.8065 - acc: 0.02 - ETA: 37s - loss: 4.8068 - acc: 0.02 - ETA: 37s - loss: 4.8070 - acc: 0.02 - ETA: 37s - loss: 4.8084 - acc: 0.02 - ETA: 37s - loss: 4.8083 - acc: 0.02 - ETA: 37s - loss: 4.8075 - acc: 0.02 - ETA: 36s - loss: 4.8071 - acc: 0.02 - ETA: 37s - loss: 4.8075 - acc: 0.02 - ETA: 36s - loss: 4.8074 - acc: 0.02 - ETA: 36s - loss: 4.8073 - acc: 0.02 - ETA: 36s - loss: 4.8076 - acc: 0.02 - ETA: 36s - loss: 4.8080 - acc: 0.02 - ETA: 36s - loss: 4.8082 - acc: 0.02 - ETA: 36s - loss: 4.8078 - acc: 0.02 - ETA: 36s - loss: 4.8073 - acc: 0.02 - ETA: 35s - loss: 4.8076 - acc: 0.02 - ETA: 35s - loss: 4.8079 - acc: 0.02 - ETA: 35s - loss: 4.8073 - acc: 0.02 - ETA: 35s - loss: 4.8074 - acc: 0.02 - ETA: 35s - loss: 4.8080 - acc: 0.02 - ETA: 35s - loss: 4.8073 - acc: 0.02 - ETA: 35s - loss: 4.8072 - acc: 0.02 - ETA: 35s - loss: 4.8074 - acc: 0.02 - ETA: 35s - loss: 4.8069 - acc: 0.02 - ETA: 34s - loss: 4.8068 - acc: 0.02 - ETA: 34s - loss: 4.8072 - acc: 0.02 - ETA: 34s - loss: 4.8071 - acc: 0.02 - ETA: 34s - loss: 4.8065 - acc: 0.02 - ETA: 34s - loss: 4.8060 - acc: 0.02 - ETA: 34s - loss: 4.8060 - acc: 0.02 - ETA: 33s - loss: 4.8061 - acc: 0.02 - ETA: 33s - loss: 4.8061 - acc: 0.02 - ETA: 33s - loss: 4.8059 - acc: 0.02 - ETA: 33s - loss: 4.8047 - acc: 0.02 - ETA: 33s - loss: 4.8056 - acc: 0.02 - ETA: 33s - loss: 4.8061 - acc: 0.02 - ETA: 33s - loss: 4.8060 - acc: 0.02 - ETA: 32s - loss: 4.8058 - acc: 0.02 - ETA: 32s - loss: 4.8057 - acc: 0.02 - ETA: 32s - loss: 4.8048 - acc: 0.02 - ETA: 32s - loss: 4.8061 - acc: 0.02 - ETA: 32s - loss: 4.8063 - acc: 0.02 - ETA: 32s - loss: 4.8064 - acc: 0.02 - ETA: 31s - loss: 4.8065 - acc: 0.02 - ETA: 31s - loss: 4.8070 - acc: 0.02 - ETA: 31s - loss: 4.8075 - acc: 0.02 - ETA: 31s - loss: 4.8071 - acc: 0.02 - ETA: 31s - loss: 4.8072 - acc: 0.02 - ETA: 31s - loss: 4.8068 - acc: 0.02 - ETA: 31s - loss: 4.8073 - acc: 0.02 - ETA: 30s - loss: 4.8073 - acc: 0.02 - ETA: 30s - loss: 4.8081 - acc: 0.02 - ETA: 30s - loss: 4.8073 - acc: 0.02 - ETA: 30s - loss: 4.8077 - acc: 0.02 - ETA: 30s - loss: 4.8075 - acc: 0.02 - ETA: 30s - loss: 4.8070 - acc: 0.02 - ETA: 30s - loss: 4.8078 - acc: 0.02 - ETA: 30s - loss: 4.8077 - acc: 0.02 - ETA: 29s - loss: 4.8075 - acc: 0.02 - ETA: 29s - loss: 4.8078 - acc: 0.02 - ETA: 29s - loss: 4.8085 - acc: 0.02 - ETA: 29s - loss: 4.8084 - acc: 0.02 - ETA: 29s - loss: 4.8080 - acc: 0.02 - ETA: 29s - loss: 4.8081 - acc: 0.02 - ETA: 29s - loss: 4.8079 - acc: 0.02 - ETA: 28s - loss: 4.8075 - acc: 0.02 - ETA: 28s - loss: 4.8073 - acc: 0.02 - ETA: 28s - loss: 4.8068 - acc: 0.02 - ETA: 28s - loss: 4.8061 - acc: 0.02 - ETA: 28s - loss: 4.8065 - acc: 0.02 - ETA: 28s - loss: 4.8065 - acc: 0.02 - ETA: 28s - loss: 4.8068 - acc: 0.0243"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 27s - loss: 4.8065 - acc: 0.02 - ETA: 27s - loss: 4.8066 - acc: 0.02 - ETA: 27s - loss: 4.8068 - acc: 0.02 - ETA: 27s - loss: 4.8072 - acc: 0.02 - ETA: 27s - loss: 4.8068 - acc: 0.02 - ETA: 27s - loss: 4.8066 - acc: 0.02 - ETA: 27s - loss: 4.8067 - acc: 0.02 - ETA: 27s - loss: 4.8067 - acc: 0.02 - ETA: 26s - loss: 4.8068 - acc: 0.02 - ETA: 26s - loss: 4.8070 - acc: 0.02 - ETA: 26s - loss: 4.8073 - acc: 0.02 - ETA: 26s - loss: 4.8063 - acc: 0.02 - ETA: 26s - loss: 4.8065 - acc: 0.02 - ETA: 26s - loss: 4.8067 - acc: 0.02 - ETA: 26s - loss: 4.8069 - acc: 0.02 - ETA: 26s - loss: 4.8076 - acc: 0.02 - ETA: 25s - loss: 4.8079 - acc: 0.02 - ETA: 25s - loss: 4.8076 - acc: 0.02 - ETA: 25s - loss: 4.8072 - acc: 0.02 - ETA: 25s - loss: 4.8077 - acc: 0.02 - ETA: 25s - loss: 4.8075 - acc: 0.02 - ETA: 25s - loss: 4.8078 - acc: 0.02 - ETA: 25s - loss: 4.8082 - acc: 0.02 - ETA: 24s - loss: 4.8081 - acc: 0.02 - ETA: 24s - loss: 4.8087 - acc: 0.02 - ETA: 24s - loss: 4.8090 - acc: 0.02 - ETA: 24s - loss: 4.8087 - acc: 0.02 - ETA: 24s - loss: 4.8086 - acc: 0.02 - ETA: 24s - loss: 4.8089 - acc: 0.02 - ETA: 23s - loss: 4.8090 - acc: 0.02 - ETA: 23s - loss: 4.8094 - acc: 0.02 - ETA: 23s - loss: 4.8096 - acc: 0.02 - ETA: 23s - loss: 4.8095 - acc: 0.02 - ETA: 23s - loss: 4.8090 - acc: 0.02 - ETA: 23s - loss: 4.8090 - acc: 0.02 - ETA: 23s - loss: 4.8085 - acc: 0.02 - ETA: 23s - loss: 4.8092 - acc: 0.02 - ETA: 22s - loss: 4.8091 - acc: 0.02 - ETA: 22s - loss: 4.8090 - acc: 0.02 - ETA: 22s - loss: 4.8091 - acc: 0.02 - ETA: 22s - loss: 4.8093 - acc: 0.02 - ETA: 22s - loss: 4.8093 - acc: 0.02 - ETA: 22s - loss: 4.8095 - acc: 0.02 - ETA: 22s - loss: 4.8093 - acc: 0.02 - ETA: 21s - loss: 4.8095 - acc: 0.02 - ETA: 21s - loss: 4.8088 - acc: 0.02 - ETA: 21s - loss: 4.8085 - acc: 0.02 - ETA: 21s - loss: 4.8088 - acc: 0.02 - ETA: 21s - loss: 4.8089 - acc: 0.02 - ETA: 21s - loss: 4.8089 - acc: 0.02 - ETA: 21s - loss: 4.8088 - acc: 0.02 - ETA: 20s - loss: 4.8094 - acc: 0.02 - ETA: 20s - loss: 4.8089 - acc: 0.02 - ETA: 20s - loss: 4.8085 - acc: 0.02 - ETA: 20s - loss: 4.8083 - acc: 0.02 - ETA: 20s - loss: 4.8083 - acc: 0.02 - ETA: 20s - loss: 4.8083 - acc: 0.02 - ETA: 20s - loss: 4.8087 - acc: 0.02 - ETA: 19s - loss: 4.8084 - acc: 0.02 - ETA: 19s - loss: 4.8084 - acc: 0.02 - ETA: 19s - loss: 4.8083 - acc: 0.02 - ETA: 19s - loss: 4.8089 - acc: 0.02 - ETA: 19s - loss: 4.8088 - acc: 0.02 - ETA: 19s - loss: 4.8086 - acc: 0.02 - ETA: 19s - loss: 4.8086 - acc: 0.02 - ETA: 18s - loss: 4.8084 - acc: 0.02 - ETA: 18s - loss: 4.8088 - acc: 0.02 - ETA: 18s - loss: 4.8082 - acc: 0.02 - ETA: 18s - loss: 4.8082 - acc: 0.02 - ETA: 18s - loss: 4.8084 - acc: 0.02 - ETA: 18s - loss: 4.8083 - acc: 0.02 - ETA: 17s - loss: 4.8079 - acc: 0.02 - ETA: 17s - loss: 4.8075 - acc: 0.02 - ETA: 17s - loss: 4.8072 - acc: 0.02 - ETA: 17s - loss: 4.8070 - acc: 0.02 - ETA: 17s - loss: 4.8069 - acc: 0.02 - ETA: 17s - loss: 4.8070 - acc: 0.02 - ETA: 17s - loss: 4.8075 - acc: 0.02 - ETA: 16s - loss: 4.8072 - acc: 0.02 - ETA: 16s - loss: 4.8071 - acc: 0.02 - ETA: 16s - loss: 4.8070 - acc: 0.02 - ETA: 16s - loss: 4.8066 - acc: 0.02 - ETA: 16s - loss: 4.8069 - acc: 0.02 - ETA: 16s - loss: 4.8073 - acc: 0.02 - ETA: 16s - loss: 4.8075 - acc: 0.02 - ETA: 15s - loss: 4.8076 - acc: 0.02 - ETA: 15s - loss: 4.8070 - acc: 0.02 - ETA: 15s - loss: 4.8073 - acc: 0.02 - ETA: 15s - loss: 4.8065 - acc: 0.02 - ETA: 15s - loss: 4.8066 - acc: 0.02 - ETA: 15s - loss: 4.8062 - acc: 0.02 - ETA: 14s - loss: 4.8062 - acc: 0.02 - ETA: 14s - loss: 4.8064 - acc: 0.02 - ETA: 14s - loss: 4.8063 - acc: 0.02 - ETA: 14s - loss: 4.8061 - acc: 0.02 - ETA: 14s - loss: 4.8060 - acc: 0.02 - ETA: 14s - loss: 4.8061 - acc: 0.02 - ETA: 14s - loss: 4.8062 - acc: 0.02 - ETA: 13s - loss: 4.8062 - acc: 0.02 - ETA: 13s - loss: 4.8059 - acc: 0.02 - ETA: 13s - loss: 4.8056 - acc: 0.02 - ETA: 13s - loss: 4.8064 - acc: 0.02 - ETA: 13s - loss: 4.8063 - acc: 0.02 - ETA: 13s - loss: 4.8063 - acc: 0.02 - ETA: 13s - loss: 4.8065 - acc: 0.02 - ETA: 12s - loss: 4.8065 - acc: 0.02 - ETA: 12s - loss: 4.8062 - acc: 0.02 - ETA: 12s - loss: 4.8062 - acc: 0.02 - ETA: 12s - loss: 4.8062 - acc: 0.02 - ETA: 12s - loss: 4.8062 - acc: 0.02 - ETA: 12s - loss: 4.8056 - acc: 0.02 - ETA: 12s - loss: 4.8058 - acc: 0.02 - ETA: 11s - loss: 4.8059 - acc: 0.02 - ETA: 11s - loss: 4.8064 - acc: 0.02 - ETA: 11s - loss: 4.8066 - acc: 0.02 - ETA: 11s - loss: 4.8066 - acc: 0.02 - ETA: 11s - loss: 4.8063 - acc: 0.02 - ETA: 11s - loss: 4.8066 - acc: 0.02 - ETA: 10s - loss: 4.8067 - acc: 0.02 - ETA: 10s - loss: 4.8067 - acc: 0.02 - ETA: 10s - loss: 4.8069 - acc: 0.02 - ETA: 10s - loss: 4.8067 - acc: 0.02 - ETA: 10s - loss: 4.8065 - acc: 0.02 - ETA: 10s - loss: 4.8062 - acc: 0.02 - ETA: 10s - loss: 4.8060 - acc: 0.02 - ETA: 9s - loss: 4.8060 - acc: 0.0224 - ETA: 9s - loss: 4.8060 - acc: 0.022 - ETA: 9s - loss: 4.8060 - acc: 0.022 - ETA: 9s - loss: 4.8059 - acc: 0.022 - ETA: 9s - loss: 4.8060 - acc: 0.022 - ETA: 9s - loss: 4.8064 - acc: 0.022 - ETA: 8s - loss: 4.8066 - acc: 0.022 - ETA: 8s - loss: 4.8064 - acc: 0.022 - ETA: 8s - loss: 4.8065 - acc: 0.022 - ETA: 8s - loss: 4.8070 - acc: 0.022 - ETA: 8s - loss: 4.8071 - acc: 0.021 - ETA: 8s - loss: 4.8069 - acc: 0.021 - ETA: 8s - loss: 4.8067 - acc: 0.021 - ETA: 7s - loss: 4.8070 - acc: 0.021 - ETA: 7s - loss: 4.8073 - acc: 0.021 - ETA: 7s - loss: 4.8071 - acc: 0.021 - ETA: 7s - loss: 4.8065 - acc: 0.021 - ETA: 7s - loss: 4.8068 - acc: 0.021 - ETA: 7s - loss: 4.8070 - acc: 0.021 - ETA: 7s - loss: 4.8067 - acc: 0.021 - ETA: 6s - loss: 4.8067 - acc: 0.021 - ETA: 6s - loss: 4.8065 - acc: 0.021 - ETA: 6s - loss: 4.8063 - acc: 0.021 - ETA: 6s - loss: 4.8065 - acc: 0.021 - ETA: 6s - loss: 4.8065 - acc: 0.021 - ETA: 6s - loss: 4.8066 - acc: 0.021 - ETA: 5s - loss: 4.8066 - acc: 0.021 - ETA: 5s - loss: 4.8069 - acc: 0.021 - ETA: 5s - loss: 4.8068 - acc: 0.021 - ETA: 5s - loss: 4.8070 - acc: 0.021 - ETA: 5s - loss: 4.8068 - acc: 0.021 - ETA: 5s - loss: 4.8067 - acc: 0.021 - ETA: 5s - loss: 4.8066 - acc: 0.021 - ETA: 4s - loss: 4.8063 - acc: 0.021 - ETA: 4s - loss: 4.8063 - acc: 0.021 - ETA: 4s - loss: 4.8062 - acc: 0.022 - ETA: 4s - loss: 4.8061 - acc: 0.021 - ETA: 4s - loss: 4.8057 - acc: 0.022 - ETA: 4s - loss: 4.8057 - acc: 0.022 - ETA: 3s - loss: 4.8055 - acc: 0.022 - ETA: 3s - loss: 4.8056 - acc: 0.022 - ETA: 3s - loss: 4.8058 - acc: 0.022 - ETA: 3s - loss: 4.8054 - acc: 0.022 - ETA: 3s - loss: 4.8054 - acc: 0.022 - ETA: 3s - loss: 4.8051 - acc: 0.022 - ETA: 3s - loss: 4.8051 - acc: 0.022 - ETA: 2s - loss: 4.8053 - acc: 0.022 - ETA: 2s - loss: 4.8053 - acc: 0.022 - ETA: 2s - loss: 4.8052 - acc: 0.022 - ETA: 2s - loss: 4.8053 - acc: 0.022 - ETA: 2s - loss: 4.8052 - acc: 0.022 - ETA: 2s - loss: 4.8053 - acc: 0.022 - ETA: 1s - loss: 4.8054 - acc: 0.022 - ETA: 1s - loss: 4.8057 - acc: 0.021 - ETA: 1s - loss: 4.8050 - acc: 0.021 - ETA: 1s - loss: 4.8051 - acc: 0.021 - ETA: 1s - loss: 4.8048 - acc: 0.021 - ETA: 1s - loss: 4.8047 - acc: 0.021 - ETA: 1s - loss: 4.8051 - acc: 0.021 - ETA: 0s - loss: 4.8048 - acc: 0.021 - ETA: 0s - loss: 4.8050 - acc: 0.021 - ETA: 0s - loss: 4.8051 - acc: 0.021 - ETA: 0s - loss: 4.8051 - acc: 0.021 - ETA: 0s - loss: 4.8047 - acc: 0.021 - ETA: 0s - loss: 4.8050 - acc: 0.021 - 68s 163ms/step - loss: 4.8049 - acc: 0.0216 - val_loss: 4.7717 - val_acc: 0.0391\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 4.75676\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/417 [===============>..............] - ETA: 5s - loss: 4.8365 - acc: 0.0000e+0 - ETA: 6s - loss: 4.7971 - acc: 0.0125    - ETA: 6s - loss: 4.7846 - acc: 0.006 - ETA: 6s - loss: 4.7995 - acc: 0.005 - ETA: 12s - loss: 4.8046 - acc: 0.00 - ETA: 15s - loss: 4.7924 - acc: 0.00 - ETA: 20s - loss: 4.7969 - acc: 0.00 - ETA: 23s - loss: 4.7934 - acc: 0.00 - ETA: 26s - loss: 4.7885 - acc: 0.00 - ETA: 27s - loss: 4.7957 - acc: 0.00 - ETA: 29s - loss: 4.7961 - acc: 0.00 - ETA: 30s - loss: 4.7984 - acc: 0.00 - ETA: 33s - loss: 4.7897 - acc: 0.00 - ETA: 34s - loss: 4.7880 - acc: 0.01 - ETA: 35s - loss: 4.7874 - acc: 0.01 - ETA: 36s - loss: 4.7809 - acc: 0.01 - ETA: 38s - loss: 4.7799 - acc: 0.01 - ETA: 40s - loss: 4.7806 - acc: 0.01 - ETA: 40s - loss: 4.7819 - acc: 0.01 - ETA: 42s - loss: 4.7841 - acc: 0.01 - ETA: 42s - loss: 4.7842 - acc: 0.01 - ETA: 45s - loss: 4.7779 - acc: 0.01 - ETA: 46s - loss: 4.7789 - acc: 0.02 - ETA: 46s - loss: 4.7760 - acc: 0.01 - ETA: 47s - loss: 4.7754 - acc: 0.01 - ETA: 47s - loss: 4.7727 - acc: 0.02 - ETA: 47s - loss: 4.7753 - acc: 0.01 - ETA: 47s - loss: 4.7788 - acc: 0.01 - ETA: 47s - loss: 4.7772 - acc: 0.01 - ETA: 48s - loss: 4.7796 - acc: 0.01 - ETA: 49s - loss: 4.7833 - acc: 0.01 - ETA: 48s - loss: 4.7825 - acc: 0.01 - ETA: 49s - loss: 4.7774 - acc: 0.01 - ETA: 49s - loss: 4.7799 - acc: 0.01 - ETA: 49s - loss: 4.7787 - acc: 0.01 - ETA: 49s - loss: 4.7775 - acc: 0.01 - ETA: 49s - loss: 4.7800 - acc: 0.01 - ETA: 50s - loss: 4.7804 - acc: 0.02 - ETA: 51s - loss: 4.7832 - acc: 0.01 - ETA: 51s - loss: 4.7787 - acc: 0.01 - ETA: 51s - loss: 4.7805 - acc: 0.02 - ETA: 50s - loss: 4.7831 - acc: 0.02 - ETA: 50s - loss: 4.7864 - acc: 0.01 - ETA: 50s - loss: 4.7916 - acc: 0.01 - ETA: 50s - loss: 4.7902 - acc: 0.02 - ETA: 50s - loss: 4.7958 - acc: 0.01 - ETA: 50s - loss: 4.7946 - acc: 0.01 - ETA: 51s - loss: 4.7922 - acc: 0.01 - ETA: 50s - loss: 4.7943 - acc: 0.01 - ETA: 50s - loss: 4.7945 - acc: 0.01 - ETA: 50s - loss: 4.7919 - acc: 0.02 - ETA: 50s - loss: 4.7935 - acc: 0.02 - ETA: 50s - loss: 4.7922 - acc: 0.02 - ETA: 50s - loss: 4.7905 - acc: 0.02 - ETA: 50s - loss: 4.7922 - acc: 0.02 - ETA: 50s - loss: 4.7921 - acc: 0.02 - ETA: 50s - loss: 4.7936 - acc: 0.02 - ETA: 50s - loss: 4.7949 - acc: 0.01 - ETA: 49s - loss: 4.7983 - acc: 0.01 - ETA: 49s - loss: 4.7982 - acc: 0.02 - ETA: 49s - loss: 4.7979 - acc: 0.01 - ETA: 49s - loss: 4.7999 - acc: 0.01 - ETA: 49s - loss: 4.8013 - acc: 0.01 - ETA: 49s - loss: 4.7999 - acc: 0.01 - ETA: 49s - loss: 4.7999 - acc: 0.01 - ETA: 49s - loss: 4.7983 - acc: 0.01 - ETA: 49s - loss: 4.7989 - acc: 0.01 - ETA: 48s - loss: 4.7981 - acc: 0.01 - ETA: 49s - loss: 4.7958 - acc: 0.01 - ETA: 49s - loss: 4.7929 - acc: 0.01 - ETA: 49s - loss: 4.7923 - acc: 0.01 - ETA: 49s - loss: 4.7919 - acc: 0.01 - ETA: 49s - loss: 4.7918 - acc: 0.01 - ETA: 49s - loss: 4.7898 - acc: 0.02 - ETA: 50s - loss: 4.7903 - acc: 0.02 - ETA: 50s - loss: 4.7895 - acc: 0.02 - ETA: 49s - loss: 4.7906 - acc: 0.02 - ETA: 49s - loss: 4.7909 - acc: 0.02 - ETA: 49s - loss: 4.7905 - acc: 0.02 - ETA: 49s - loss: 4.7921 - acc: 0.02 - ETA: 48s - loss: 4.7923 - acc: 0.02 - ETA: 48s - loss: 4.7910 - acc: 0.02 - ETA: 48s - loss: 4.7911 - acc: 0.02 - ETA: 48s - loss: 4.7904 - acc: 0.02 - ETA: 47s - loss: 4.7924 - acc: 0.02 - ETA: 48s - loss: 4.7931 - acc: 0.02 - ETA: 48s - loss: 4.7934 - acc: 0.02 - ETA: 47s - loss: 4.7919 - acc: 0.02 - ETA: 47s - loss: 4.7917 - acc: 0.02 - ETA: 47s - loss: 4.7919 - acc: 0.02 - ETA: 47s - loss: 4.7916 - acc: 0.02 - ETA: 47s - loss: 4.7923 - acc: 0.02 - ETA: 47s - loss: 4.7932 - acc: 0.02 - ETA: 46s - loss: 4.7917 - acc: 0.02 - ETA: 46s - loss: 4.7934 - acc: 0.02 - ETA: 46s - loss: 4.7919 - acc: 0.02 - ETA: 46s - loss: 4.7926 - acc: 0.02 - ETA: 46s - loss: 4.7930 - acc: 0.02 - ETA: 46s - loss: 4.7935 - acc: 0.02 - ETA: 45s - loss: 4.7928 - acc: 0.02 - ETA: 45s - loss: 4.7924 - acc: 0.02 - ETA: 45s - loss: 4.7916 - acc: 0.02 - ETA: 45s - loss: 4.7915 - acc: 0.02 - ETA: 45s - loss: 4.7909 - acc: 0.02 - ETA: 45s - loss: 4.7926 - acc: 0.02 - ETA: 44s - loss: 4.7948 - acc: 0.02 - ETA: 44s - loss: 4.7954 - acc: 0.02 - ETA: 44s - loss: 4.7955 - acc: 0.02 - ETA: 44s - loss: 4.7954 - acc: 0.02 - ETA: 44s - loss: 4.7966 - acc: 0.02 - ETA: 43s - loss: 4.7972 - acc: 0.02 - ETA: 43s - loss: 4.7965 - acc: 0.02 - ETA: 43s - loss: 4.7980 - acc: 0.02 - ETA: 43s - loss: 4.7986 - acc: 0.02 - ETA: 43s - loss: 4.7986 - acc: 0.02 - ETA: 43s - loss: 4.7988 - acc: 0.02 - ETA: 43s - loss: 4.7995 - acc: 0.02 - ETA: 43s - loss: 4.7981 - acc: 0.02 - ETA: 43s - loss: 4.7978 - acc: 0.02 - ETA: 42s - loss: 4.7968 - acc: 0.02 - ETA: 42s - loss: 4.7964 - acc: 0.02 - ETA: 42s - loss: 4.7973 - acc: 0.02 - ETA: 42s - loss: 4.7971 - acc: 0.02 - ETA: 42s - loss: 4.7973 - acc: 0.02 - ETA: 42s - loss: 4.7967 - acc: 0.02 - ETA: 42s - loss: 4.7961 - acc: 0.02 - ETA: 42s - loss: 4.7963 - acc: 0.02 - ETA: 41s - loss: 4.7966 - acc: 0.02 - ETA: 41s - loss: 4.7966 - acc: 0.02 - ETA: 41s - loss: 4.7972 - acc: 0.02 - ETA: 41s - loss: 4.7964 - acc: 0.02 - ETA: 41s - loss: 4.7962 - acc: 0.02 - ETA: 41s - loss: 4.7966 - acc: 0.02 - ETA: 40s - loss: 4.7967 - acc: 0.02 - ETA: 40s - loss: 4.7961 - acc: 0.02 - ETA: 40s - loss: 4.7965 - acc: 0.02 - ETA: 40s - loss: 4.7975 - acc: 0.02 - ETA: 40s - loss: 4.7980 - acc: 0.02 - ETA: 40s - loss: 4.7973 - acc: 0.02 - ETA: 39s - loss: 4.7982 - acc: 0.02 - ETA: 39s - loss: 4.7960 - acc: 0.02 - ETA: 39s - loss: 4.7956 - acc: 0.02 - ETA: 39s - loss: 4.7968 - acc: 0.02 - ETA: 39s - loss: 4.7963 - acc: 0.02 - ETA: 39s - loss: 4.7971 - acc: 0.02 - ETA: 39s - loss: 4.7966 - acc: 0.02 - ETA: 38s - loss: 4.7965 - acc: 0.02 - ETA: 38s - loss: 4.7968 - acc: 0.02 - ETA: 38s - loss: 4.7969 - acc: 0.02 - ETA: 38s - loss: 4.7972 - acc: 0.02 - ETA: 38s - loss: 4.7971 - acc: 0.02 - ETA: 38s - loss: 4.7966 - acc: 0.02 - ETA: 38s - loss: 4.7968 - acc: 0.02 - ETA: 38s - loss: 4.7961 - acc: 0.02 - ETA: 37s - loss: 4.7958 - acc: 0.02 - ETA: 37s - loss: 4.7949 - acc: 0.02 - ETA: 37s - loss: 4.7949 - acc: 0.02 - ETA: 37s - loss: 4.7954 - acc: 0.02 - ETA: 37s - loss: 4.7954 - acc: 0.02 - ETA: 37s - loss: 4.7951 - acc: 0.02 - ETA: 36s - loss: 4.7957 - acc: 0.02 - ETA: 36s - loss: 4.7960 - acc: 0.02 - ETA: 36s - loss: 4.7960 - acc: 0.02 - ETA: 36s - loss: 4.7959 - acc: 0.02 - ETA: 36s - loss: 4.7953 - acc: 0.02 - ETA: 36s - loss: 4.7951 - acc: 0.02 - ETA: 36s - loss: 4.7944 - acc: 0.02 - ETA: 35s - loss: 4.7944 - acc: 0.02 - ETA: 35s - loss: 4.7945 - acc: 0.02 - ETA: 35s - loss: 4.7940 - acc: 0.02 - ETA: 35s - loss: 4.7935 - acc: 0.02 - ETA: 35s - loss: 4.7940 - acc: 0.02 - ETA: 35s - loss: 4.7943 - acc: 0.02 - ETA: 34s - loss: 4.7949 - acc: 0.02 - ETA: 34s - loss: 4.7952 - acc: 0.02 - ETA: 34s - loss: 4.7961 - acc: 0.02 - ETA: 34s - loss: 4.7960 - acc: 0.02 - ETA: 34s - loss: 4.7962 - acc: 0.02 - ETA: 34s - loss: 4.7976 - acc: 0.02 - ETA: 34s - loss: 4.7978 - acc: 0.02 - ETA: 34s - loss: 4.7971 - acc: 0.02 - ETA: 33s - loss: 4.7968 - acc: 0.02 - ETA: 33s - loss: 4.7965 - acc: 0.02 - ETA: 33s - loss: 4.7968 - acc: 0.02 - ETA: 33s - loss: 4.7959 - acc: 0.02 - ETA: 33s - loss: 4.7959 - acc: 0.02 - ETA: 33s - loss: 4.7954 - acc: 0.02 - ETA: 33s - loss: 4.7955 - acc: 0.02 - ETA: 32s - loss: 4.7956 - acc: 0.02 - ETA: 32s - loss: 4.7953 - acc: 0.02 - ETA: 32s - loss: 4.7953 - acc: 0.02 - ETA: 32s - loss: 4.7957 - acc: 0.02 - ETA: 32s - loss: 4.7958 - acc: 0.02 - ETA: 32s - loss: 4.7967 - acc: 0.02 - ETA: 32s - loss: 4.7966 - acc: 0.02 - ETA: 32s - loss: 4.7973 - acc: 0.02 - ETA: 32s - loss: 4.7977 - acc: 0.02 - ETA: 31s - loss: 4.7982 - acc: 0.02 - ETA: 31s - loss: 4.7979 - acc: 0.02 - ETA: 31s - loss: 4.7981 - acc: 0.02 - ETA: 31s - loss: 4.7980 - acc: 0.02 - ETA: 31s - loss: 4.7986 - acc: 0.02 - ETA: 31s - loss: 4.7983 - acc: 0.02 - ETA: 31s - loss: 4.7985 - acc: 0.02 - ETA: 30s - loss: 4.7992 - acc: 0.02 - ETA: 30s - loss: 4.7994 - acc: 0.02 - ETA: 30s - loss: 4.7993 - acc: 0.02 - ETA: 30s - loss: 4.7992 - acc: 0.02 - ETA: 30s - loss: 4.7994 - acc: 0.02 - ETA: 30s - loss: 4.7996 - acc: 0.02 - ETA: 29s - loss: 4.7995 - acc: 0.02 - ETA: 29s - loss: 4.7997 - acc: 0.02 - ETA: 29s - loss: 4.7992 - acc: 0.02 - ETA: 29s - loss: 4.7986 - acc: 0.02 - ETA: 29s - loss: 4.7985 - acc: 0.0210"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - ETA: 29s - loss: 4.7994 - acc: 0.02 - ETA: 29s - loss: 4.7990 - acc: 0.02 - ETA: 28s - loss: 4.7990 - acc: 0.02 - ETA: 28s - loss: 4.7987 - acc: 0.02 - ETA: 28s - loss: 4.7984 - acc: 0.02 - ETA: 28s - loss: 4.7987 - acc: 0.02 - ETA: 28s - loss: 4.7985 - acc: 0.02 - ETA: 28s - loss: 4.7983 - acc: 0.02 - ETA: 27s - loss: 4.7981 - acc: 0.02 - ETA: 27s - loss: 4.7978 - acc: 0.02 - ETA: 27s - loss: 4.7973 - acc: 0.02 - ETA: 27s - loss: 4.7971 - acc: 0.02 - ETA: 27s - loss: 4.7974 - acc: 0.02 - ETA: 27s - loss: 4.7977 - acc: 0.02 - ETA: 27s - loss: 4.7978 - acc: 0.02 - ETA: 26s - loss: 4.7967 - acc: 0.02 - ETA: 26s - loss: 4.7975 - acc: 0.02 - ETA: 26s - loss: 4.7978 - acc: 0.02 - ETA: 26s - loss: 4.7972 - acc: 0.02 - ETA: 26s - loss: 4.7969 - acc: 0.02 - ETA: 26s - loss: 4.7968 - acc: 0.02 - ETA: 25s - loss: 4.7973 - acc: 0.02 - ETA: 25s - loss: 4.7970 - acc: 0.02 - ETA: 25s - loss: 4.7971 - acc: 0.02 - ETA: 25s - loss: 4.7966 - acc: 0.02 - ETA: 25s - loss: 4.7966 - acc: 0.02 - ETA: 25s - loss: 4.7963 - acc: 0.02 - ETA: 25s - loss: 4.7965 - acc: 0.02 - ETA: 24s - loss: 4.7968 - acc: 0.02 - ETA: 24s - loss: 4.7965 - acc: 0.02 - ETA: 24s - loss: 4.7965 - acc: 0.02 - ETA: 24s - loss: 4.7973 - acc: 0.02 - ETA: 24s - loss: 4.7967 - acc: 0.02 - ETA: 24s - loss: 4.7968 - acc: 0.02 - ETA: 23s - loss: 4.7963 - acc: 0.02 - ETA: 23s - loss: 4.7964 - acc: 0.02 - ETA: 23s - loss: 4.7968 - acc: 0.02 - ETA: 23s - loss: 4.7962 - acc: 0.02 - ETA: 23s - loss: 4.7964 - acc: 0.02 - ETA: 23s - loss: 4.7958 - acc: 0.02 - ETA: 23s - loss: 4.7954 - acc: 0.02 - ETA: 22s - loss: 4.7953 - acc: 0.02 - ETA: 22s - loss: 4.7958 - acc: 0.02 - ETA: 22s - loss: 4.7964 - acc: 0.02 - ETA: 22s - loss: 4.7962 - acc: 0.02 - ETA: 22s - loss: 4.7963 - acc: 0.02 - ETA: 22s - loss: 4.7963 - acc: 0.02 - ETA: 21s - loss: 4.7964 - acc: 0.02 - ETA: 21s - loss: 4.7968 - acc: 0.02 - ETA: 21s - loss: 4.7971 - acc: 0.02 - ETA: 21s - loss: 4.7973 - acc: 0.02 - ETA: 21s - loss: 4.7976 - acc: 0.02 - ETA: 21s - loss: 4.7980 - acc: 0.02 - ETA: 21s - loss: 4.7983 - acc: 0.02 - ETA: 20s - loss: 4.7986 - acc: 0.02 - ETA: 20s - loss: 4.7986 - acc: 0.02 - ETA: 20s - loss: 4.7978 - acc: 0.02 - ETA: 20s - loss: 4.7976 - acc: 0.02 - ETA: 20s - loss: 4.7975 - acc: 0.02 - ETA: 20s - loss: 4.7980 - acc: 0.02 - ETA: 19s - loss: 4.7981 - acc: 0.02 - ETA: 19s - loss: 4.7972 - acc: 0.02 - ETA: 19s - loss: 4.7970 - acc: 0.02 - ETA: 19s - loss: 4.7971 - acc: 0.02 - ETA: 19s - loss: 4.7973 - acc: 0.02 - ETA: 19s - loss: 4.7968 - acc: 0.02 - ETA: 19s - loss: 4.7968 - acc: 0.02 - ETA: 18s - loss: 4.7972 - acc: 0.02 - ETA: 18s - loss: 4.7969 - acc: 0.02 - ETA: 18s - loss: 4.7967 - acc: 0.02 - ETA: 18s - loss: 4.7968 - acc: 0.02 - ETA: 18s - loss: 4.7968 - acc: 0.02 - ETA: 18s - loss: 4.7971 - acc: 0.02 - ETA: 18s - loss: 4.7967 - acc: 0.02 - ETA: 17s - loss: 4.7964 - acc: 0.02 - ETA: 17s - loss: 4.7962 - acc: 0.02 - ETA: 17s - loss: 4.7963 - acc: 0.02 - ETA: 17s - loss: 4.7962 - acc: 0.02 - ETA: 17s - loss: 4.7966 - acc: 0.02 - ETA: 17s - loss: 4.7963 - acc: 0.02 - ETA: 16s - loss: 4.7965 - acc: 0.02 - ETA: 16s - loss: 4.7965 - acc: 0.02 - ETA: 16s - loss: 4.7967 - acc: 0.02 - ETA: 16s - loss: 4.7969 - acc: 0.02 - ETA: 16s - loss: 4.7967 - acc: 0.02 - ETA: 16s - loss: 4.7962 - acc: 0.02 - ETA: 16s - loss: 4.7964 - acc: 0.02 - ETA: 15s - loss: 4.7958 - acc: 0.02 - ETA: 15s - loss: 4.7957 - acc: 0.02 - ETA: 15s - loss: 4.7955 - acc: 0.02 - ETA: 15s - loss: 4.7962 - acc: 0.02 - ETA: 15s - loss: 4.7965 - acc: 0.02 - ETA: 15s - loss: 4.7964 - acc: 0.02 - ETA: 14s - loss: 4.7966 - acc: 0.02 - ETA: 14s - loss: 4.7963 - acc: 0.02 - ETA: 14s - loss: 4.7958 - acc: 0.02 - ETA: 14s - loss: 4.7950 - acc: 0.02 - ETA: 14s - loss: 4.7949 - acc: 0.02 - ETA: 14s - loss: 4.7949 - acc: 0.02 - ETA: 14s - loss: 4.7949 - acc: 0.02 - ETA: 13s - loss: 4.7950 - acc: 0.02 - ETA: 13s - loss: 4.7954 - acc: 0.02 - ETA: 13s - loss: 4.7954 - acc: 0.02 - ETA: 13s - loss: 4.7957 - acc: 0.02 - ETA: 13s - loss: 4.7960 - acc: 0.02 - ETA: 13s - loss: 4.7957 - acc: 0.02 - ETA: 13s - loss: 4.7953 - acc: 0.02 - ETA: 12s - loss: 4.7953 - acc: 0.02 - ETA: 12s - loss: 4.7944 - acc: 0.02 - ETA: 12s - loss: 4.7945 - acc: 0.02 - ETA: 12s - loss: 4.7942 - acc: 0.02 - ETA: 12s - loss: 4.7940 - acc: 0.02 - ETA: 12s - loss: 4.7942 - acc: 0.02 - ETA: 11s - loss: 4.7940 - acc: 0.02 - ETA: 11s - loss: 4.7941 - acc: 0.02 - ETA: 11s - loss: 4.7943 - acc: 0.02 - ETA: 11s - loss: 4.7941 - acc: 0.02 - ETA: 11s - loss: 4.7937 - acc: 0.02 - ETA: 11s - loss: 4.7930 - acc: 0.02 - ETA: 11s - loss: 4.7936 - acc: 0.02 - ETA: 10s - loss: 4.7934 - acc: 0.02 - ETA: 10s - loss: 4.7933 - acc: 0.02 - ETA: 10s - loss: 4.7931 - acc: 0.02 - ETA: 10s - loss: 4.7929 - acc: 0.02 - ETA: 10s - loss: 4.7930 - acc: 0.02 - ETA: 10s - loss: 4.7936 - acc: 0.02 - ETA: 10s - loss: 4.7938 - acc: 0.02 - ETA: 9s - loss: 4.7938 - acc: 0.0239 - ETA: 9s - loss: 4.7943 - acc: 0.023 - ETA: 9s - loss: 4.7949 - acc: 0.023 - ETA: 9s - loss: 4.7951 - acc: 0.023 - ETA: 9s - loss: 4.7950 - acc: 0.023 - ETA: 9s - loss: 4.7947 - acc: 0.023 - ETA: 8s - loss: 4.7945 - acc: 0.023 - ETA: 8s - loss: 4.7942 - acc: 0.023 - ETA: 8s - loss: 4.7939 - acc: 0.023 - ETA: 8s - loss: 4.7939 - acc: 0.023 - ETA: 8s - loss: 4.7941 - acc: 0.023 - ETA: 8s - loss: 4.7941 - acc: 0.023 - ETA: 8s - loss: 4.7942 - acc: 0.023 - ETA: 7s - loss: 4.7942 - acc: 0.023 - ETA: 7s - loss: 4.7940 - acc: 0.023 - ETA: 7s - loss: 4.7938 - acc: 0.023 - ETA: 7s - loss: 4.7936 - acc: 0.023 - ETA: 7s - loss: 4.7937 - acc: 0.023 - ETA: 7s - loss: 4.7938 - acc: 0.023 - ETA: 7s - loss: 4.7940 - acc: 0.023 - ETA: 6s - loss: 4.7938 - acc: 0.023 - ETA: 6s - loss: 4.7937 - acc: 0.023 - ETA: 6s - loss: 4.7940 - acc: 0.023 - ETA: 6s - loss: 4.7936 - acc: 0.023 - ETA: 6s - loss: 4.7937 - acc: 0.023 - ETA: 6s - loss: 4.7938 - acc: 0.023 - ETA: 5s - loss: 4.7939 - acc: 0.023 - ETA: 5s - loss: 4.7939 - acc: 0.023 - ETA: 5s - loss: 4.7942 - acc: 0.023 - ETA: 5s - loss: 4.7942 - acc: 0.023 - ETA: 5s - loss: 4.7938 - acc: 0.023 - ETA: 5s - loss: 4.7940 - acc: 0.022 - ETA: 5s - loss: 4.7942 - acc: 0.023 - ETA: 4s - loss: 4.7947 - acc: 0.023 - ETA: 4s - loss: 4.7944 - acc: 0.023 - ETA: 4s - loss: 4.7952 - acc: 0.023 - ETA: 4s - loss: 4.7952 - acc: 0.022 - ETA: 4s - loss: 4.7954 - acc: 0.023 - ETA: 4s - loss: 4.7956 - acc: 0.023 - ETA: 4s - loss: 4.7954 - acc: 0.022 - ETA: 3s - loss: 4.7955 - acc: 0.022 - ETA: 3s - loss: 4.7957 - acc: 0.022 - ETA: 3s - loss: 4.7956 - acc: 0.022 - ETA: 3s - loss: 4.7956 - acc: 0.023 - ETA: 3s - loss: 4.7956 - acc: 0.022 - ETA: 3s - loss: 4.7956 - acc: 0.022 - ETA: 2s - loss: 4.7961 - acc: 0.022 - ETA: 2s - loss: 4.7962 - acc: 0.022 - ETA: 2s - loss: 4.7963 - acc: 0.022 - ETA: 2s - loss: 4.7963 - acc: 0.022 - ETA: 2s - loss: 4.7962 - acc: 0.022 - ETA: 2s - loss: 4.7954 - acc: 0.023 - ETA: 2s - loss: 4.7954 - acc: 0.023 - ETA: 1s - loss: 4.7952 - acc: 0.023 - ETA: 1s - loss: 4.7953 - acc: 0.023 - ETA: 1s - loss: 4.7953 - acc: 0.022 - ETA: 1s - loss: 4.7954 - acc: 0.022 - ETA: 1s - loss: 4.7956 - acc: 0.022 - ETA: 1s - loss: 4.7953 - acc: 0.022 - ETA: 1s - loss: 4.7954 - acc: 0.022 - ETA: 0s - loss: 4.7952 - acc: 0.022 - ETA: 0s - loss: 4.7953 - acc: 0.022 - ETA: 0s - loss: 4.7953 - acc: 0.022 - ETA: 0s - loss: 4.7953 - acc: 0.022 - ETA: 0s - loss: 4.7953 - acc: 0.022 - ETA: 0s - loss: 4.7953 - acc: 0.022 - 66s 158ms/step - loss: 4.7952 - acc: 0.0225 - val_loss: 4.7593 - val_acc: 0.0330\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 4.75676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e33ac6fc18>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = History()\n",
    "\n",
    "print('training model...')\n",
    "checkpointer = ModelCheckpoint(filepath=f'saved_models/weights.best.groundup_1.hdf5', \n",
    "                           verbose=1, save_best_only=True)\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch = 6680 // batch_size,\n",
    "                    epochs = 50,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = 835 // batch_size,\n",
    "                    callbacks = [checkpointer, history],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model achieved a max validation accuracy of 0.040293040293040296\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "epochs = range(len(history.history['acc']))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2)\n",
    "\n",
    "sns.lineplot(x = epochs, y=history.history['acc'], ax=ax1, label = 'acc')\n",
    "sns.lineplot(x = epochs, y=history.history['val_acc'], ax=ax1, label = 'val_acc')\n",
    "ax1.set_ylim(0, 1.05);\n",
    "ax1.set_title('Rolling accuracy');\n",
    "\n",
    "sns.lineplot(x = epochs, y=history.history['loss'], ax=ax2, label = 'loss')\n",
    "sns.lineplot(x = epochs, y=history.history['val_loss'], ax=ax2, label = 'val_loss')\n",
    "#ax[1].set_ylim(.5, 1.05);\n",
    "ax2.set_title('Rolling loss');\n",
    "\n",
    "fig.suptitle(f'ground-up training metrics', fontsize = 16);\n",
    "max_val_acc = max(history.history['val_acc'])\n",
    "print(f'This model achieved a max validation accuracy of {max_val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# create my own bottleneck features\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "vgg16_model = VGG16(weights='imagenet', include_top=False)\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Load the model weights with the best validation loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Calculate classification accuracy on the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan_hound`, etc) that is predicted by your model.  \n",
    "\n",
    "Similar to the analogous function in Step 5, your function should have three steps:\n",
    "1. Extract the bottleneck features corresponding to the chosen CNN model.\n",
    "2. Supply the bottleneck features as input to the model to return the predicted vector.  Note that the argmax of this prediction vector gives the index of the predicted dog breed.\n",
    "3. Use the `dog_names` array defined in Step 0 of this notebook to return the corresponding breed.\n",
    "\n",
    "The functions to extract the bottleneck features can be found in `extract_bottleneck_features.py`, and they have been imported in an earlier code cell.  To obtain the bottleneck features corresponding to your chosen CNN architecture, you need to use the function\n",
    "\n",
    "    extract_{network}\n",
    "    \n",
    "where `{network}`, in the above filename, should be one of `VGG19`, `Resnet50`, `InceptionV3`, or `Xception`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `dog_detector` functions developed above.  You are __required__ to use your CNN from Step 5 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](images/sample_human_output.png)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step7'></a>\n",
    "## Step 7: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that __you__ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm.\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (testenv)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
